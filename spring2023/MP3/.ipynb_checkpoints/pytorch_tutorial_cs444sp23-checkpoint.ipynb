{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwxBJg3054tF"
   },
   "source": [
    "# PyTorch Tutorial\n",
    "\n",
    "This tutorial is mostly based on:\n",
    "\n",
    "* https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "* https://pytorch.org/tutorials/beginner/pytorch_with_examples.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F4GoE0Hq54tG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ig65bPGsDeqq"
   },
   "source": [
    "## Overview\n",
    "- `torch.Tensor` basic tensor operation\n",
    "- `torch.Tensor.grad` auto-differentiation\n",
    "- `torch.cuda` devices other than CPU\n",
    "- `torch.nn` neural network blocks\n",
    "- `torch.utils.data` dataset and dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5AXjLCz54tJ"
   },
   "source": [
    "## PyTorch Tensors\n",
    "\n",
    "PyTorch tensors are just like NumPy arrays, and they include many of the same operations you are used to from NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KSKVAxA54tJ"
   },
   "source": [
    "Construct a tensor of size $5 \\times 3$ with random values:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2EKqc9Rq54tK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2722, 0.0695, 0.4285],\n",
      "        [0.6026, 0.0267, 0.1009],\n",
      "        [0.3482, 0.6471, 0.7216],\n",
      "        [0.7308, 0.1805, 0.4067],\n",
      "        [0.6929, 0.0327, 0.9049]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZ9KbuE554tM"
   },
   "source": [
    "Construct a matrix filled zeros and of dtype long:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Oa8OceHw54tN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiiA773h54tP"
   },
   "source": [
    "Make a tensor from a list of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "g5fCpQsy54tP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "torch.int64\n",
      "tensor([1., 2., 3.])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x  = torch.tensor([1, 2, 3])\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "\n",
    "x  = torch.tensor([1., 2., 3.])\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNNJG12d54tS"
   },
   "source": [
    "Create a tensor based on another tensor (inherit size and dtype, unless otherwise specified):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95vGdEesf-8I"
   },
   "source": [
    "By default, the returned Tensor of `new_ones` has the same torch.dtype and torch.device as input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "At5-rz6O54tS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[-0.6663,  0.9611,  0.1380],\n",
      "        [-1.3115,  1.3327,  0.2201],\n",
      "        [ 0.5845,  0.8098,  0.6737],\n",
      "        [ 1.5339,  0.7332,  0.3422],\n",
      "        [ 1.3306, -0.9318,  1.4281]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3)  # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)  # override dtype!\n",
    "print(x)                                    # result has the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnbhwMxT54tW"
   },
   "source": [
    "Get the size object of a tensor, an object which supports tuple operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0WN8pUnL54tW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.size())\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Yl7e9aq54tY"
   },
   "source": [
    "Operations on tensors use similar syntax to NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "88YT3jWB54tZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x + y: tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "torch.add(x, y): tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "x: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, 3)\n",
    "y = torch.ones(5, 3)\n",
    "print(\"x + y:\", x + y)\n",
    "print(\"torch.add(x, y):\", torch.add(x, y))\n",
    "print(\"x:\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TA5GHiwL54tb"
   },
   "source": [
    "PyTorch also supports in-place operations (method names end in '_'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KIVoVr4t54tb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pB4lLJtW5FbL"
   },
   "source": [
    "Example of broadcasting:\n",
    "\n",
    "To learn more: \n",
    "- https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
    "- https://pytorch.org/docs/stable/notes/broadcasting.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QJ96VUUj5LGZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x + y: [[2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]]\n",
      "x + y: tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "x + y: tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "x + y: tensor([[[2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.]]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.ones((5,3))\n",
    "y = 1\n",
    "print(\"x + y:\", x + y)\n",
    "\n",
    "x = torch.ones(5, 3)\n",
    "y = 1\n",
    "print(\"x + y:\", x + y)\n",
    "\n",
    "x = torch.ones(5, 3)\n",
    "y = torch.ones(5, 1)\n",
    "print(\"x + y:\", x + y)\n",
    "\n",
    "# failed case of conflicting dimension\n",
    "x = torch.ones(5, 3, 1)\n",
    "y = torch.ones(3, 5)\n",
    "print(\"x + y:\", x + y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxMWCAkB54te"
   },
   "source": [
    "Indexing works as you would expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "m39EwjI354te"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7559,  1.0919, -2.3161],\n",
      "        [ 0.3333,  1.3078, -0.7834],\n",
      "        [-0.6864,  1.2312,  0.8285],\n",
      "        [ 0.3530, -0.8918, -0.3923],\n",
      "        [ 0.1879,  0.7752, -0.4788]])\n",
      "tensor([[ 0.3333,  1.3078, -0.7834],\n",
      "        [-0.6864,  1.2312,  0.8285],\n",
      "        [ 0.3530, -0.8918, -0.3923]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 3)\n",
    "print(x)\n",
    "print(x[1:4, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eV_vZgX30bft"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7559, 1.0919, 0.0000],\n",
      "        [0.3333, 1.3078, 0.0000],\n",
      "        [0.0000, 1.2312, 0.8285],\n",
      "        [0.3530, 0.0000, 0.0000],\n",
      "        [0.1879, 0.7752, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# indexing by operators\n",
    "x[x < 0] = 0\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipHSy8b-gv0e"
   },
   "source": [
    "You can change the order of the dimensions of a tensor with `torch.permute()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RrYUa-7ag1LG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 2])\n",
      "torch.Size([3, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 3, 2)\n",
    "print(x.shape)\n",
    "print(x.permute(1,2,0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBccd2N7Mp4_"
   },
   "source": [
    "Tensor data types and casting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "v52347k654th"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "torch.LongTensor\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(3, 3, dtype=torch.double)\n",
    "print(a)\n",
    "b = a.long()\n",
    "print(b.type())\n",
    "c = a.int()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9jROw58rvVZ"
   },
   "source": [
    "Documentation on various dtypes: https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "strIC2QY54tk"
   },
   "source": [
    "### More useful PyTorch Tensor operations\n",
    "\n",
    "To see the complete API check here: https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tWE7sT0uvue"
   },
   "source": [
    "`.view()` can be used to resize/reshape tensors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lXwIvBQS54tk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYTgOyt5u1ph"
   },
   "source": [
    "If you have a one element tensor, use `.item()` to get the value as a Python number:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "e-rltnVuu69S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.)\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(4,5)\n",
    "x = x.sum()\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eV_tHHW85m-U"
   },
   "source": [
    "Concatenating two matrices together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "C7L-sqwK5mOA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, 3)\n",
    "y = torch.zeros(5, 2)\n",
    "print(torch.cat([x, y], dim=1))\n",
    "# wrong:\n",
    "# print(torch.cat([x, y], dim=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y023N4uw54tm"
   },
   "source": [
    "### Converting between NumPy arrays and PyTorch Tensors\n",
    "\n",
    "Important: PyTorch Tensors and NumPy arrays will share the same underlying memory locations. If you change values for one, the values for the other will be changed too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3VKumG9ump-"
   },
   "source": [
    "Convert PyTorch Tensor to NumPy array:\n",
    "\n",
    "such conversion requires source tensor to be on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3xa88YHL54tn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMIhgJgivCsm"
   },
   "source": [
    "Convert NumPy array to PyTorch Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "55AFarlO54tp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gg90vky-54tr"
   },
   "source": [
    "## CUDA Tensors (On GPU)\n",
    "\n",
    "PyTorch tensors have the added benefit that they can easily be placed on a GPU to speed up computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_Lfnh2wPeQz"
   },
   "source": [
    "Query information about the GPU (if CUDA is available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0i9K6ucxPLZr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar  7 23:58:36 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:06:00.0 Off |                  N/A |\r\n",
      "| N/A   48C    P8    N/A /  N/A |      6MiB /  4096MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1626      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiEkS3ZjP5aH"
   },
   "source": [
    "You can use `torch.device` objects to move tensors to and from the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "d2ue8FEc54tr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]], device='cuda:0')\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings `.to(\"cuda\")`\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # `.to` can also change dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzlpOvUg64mB"
   },
   "source": [
    "Default device can be specified by [`torch.cuda.set_device(device)`](https://pytorch.org/docs/stable/generated/torch.cuda.set_device.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXF6Ykbr54tu"
   },
   "source": [
    "\n",
    "## Autograd: Automatic Differentiation\n",
    "\n",
    "From: https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
    "\n",
    "Now that you have learned how to use PyTorch Tensors you will learn how we can use PyTorch for automatic differentiation.\n",
    "\n",
    "The `autograd` package in PyTorch provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n",
    "\n",
    "To allow PyTorch to keep track of operations for automatic differentiation, we need to set `requires_grad` as `True` for a Tensor. Autograd will then start to track all operations on the Tensor. When you finish your computation you can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into the `.grad` attribute.\n",
    "\n",
    "To stop a tensor from tracking history, you can call `.detach()` to detach\n",
    "it from the computation history, and to prevent future computation from being\n",
    "tracked.\n",
    "\n",
    "To prevent tracking history (and using memory), you can also wrap the code block in `with torch.no_grad():`. This can be particularly helpful when evaluating a model because the model may have trainable parameters with `requires_grad=True`, but for which we don't need the gradients.\n",
    "\n",
    "There’s one more class which is very important for autograd implementation - a `Function`.\n",
    "\n",
    "`Tensor` and `Function` are interconnected and build up an acyclic\n",
    "graph that encodes a complete history of computation. Each tensor has\n",
    "a `.grad_fn` attribute that references a `Function` that has created\n",
    "the `Tensor` (except for Tensors created by the user - their `grad_fn` is `None`).\n",
    "\n",
    "If you want to compute the derivatives, you can call `.backward()` on a `Tensor`. If `Tensor` is a scalar (i.e. it holds a one element data), you don’t need to specify any arguments to `backward()`, however if it has more elements, you need to specify a `gradient` argument that is a tensor of matching shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_7reitR54tv"
   },
   "source": [
    "Create a tensor and set `requires_grad=True` to track computation with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BiUIjct_54tw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceISCrjA54ty"
   },
   "source": [
    "Perform a tensor operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "jol5D-i754tz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELfAiQbe54t1"
   },
   "source": [
    "`y` was created as a result of an operation, so it has a `grad_fn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "N1-bfsGg54t1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f8677fb8d00>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKGpA_tx54t3"
   },
   "source": [
    "Do more operations on `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ZEr955CF54t3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "print(z)\n",
    "out = z.mean()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W_IdTf054t5"
   },
   "source": [
    "`.requires_grad_()` changes an existing Tensor's `requires_grad` flag in-place. The input flag defaults to `False` if not given:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Mqhs7laq54t5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x7f873b9d49d0>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmHvopdf54t7"
   },
   "source": [
    "### Gradients\n",
    "\n",
    "Let's backprop now. Because `out` contains a single scalar, `out.backward()` is equivalent to `out.backward(torch.tensor(1))`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "AAHwiVuB54t8"
   },
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-PJNi8j54t-"
   },
   "source": [
    "Print gradients $\\frac{d(\\texttt{out})}{d\\texttt{x}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ZMFshmPS54t-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISxLOt0d54uB"
   },
   "source": [
    "You should get a matrix of `4.5`. Let's call the `out` *Tensor* \"$o$\". We find that $o = \\frac{1}{4}\\sum_i z_i$, $z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$. Therefore, $\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, hence $\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOnU_3Q_54uB"
   },
   "source": [
    "You can do many crazy things with autograd!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7Vy1rJr54uB"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wN5uMku54uE"
   },
   "outputs": [],
   "source": [
    "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(gradients)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3WfxSbS54uF"
   },
   "source": [
    "You can also stop autograd from tracking history on Tensors with `.requires_grad=True` by wrapping the code block in `with torch.no_grad()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxbhHk8654uG"
   },
   "outputs": [],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "\tprint((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtHPCO3R54uI"
   },
   "source": [
    "**Read Later:**\n",
    "\n",
    "Documentation of `torch.autograd` and `Function` is at\n",
    "http://pytorch.org/docs/autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDKBSQ9n54uJ"
   },
   "source": [
    "## Neural Networks\n",
    "\n",
    "The `torch.nn` package in PyTorch provides higher level building blocks for neural networks like fully connected or convolutional layers. The `nn` package makes use of the `autograd` functionality to define these model building blocks and differentiate them. This allows us to quickly and easily implement neural networks by putting together layers and using PyTorch to help us update learnable parameters with the gradient.\n",
    "\n",
    "An `nn.Module` contains layers, and a method `forward(input)` that\n",
    "returns the `output`.\n",
    "\n",
    "A typical training procedure for a neural network is as follows:\n",
    "\n",
    "- Define the neural network that has some learnable parameters (or\n",
    "  weights)\n",
    "- Iterate over a dataset of inputs\n",
    "- Process input through the network\n",
    "- Compute the loss (how far is the output from being correct)\n",
    "- Propagate gradients back into the network’s parameters\n",
    "- Update the weights of the network, typically using a simple update rule:\n",
    "  `weight = weight - learning_rate * gradient`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szNq6Hk854uJ"
   },
   "source": [
    "### Define the network\n",
    "\n",
    "In the cell below we define a simple convolutional neural network. Notice that we use the `nn.Conv2d` and `nn.Linear` Modules as building blocks for the network.\n",
    "\n",
    "There are plenty of other types of layers and tools available in the [torch.nn](https://pytorch.org/docs/stable/nn.html) package such as pooling layers, dropout, and batchnorm.\n",
    "\n",
    "Conveniently, PyTorch is completely open source so you can check out exactly how each of these Modules are implemented:\n",
    "\n",
    "* https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py\n",
    "* https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/conv.py\n",
    "\n",
    "**Important:** Whenever you extend the `nn.Module` class (e.g. with the `Net` class below) you will need to call the superclass constructor or an error will be thrown. In this example below this line is: `super().__init__()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "A6MyjNHm54uK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8_soKaq54uM"
   },
   "source": [
    "You just have to define the ``forward`` function, and the ``backward``\n",
    "function (where gradients are computed) is automatically defined for you\n",
    "using ``autograd``.\n",
    "You can use any of the Tensor operations in the ``forward`` function.\n",
    "\n",
    "The learnable parameters of a model are returned by ``net.parameters()``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "kNW8772A54uN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuMk3eX654uP"
   },
   "source": [
    "Continuing, let's try a random 32x32 input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "3VGmILUs54uP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0666, -0.0826,  0.0656, -0.0511,  0.0867, -0.0361,  0.1101,  0.0243,\n",
      "          0.0269, -0.0701]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)\n",
    "\n",
    "# wrong:\n",
    "# net.forward(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-C9Gy0Sy54uR"
   },
   "source": [
    "- Zero the gradient buffers of all parameters\n",
    "- To calculate the gradient of all the parameters that used to compute `out` w.r.t. some random value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "jUb7RxZm54uR"
   },
   "outputs": [],
   "source": [
    "net.zero_grad()  # important, since gradient is accumulated\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "nOkP3pBmSGjX"
   },
   "outputs": [],
   "source": [
    "# to check gradient buffer:\n",
    "# net.conv1.bias.grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doU9r69emwm9"
   },
   "source": [
    "The [`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) module can sometimes be helpful to define blocks succintly or avoid creating a new `nn.Module` class for a small network. The `.forward()` function will be automatically defined by running modules in the order they are passed in to `nn.Sequential`. \n",
    "\n",
    "For example, you can define a block of convolutional layers below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "N8y-QNNLnjmd"
   },
   "outputs": [],
   "source": [
    "conv_layers = nn.Sequential(\n",
    "                nn.Conv2d(1, 6, 5),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(6, 16, 5),\n",
    "                nn.ReLU()\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaONPht_54uT"
   },
   "source": [
    "**Note:**\n",
    "\n",
    "`torch.nn` only supports mini-batches. The entire `torch.nn` package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
    "\n",
    "For example, `nn.Conv2d` will take in a 4D Tensor of `nSamples x nChannels x Height x Width`.\n",
    "\n",
    "If you have a single sample, just use `input.unsqueeze(0)` to add a fake batch dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLLYpQ7O54uT"
   },
   "source": [
    "Before proceeding further, let's recap all the classes you’ve seen so far.\n",
    "\n",
    "**Recap:**\n",
    "- `torch.Tensor` - A *multi-dimensional array* with support for autograd operations like `backward()`. Also *holds the gradient* w.r.t. the tensor.\n",
    "- `nn.Module` - Neural network module. *Convenient way of encapsulating parameters*, with helpers for moving them to GPU, exporting, loading, etc.\n",
    "- `nn.Parameter` - A kind of Tensor, that is *automatically registered as a parameter when assigned as an attribute to a* `Module`.\n",
    "- `autograd.Function` - Implements *forward and backward definitions of an autograd operation*. Every `Tensor` operation, creates at least a single `Function` node, that connects to functions that created a `Tensor` and *encodes its history*.\n",
    "\n",
    "**At this point, we covered:**\n",
    "- Defining a neural network\n",
    "- Processing inputs and calling backward\n",
    "\n",
    "**Still Left:**\n",
    "- Computing the loss\n",
    "- Updating the weights of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omNVq_XZ2KV5"
   },
   "source": [
    "### Loss Function\n",
    "\n",
    "A loss function takes the (output, target) pair of inputs, and computes a\n",
    "value that estimates how far away the output is from the target.\n",
    "\n",
    "There are several different [loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions) under the `nn` package. A simple loss is `nn.MSELoss`, which computes the mean-squared error between the input and the target.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "uMUJ2zAO54uU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2201, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85d4XN3W54uW"
   },
   "source": [
    "Now, if you follow `loss` in the backward direction, using its `.grad_fn` attribute, you will see a graph of computations that looks like this:\n",
    "\n",
    "    input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "          -> view -> linear -> relu -> linear -> relu -> linear\n",
    "          -> MSELoss\n",
    "          -> loss\n",
    "\n",
    "So, when we call `loss.backward()`, the whole graph is differentiated w.r.t. the loss, and all Tensors in the graph that have `requires_grad=True` will have their `.grad` Tensor accumulated with the gradient.\n",
    "\n",
    "For illustration, let us follow a few steps backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "am1pApy254uW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x7f8677fb8e20>\n",
      "<AddmmBackward0 object at 0x7f8677fb8f10>\n",
      "<ReluBackward0 object at 0x7f8677fb8eb0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[1][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRqVnKtx54uY"
   },
   "source": [
    "### Backprop\n",
    "\n",
    "To backpropagate the error all we have to do is call `loss.backward()`. You need to clear the existing gradients though, otherwise the gradients will be accumulated to existing gradients.\n",
    "\n",
    "Now we'll call `loss.backward()`, and have a look at conv1's bias\n",
    "gradients before and after the backward step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "7u45jgvE54uZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0027,  0.0031, -0.0009,  0.0013, -0.0031,  0.0041])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()  # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzHCWS8554ub"
   },
   "source": [
    "Now, we have seen how to use loss functions.\n",
    "\n",
    "**The only thing left to learn is:**\n",
    "\n",
    "- Updating the weights of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxIYATs33dW4"
   },
   "source": [
    "### Update the weights\n",
    "\n",
    "The simplest update rule used in practice is the Stochastic Gradient\n",
    "Descent (SGD):\n",
    "\n",
    "     weight = weight - learning_rate * gradient\n",
    "\n",
    "We can implement this using simple python code:\n",
    "\n",
    "```python\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)\n",
    "```\n",
    "\n",
    "However, as you use neural networks, you'll want to use various different\n",
    "update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc.\n",
    "To enable this, PyTorch has a small package: `torch.optim` that\n",
    "implements all these methods. Using it is very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Jy4gmWx054ub"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2201, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# In your training loop:\n",
    "optimizer.zero_grad()             # zero the gradient buffers\n",
    "output = net(input)               # compute the forward pass\n",
    "loss = criterion(output, target)  # compute the loss\n",
    "loss.backward()                   # compute the gradients\n",
    "optimizer.step()                  # update the parameters\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jpw3IUEi54uc"
   },
   "source": [
    "**Important:** Note how gradient buffers had to be manually set to zero using `optimizer.zero_grad()`. This is because gradients are accumulated, so if you don't zero gradients before each `backward()` call, you will begin accumulating gradients from previous forward/backward passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-IGO5uO54ud"
   },
   "source": [
    "#### Note on eval and train modes\n",
    "\n",
    "**Important**: If you use layers in your network like `torch.nn.Dropout` or `torch.nn.BatchNorm2d` which have different behavior during training and evaluation, you will need to make sure the modules in your network are appropriately set. PyTorch makes this easy with `eval` and `train` methods for any network extending `nn.Module`. Before beginning training you will call `net.train()` to set all modules in the network to train mode, and equivalently before evaluating you should call `net.eval()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qptw28n21n2K"
   },
   "source": [
    "## Training a Classifier\n",
    "\n",
    "Now that you have seen the basics of how to define neural networks, compute losses, and make training updates, you will see how a simple classifier is trained in PyTorch on CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-jXBv_c15mP"
   },
   "source": [
    "### What about data?\n",
    "\n",
    "Generally, when you have to deal with image, text, audio, or video data,\n",
    "you can use standard python packages that load data into a numpy array.\n",
    "Then you can convert this array into a `torch.*Tensor`.\n",
    "\n",
    "-  For images, packages such as Pillow, OpenCV are useful\n",
    "-  For audio, packages such as scipy and librosa\n",
    "-  For text, either raw Python or Cython based loading, or NLTK and\n",
    "   SpaCy are useful\n",
    "\n",
    "Specifically for vision, we have created a package called\n",
    "`torchvision`, that has data loaders for common datasets such as\n",
    "Imagenet, CIFAR10, MNIST, etc., models for common architectures, and data transformers for images.\n",
    "\n",
    "This provides a huge convenience and avoids writing boilerplate code.\n",
    "\n",
    "For this tutorial, we will use the CIFAR10 dataset.\n",
    "It has the classes: 'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "'dog', 'frog', 'horse', 'ship', 'truck'. The images in CIFAR-10 are of\n",
    "size $3 \\times 32 \\times 32$, i.e. 3-channel color images of $32 \\times 32$ pixels in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiDBy41M1_0j"
   },
   "source": [
    "### Training an image classifier\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using ``torchvision``\n",
    "2. Define a Convolution Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KbELnF454uk"
   },
   "source": [
    "### 1) Loading and normalizing CIFAR10\n",
    "\n",
    "Using `torchvision`, it’s extremely easy to load CIFAR10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "0uqKo7VI54ul"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLCMgb2Y54uo"
   },
   "source": [
    "The output of torchvision datasets are `PIL` images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1] using the `transforms.ToTensor` and `transforms.Normalize` functions. \n",
    "\n",
    "The [transforms package](https://pytorch.org/vision/stable/transforms.html) has other functions that you might use for **data augmentation**. For example, `torchvision.transforms.RandomResizedCrop` and `torchvision.transforms.RandomHorizontalFlip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "SgoDH0Yh54uo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=train_transform)\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "# Data loaders\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGfPvUSa54uq"
   },
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "wc0QqWeK54uq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bird      horse       bird      truck\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    \"\"\"Function to display an image.\"\"\"\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# Print labels\n",
    "print('      '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFVH9GDs54ut"
   },
   "source": [
    "#### Training on GPU\n",
    "\n",
    "Just like how you transfer a Tensor on to the GPU, you transfer the neural\n",
    "net onto the GPU.\n",
    "\n",
    "Let's first define our device as the first visible cuda device if we have\n",
    "CUDA available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "Tg4nH4kL54ut"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAi1IRlm54uv"
   },
   "source": [
    "If `device` is in fact set to a CUDA device, then these methods will recursively go over all modules and convert their parameters and buffers to CUDA tensors:\n",
    "\n",
    "```python\n",
    "net = net.to(device)\n",
    "```\n",
    "\n",
    "Remember that you will have to send the inputs and targets at every step\n",
    "to the GPU too:\n",
    "\n",
    "```python\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "```\n",
    "\n",
    "Why don't I notice MASSIVE speedup compared to CPU? Because your network\n",
    "is *realllly* small.\n",
    "\n",
    "**Exercise:** Try increasing the width of your network (argument 2 of\n",
    "the first `nn.Conv2d`, and argument 1 of the second `nn.Conv2d` –\n",
    "they need to be the same number), see what kind of speedup you get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f3yqmzZ54uv"
   },
   "source": [
    "### 2) Define a Convolution Neural Network\n",
    "\n",
    "Copy the neural network from the Neural Networks section before and modify it to\n",
    "take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "QFxHduMg54uw"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.out_channels1 = 6\n",
    "        self.out_channels2 = 16\n",
    "        self.conv1 = nn.Conv2d(3, self.out_channels1, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(self.out_channels1, self.out_channels2, 5)\n",
    "        self.fc1 = nn.Linear(self.out_channels2 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNZpQALm54ux"
   },
   "source": [
    "### 3) Define a Loss function and optimizer\n",
    "\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "CxS9T6ly54uy"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUwlfYEh54u0"
   },
   "source": [
    "### 4) Train the network\n",
    "\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0))\n",
    "input = torch.randn(20, 16, 10, 50, 100)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.89927765 3.7986363 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "b1 = 0.9\n",
    "b2 = 0.999\n",
    "lr = 1e-3\n",
    "eps = 1e-8\n",
    "w = np.array([3.0, 4.0])\n",
    "grad_w = np.array([0.004, 0.001])\n",
    "m = np.array([0.5, 1.0])\n",
    "v = np.array([0.00002, 0.00002])\n",
    "\n",
    "m = (1-b1) * grad_w + m * b1\n",
    "v = b2 * v + (1-b2) * np.square(grad_w)\n",
    "w -= lr*m/(np.sqrt(v)+eps)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.369, -2.742])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([-0.55, -1.65])- np.array([2.0, 2.0]) * 0.182\n",
    "np.array([-0.914, -2.014]) - np.array([2.5, 4.0]) * 0.182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "dwXciSA454u0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "[1,  2000] loss: 1.573\n",
      "iters time: 6.024772644042969\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23349/3193287141.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "net = net.train()\n",
    "\n",
    "# Loop over the dataset for multiple epochs\n",
    "for epoch in range(1, 3):\n",
    "    running_loss = 0.0\n",
    "    t_s = time.time()\n",
    "\n",
    "    # For each mini-batch...\n",
    "    for i, data in enumerate(trainloader, 1):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 0:  # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch, i, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            print('iters time:', time.time() - t_s)\n",
    "            t_s = time.time()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxqpJ27N_23W"
   },
   "source": [
    "Let’s quickly save our trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "65bQ4MFR_y52"
   },
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdGUM74bAJn6"
   },
   "source": [
    "We can load back in a saved model with the following: (note: saving and re-loading the model wasn’t necessary here, we only did it to illustrate how to do so):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "QuoPRDvWAUYs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0X8mDOw54u1"
   },
   "source": [
    "### 5) Test the network on the test data\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.\n",
    "But we need to check if the network has learned anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "AxuALLU054u2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth:\n",
      "  cat       ship       ship      plane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('Ground truth:')\n",
    "print('      '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17PzSHOh54u4"
   },
   "source": [
    "Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "YUalV9gM54u4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "net = net.eval()\n",
    "\n",
    "outputs = net(images.to(device))\n",
    "print(outputs.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXLcTThZ54u6"
   },
   "source": [
    "The outputs are energies for the 10 classes.\n",
    "Higher the energy for a class, the more the network\n",
    "thinks that the image is of the particular class.\n",
    "So, let's get the index of the highest energy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "BttfSl0_54u7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:\n",
      "  cat       ship        car      plane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('Predicted:')\n",
    "print('      '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQOFenEC54u-"
   },
   "source": [
    "The results seem pretty good.\n",
    "\n",
    "Let us look at how the network performs on the whole dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "iKFpv3i354u-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 59%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d%%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwJ2a57954vA"
   },
   "source": [
    "That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
    "a class out of 10 classes).\n",
    "Seems like the network learned something.\n",
    "\n",
    "Hmmm, what are the classes that performed well, and the classes that did\n",
    "not perform well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "6kRdd7As54vB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane: 67%\n",
      "Accuracy of   car: 73%\n",
      "Accuracy of  bird: 52%\n",
      "Accuracy of   cat: 52%\n",
      "Accuracy of  deer: 40%\n",
      "Accuracy of   dog: 43%\n",
      "Accuracy of  frog: 80%\n",
      "Accuracy of horse: 61%\n",
      "Accuracy of  ship: 62%\n",
      "Accuracy of truck: 58%\n"
     ]
    }
   ],
   "source": [
    "class_correct = [0] * 10\n",
    "class_total = [0] * 10\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s: %2d%%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3V4E0pI54vE"
   },
   "source": [
    "### Other information\n",
    "\n",
    "How to write data loading code in PyTorch: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "More details on saving and loading models: https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mw33n0lVaflD"
   },
   "source": [
    "## Other Tips and Helpful Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-XdYBHho1b1"
   },
   "source": [
    "### Tips for debugging\n",
    "\n",
    "Checklist for common PyTorch mistakes:\n",
    "\n",
    "* Did you set `shuffle=True` in your train dataloader?\n",
    "* Did you properly set `net.train()` and `net.eval()` in your training and evaluation code?\n",
    "* Did you call `zero_grad()` in your training loop before `.backward()` to prevent gradients from accumulating?\n",
    "\n",
    "Other tips:\n",
    "* Have you visualized your loaded images? This is the best way to catch data loader issues.\n",
    "* If you are getting a CUDA out of memory error, first try decreasing the batch size. If you are still getting the same error, your network may simply be too large, or you could be accidentally allocating a large array in memory.\n",
    "* Getting CUDA errors that are hard to understand? Sometimes error messages will be simpler if you switch your network to cpu memory to debug the forward and backward passes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IM517FCeGGmh"
   },
   "source": [
    "### Pretrained models\n",
    "\n",
    "PyTorch provides easy access to load many pretrained models. You can find a wide variety of vision models pretrained for different tasks in the `torchvision` package: https://pytorch.org/vision/stable/models.html\n",
    "\n",
    "To load a ResNet50 model pretrained on ImageNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-02dfgAagK3"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "weights = ResNet50_Weights.IMAGENET1K_V1\n",
    "resnet = resnet50(weights=weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ryw7NzWLs-_"
   },
   "source": [
    "It's common that you may want to finetune some or all of the weights in a pretrained model. You can check here for more details on how to do this: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html \n",
    "\n",
    "\n",
    "There are even more pretrained models available on the PyTorch Hub: https://pytorch.org/hub/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uv9zqWFlR9jx"
   },
   "source": [
    "### More Tensor operations\n",
    "\n",
    "The `torch.einsum` function offers a compact way to express various matrix transformations and products. Many of common matrix and vector computations can be easily expressed elegantly with a call to this function. \n",
    "\n",
    "Some simple examples are below, but you can find many more example einsum operations in this helpful blog post: https://rockt.github.io/2018/04/30/einsum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nls4hhaUZggy"
   },
   "outputs": [],
   "source": [
    "x = torch.arange(6).reshape(2, 3)\n",
    "print('x: ', x)\n",
    "\n",
    "# matrix transpose\n",
    "out = torch.einsum('ij->ji', [x])\n",
    "print(out)\n",
    "\n",
    "# sum all the rows in a matrix\n",
    "out = torch.einsum('ij->i', [x])\n",
    "print(out)\n",
    "\n",
    "# sum all the values in a matrix\n",
    "out = torch.einsum('ij->', [x])\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DU8WXqJbUUZ"
   },
   "source": [
    "Operations on two matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2vLY0r0aygj"
   },
   "outputs": [],
   "source": [
    "x = torch.arange(9).reshape(3, 3)\n",
    "y = torch.arange(9).reshape(3, 3)\n",
    "print('x: ', x)\n",
    "print('y: ', y)\n",
    "\n",
    "# element-wise multiplication\n",
    "out = torch.einsum('ij,ij->ij', [x, y])\n",
    "print(out)\n",
    "\n",
    "# matrix multiplication\n",
    "out = torch.einsum('ik,kj->ij', [x, y])\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
