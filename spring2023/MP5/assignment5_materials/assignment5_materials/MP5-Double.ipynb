{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install gym pyvirtualdisplay\n",
    "!sudo apt-get install -y xvfb python-opengl ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade setuptools --user\n",
    "!pip3 install ez_setup \n",
    "!pip3 install gym[atari] \n",
    "!pip3 install gym[accept-rom-license] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import gym\n",
    "import torch\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from utils import find_max_lives, check_live, get_frame, get_init_state\n",
    "from model import DQN\n",
    "from config import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://www.gymlibrary.dev/environments/atari/breakout/. \n",
    "\n",
    "In breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_lives = find_max_lives(env)\n",
    "state_size = env.observation_space.shape\n",
    "action_size = 3 #fire, left, and right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DQN Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n",
    "\n",
    "__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n",
    "\n",
    "__Frame__ : Number of frames processed in total.\n",
    "\n",
    "__Memory Size__ : The current size of the replay memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_dqn = True # set to True if using double DQN agent\n",
    "\n",
    "if double_dqn:\n",
    "    from agent_double import Agent\n",
    "else:\n",
    "    from agent import Agent\n",
    "\n",
    "agent = Agent(action_size)\n",
    "evaluation_reward = deque(maxlen=evaluation_reward_length)\n",
    "frame = 0\n",
    "memory_size = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_243996/1886764261.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
      "/tmp/ipykernel_243996/1886764261.py:20: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 0   score: 1.0   mem len: 151   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.0\n",
      "epis: 1   score: 1.0   mem len: 322   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.0\n",
      "epis: 2   score: 0.0   mem len: 445   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 0.67\n",
      "epis: 3   score: 3.0   mem len: 691   epsilon: 1.0    steps: 246    lr: 0.0001     reward: 1.25\n",
      "epis: 4   score: 0.0   mem len: 814   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.0\n",
      "epis: 5   score: 0.0   mem len: 937   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 0.83\n",
      "epis: 6   score: 3.0   mem len: 1163   epsilon: 1.0    steps: 226    lr: 0.0001     reward: 1.14\n",
      "epis: 7   score: 1.0   mem len: 1332   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.12\n",
      "epis: 8   score: 3.0   mem len: 1598   epsilon: 1.0    steps: 266    lr: 0.0001     reward: 1.33\n",
      "epis: 9   score: 0.0   mem len: 1720   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.2\n",
      "epis: 10   score: 1.0   mem len: 1871   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.18\n",
      "epis: 11   score: 6.0   mem len: 2224   epsilon: 1.0    steps: 353    lr: 0.0001     reward: 1.58\n",
      "epis: 12   score: 2.0   mem len: 2443   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.62\n",
      "epis: 13   score: 1.0   mem len: 2613   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.57\n",
      "epis: 14   score: 3.0   mem len: 2858   epsilon: 1.0    steps: 245    lr: 0.0001     reward: 1.67\n",
      "epis: 15   score: 3.0   mem len: 3101   epsilon: 1.0    steps: 243    lr: 0.0001     reward: 1.75\n",
      "epis: 16   score: 1.0   mem len: 3272   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.71\n",
      "epis: 17   score: 2.0   mem len: 3451   epsilon: 1.0    steps: 179    lr: 0.0001     reward: 1.72\n",
      "epis: 18   score: 1.0   mem len: 3620   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.68\n",
      "epis: 19   score: 0.0   mem len: 3742   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.6\n",
      "epis: 20   score: 2.0   mem len: 3940   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.62\n",
      "epis: 21   score: 0.0   mem len: 4063   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.55\n",
      "epis: 22   score: 2.0   mem len: 4244   epsilon: 1.0    steps: 181    lr: 0.0001     reward: 1.57\n",
      "epis: 23   score: 0.0   mem len: 4366   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.5\n",
      "epis: 24   score: 0.0   mem len: 4488   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.44\n",
      "epis: 25   score: 0.0   mem len: 4610   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.38\n",
      "epis: 26   score: 1.0   mem len: 4779   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.37\n",
      "epis: 27   score: 1.0   mem len: 4930   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.36\n",
      "epis: 28   score: 2.0   mem len: 5148   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.38\n",
      "epis: 29   score: 1.0   mem len: 5317   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.37\n",
      "epis: 30   score: 0.0   mem len: 5440   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.32\n",
      "epis: 31   score: 1.0   mem len: 5609   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.31\n",
      "epis: 32   score: 3.0   mem len: 5875   epsilon: 1.0    steps: 266    lr: 0.0001     reward: 1.36\n",
      "epis: 33   score: 1.0   mem len: 6026   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.35\n",
      "epis: 34   score: 0.0   mem len: 6148   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.31\n",
      "epis: 35   score: 1.0   mem len: 6298   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.31\n",
      "epis: 36   score: 2.0   mem len: 6518   epsilon: 1.0    steps: 220    lr: 0.0001     reward: 1.32\n",
      "epis: 37   score: 1.0   mem len: 6669   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.32\n",
      "epis: 38   score: 2.0   mem len: 6886   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.33\n",
      "epis: 39   score: 5.0   mem len: 7210   epsilon: 1.0    steps: 324    lr: 0.0001     reward: 1.42\n",
      "epis: 40   score: 2.0   mem len: 7409   epsilon: 1.0    steps: 199    lr: 0.0001     reward: 1.44\n",
      "epis: 41   score: 1.0   mem len: 7560   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.43\n",
      "epis: 42   score: 0.0   mem len: 7683   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 43   score: 3.0   mem len: 7952   epsilon: 1.0    steps: 269    lr: 0.0001     reward: 1.43\n",
      "epis: 44   score: 2.0   mem len: 8149   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.44\n",
      "epis: 45   score: 7.0   mem len: 8537   epsilon: 1.0    steps: 388    lr: 0.0001     reward: 1.57\n",
      "epis: 46   score: 2.0   mem len: 8752   epsilon: 1.0    steps: 215    lr: 0.0001     reward: 1.57\n",
      "epis: 47   score: 1.0   mem len: 8920   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.56\n",
      "epis: 48   score: 2.0   mem len: 9117   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.57\n",
      "epis: 49   score: 2.0   mem len: 9336   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.58\n",
      "epis: 50   score: 3.0   mem len: 9579   epsilon: 1.0    steps: 243    lr: 0.0001     reward: 1.61\n",
      "epis: 51   score: 1.0   mem len: 9750   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.6\n",
      "epis: 52   score: 2.0   mem len: 9950   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.6\n",
      "epis: 53   score: 4.0   mem len: 10245   epsilon: 1.0    steps: 295    lr: 0.0001     reward: 1.65\n",
      "epis: 54   score: 6.0   mem len: 10641   epsilon: 1.0    steps: 396    lr: 0.0001     reward: 1.73\n",
      "epis: 55   score: 0.0   mem len: 10764   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.7\n",
      "epis: 56   score: 2.0   mem len: 10961   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.7\n",
      "epis: 57   score: 0.0   mem len: 11084   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.67\n",
      "epis: 58   score: 1.0   mem len: 11253   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.66\n",
      "epis: 59   score: 2.0   mem len: 11470   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.67\n",
      "epis: 60   score: 2.0   mem len: 11687   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.67\n",
      "epis: 61   score: 2.0   mem len: 11884   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.68\n",
      "epis: 62   score: 0.0   mem len: 12007   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.65\n",
      "epis: 63   score: 0.0   mem len: 12129   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.62\n",
      "epis: 64   score: 7.0   mem len: 12574   epsilon: 1.0    steps: 445    lr: 0.0001     reward: 1.71\n",
      "epis: 65   score: 0.0   mem len: 12697   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.68\n",
      "epis: 66   score: 0.0   mem len: 12819   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.66\n",
      "epis: 67   score: 1.0   mem len: 12988   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.65\n",
      "epis: 68   score: 2.0   mem len: 13185   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.65\n",
      "epis: 69   score: 3.0   mem len: 13431   epsilon: 1.0    steps: 246    lr: 0.0001     reward: 1.67\n",
      "epis: 70   score: 6.0   mem len: 13809   epsilon: 1.0    steps: 378    lr: 0.0001     reward: 1.73\n",
      "epis: 71   score: 1.0   mem len: 13979   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.72\n",
      "epis: 72   score: 3.0   mem len: 14243   epsilon: 1.0    steps: 264    lr: 0.0001     reward: 1.74\n",
      "epis: 73   score: 3.0   mem len: 14469   epsilon: 1.0    steps: 226    lr: 0.0001     reward: 1.76\n",
      "epis: 74   score: 1.0   mem len: 14620   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.75\n",
      "epis: 75   score: 2.0   mem len: 14840   epsilon: 1.0    steps: 220    lr: 0.0001     reward: 1.75\n",
      "epis: 76   score: 0.0   mem len: 14963   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.73\n",
      "epis: 77   score: 2.0   mem len: 15161   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.73\n",
      "epis: 78   score: 3.0   mem len: 15430   epsilon: 1.0    steps: 269    lr: 0.0001     reward: 1.75\n",
      "epis: 79   score: 4.0   mem len: 15726   epsilon: 1.0    steps: 296    lr: 0.0001     reward: 1.78\n",
      "epis: 80   score: 3.0   mem len: 15952   epsilon: 1.0    steps: 226    lr: 0.0001     reward: 1.79\n",
      "epis: 81   score: 3.0   mem len: 16218   epsilon: 1.0    steps: 266    lr: 0.0001     reward: 1.8\n",
      "epis: 82   score: 2.0   mem len: 16435   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.81\n",
      "epis: 83   score: 2.0   mem len: 16651   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 84   score: 2.0   mem len: 16851   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.81\n",
      "epis: 85   score: 2.0   mem len: 17070   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.81\n",
      "epis: 86   score: 1.0   mem len: 17239   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.8\n",
      "epis: 87   score: 0.0   mem len: 17362   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.78\n",
      "epis: 88   score: 4.0   mem len: 17603   epsilon: 1.0    steps: 241    lr: 0.0001     reward: 1.81\n",
      "epis: 89   score: 2.0   mem len: 17819   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.81\n",
      "epis: 90   score: 1.0   mem len: 17990   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.8\n",
      "epis: 91   score: 0.0   mem len: 18112   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.78\n",
      "epis: 92   score: 2.0   mem len: 18331   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.78\n",
      "epis: 93   score: 1.0   mem len: 18482   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.78\n",
      "epis: 94   score: 1.0   mem len: 18654   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.77\n",
      "epis: 95   score: 1.0   mem len: 18822   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.76\n",
      "epis: 96   score: 0.0   mem len: 18945   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.74\n",
      "epis: 97   score: 1.0   mem len: 19114   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.73\n",
      "epis: 98   score: 4.0   mem len: 19401   epsilon: 1.0    steps: 287    lr: 0.0001     reward: 1.76\n",
      "epis: 99   score: 8.0   mem len: 19824   epsilon: 1.0    steps: 423    lr: 0.0001     reward: 1.82\n",
      "epis: 100   score: 2.0   mem len: 20022   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.83\n",
      "epis: 101   score: 1.0   mem len: 20173   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.83\n",
      "epis: 102   score: 0.0   mem len: 20296   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.83\n",
      "epis: 103   score: 2.0   mem len: 20512   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.82\n",
      "epis: 104   score: 0.0   mem len: 20634   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.82\n",
      "epis: 105   score: 1.0   mem len: 20803   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.83\n",
      "epis: 106   score: 0.0   mem len: 20925   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.8\n",
      "epis: 107   score: 3.0   mem len: 21188   epsilon: 1.0    steps: 263    lr: 0.0001     reward: 1.82\n",
      "epis: 108   score: 2.0   mem len: 21388   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.81\n",
      "epis: 109   score: 2.0   mem len: 21589   epsilon: 1.0    steps: 201    lr: 0.0001     reward: 1.83\n",
      "epis: 110   score: 3.0   mem len: 21854   epsilon: 1.0    steps: 265    lr: 0.0001     reward: 1.85\n",
      "epis: 111   score: 0.0   mem len: 21977   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.79\n",
      "epis: 112   score: 1.0   mem len: 22146   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.78\n",
      "epis: 113   score: 0.0   mem len: 22269   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.77\n",
      "epis: 114   score: 1.0   mem len: 22420   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.75\n",
      "epis: 115   score: 5.0   mem len: 22761   epsilon: 1.0    steps: 341    lr: 0.0001     reward: 1.77\n",
      "epis: 116   score: 2.0   mem len: 22977   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.78\n",
      "epis: 117   score: 1.0   mem len: 23149   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.77\n",
      "epis: 118   score: 0.0   mem len: 23271   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.76\n",
      "epis: 119   score: 0.0   mem len: 23394   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.76\n",
      "epis: 120   score: 2.0   mem len: 23592   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.76\n",
      "epis: 121   score: 1.0   mem len: 23761   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.77\n",
      "epis: 122   score: 1.0   mem len: 23930   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.76\n",
      "epis: 123   score: 1.0   mem len: 24099   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.77\n",
      "epis: 124   score: 2.0   mem len: 24297   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.79\n",
      "epis: 125   score: 3.0   mem len: 24565   epsilon: 1.0    steps: 268    lr: 0.0001     reward: 1.82\n",
      "epis: 126   score: 1.0   mem len: 24734   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.82\n",
      "epis: 127   score: 0.0   mem len: 24856   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.81\n",
      "epis: 128   score: 1.0   mem len: 25025   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.8\n",
      "epis: 129   score: 2.0   mem len: 25223   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.81\n",
      "epis: 130   score: 5.0   mem len: 25569   epsilon: 1.0    steps: 346    lr: 0.0001     reward: 1.86\n",
      "epis: 131   score: 1.0   mem len: 25741   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.86\n",
      "epis: 132   score: 1.0   mem len: 25909   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.84\n",
      "epis: 133   score: 4.0   mem len: 26220   epsilon: 1.0    steps: 311    lr: 0.0001     reward: 1.87\n",
      "epis: 134   score: 0.0   mem len: 26342   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.87\n",
      "epis: 135   score: 1.0   mem len: 26511   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.87\n",
      "epis: 136   score: 0.0   mem len: 26634   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.85\n",
      "epis: 137   score: 2.0   mem len: 26832   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.86\n",
      "epis: 138   score: 2.0   mem len: 27032   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.86\n",
      "epis: 139   score: 2.0   mem len: 27230   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.83\n",
      "epis: 140   score: 3.0   mem len: 27478   epsilon: 1.0    steps: 248    lr: 0.0001     reward: 1.84\n",
      "epis: 141   score: 0.0   mem len: 27601   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.83\n",
      "epis: 142   score: 2.0   mem len: 27820   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.85\n",
      "epis: 143   score: 2.0   mem len: 28017   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.84\n",
      "epis: 144   score: 0.0   mem len: 28140   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.82\n",
      "epis: 145   score: 1.0   mem len: 28309   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.76\n",
      "epis: 146   score: 2.0   mem len: 28508   epsilon: 1.0    steps: 199    lr: 0.0001     reward: 1.76\n",
      "epis: 147   score: 0.0   mem len: 28631   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.75\n",
      "epis: 148   score: 0.0   mem len: 28753   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.73\n",
      "epis: 149   score: 1.0   mem len: 28922   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.72\n",
      "epis: 150   score: 2.0   mem len: 29119   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.71\n",
      "epis: 151   score: 0.0   mem len: 29242   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.7\n",
      "epis: 152   score: 1.0   mem len: 29411   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.69\n",
      "epis: 153   score: 2.0   mem len: 29609   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.67\n",
      "epis: 154   score: 0.0   mem len: 29732   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.61\n",
      "epis: 155   score: 2.0   mem len: 29930   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.63\n",
      "epis: 156   score: 0.0   mem len: 30052   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.61\n",
      "epis: 157   score: 1.0   mem len: 30221   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.62\n",
      "epis: 158   score: 1.0   mem len: 30391   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.62\n",
      "epis: 159   score: 1.0   mem len: 30559   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.61\n",
      "epis: 160   score: 2.0   mem len: 30741   epsilon: 1.0    steps: 182    lr: 0.0001     reward: 1.61\n",
      "epis: 161   score: 3.0   mem len: 31012   epsilon: 1.0    steps: 271    lr: 0.0001     reward: 1.62\n",
      "epis: 162   score: 2.0   mem len: 31211   epsilon: 1.0    steps: 199    lr: 0.0001     reward: 1.64\n",
      "epis: 163   score: 2.0   mem len: 31409   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.66\n",
      "epis: 164   score: 0.0   mem len: 31531   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.59\n",
      "epis: 165   score: 0.0   mem len: 31654   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.59\n",
      "epis: 166   score: 1.0   mem len: 31804   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 167   score: 1.0   mem len: 31955   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.6\n",
      "epis: 168   score: 0.0   mem len: 32077   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.58\n",
      "epis: 169   score: 2.0   mem len: 32296   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.57\n",
      "epis: 170   score: 1.0   mem len: 32465   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.52\n",
      "epis: 171   score: 2.0   mem len: 32680   epsilon: 1.0    steps: 215    lr: 0.0001     reward: 1.53\n",
      "epis: 172   score: 0.0   mem len: 32803   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.5\n",
      "epis: 173   score: 2.0   mem len: 33023   epsilon: 1.0    steps: 220    lr: 0.0001     reward: 1.49\n",
      "epis: 174   score: 2.0   mem len: 33220   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.5\n",
      "epis: 175   score: 3.0   mem len: 33445   epsilon: 1.0    steps: 225    lr: 0.0001     reward: 1.51\n",
      "epis: 176   score: 2.0   mem len: 33642   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.53\n",
      "epis: 177   score: 3.0   mem len: 33868   epsilon: 1.0    steps: 226    lr: 0.0001     reward: 1.54\n",
      "epis: 178   score: 0.0   mem len: 33990   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.51\n",
      "epis: 179   score: 0.0   mem len: 34112   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.47\n",
      "epis: 180   score: 2.0   mem len: 34329   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.46\n",
      "epis: 181   score: 0.0   mem len: 34451   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.43\n",
      "epis: 182   score: 1.0   mem len: 34619   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.42\n",
      "epis: 183   score: 2.0   mem len: 34819   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.42\n",
      "epis: 184   score: 2.0   mem len: 34999   epsilon: 1.0    steps: 180    lr: 0.0001     reward: 1.42\n",
      "epis: 185   score: 0.0   mem len: 35122   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 186   score: 0.0   mem len: 35245   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.39\n",
      "epis: 187   score: 0.0   mem len: 35367   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.39\n",
      "epis: 188   score: 0.0   mem len: 35489   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.35\n",
      "epis: 189   score: 2.0   mem len: 35687   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.35\n",
      "epis: 190   score: 3.0   mem len: 35952   epsilon: 1.0    steps: 265    lr: 0.0001     reward: 1.37\n",
      "epis: 191   score: 2.0   mem len: 36150   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.39\n",
      "epis: 192   score: 0.0   mem len: 36273   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.37\n",
      "epis: 193   score: 1.0   mem len: 36424   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.37\n",
      "epis: 194   score: 3.0   mem len: 36671   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.39\n",
      "epis: 195   score: 1.0   mem len: 36839   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.39\n",
      "epis: 196   score: 2.0   mem len: 37037   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.41\n",
      "epis: 197   score: 2.0   mem len: 37216   epsilon: 1.0    steps: 179    lr: 0.0001     reward: 1.42\n",
      "epis: 198   score: 3.0   mem len: 37447   epsilon: 1.0    steps: 231    lr: 0.0001     reward: 1.41\n",
      "epis: 199   score: 0.0   mem len: 37570   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.33\n",
      "epis: 200   score: 5.0   mem len: 37878   epsilon: 1.0    steps: 308    lr: 0.0001     reward: 1.36\n",
      "epis: 201   score: 6.0   mem len: 38252   epsilon: 1.0    steps: 374    lr: 0.0001     reward: 1.41\n",
      "epis: 202   score: 0.0   mem len: 38375   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.41\n",
      "epis: 203   score: 1.0   mem len: 38526   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.4\n",
      "epis: 204   score: 0.0   mem len: 38649   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 205   score: 3.0   mem len: 38896   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.42\n",
      "epis: 206   score: 1.0   mem len: 39065   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.43\n",
      "epis: 207   score: 4.0   mem len: 39362   epsilon: 1.0    steps: 297    lr: 0.0001     reward: 1.44\n",
      "epis: 208   score: 1.0   mem len: 39533   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.43\n",
      "epis: 209   score: 0.0   mem len: 39656   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.41\n",
      "epis: 210   score: 1.0   mem len: 39807   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.39\n",
      "epis: 211   score: 0.0   mem len: 39929   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.39\n",
      "epis: 212   score: 0.0   mem len: 40051   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.38\n",
      "epis: 213   score: 2.0   mem len: 40250   epsilon: 1.0    steps: 199    lr: 0.0001     reward: 1.4\n",
      "epis: 214   score: 6.0   mem len: 40584   epsilon: 1.0    steps: 334    lr: 0.0001     reward: 1.45\n",
      "epis: 215   score: 2.0   mem len: 40802   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.42\n",
      "epis: 216   score: 1.0   mem len: 40971   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.41\n",
      "epis: 217   score: 3.0   mem len: 41198   epsilon: 1.0    steps: 227    lr: 0.0001     reward: 1.43\n",
      "epis: 218   score: 0.0   mem len: 41321   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 219   score: 0.0   mem len: 41443   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.43\n",
      "epis: 220   score: 6.0   mem len: 41819   epsilon: 1.0    steps: 376    lr: 0.0001     reward: 1.47\n",
      "epis: 221   score: 1.0   mem len: 41987   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.47\n",
      "epis: 222   score: 3.0   mem len: 42219   epsilon: 1.0    steps: 232    lr: 0.0001     reward: 1.49\n",
      "epis: 223   score: 6.0   mem len: 42615   epsilon: 1.0    steps: 396    lr: 0.0001     reward: 1.54\n",
      "epis: 224   score: 3.0   mem len: 42881   epsilon: 1.0    steps: 266    lr: 0.0001     reward: 1.55\n",
      "epis: 225   score: 2.0   mem len: 43081   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.54\n",
      "epis: 226   score: 0.0   mem len: 43203   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.53\n",
      "epis: 227   score: 2.0   mem len: 43424   epsilon: 1.0    steps: 221    lr: 0.0001     reward: 1.55\n",
      "epis: 228   score: 2.0   mem len: 43643   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.56\n",
      "epis: 229   score: 0.0   mem len: 43765   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.54\n",
      "epis: 230   score: 0.0   mem len: 43888   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.49\n",
      "epis: 231   score: 0.0   mem len: 44011   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.48\n",
      "epis: 232   score: 0.0   mem len: 44133   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.47\n",
      "epis: 233   score: 1.0   mem len: 44301   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.44\n",
      "epis: 234   score: 1.0   mem len: 44453   epsilon: 1.0    steps: 152    lr: 0.0001     reward: 1.45\n",
      "epis: 235   score: 3.0   mem len: 44700   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.47\n",
      "epis: 236   score: 0.0   mem len: 44823   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.47\n",
      "epis: 237   score: 1.0   mem len: 44973   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.46\n",
      "epis: 238   score: 2.0   mem len: 45171   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.46\n",
      "epis: 239   score: 1.0   mem len: 45321   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.45\n",
      "epis: 240   score: 1.0   mem len: 45472   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.43\n",
      "epis: 241   score: 2.0   mem len: 45654   epsilon: 1.0    steps: 182    lr: 0.0001     reward: 1.45\n",
      "epis: 242   score: 1.0   mem len: 45805   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.44\n",
      "epis: 243   score: 0.0   mem len: 45927   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.42\n",
      "epis: 244   score: 2.0   mem len: 46125   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.44\n",
      "epis: 245   score: 0.0   mem len: 46248   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 246   score: 1.0   mem len: 46416   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.42\n",
      "epis: 247   score: 0.0   mem len: 46539   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.42\n",
      "epis: 248   score: 1.0   mem len: 46709   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 249   score: 2.0   mem len: 46928   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.44\n",
      "epis: 250   score: 3.0   mem len: 47155   epsilon: 1.0    steps: 227    lr: 0.0001     reward: 1.45\n",
      "epis: 251   score: 1.0   mem len: 47305   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.46\n",
      "epis: 252   score: 1.0   mem len: 47474   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.46\n",
      "epis: 253   score: 1.0   mem len: 47643   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.45\n",
      "epis: 254   score: 1.0   mem len: 47812   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.46\n",
      "epis: 255   score: 0.0   mem len: 47935   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.44\n",
      "epis: 256   score: 2.0   mem len: 48135   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.46\n",
      "epis: 257   score: 2.0   mem len: 48333   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.47\n",
      "epis: 258   score: 1.0   mem len: 48503   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.47\n",
      "epis: 259   score: 0.0   mem len: 48626   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.46\n",
      "epis: 260   score: 1.0   mem len: 48795   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.45\n",
      "epis: 261   score: 1.0   mem len: 48967   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.43\n",
      "epis: 262   score: 3.0   mem len: 49217   epsilon: 1.0    steps: 250    lr: 0.0001     reward: 1.44\n",
      "epis: 263   score: 0.0   mem len: 49339   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.42\n",
      "epis: 264   score: 1.0   mem len: 49507   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.43\n",
      "epis: 265   score: 0.0   mem len: 49630   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 266   score: 2.0   mem len: 49810   epsilon: 1.0    steps: 180    lr: 0.0001     reward: 1.44\n",
      "epis: 267   score: 2.0   mem len: 50009   epsilon: 1.0    steps: 199    lr: 0.0001     reward: 1.45\n",
      "epis: 268   score: 0.0   mem len: 50131   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.45\n",
      "epis: 269   score: 2.0   mem len: 50329   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.45\n",
      "epis: 270   score: 0.0   mem len: 50452   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.44\n",
      "epis: 271   score: 4.0   mem len: 50729   epsilon: 1.0    steps: 277    lr: 0.0001     reward: 1.46\n",
      "epis: 272   score: 0.0   mem len: 50852   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.46\n",
      "epis: 273   score: 1.0   mem len: 51005   epsilon: 1.0    steps: 153    lr: 0.0001     reward: 1.45\n",
      "epis: 274   score: 2.0   mem len: 51220   epsilon: 1.0    steps: 215    lr: 0.0001     reward: 1.45\n",
      "epis: 275   score: 2.0   mem len: 51404   epsilon: 1.0    steps: 184    lr: 0.0001     reward: 1.44\n",
      "epis: 276   score: 0.0   mem len: 51526   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.42\n",
      "epis: 277   score: 1.0   mem len: 51696   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.4\n",
      "epis: 278   score: 2.0   mem len: 51893   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.42\n",
      "epis: 279   score: 1.0   mem len: 52061   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.43\n",
      "epis: 280   score: 0.0   mem len: 52184   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.41\n",
      "epis: 281   score: 3.0   mem len: 52430   epsilon: 1.0    steps: 246    lr: 0.0001     reward: 1.44\n",
      "epis: 282   score: 5.0   mem len: 52771   epsilon: 1.0    steps: 341    lr: 0.0001     reward: 1.48\n",
      "epis: 283   score: 2.0   mem len: 52969   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.48\n",
      "epis: 284   score: 0.0   mem len: 53092   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.46\n",
      "epis: 285   score: 1.0   mem len: 53261   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.47\n",
      "epis: 286   score: 3.0   mem len: 53530   epsilon: 1.0    steps: 269    lr: 0.0001     reward: 1.5\n",
      "epis: 287   score: 2.0   mem len: 53730   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.52\n",
      "epis: 288   score: 4.0   mem len: 54003   epsilon: 1.0    steps: 273    lr: 0.0001     reward: 1.56\n",
      "epis: 289   score: 0.0   mem len: 54125   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.54\n",
      "epis: 290   score: 2.0   mem len: 54341   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.53\n",
      "epis: 291   score: 2.0   mem len: 54521   epsilon: 1.0    steps: 180    lr: 0.0001     reward: 1.53\n",
      "epis: 292   score: 0.0   mem len: 54644   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.53\n",
      "epis: 293   score: 3.0   mem len: 54870   epsilon: 1.0    steps: 226    lr: 0.0001     reward: 1.55\n",
      "epis: 294   score: 1.0   mem len: 55021   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.53\n",
      "epis: 295   score: 2.0   mem len: 55239   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.54\n",
      "epis: 296   score: 1.0   mem len: 55390   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.53\n",
      "epis: 297   score: 0.0   mem len: 55512   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.51\n",
      "epis: 298   score: 4.0   mem len: 55806   epsilon: 1.0    steps: 294    lr: 0.0001     reward: 1.52\n",
      "epis: 299   score: 3.0   mem len: 56070   epsilon: 1.0    steps: 264    lr: 0.0001     reward: 1.55\n",
      "epis: 300   score: 1.0   mem len: 56240   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.51\n",
      "epis: 301   score: 2.0   mem len: 56439   epsilon: 1.0    steps: 199    lr: 0.0001     reward: 1.47\n",
      "epis: 302   score: 1.0   mem len: 56590   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.48\n",
      "epis: 303   score: 2.0   mem len: 56788   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.49\n",
      "epis: 304   score: 2.0   mem len: 56986   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.51\n",
      "epis: 305   score: 1.0   mem len: 57156   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.49\n",
      "epis: 306   score: 1.0   mem len: 57328   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.49\n",
      "epis: 307   score: 1.0   mem len: 57480   epsilon: 1.0    steps: 152    lr: 0.0001     reward: 1.46\n",
      "epis: 308   score: 0.0   mem len: 57602   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.45\n",
      "epis: 309   score: 2.0   mem len: 57818   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.47\n",
      "epis: 310   score: 0.0   mem len: 57941   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.46\n",
      "epis: 311   score: 1.0   mem len: 58112   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.47\n",
      "epis: 312   score: 1.0   mem len: 58281   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.48\n",
      "epis: 313   score: 5.0   mem len: 58610   epsilon: 1.0    steps: 329    lr: 0.0001     reward: 1.51\n",
      "epis: 314   score: 0.0   mem len: 58733   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.45\n",
      "epis: 315   score: 0.0   mem len: 58855   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.43\n",
      "epis: 316   score: 0.0   mem len: 58977   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.42\n",
      "epis: 317   score: 3.0   mem len: 59209   epsilon: 1.0    steps: 232    lr: 0.0001     reward: 1.42\n",
      "epis: 318   score: 1.0   mem len: 59359   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.43\n",
      "epis: 319   score: 4.0   mem len: 59639   epsilon: 1.0    steps: 280    lr: 0.0001     reward: 1.47\n",
      "epis: 320   score: 0.0   mem len: 59762   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.41\n",
      "epis: 321   score: 5.0   mem len: 60101   epsilon: 1.0    steps: 339    lr: 0.0001     reward: 1.45\n",
      "epis: 322   score: 0.0   mem len: 60223   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.42\n",
      "epis: 323   score: 3.0   mem len: 60490   epsilon: 1.0    steps: 267    lr: 0.0001     reward: 1.39\n",
      "epis: 324   score: 2.0   mem len: 60708   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.38\n",
      "epis: 325   score: 0.0   mem len: 60831   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.36\n",
      "epis: 326   score: 0.0   mem len: 60954   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.36\n",
      "epis: 327   score: 2.0   mem len: 61133   epsilon: 1.0    steps: 179    lr: 0.0001     reward: 1.36\n",
      "epis: 328   score: 0.0   mem len: 61255   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.34\n",
      "epis: 329   score: 1.0   mem len: 61425   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.35\n",
      "epis: 330   score: 0.0   mem len: 61547   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 331   score: 2.0   mem len: 61770   epsilon: 1.0    steps: 223    lr: 0.0001     reward: 1.37\n",
      "epis: 332   score: 0.0   mem len: 61892   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.37\n",
      "epis: 333   score: 2.0   mem len: 62090   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.38\n",
      "epis: 334   score: 2.0   mem len: 62287   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.39\n",
      "epis: 335   score: 0.0   mem len: 62410   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.36\n",
      "epis: 336   score: 1.0   mem len: 62561   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.37\n",
      "epis: 337   score: 5.0   mem len: 62887   epsilon: 1.0    steps: 326    lr: 0.0001     reward: 1.41\n",
      "epis: 338   score: 1.0   mem len: 63056   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.4\n",
      "epis: 339   score: 1.0   mem len: 63206   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.4\n",
      "epis: 340   score: 0.0   mem len: 63329   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.39\n",
      "epis: 341   score: 3.0   mem len: 63556   epsilon: 1.0    steps: 227    lr: 0.0001     reward: 1.4\n",
      "epis: 342   score: 2.0   mem len: 63774   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.41\n",
      "epis: 343   score: 2.0   mem len: 63992   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.43\n",
      "epis: 344   score: 2.0   mem len: 64190   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.43\n",
      "epis: 345   score: 3.0   mem len: 64456   epsilon: 1.0    steps: 266    lr: 0.0001     reward: 1.46\n",
      "epis: 346   score: 1.0   mem len: 64625   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.46\n",
      "epis: 347   score: 2.0   mem len: 64842   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.48\n",
      "epis: 348   score: 0.0   mem len: 64965   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.47\n",
      "epis: 349   score: 1.0   mem len: 65134   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.46\n",
      "epis: 350   score: 1.0   mem len: 65285   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.44\n",
      "epis: 351   score: 1.0   mem len: 65453   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.44\n",
      "epis: 352   score: 0.0   mem len: 65576   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 353   score: 1.0   mem len: 65727   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.43\n",
      "epis: 354   score: 1.0   mem len: 65878   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.43\n",
      "epis: 355   score: 2.0   mem len: 66077   epsilon: 1.0    steps: 199    lr: 0.0001     reward: 1.45\n",
      "epis: 356   score: 3.0   mem len: 66343   epsilon: 1.0    steps: 266    lr: 0.0001     reward: 1.46\n",
      "epis: 357   score: 0.0   mem len: 66465   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.44\n",
      "epis: 358   score: 1.0   mem len: 66633   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.44\n",
      "epis: 359   score: 1.0   mem len: 66805   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.45\n",
      "epis: 360   score: 2.0   mem len: 67003   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.46\n",
      "epis: 361   score: 1.0   mem len: 67171   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.46\n",
      "epis: 362   score: 2.0   mem len: 67392   epsilon: 1.0    steps: 221    lr: 0.0001     reward: 1.45\n",
      "epis: 363   score: 3.0   mem len: 67618   epsilon: 1.0    steps: 226    lr: 0.0001     reward: 1.48\n",
      "epis: 364   score: 1.0   mem len: 67786   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.48\n",
      "epis: 365   score: 0.0   mem len: 67908   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.48\n",
      "epis: 366   score: 2.0   mem len: 68125   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.48\n",
      "epis: 367   score: 1.0   mem len: 68296   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.47\n",
      "epis: 368   score: 2.0   mem len: 68494   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.49\n",
      "epis: 369   score: 1.0   mem len: 68645   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.48\n",
      "epis: 370   score: 3.0   mem len: 68893   epsilon: 1.0    steps: 248    lr: 0.0001     reward: 1.51\n",
      "epis: 371   score: 2.0   mem len: 69091   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.49\n",
      "epis: 372   score: 3.0   mem len: 69360   epsilon: 1.0    steps: 269    lr: 0.0001     reward: 1.52\n",
      "epis: 373   score: 0.0   mem len: 69483   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.51\n",
      "epis: 374   score: 1.0   mem len: 69651   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.5\n",
      "epis: 375   score: 1.0   mem len: 69801   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.49\n",
      "epis: 376   score: 1.0   mem len: 69969   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.5\n",
      "epis: 377   score: 1.0   mem len: 70141   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.5\n",
      "epis: 378   score: 1.0   mem len: 70309   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.49\n",
      "epis: 379   score: 1.0   mem len: 70478   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.49\n",
      "epis: 380   score: 0.0   mem len: 70600   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.49\n",
      "epis: 381   score: 0.0   mem len: 70722   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.46\n",
      "epis: 382   score: 2.0   mem len: 70919   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.43\n",
      "epis: 383   score: 3.0   mem len: 71190   epsilon: 1.0    steps: 271    lr: 0.0001     reward: 1.44\n",
      "epis: 384   score: 2.0   mem len: 71388   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.46\n",
      "epis: 385   score: 2.0   mem len: 71586   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.47\n",
      "epis: 386   score: 0.0   mem len: 71709   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.44\n",
      "epis: 387   score: 1.0   mem len: 71877   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.43\n",
      "epis: 388   score: 1.0   mem len: 72046   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.4\n",
      "epis: 389   score: 2.0   mem len: 72244   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.42\n",
      "epis: 390   score: 0.0   mem len: 72367   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 391   score: 2.0   mem len: 72566   epsilon: 1.0    steps: 199    lr: 0.0001     reward: 1.4\n",
      "epis: 392   score: 0.0   mem len: 72688   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.4\n",
      "epis: 393   score: 3.0   mem len: 72935   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.4\n",
      "epis: 394   score: 1.0   mem len: 73104   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.4\n",
      "epis: 395   score: 0.0   mem len: 73227   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.38\n",
      "epis: 396   score: 3.0   mem len: 73475   epsilon: 1.0    steps: 248    lr: 0.0001     reward: 1.4\n",
      "epis: 397   score: 1.0   mem len: 73626   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.41\n",
      "epis: 398   score: 2.0   mem len: 73829   epsilon: 1.0    steps: 203    lr: 0.0001     reward: 1.39\n",
      "epis: 399   score: 0.0   mem len: 73952   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.36\n",
      "epis: 400   score: 3.0   mem len: 74198   epsilon: 1.0    steps: 246    lr: 0.0001     reward: 1.38\n",
      "epis: 401   score: 1.0   mem len: 74348   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.37\n",
      "epis: 402   score: 2.0   mem len: 74565   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.38\n",
      "epis: 403   score: 1.0   mem len: 74734   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.37\n",
      "epis: 404   score: 0.0   mem len: 74857   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.35\n",
      "epis: 405   score: 0.0   mem len: 74979   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.34\n",
      "epis: 406   score: 7.0   mem len: 75388   epsilon: 1.0    steps: 409    lr: 0.0001     reward: 1.4\n",
      "epis: 407   score: 1.0   mem len: 75539   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.4\n",
      "epis: 408   score: 0.0   mem len: 75661   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.4\n",
      "epis: 409   score: 2.0   mem len: 75858   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.4\n",
      "epis: 410   score: 5.0   mem len: 76167   epsilon: 1.0    steps: 309    lr: 0.0001     reward: 1.45\n",
      "epis: 411   score: 1.0   mem len: 76336   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.45\n",
      "epis: 412   score: 2.0   mem len: 76534   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.46\n",
      "epis: 413   score: 0.0   mem len: 76656   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 414   score: 1.0   mem len: 76806   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.42\n",
      "epis: 415   score: 5.0   mem len: 77153   epsilon: 1.0    steps: 347    lr: 0.0001     reward: 1.47\n",
      "epis: 416   score: 0.0   mem len: 77276   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.47\n",
      "epis: 417   score: 4.0   mem len: 77573   epsilon: 1.0    steps: 297    lr: 0.0001     reward: 1.48\n",
      "epis: 418   score: 1.0   mem len: 77741   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.48\n",
      "epis: 419   score: 0.0   mem len: 77864   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.44\n",
      "epis: 420   score: 4.0   mem len: 78157   epsilon: 1.0    steps: 293    lr: 0.0001     reward: 1.48\n",
      "epis: 421   score: 0.0   mem len: 78280   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 422   score: 0.0   mem len: 78403   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 423   score: 0.0   mem len: 78526   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 424   score: 0.0   mem len: 78649   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.38\n",
      "epis: 425   score: 2.0   mem len: 78867   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.4\n",
      "epis: 426   score: 2.0   mem len: 79047   epsilon: 1.0    steps: 180    lr: 0.0001     reward: 1.42\n",
      "epis: 427   score: 2.0   mem len: 79247   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.42\n",
      "epis: 428   score: 0.0   mem len: 79369   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.42\n",
      "epis: 429   score: 0.0   mem len: 79491   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.41\n",
      "epis: 430   score: 4.0   mem len: 79750   epsilon: 1.0    steps: 259    lr: 0.0001     reward: 1.45\n",
      "epis: 431   score: 0.0   mem len: 79873   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 432   score: 1.0   mem len: 80041   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.44\n",
      "epis: 433   score: 1.0   mem len: 80191   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.43\n",
      "epis: 434   score: 0.0   mem len: 80313   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.41\n",
      "epis: 435   score: 2.0   mem len: 80532   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.43\n",
      "epis: 436   score: 2.0   mem len: 80748   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.44\n",
      "epis: 437   score: 2.0   mem len: 80966   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.41\n",
      "epis: 438   score: 2.0   mem len: 81164   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.42\n",
      "epis: 439   score: 1.0   mem len: 81335   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.42\n",
      "epis: 440   score: 0.0   mem len: 81457   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.42\n",
      "epis: 441   score: 4.0   mem len: 81751   epsilon: 1.0    steps: 294    lr: 0.0001     reward: 1.43\n",
      "epis: 442   score: 1.0   mem len: 81923   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.42\n",
      "epis: 443   score: 2.0   mem len: 82143   epsilon: 1.0    steps: 220    lr: 0.0001     reward: 1.42\n",
      "epis: 444   score: 0.0   mem len: 82265   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.4\n",
      "epis: 445   score: 1.0   mem len: 82433   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.38\n",
      "epis: 446   score: 3.0   mem len: 82699   epsilon: 1.0    steps: 266    lr: 0.0001     reward: 1.4\n",
      "epis: 447   score: 1.0   mem len: 82870   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.39\n",
      "epis: 448   score: 4.0   mem len: 83187   epsilon: 1.0    steps: 317    lr: 0.0001     reward: 1.43\n",
      "epis: 449   score: 1.0   mem len: 83338   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.43\n",
      "epis: 450   score: 1.0   mem len: 83510   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.43\n",
      "epis: 451   score: 3.0   mem len: 83737   epsilon: 1.0    steps: 227    lr: 0.0001     reward: 1.45\n",
      "epis: 452   score: 0.0   mem len: 83859   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.45\n",
      "epis: 453   score: 1.0   mem len: 84030   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.45\n",
      "epis: 454   score: 2.0   mem len: 84212   epsilon: 1.0    steps: 182    lr: 0.0001     reward: 1.46\n",
      "epis: 455   score: 2.0   mem len: 84432   epsilon: 1.0    steps: 220    lr: 0.0001     reward: 1.46\n",
      "epis: 456   score: 4.0   mem len: 84727   epsilon: 1.0    steps: 295    lr: 0.0001     reward: 1.47\n",
      "epis: 457   score: 3.0   mem len: 84972   epsilon: 1.0    steps: 245    lr: 0.0001     reward: 1.5\n",
      "epis: 458   score: 2.0   mem len: 85172   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.51\n",
      "epis: 459   score: 2.0   mem len: 85369   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.52\n",
      "epis: 460   score: 4.0   mem len: 85609   epsilon: 1.0    steps: 240    lr: 0.0001     reward: 1.54\n",
      "epis: 461   score: 1.0   mem len: 85760   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.54\n",
      "epis: 462   score: 0.0   mem len: 85882   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.52\n",
      "epis: 463   score: 3.0   mem len: 86128   epsilon: 1.0    steps: 246    lr: 0.0001     reward: 1.52\n",
      "epis: 464   score: 1.0   mem len: 86297   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.52\n",
      "epis: 465   score: 3.0   mem len: 86542   epsilon: 1.0    steps: 245    lr: 0.0001     reward: 1.55\n",
      "epis: 466   score: 1.0   mem len: 86712   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.54\n",
      "epis: 467   score: 0.0   mem len: 86834   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.53\n",
      "epis: 468   score: 1.0   mem len: 86984   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.52\n",
      "epis: 469   score: 5.0   mem len: 87311   epsilon: 1.0    steps: 327    lr: 0.0001     reward: 1.56\n",
      "epis: 470   score: 0.0   mem len: 87434   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.53\n",
      "epis: 471   score: 1.0   mem len: 87585   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.52\n",
      "epis: 472   score: 0.0   mem len: 87708   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.49\n",
      "epis: 473   score: 4.0   mem len: 88004   epsilon: 1.0    steps: 296    lr: 0.0001     reward: 1.53\n",
      "epis: 474   score: 0.0   mem len: 88126   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.52\n",
      "epis: 475   score: 2.0   mem len: 88305   epsilon: 1.0    steps: 179    lr: 0.0001     reward: 1.53\n",
      "epis: 476   score: 1.0   mem len: 88475   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.53\n",
      "epis: 477   score: 0.0   mem len: 88598   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.52\n",
      "epis: 478   score: 2.0   mem len: 88798   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.53\n",
      "epis: 479   score: 0.0   mem len: 88920   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.52\n",
      "epis: 480   score: 3.0   mem len: 89187   epsilon: 1.0    steps: 267    lr: 0.0001     reward: 1.55\n",
      "epis: 481   score: 7.0   mem len: 89486   epsilon: 1.0    steps: 299    lr: 0.0001     reward: 1.62\n",
      "epis: 482   score: 0.0   mem len: 89609   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.6\n",
      "epis: 483   score: 3.0   mem len: 89876   epsilon: 1.0    steps: 267    lr: 0.0001     reward: 1.6\n",
      "epis: 484   score: 2.0   mem len: 90076   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.6\n",
      "epis: 485   score: 0.0   mem len: 90198   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.58\n",
      "epis: 486   score: 1.0   mem len: 90349   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.59\n",
      "epis: 487   score: 0.0   mem len: 90472   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.58\n",
      "epis: 488   score: 1.0   mem len: 90641   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.58\n",
      "epis: 489   score: 2.0   mem len: 90839   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.58\n",
      "epis: 490   score: 1.0   mem len: 90989   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.59\n",
      "epis: 491   score: 2.0   mem len: 91187   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.59\n",
      "epis: 492   score: 0.0   mem len: 91309   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.59\n",
      "epis: 493   score: 0.0   mem len: 91432   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.56\n",
      "epis: 494   score: 1.0   mem len: 91582   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.56\n",
      "epis: 495   score: 2.0   mem len: 91779   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.58\n",
      "epis: 496   score: 1.0   mem len: 91947   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 497   score: 1.0   mem len: 92097   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.56\n",
      "epis: 498   score: 0.0   mem len: 92220   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.54\n",
      "epis: 499   score: 2.0   mem len: 92418   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.56\n",
      "epis: 500   score: 1.0   mem len: 92587   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.54\n",
      "epis: 501   score: 4.0   mem len: 92882   epsilon: 1.0    steps: 295    lr: 0.0001     reward: 1.57\n",
      "epis: 502   score: 0.0   mem len: 93005   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.55\n",
      "epis: 503   score: 2.0   mem len: 93203   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.56\n",
      "epis: 504   score: 0.0   mem len: 93326   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.56\n",
      "epis: 505   score: 1.0   mem len: 93495   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.57\n",
      "epis: 506   score: 2.0   mem len: 93677   epsilon: 1.0    steps: 182    lr: 0.0001     reward: 1.52\n",
      "epis: 507   score: 1.0   mem len: 93846   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.52\n",
      "epis: 508   score: 0.0   mem len: 93969   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.52\n",
      "epis: 509   score: 2.0   mem len: 94167   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.52\n",
      "epis: 510   score: 1.0   mem len: 94335   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.48\n",
      "epis: 511   score: 2.0   mem len: 94553   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.49\n",
      "epis: 512   score: 0.0   mem len: 94676   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.47\n",
      "epis: 513   score: 0.0   mem len: 94799   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.47\n",
      "epis: 514   score: 0.0   mem len: 94921   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.46\n",
      "epis: 515   score: 0.0   mem len: 95044   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.41\n",
      "epis: 516   score: 1.0   mem len: 95213   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.42\n",
      "epis: 517   score: 3.0   mem len: 95461   epsilon: 1.0    steps: 248    lr: 0.0001     reward: 1.41\n",
      "epis: 518   score: 0.0   mem len: 95584   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 519   score: 1.0   mem len: 95734   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.41\n",
      "epis: 520   score: 2.0   mem len: 95955   epsilon: 1.0    steps: 221    lr: 0.0001     reward: 1.39\n",
      "epis: 521   score: 0.0   mem len: 96078   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.39\n",
      "epis: 522   score: 1.0   mem len: 96249   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.4\n",
      "epis: 523   score: 2.0   mem len: 96467   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.42\n",
      "epis: 524   score: 0.0   mem len: 96590   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.42\n",
      "epis: 525   score: 1.0   mem len: 96761   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.41\n",
      "epis: 526   score: 2.0   mem len: 96961   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.41\n",
      "epis: 527   score: 2.0   mem len: 97160   epsilon: 1.0    steps: 199    lr: 0.0001     reward: 1.41\n",
      "epis: 528   score: 3.0   mem len: 97403   epsilon: 1.0    steps: 243    lr: 0.0001     reward: 1.44\n",
      "epis: 529   score: 3.0   mem len: 97654   epsilon: 1.0    steps: 251    lr: 0.0001     reward: 1.47\n",
      "epis: 530   score: 1.0   mem len: 97805   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.44\n",
      "epis: 531   score: 1.0   mem len: 97975   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.45\n",
      "epis: 532   score: 2.0   mem len: 98172   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.46\n",
      "epis: 533   score: 3.0   mem len: 98420   epsilon: 1.0    steps: 248    lr: 0.0001     reward: 1.48\n",
      "epis: 534   score: 2.0   mem len: 98617   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.5\n",
      "epis: 535   score: 4.0   mem len: 98914   epsilon: 1.0    steps: 297    lr: 0.0001     reward: 1.52\n",
      "epis: 536   score: 1.0   mem len: 99065   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.51\n",
      "epis: 537   score: 5.0   mem len: 99391   epsilon: 1.0    steps: 326    lr: 0.0001     reward: 1.54\n",
      "epis: 538   score: 0.0   mem len: 99513   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.52\n",
      "epis: 539   score: 4.0   mem len: 99806   epsilon: 1.0    steps: 293    lr: 0.0001     reward: 1.55\n",
      "epis: 540   score: 1.0   mem len: 99977   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiwenjon/Documents/Spring2023/Deep-Learning-for-CV/spring2023/MP5/assignment5_materials/assignment5_materials/memory.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sample = np.array(sample)\n",
      "/home/kaiwenjon/Documents/Spring2023/Deep-Learning-for-CV/spring2023/MP5/assignment5_materials/assignment5_materials/agent_double.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mini_batch = np.array(mini_batch).transpose()\n",
      "/home/kaiwenjon/Documents/Spring2023/Deep-Learning-for-CV/spring2023/MP5/assignment5_materials/assignment5_materials/agent_double.py:121: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  next_q_values[mask] = self.target_net(non_final_next_states).gather(1, next_action.unsqueeze(1)).cuda()[mask]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 541   score: 0.0   mem len: 100100   epsilon: 0.9998    steps: 123    lr: 0.0001     reward: 1.52\n",
      "epis: 542   score: 1.0   mem len: 100251   epsilon: 0.9995    steps: 151    lr: 0.0001     reward: 1.52\n",
      "epis: 543   score: 0.0   mem len: 100374   epsilon: 0.9993    steps: 123    lr: 0.0001     reward: 1.5\n",
      "epis: 544   score: 1.0   mem len: 100525   epsilon: 0.999    steps: 151    lr: 0.0001     reward: 1.51\n",
      "epis: 545   score: 1.0   mem len: 100693   epsilon: 0.9986    steps: 168    lr: 0.0001     reward: 1.51\n",
      "epis: 546   score: 1.0   mem len: 100862   epsilon: 0.9983    steps: 169    lr: 0.0001     reward: 1.49\n",
      "epis: 547   score: 3.0   mem len: 101108   epsilon: 0.9978    steps: 246    lr: 0.0001     reward: 1.51\n",
      "epis: 548   score: 1.0   mem len: 101277   epsilon: 0.9975    steps: 169    lr: 0.0001     reward: 1.48\n",
      "epis: 549   score: 1.0   mem len: 101428   epsilon: 0.9972    steps: 151    lr: 0.0001     reward: 1.48\n",
      "epis: 550   score: 1.0   mem len: 101579   epsilon: 0.9969    steps: 151    lr: 0.0001     reward: 1.48\n",
      "epis: 551   score: 4.0   mem len: 101876   epsilon: 0.9963    steps: 297    lr: 0.0001     reward: 1.49\n",
      "epis: 552   score: 1.0   mem len: 102044   epsilon: 0.996    steps: 168    lr: 0.0001     reward: 1.5\n",
      "epis: 553   score: 1.0   mem len: 102214   epsilon: 0.9956    steps: 170    lr: 0.0001     reward: 1.5\n",
      "epis: 554   score: 0.0   mem len: 102337   epsilon: 0.9954    steps: 123    lr: 0.0001     reward: 1.48\n",
      "epis: 555   score: 5.0   mem len: 102664   epsilon: 0.9947    steps: 327    lr: 0.0001     reward: 1.51\n",
      "epis: 556   score: 2.0   mem len: 102863   epsilon: 0.9943    steps: 199    lr: 0.0001     reward: 1.49\n",
      "epis: 557   score: 0.0   mem len: 102986   epsilon: 0.9941    steps: 123    lr: 0.0001     reward: 1.46\n",
      "epis: 558   score: 2.0   mem len: 103184   epsilon: 0.9937    steps: 198    lr: 0.0001     reward: 1.46\n",
      "epis: 559   score: 3.0   mem len: 103431   epsilon: 0.9932    steps: 247    lr: 0.0001     reward: 1.47\n",
      "epis: 560   score: 0.0   mem len: 103554   epsilon: 0.993    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 561   score: 1.0   mem len: 103704   epsilon: 0.9927    steps: 150    lr: 0.0001     reward: 1.43\n",
      "epis: 562   score: 2.0   mem len: 103901   epsilon: 0.9923    steps: 197    lr: 0.0001     reward: 1.45\n",
      "epis: 563   score: 4.0   mem len: 104157   epsilon: 0.9918    steps: 256    lr: 0.0001     reward: 1.46\n",
      "epis: 564   score: 2.0   mem len: 104375   epsilon: 0.9913    steps: 218    lr: 0.0001     reward: 1.47\n",
      "epis: 565   score: 2.0   mem len: 104572   epsilon: 0.9909    steps: 197    lr: 0.0001     reward: 1.46\n",
      "epis: 566   score: 1.0   mem len: 104743   epsilon: 0.9906    steps: 171    lr: 0.0001     reward: 1.46\n",
      "epis: 567   score: 1.0   mem len: 104911   epsilon: 0.9903    steps: 168    lr: 0.0001     reward: 1.47\n",
      "epis: 568   score: 2.0   mem len: 105131   epsilon: 0.9898    steps: 220    lr: 0.0001     reward: 1.48\n",
      "epis: 569   score: 0.0   mem len: 105254   epsilon: 0.9896    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 570   score: 0.0   mem len: 105376   epsilon: 0.9894    steps: 122    lr: 0.0001     reward: 1.43\n",
      "epis: 571   score: 2.0   mem len: 105594   epsilon: 0.9889    steps: 218    lr: 0.0001     reward: 1.44\n",
      "epis: 572   score: 0.0   mem len: 105717   epsilon: 0.9887    steps: 123    lr: 0.0001     reward: 1.44\n",
      "epis: 573   score: 2.0   mem len: 105914   epsilon: 0.9883    steps: 197    lr: 0.0001     reward: 1.42\n",
      "epis: 574   score: 3.0   mem len: 106141   epsilon: 0.9878    steps: 227    lr: 0.0001     reward: 1.45\n",
      "epis: 575   score: 1.0   mem len: 106310   epsilon: 0.9875    steps: 169    lr: 0.0001     reward: 1.44\n",
      "epis: 576   score: 0.0   mem len: 106433   epsilon: 0.9873    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 577   score: 1.0   mem len: 106602   epsilon: 0.9869    steps: 169    lr: 0.0001     reward: 1.44\n",
      "epis: 578   score: 0.0   mem len: 106725   epsilon: 0.9867    steps: 123    lr: 0.0001     reward: 1.42\n",
      "epis: 579   score: 1.0   mem len: 106894   epsilon: 0.9863    steps: 169    lr: 0.0001     reward: 1.43\n",
      "epis: 580   score: 2.0   mem len: 107092   epsilon: 0.986    steps: 198    lr: 0.0001     reward: 1.42\n",
      "epis: 581   score: 2.0   mem len: 107310   epsilon: 0.9855    steps: 218    lr: 0.0001     reward: 1.37\n",
      "epis: 582   score: 2.0   mem len: 107508   epsilon: 0.9851    steps: 198    lr: 0.0001     reward: 1.39\n",
      "epis: 583   score: 1.0   mem len: 107659   epsilon: 0.9848    steps: 151    lr: 0.0001     reward: 1.37\n",
      "epis: 584   score: 3.0   mem len: 107906   epsilon: 0.9843    steps: 247    lr: 0.0001     reward: 1.38\n",
      "epis: 585   score: 2.0   mem len: 108103   epsilon: 0.984    steps: 197    lr: 0.0001     reward: 1.4\n",
      "epis: 586   score: 0.0   mem len: 108226   epsilon: 0.9837    steps: 123    lr: 0.0001     reward: 1.39\n",
      "epis: 587   score: 0.0   mem len: 108349   epsilon: 0.9835    steps: 123    lr: 0.0001     reward: 1.39\n",
      "epis: 588   score: 1.0   mem len: 108519   epsilon: 0.9831    steps: 170    lr: 0.0001     reward: 1.39\n",
      "epis: 589   score: 2.0   mem len: 108717   epsilon: 0.9827    steps: 198    lr: 0.0001     reward: 1.39\n",
      "epis: 590   score: 1.0   mem len: 108869   epsilon: 0.9824    steps: 152    lr: 0.0001     reward: 1.39\n",
      "epis: 591   score: 1.0   mem len: 109019   epsilon: 0.9821    steps: 150    lr: 0.0001     reward: 1.38\n",
      "epis: 592   score: 1.0   mem len: 109191   epsilon: 0.9818    steps: 172    lr: 0.0001     reward: 1.39\n",
      "epis: 593   score: 3.0   mem len: 109435   epsilon: 0.9813    steps: 244    lr: 0.0001     reward: 1.42\n",
      "epis: 594   score: 0.0   mem len: 109558   epsilon: 0.9811    steps: 123    lr: 0.0001     reward: 1.41\n",
      "epis: 595   score: 2.0   mem len: 109756   epsilon: 0.9807    steps: 198    lr: 0.0001     reward: 1.41\n",
      "epis: 596   score: 0.0   mem len: 109879   epsilon: 0.9804    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 597   score: 1.0   mem len: 110048   epsilon: 0.9801    steps: 169    lr: 0.0001     reward: 1.4\n",
      "epis: 598   score: 2.0   mem len: 110245   epsilon: 0.9797    steps: 197    lr: 0.0001     reward: 1.42\n",
      "epis: 599   score: 2.0   mem len: 110442   epsilon: 0.9793    steps: 197    lr: 0.0001     reward: 1.42\n",
      "epis: 600   score: 1.0   mem len: 110593   epsilon: 0.979    steps: 151    lr: 0.0001     reward: 1.42\n",
      "epis: 601   score: 0.0   mem len: 110716   epsilon: 0.9788    steps: 123    lr: 0.0001     reward: 1.38\n",
      "epis: 602   score: 1.0   mem len: 110886   epsilon: 0.9784    steps: 170    lr: 0.0001     reward: 1.39\n",
      "epis: 603   score: 0.0   mem len: 111009   epsilon: 0.9782    steps: 123    lr: 0.0001     reward: 1.37\n",
      "epis: 604   score: 0.0   mem len: 111131   epsilon: 0.978    steps: 122    lr: 0.0001     reward: 1.37\n",
      "epis: 605   score: 1.0   mem len: 111299   epsilon: 0.9776    steps: 168    lr: 0.0001     reward: 1.37\n",
      "epis: 606   score: 5.0   mem len: 111621   epsilon: 0.977    steps: 322    lr: 0.0001     reward: 1.4\n",
      "epis: 607   score: 5.0   mem len: 111935   epsilon: 0.9764    steps: 314    lr: 0.0001     reward: 1.44\n",
      "epis: 608   score: 2.0   mem len: 112153   epsilon: 0.9759    steps: 218    lr: 0.0001     reward: 1.46\n",
      "epis: 609   score: 1.0   mem len: 112324   epsilon: 0.9756    steps: 171    lr: 0.0001     reward: 1.45\n",
      "epis: 610   score: 1.0   mem len: 112493   epsilon: 0.9753    steps: 169    lr: 0.0001     reward: 1.45\n",
      "epis: 611   score: 0.0   mem len: 112615   epsilon: 0.975    steps: 122    lr: 0.0001     reward: 1.43\n",
      "epis: 612   score: 1.0   mem len: 112787   epsilon: 0.9747    steps: 172    lr: 0.0001     reward: 1.44\n",
      "epis: 613   score: 1.0   mem len: 112956   epsilon: 0.9743    steps: 169    lr: 0.0001     reward: 1.45\n",
      "epis: 614   score: 0.0   mem len: 113078   epsilon: 0.9741    steps: 122    lr: 0.0001     reward: 1.45\n",
      "epis: 615   score: 1.0   mem len: 113228   epsilon: 0.9738    steps: 150    lr: 0.0001     reward: 1.46\n",
      "epis: 616   score: 1.0   mem len: 113397   epsilon: 0.9735    steps: 169    lr: 0.0001     reward: 1.46\n",
      "epis: 617   score: 0.0   mem len: 113520   epsilon: 0.9732    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 618   score: 1.0   mem len: 113670   epsilon: 0.9729    steps: 150    lr: 0.0001     reward: 1.44\n",
      "epis: 619   score: 3.0   mem len: 113937   epsilon: 0.9724    steps: 267    lr: 0.0001     reward: 1.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 620   score: 3.0   mem len: 114181   epsilon: 0.9719    steps: 244    lr: 0.0001     reward: 1.47\n",
      "epis: 621   score: 0.0   mem len: 114304   epsilon: 0.9717    steps: 123    lr: 0.0001     reward: 1.47\n",
      "epis: 622   score: 0.0   mem len: 114427   epsilon: 0.9714    steps: 123    lr: 0.0001     reward: 1.46\n",
      "epis: 623   score: 3.0   mem len: 114677   epsilon: 0.9709    steps: 250    lr: 0.0001     reward: 1.47\n",
      "epis: 624   score: 4.0   mem len: 114977   epsilon: 0.9703    steps: 300    lr: 0.0001     reward: 1.51\n",
      "epis: 625   score: 2.0   mem len: 115178   epsilon: 0.9699    steps: 201    lr: 0.0001     reward: 1.52\n",
      "epis: 626   score: 0.0   mem len: 115301   epsilon: 0.9697    steps: 123    lr: 0.0001     reward: 1.5\n",
      "epis: 627   score: 0.0   mem len: 115424   epsilon: 0.9695    steps: 123    lr: 0.0001     reward: 1.48\n",
      "epis: 628   score: 1.0   mem len: 115594   epsilon: 0.9691    steps: 170    lr: 0.0001     reward: 1.46\n",
      "epis: 629   score: 4.0   mem len: 115888   epsilon: 0.9685    steps: 294    lr: 0.0001     reward: 1.47\n",
      "epis: 630   score: 1.0   mem len: 116038   epsilon: 0.9682    steps: 150    lr: 0.0001     reward: 1.47\n",
      "epis: 631   score: 2.0   mem len: 116259   epsilon: 0.9678    steps: 221    lr: 0.0001     reward: 1.48\n",
      "epis: 632   score: 1.0   mem len: 116428   epsilon: 0.9675    steps: 169    lr: 0.0001     reward: 1.47\n",
      "epis: 633   score: 2.0   mem len: 116647   epsilon: 0.967    steps: 219    lr: 0.0001     reward: 1.46\n",
      "epis: 634   score: 2.0   mem len: 116845   epsilon: 0.9666    steps: 198    lr: 0.0001     reward: 1.46\n",
      "epis: 635   score: 1.0   mem len: 117016   epsilon: 0.9663    steps: 171    lr: 0.0001     reward: 1.43\n",
      "epis: 636   score: 1.0   mem len: 117167   epsilon: 0.966    steps: 151    lr: 0.0001     reward: 1.43\n",
      "epis: 637   score: 1.0   mem len: 117337   epsilon: 0.9657    steps: 170    lr: 0.0001     reward: 1.39\n",
      "epis: 638   score: 1.0   mem len: 117505   epsilon: 0.9653    steps: 168    lr: 0.0001     reward: 1.4\n",
      "epis: 639   score: 0.0   mem len: 117628   epsilon: 0.9651    steps: 123    lr: 0.0001     reward: 1.36\n",
      "epis: 640   score: 0.0   mem len: 117751   epsilon: 0.9649    steps: 123    lr: 0.0001     reward: 1.35\n",
      "epis: 641   score: 1.0   mem len: 117921   epsilon: 0.9645    steps: 170    lr: 0.0001     reward: 1.36\n",
      "epis: 642   score: 0.0   mem len: 118043   epsilon: 0.9643    steps: 122    lr: 0.0001     reward: 1.35\n",
      "epis: 643   score: 0.0   mem len: 118166   epsilon: 0.964    steps: 123    lr: 0.0001     reward: 1.35\n",
      "epis: 644   score: 0.0   mem len: 118288   epsilon: 0.9638    steps: 122    lr: 0.0001     reward: 1.34\n",
      "epis: 645   score: 3.0   mem len: 118538   epsilon: 0.9633    steps: 250    lr: 0.0001     reward: 1.36\n",
      "epis: 646   score: 0.0   mem len: 118660   epsilon: 0.9631    steps: 122    lr: 0.0001     reward: 1.35\n",
      "epis: 647   score: 0.0   mem len: 118783   epsilon: 0.9628    steps: 123    lr: 0.0001     reward: 1.32\n",
      "epis: 648   score: 3.0   mem len: 119010   epsilon: 0.9624    steps: 227    lr: 0.0001     reward: 1.34\n",
      "epis: 649   score: 4.0   mem len: 119306   epsilon: 0.9618    steps: 296    lr: 0.0001     reward: 1.37\n",
      "epis: 650   score: 1.0   mem len: 119478   epsilon: 0.9614    steps: 172    lr: 0.0001     reward: 1.37\n",
      "epis: 651   score: 1.0   mem len: 119646   epsilon: 0.9611    steps: 168    lr: 0.0001     reward: 1.34\n",
      "epis: 652   score: 0.0   mem len: 119769   epsilon: 0.9609    steps: 123    lr: 0.0001     reward: 1.33\n",
      "epis: 653   score: 1.0   mem len: 119920   epsilon: 0.9606    steps: 151    lr: 0.0001     reward: 1.33\n",
      "epis: 654   score: 3.0   mem len: 120166   epsilon: 0.9601    steps: 246    lr: 0.0001     reward: 1.36\n",
      "epis: 655   score: 4.0   mem len: 120483   epsilon: 0.9594    steps: 317    lr: 0.0001     reward: 1.35\n",
      "epis: 656   score: 0.0   mem len: 120605   epsilon: 0.9592    steps: 122    lr: 0.0001     reward: 1.33\n",
      "epis: 657   score: 0.0   mem len: 120728   epsilon: 0.959    steps: 123    lr: 0.0001     reward: 1.33\n",
      "epis: 658   score: 2.0   mem len: 120909   epsilon: 0.9586    steps: 181    lr: 0.0001     reward: 1.33\n",
      "epis: 659   score: 0.0   mem len: 121031   epsilon: 0.9584    steps: 122    lr: 0.0001     reward: 1.3\n",
      "epis: 660   score: 1.0   mem len: 121181   epsilon: 0.9581    steps: 150    lr: 0.0001     reward: 1.31\n",
      "epis: 661   score: 2.0   mem len: 121399   epsilon: 0.9576    steps: 218    lr: 0.0001     reward: 1.32\n",
      "epis: 662   score: 2.0   mem len: 121599   epsilon: 0.9572    steps: 200    lr: 0.0001     reward: 1.32\n",
      "epis: 663   score: 0.0   mem len: 121721   epsilon: 0.957    steps: 122    lr: 0.0001     reward: 1.28\n",
      "epis: 664   score: 2.0   mem len: 121940   epsilon: 0.9566    steps: 219    lr: 0.0001     reward: 1.28\n",
      "epis: 665   score: 2.0   mem len: 122137   epsilon: 0.9562    steps: 197    lr: 0.0001     reward: 1.28\n",
      "epis: 666   score: 4.0   mem len: 122433   epsilon: 0.9556    steps: 296    lr: 0.0001     reward: 1.31\n",
      "epis: 667   score: 1.0   mem len: 122604   epsilon: 0.9552    steps: 171    lr: 0.0001     reward: 1.31\n",
      "epis: 668   score: 2.0   mem len: 122801   epsilon: 0.9549    steps: 197    lr: 0.0001     reward: 1.31\n",
      "epis: 669   score: 2.0   mem len: 122999   epsilon: 0.9545    steps: 198    lr: 0.0001     reward: 1.33\n",
      "epis: 670   score: 2.0   mem len: 123197   epsilon: 0.9541    steps: 198    lr: 0.0001     reward: 1.35\n",
      "epis: 671   score: 1.0   mem len: 123367   epsilon: 0.9537    steps: 170    lr: 0.0001     reward: 1.34\n",
      "epis: 672   score: 1.0   mem len: 123538   epsilon: 0.9534    steps: 171    lr: 0.0001     reward: 1.35\n",
      "epis: 673   score: 2.0   mem len: 123736   epsilon: 0.953    steps: 198    lr: 0.0001     reward: 1.35\n",
      "epis: 674   score: 3.0   mem len: 124001   epsilon: 0.9525    steps: 265    lr: 0.0001     reward: 1.35\n",
      "epis: 675   score: 3.0   mem len: 124246   epsilon: 0.952    steps: 245    lr: 0.0001     reward: 1.37\n",
      "epis: 676   score: 1.0   mem len: 124397   epsilon: 0.9517    steps: 151    lr: 0.0001     reward: 1.38\n",
      "epis: 677   score: 1.0   mem len: 124566   epsilon: 0.9514    steps: 169    lr: 0.0001     reward: 1.38\n",
      "epis: 678   score: 1.0   mem len: 124717   epsilon: 0.9511    steps: 151    lr: 0.0001     reward: 1.39\n",
      "epis: 679   score: 5.0   mem len: 125063   epsilon: 0.9504    steps: 346    lr: 0.0001     reward: 1.43\n",
      "epis: 680   score: 1.0   mem len: 125232   epsilon: 0.95    steps: 169    lr: 0.0001     reward: 1.42\n",
      "epis: 681   score: 2.0   mem len: 125449   epsilon: 0.9496    steps: 217    lr: 0.0001     reward: 1.42\n",
      "epis: 682   score: 1.0   mem len: 125600   epsilon: 0.9493    steps: 151    lr: 0.0001     reward: 1.41\n",
      "epis: 683   score: 2.0   mem len: 125818   epsilon: 0.9489    steps: 218    lr: 0.0001     reward: 1.42\n",
      "epis: 684   score: 4.0   mem len: 126108   epsilon: 0.9483    steps: 290    lr: 0.0001     reward: 1.43\n",
      "epis: 685   score: 2.0   mem len: 126306   epsilon: 0.9479    steps: 198    lr: 0.0001     reward: 1.43\n",
      "epis: 686   score: 2.0   mem len: 126524   epsilon: 0.9475    steps: 218    lr: 0.0001     reward: 1.45\n",
      "epis: 687   score: 1.0   mem len: 126692   epsilon: 0.9471    steps: 168    lr: 0.0001     reward: 1.46\n",
      "epis: 688   score: 3.0   mem len: 126919   epsilon: 0.9467    steps: 227    lr: 0.0001     reward: 1.48\n",
      "epis: 689   score: 2.0   mem len: 127136   epsilon: 0.9463    steps: 217    lr: 0.0001     reward: 1.48\n",
      "epis: 690   score: 2.0   mem len: 127334   epsilon: 0.9459    steps: 198    lr: 0.0001     reward: 1.49\n",
      "epis: 691   score: 2.0   mem len: 127532   epsilon: 0.9455    steps: 198    lr: 0.0001     reward: 1.5\n",
      "epis: 692   score: 3.0   mem len: 127778   epsilon: 0.945    steps: 246    lr: 0.0001     reward: 1.52\n",
      "epis: 693   score: 7.0   mem len: 128160   epsilon: 0.9442    steps: 382    lr: 0.0001     reward: 1.56\n",
      "epis: 694   score: 0.0   mem len: 128282   epsilon: 0.944    steps: 122    lr: 0.0001     reward: 1.56\n",
      "epis: 695   score: 1.0   mem len: 128451   epsilon: 0.9437    steps: 169    lr: 0.0001     reward: 1.55\n",
      "epis: 696   score: 2.0   mem len: 128633   epsilon: 0.9433    steps: 182    lr: 0.0001     reward: 1.57\n",
      "epis: 697   score: 0.0   mem len: 128756   epsilon: 0.9431    steps: 123    lr: 0.0001     reward: 1.56\n",
      "epis: 698   score: 2.0   mem len: 128956   epsilon: 0.9427    steps: 200    lr: 0.0001     reward: 1.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 699   score: 0.0   mem len: 129078   epsilon: 0.9424    steps: 122    lr: 0.0001     reward: 1.54\n",
      "epis: 700   score: 2.0   mem len: 129277   epsilon: 0.942    steps: 199    lr: 0.0001     reward: 1.55\n",
      "epis: 701   score: 0.0   mem len: 129400   epsilon: 0.9418    steps: 123    lr: 0.0001     reward: 1.55\n",
      "epis: 702   score: 0.0   mem len: 129523   epsilon: 0.9415    steps: 123    lr: 0.0001     reward: 1.54\n",
      "epis: 703   score: 1.0   mem len: 129674   epsilon: 0.9412    steps: 151    lr: 0.0001     reward: 1.55\n",
      "epis: 704   score: 0.0   mem len: 129797   epsilon: 0.941    steps: 123    lr: 0.0001     reward: 1.55\n",
      "epis: 705   score: 1.0   mem len: 129948   epsilon: 0.9407    steps: 151    lr: 0.0001     reward: 1.55\n",
      "epis: 706   score: 1.0   mem len: 130118   epsilon: 0.9404    steps: 170    lr: 0.0001     reward: 1.51\n",
      "epis: 707   score: 1.0   mem len: 130289   epsilon: 0.94    steps: 171    lr: 0.0001     reward: 1.47\n",
      "epis: 708   score: 5.0   mem len: 130609   epsilon: 0.9394    steps: 320    lr: 0.0001     reward: 1.5\n",
      "epis: 709   score: 0.0   mem len: 130732   epsilon: 0.9391    steps: 123    lr: 0.0001     reward: 1.49\n",
      "epis: 710   score: 0.0   mem len: 130854   epsilon: 0.9389    steps: 122    lr: 0.0001     reward: 1.48\n",
      "epis: 711   score: 2.0   mem len: 131053   epsilon: 0.9385    steps: 199    lr: 0.0001     reward: 1.5\n",
      "epis: 712   score: 0.0   mem len: 131176   epsilon: 0.9383    steps: 123    lr: 0.0001     reward: 1.49\n",
      "epis: 713   score: 1.0   mem len: 131345   epsilon: 0.9379    steps: 169    lr: 0.0001     reward: 1.49\n",
      "epis: 714   score: 1.0   mem len: 131497   epsilon: 0.9376    steps: 152    lr: 0.0001     reward: 1.5\n",
      "epis: 715   score: 4.0   mem len: 131753   epsilon: 0.9371    steps: 256    lr: 0.0001     reward: 1.53\n",
      "epis: 716   score: 7.0   mem len: 132172   epsilon: 0.9363    steps: 419    lr: 0.0001     reward: 1.59\n",
      "epis: 717   score: 1.0   mem len: 132323   epsilon: 0.936    steps: 151    lr: 0.0001     reward: 1.6\n",
      "epis: 718   score: 0.0   mem len: 132446   epsilon: 0.9358    steps: 123    lr: 0.0001     reward: 1.59\n",
      "epis: 719   score: 2.0   mem len: 132644   epsilon: 0.9354    steps: 198    lr: 0.0001     reward: 1.58\n",
      "epis: 720   score: 0.0   mem len: 132767   epsilon: 0.9351    steps: 123    lr: 0.0001     reward: 1.55\n",
      "epis: 721   score: 3.0   mem len: 132992   epsilon: 0.9347    steps: 225    lr: 0.0001     reward: 1.58\n",
      "epis: 722   score: 1.0   mem len: 133143   epsilon: 0.9344    steps: 151    lr: 0.0001     reward: 1.59\n",
      "epis: 723   score: 1.0   mem len: 133294   epsilon: 0.9341    steps: 151    lr: 0.0001     reward: 1.57\n",
      "epis: 724   score: 3.0   mem len: 133543   epsilon: 0.9336    steps: 249    lr: 0.0001     reward: 1.56\n",
      "epis: 725   score: 1.0   mem len: 133711   epsilon: 0.9333    steps: 168    lr: 0.0001     reward: 1.55\n",
      "epis: 726   score: 1.0   mem len: 133880   epsilon: 0.9329    steps: 169    lr: 0.0001     reward: 1.56\n",
      "epis: 727   score: 2.0   mem len: 134078   epsilon: 0.9325    steps: 198    lr: 0.0001     reward: 1.58\n",
      "epis: 728   score: 2.0   mem len: 134276   epsilon: 0.9321    steps: 198    lr: 0.0001     reward: 1.59\n",
      "epis: 729   score: 0.0   mem len: 134399   epsilon: 0.9319    steps: 123    lr: 0.0001     reward: 1.55\n",
      "epis: 730   score: 4.0   mem len: 134674   epsilon: 0.9313    steps: 275    lr: 0.0001     reward: 1.58\n",
      "epis: 731   score: 2.0   mem len: 134857   epsilon: 0.931    steps: 183    lr: 0.0001     reward: 1.58\n",
      "epis: 732   score: 1.0   mem len: 135008   epsilon: 0.9307    steps: 151    lr: 0.0001     reward: 1.58\n",
      "epis: 733   score: 1.0   mem len: 135158   epsilon: 0.9304    steps: 150    lr: 0.0001     reward: 1.57\n",
      "epis: 734   score: 1.0   mem len: 135327   epsilon: 0.9301    steps: 169    lr: 0.0001     reward: 1.56\n",
      "epis: 735   score: 1.0   mem len: 135497   epsilon: 0.9297    steps: 170    lr: 0.0001     reward: 1.56\n",
      "epis: 736   score: 0.0   mem len: 135619   epsilon: 0.9295    steps: 122    lr: 0.0001     reward: 1.55\n",
      "epis: 737   score: 0.0   mem len: 135741   epsilon: 0.9292    steps: 122    lr: 0.0001     reward: 1.54\n",
      "epis: 738   score: 0.0   mem len: 135864   epsilon: 0.929    steps: 123    lr: 0.0001     reward: 1.53\n",
      "epis: 739   score: 1.0   mem len: 136033   epsilon: 0.9287    steps: 169    lr: 0.0001     reward: 1.54\n",
      "epis: 740   score: 4.0   mem len: 136328   epsilon: 0.9281    steps: 295    lr: 0.0001     reward: 1.58\n",
      "epis: 741   score: 2.0   mem len: 136526   epsilon: 0.9277    steps: 198    lr: 0.0001     reward: 1.59\n",
      "epis: 742   score: 0.0   mem len: 136648   epsilon: 0.9274    steps: 122    lr: 0.0001     reward: 1.59\n",
      "epis: 743   score: 2.0   mem len: 136845   epsilon: 0.927    steps: 197    lr: 0.0001     reward: 1.61\n",
      "epis: 744   score: 3.0   mem len: 137109   epsilon: 0.9265    steps: 264    lr: 0.0001     reward: 1.64\n",
      "epis: 745   score: 0.0   mem len: 137231   epsilon: 0.9263    steps: 122    lr: 0.0001     reward: 1.61\n",
      "epis: 746   score: 1.0   mem len: 137400   epsilon: 0.9259    steps: 169    lr: 0.0001     reward: 1.62\n",
      "epis: 747   score: 2.0   mem len: 137617   epsilon: 0.9255    steps: 217    lr: 0.0001     reward: 1.64\n",
      "epis: 748   score: 0.0   mem len: 137739   epsilon: 0.9253    steps: 122    lr: 0.0001     reward: 1.61\n",
      "epis: 749   score: 5.0   mem len: 138065   epsilon: 0.9246    steps: 326    lr: 0.0001     reward: 1.62\n",
      "epis: 750   score: 3.0   mem len: 138312   epsilon: 0.9241    steps: 247    lr: 0.0001     reward: 1.64\n",
      "epis: 751   score: 0.0   mem len: 138435   epsilon: 0.9239    steps: 123    lr: 0.0001     reward: 1.63\n",
      "epis: 752   score: 2.0   mem len: 138633   epsilon: 0.9235    steps: 198    lr: 0.0001     reward: 1.65\n",
      "epis: 753   score: 2.0   mem len: 138849   epsilon: 0.9231    steps: 216    lr: 0.0001     reward: 1.66\n",
      "epis: 754   score: 4.0   mem len: 139145   epsilon: 0.9225    steps: 296    lr: 0.0001     reward: 1.67\n",
      "epis: 755   score: 1.0   mem len: 139297   epsilon: 0.9222    steps: 152    lr: 0.0001     reward: 1.64\n",
      "epis: 756   score: 3.0   mem len: 139566   epsilon: 0.9217    steps: 269    lr: 0.0001     reward: 1.67\n",
      "epis: 757   score: 3.0   mem len: 139816   epsilon: 0.9212    steps: 250    lr: 0.0001     reward: 1.7\n",
      "epis: 758   score: 0.0   mem len: 139939   epsilon: 0.9209    steps: 123    lr: 0.0001     reward: 1.68\n",
      "epis: 759   score: 2.0   mem len: 140137   epsilon: 0.9205    steps: 198    lr: 0.0001     reward: 1.7\n",
      "epis: 760   score: 3.0   mem len: 140364   epsilon: 0.9201    steps: 227    lr: 0.0001     reward: 1.72\n",
      "epis: 761   score: 1.0   mem len: 140533   epsilon: 0.9197    steps: 169    lr: 0.0001     reward: 1.71\n",
      "epis: 762   score: 2.0   mem len: 140731   epsilon: 0.9194    steps: 198    lr: 0.0001     reward: 1.71\n",
      "epis: 763   score: 0.0   mem len: 140854   epsilon: 0.9191    steps: 123    lr: 0.0001     reward: 1.71\n",
      "epis: 764   score: 2.0   mem len: 141051   epsilon: 0.9187    steps: 197    lr: 0.0001     reward: 1.71\n",
      "epis: 765   score: 0.0   mem len: 141174   epsilon: 0.9185    steps: 123    lr: 0.0001     reward: 1.69\n",
      "epis: 766   score: 1.0   mem len: 141344   epsilon: 0.9181    steps: 170    lr: 0.0001     reward: 1.66\n",
      "epis: 767   score: 3.0   mem len: 141591   epsilon: 0.9176    steps: 247    lr: 0.0001     reward: 1.68\n",
      "epis: 768   score: 3.0   mem len: 141817   epsilon: 0.9172    steps: 226    lr: 0.0001     reward: 1.69\n",
      "epis: 769   score: 2.0   mem len: 142020   epsilon: 0.9168    steps: 203    lr: 0.0001     reward: 1.69\n",
      "epis: 770   score: 0.0   mem len: 142143   epsilon: 0.9166    steps: 123    lr: 0.0001     reward: 1.67\n",
      "epis: 771   score: 3.0   mem len: 142371   epsilon: 0.9161    steps: 228    lr: 0.0001     reward: 1.69\n",
      "epis: 772   score: 3.0   mem len: 142597   epsilon: 0.9157    steps: 226    lr: 0.0001     reward: 1.71\n",
      "epis: 773   score: 1.0   mem len: 142766   epsilon: 0.9153    steps: 169    lr: 0.0001     reward: 1.7\n",
      "epis: 774   score: 1.0   mem len: 142936   epsilon: 0.915    steps: 170    lr: 0.0001     reward: 1.68\n",
      "epis: 775   score: 0.0   mem len: 143059   epsilon: 0.9147    steps: 123    lr: 0.0001     reward: 1.65\n",
      "epis: 776   score: 1.0   mem len: 143210   epsilon: 0.9144    steps: 151    lr: 0.0001     reward: 1.65\n",
      "epis: 777   score: 1.0   mem len: 143380   epsilon: 0.9141    steps: 170    lr: 0.0001     reward: 1.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 778   score: 0.0   mem len: 143503   epsilon: 0.9139    steps: 123    lr: 0.0001     reward: 1.64\n",
      "epis: 779   score: 3.0   mem len: 143749   epsilon: 0.9134    steps: 246    lr: 0.0001     reward: 1.62\n",
      "epis: 780   score: 1.0   mem len: 143918   epsilon: 0.913    steps: 169    lr: 0.0001     reward: 1.62\n",
      "epis: 781   score: 2.0   mem len: 144136   epsilon: 0.9126    steps: 218    lr: 0.0001     reward: 1.62\n",
      "epis: 782   score: 1.0   mem len: 144287   epsilon: 0.9123    steps: 151    lr: 0.0001     reward: 1.62\n",
      "epis: 783   score: 3.0   mem len: 144533   epsilon: 0.9118    steps: 246    lr: 0.0001     reward: 1.63\n",
      "epis: 784   score: 3.0   mem len: 144760   epsilon: 0.9114    steps: 227    lr: 0.0001     reward: 1.62\n",
      "epis: 785   score: 4.0   mem len: 145055   epsilon: 0.9108    steps: 295    lr: 0.0001     reward: 1.64\n",
      "epis: 786   score: 3.0   mem len: 145300   epsilon: 0.9103    steps: 245    lr: 0.0001     reward: 1.65\n",
      "epis: 787   score: 0.0   mem len: 145422   epsilon: 0.9101    steps: 122    lr: 0.0001     reward: 1.64\n",
      "epis: 788   score: 0.0   mem len: 145544   epsilon: 0.9098    steps: 122    lr: 0.0001     reward: 1.61\n",
      "epis: 789   score: 0.0   mem len: 145666   epsilon: 0.9096    steps: 122    lr: 0.0001     reward: 1.59\n",
      "epis: 790   score: 3.0   mem len: 145911   epsilon: 0.9091    steps: 245    lr: 0.0001     reward: 1.6\n",
      "epis: 791   score: 8.0   mem len: 146255   epsilon: 0.9084    steps: 344    lr: 0.0001     reward: 1.66\n",
      "epis: 792   score: 1.0   mem len: 146424   epsilon: 0.9081    steps: 169    lr: 0.0001     reward: 1.64\n",
      "epis: 793   score: 0.0   mem len: 146546   epsilon: 0.9078    steps: 122    lr: 0.0001     reward: 1.57\n",
      "epis: 794   score: 3.0   mem len: 146792   epsilon: 0.9073    steps: 246    lr: 0.0001     reward: 1.6\n",
      "epis: 795   score: 2.0   mem len: 146991   epsilon: 0.907    steps: 199    lr: 0.0001     reward: 1.61\n",
      "epis: 796   score: 1.0   mem len: 147142   epsilon: 0.9067    steps: 151    lr: 0.0001     reward: 1.6\n",
      "epis: 797   score: 2.0   mem len: 147360   epsilon: 0.9062    steps: 218    lr: 0.0001     reward: 1.62\n",
      "epis: 798   score: 1.0   mem len: 147531   epsilon: 0.9059    steps: 171    lr: 0.0001     reward: 1.61\n",
      "epis: 799   score: 3.0   mem len: 147796   epsilon: 0.9054    steps: 265    lr: 0.0001     reward: 1.64\n",
      "epis: 800   score: 0.0   mem len: 147919   epsilon: 0.9051    steps: 123    lr: 0.0001     reward: 1.62\n",
      "epis: 801   score: 2.0   mem len: 148136   epsilon: 0.9047    steps: 217    lr: 0.0001     reward: 1.64\n",
      "epis: 802   score: 2.0   mem len: 148357   epsilon: 0.9043    steps: 221    lr: 0.0001     reward: 1.66\n",
      "epis: 803   score: 0.0   mem len: 148479   epsilon: 0.904    steps: 122    lr: 0.0001     reward: 1.65\n",
      "epis: 804   score: 1.0   mem len: 148651   epsilon: 0.9037    steps: 172    lr: 0.0001     reward: 1.66\n",
      "epis: 805   score: 0.0   mem len: 148774   epsilon: 0.9034    steps: 123    lr: 0.0001     reward: 1.65\n",
      "epis: 806   score: 2.0   mem len: 148993   epsilon: 0.903    steps: 219    lr: 0.0001     reward: 1.66\n",
      "epis: 807   score: 0.0   mem len: 149116   epsilon: 0.9027    steps: 123    lr: 0.0001     reward: 1.65\n",
      "epis: 808   score: 1.0   mem len: 149267   epsilon: 0.9024    steps: 151    lr: 0.0001     reward: 1.61\n",
      "epis: 809   score: 0.0   mem len: 149389   epsilon: 0.9022    steps: 122    lr: 0.0001     reward: 1.61\n",
      "epis: 810   score: 0.0   mem len: 149511   epsilon: 0.902    steps: 122    lr: 0.0001     reward: 1.61\n",
      "epis: 811   score: 0.0   mem len: 149633   epsilon: 0.9017    steps: 122    lr: 0.0001     reward: 1.59\n",
      "epis: 812   score: 2.0   mem len: 149830   epsilon: 0.9013    steps: 197    lr: 0.0001     reward: 1.61\n",
      "epis: 813   score: 2.0   mem len: 150027   epsilon: 0.9009    steps: 197    lr: 0.0001     reward: 1.62\n",
      "epis: 814   score: 3.0   mem len: 150293   epsilon: 0.9004    steps: 266    lr: 0.0001     reward: 1.64\n",
      "epis: 815   score: 4.0   mem len: 150588   epsilon: 0.8998    steps: 295    lr: 0.0001     reward: 1.64\n",
      "epis: 816   score: 0.0   mem len: 150710   epsilon: 0.8996    steps: 122    lr: 0.0001     reward: 1.57\n",
      "epis: 817   score: 1.0   mem len: 150879   epsilon: 0.8993    steps: 169    lr: 0.0001     reward: 1.57\n",
      "epis: 818   score: 2.0   mem len: 151077   epsilon: 0.8989    steps: 198    lr: 0.0001     reward: 1.59\n",
      "epis: 819   score: 0.0   mem len: 151200   epsilon: 0.8986    steps: 123    lr: 0.0001     reward: 1.57\n",
      "epis: 820   score: 0.0   mem len: 151323   epsilon: 0.8984    steps: 123    lr: 0.0001     reward: 1.57\n",
      "epis: 821   score: 1.0   mem len: 151491   epsilon: 0.898    steps: 168    lr: 0.0001     reward: 1.55\n",
      "epis: 822   score: 1.0   mem len: 151660   epsilon: 0.8977    steps: 169    lr: 0.0001     reward: 1.55\n",
      "epis: 823   score: 1.0   mem len: 151831   epsilon: 0.8974    steps: 171    lr: 0.0001     reward: 1.55\n",
      "epis: 824   score: 2.0   mem len: 152028   epsilon: 0.897    steps: 197    lr: 0.0001     reward: 1.54\n",
      "epis: 825   score: 2.0   mem len: 152229   epsilon: 0.8966    steps: 201    lr: 0.0001     reward: 1.55\n",
      "epis: 826   score: 2.0   mem len: 152427   epsilon: 0.8962    steps: 198    lr: 0.0001     reward: 1.56\n",
      "epis: 827   score: 3.0   mem len: 152695   epsilon: 0.8957    steps: 268    lr: 0.0001     reward: 1.57\n",
      "epis: 828   score: 2.0   mem len: 152893   epsilon: 0.8953    steps: 198    lr: 0.0001     reward: 1.57\n",
      "epis: 829   score: 3.0   mem len: 153121   epsilon: 0.8948    steps: 228    lr: 0.0001     reward: 1.6\n",
      "epis: 830   score: 0.0   mem len: 153243   epsilon: 0.8946    steps: 122    lr: 0.0001     reward: 1.56\n",
      "epis: 831   score: 0.0   mem len: 153365   epsilon: 0.8943    steps: 122    lr: 0.0001     reward: 1.54\n",
      "epis: 832   score: 1.0   mem len: 153535   epsilon: 0.894    steps: 170    lr: 0.0001     reward: 1.54\n",
      "epis: 833   score: 0.0   mem len: 153658   epsilon: 0.8938    steps: 123    lr: 0.0001     reward: 1.53\n",
      "epis: 834   score: 0.0   mem len: 153781   epsilon: 0.8935    steps: 123    lr: 0.0001     reward: 1.52\n",
      "epis: 835   score: 1.0   mem len: 153931   epsilon: 0.8932    steps: 150    lr: 0.0001     reward: 1.52\n",
      "epis: 836   score: 3.0   mem len: 154160   epsilon: 0.8928    steps: 229    lr: 0.0001     reward: 1.55\n",
      "epis: 837   score: 3.0   mem len: 154407   epsilon: 0.8923    steps: 247    lr: 0.0001     reward: 1.58\n",
      "epis: 838   score: 1.0   mem len: 154557   epsilon: 0.892    steps: 150    lr: 0.0001     reward: 1.59\n",
      "epis: 839   score: 1.0   mem len: 154707   epsilon: 0.8917    steps: 150    lr: 0.0001     reward: 1.59\n",
      "epis: 840   score: 0.0   mem len: 154830   epsilon: 0.8914    steps: 123    lr: 0.0001     reward: 1.55\n",
      "epis: 841   score: 4.0   mem len: 155105   epsilon: 0.8909    steps: 275    lr: 0.0001     reward: 1.57\n",
      "epis: 842   score: 1.0   mem len: 155256   epsilon: 0.8906    steps: 151    lr: 0.0001     reward: 1.58\n",
      "epis: 843   score: 1.0   mem len: 155427   epsilon: 0.8903    steps: 171    lr: 0.0001     reward: 1.57\n",
      "epis: 844   score: 3.0   mem len: 155671   epsilon: 0.8898    steps: 244    lr: 0.0001     reward: 1.57\n",
      "epis: 845   score: 2.0   mem len: 155868   epsilon: 0.8894    steps: 197    lr: 0.0001     reward: 1.59\n",
      "epis: 846   score: 1.0   mem len: 156036   epsilon: 0.889    steps: 168    lr: 0.0001     reward: 1.59\n",
      "epis: 847   score: 2.0   mem len: 156233   epsilon: 0.8887    steps: 197    lr: 0.0001     reward: 1.59\n",
      "epis: 848   score: 5.0   mem len: 156577   epsilon: 0.888    steps: 344    lr: 0.0001     reward: 1.64\n",
      "epis: 849   score: 2.0   mem len: 156777   epsilon: 0.8876    steps: 200    lr: 0.0001     reward: 1.61\n",
      "epis: 850   score: 2.0   mem len: 156974   epsilon: 0.8872    steps: 197    lr: 0.0001     reward: 1.6\n",
      "epis: 851   score: 0.0   mem len: 157096   epsilon: 0.8869    steps: 122    lr: 0.0001     reward: 1.6\n",
      "epis: 852   score: 3.0   mem len: 157327   epsilon: 0.8865    steps: 231    lr: 0.0001     reward: 1.61\n",
      "epis: 853   score: 3.0   mem len: 157570   epsilon: 0.886    steps: 243    lr: 0.0001     reward: 1.62\n",
      "epis: 854   score: 2.0   mem len: 157768   epsilon: 0.8856    steps: 198    lr: 0.0001     reward: 1.6\n",
      "epis: 855   score: 2.0   mem len: 157948   epsilon: 0.8853    steps: 180    lr: 0.0001     reward: 1.61\n",
      "epis: 856   score: 0.0   mem len: 158071   epsilon: 0.885    steps: 123    lr: 0.0001     reward: 1.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 857   score: 0.0   mem len: 158194   epsilon: 0.8848    steps: 123    lr: 0.0001     reward: 1.55\n",
      "epis: 858   score: 0.0   mem len: 158316   epsilon: 0.8845    steps: 122    lr: 0.0001     reward: 1.55\n",
      "epis: 859   score: 0.0   mem len: 158439   epsilon: 0.8843    steps: 123    lr: 0.0001     reward: 1.53\n",
      "epis: 860   score: 3.0   mem len: 158684   epsilon: 0.8838    steps: 245    lr: 0.0001     reward: 1.53\n",
      "epis: 861   score: 2.0   mem len: 158866   epsilon: 0.8834    steps: 182    lr: 0.0001     reward: 1.54\n",
      "epis: 862   score: 3.0   mem len: 159115   epsilon: 0.883    steps: 249    lr: 0.0001     reward: 1.55\n",
      "epis: 863   score: 3.0   mem len: 159384   epsilon: 0.8824    steps: 269    lr: 0.0001     reward: 1.58\n",
      "epis: 864   score: 0.0   mem len: 159506   epsilon: 0.8822    steps: 122    lr: 0.0001     reward: 1.56\n",
      "epis: 865   score: 1.0   mem len: 159674   epsilon: 0.8818    steps: 168    lr: 0.0001     reward: 1.57\n",
      "epis: 866   score: 2.0   mem len: 159893   epsilon: 0.8814    steps: 219    lr: 0.0001     reward: 1.58\n",
      "epis: 867   score: 3.0   mem len: 160142   epsilon: 0.8809    steps: 249    lr: 0.0001     reward: 1.58\n",
      "epis: 868   score: 3.0   mem len: 160387   epsilon: 0.8804    steps: 245    lr: 0.0001     reward: 1.58\n",
      "epis: 869   score: 3.0   mem len: 160637   epsilon: 0.8799    steps: 250    lr: 0.0001     reward: 1.59\n",
      "epis: 870   score: 0.0   mem len: 160760   epsilon: 0.8797    steps: 123    lr: 0.0001     reward: 1.59\n",
      "epis: 871   score: 4.0   mem len: 161035   epsilon: 0.8791    steps: 275    lr: 0.0001     reward: 1.6\n",
      "epis: 872   score: 1.0   mem len: 161207   epsilon: 0.8788    steps: 172    lr: 0.0001     reward: 1.58\n",
      "epis: 873   score: 2.0   mem len: 161424   epsilon: 0.8784    steps: 217    lr: 0.0001     reward: 1.59\n",
      "epis: 874   score: 2.0   mem len: 161622   epsilon: 0.878    steps: 198    lr: 0.0001     reward: 1.6\n",
      "epis: 875   score: 3.0   mem len: 161869   epsilon: 0.8775    steps: 247    lr: 0.0001     reward: 1.63\n",
      "epis: 876   score: 1.0   mem len: 162038   epsilon: 0.8772    steps: 169    lr: 0.0001     reward: 1.63\n",
      "epis: 877   score: 1.0   mem len: 162188   epsilon: 0.8769    steps: 150    lr: 0.0001     reward: 1.63\n",
      "epis: 878   score: 1.0   mem len: 162340   epsilon: 0.8766    steps: 152    lr: 0.0001     reward: 1.64\n",
      "epis: 879   score: 0.0   mem len: 162463   epsilon: 0.8763    steps: 123    lr: 0.0001     reward: 1.61\n",
      "epis: 880   score: 0.0   mem len: 162586   epsilon: 0.8761    steps: 123    lr: 0.0001     reward: 1.6\n",
      "epis: 881   score: 4.0   mem len: 162860   epsilon: 0.8755    steps: 274    lr: 0.0001     reward: 1.62\n",
      "epis: 882   score: 1.0   mem len: 163030   epsilon: 0.8752    steps: 170    lr: 0.0001     reward: 1.62\n",
      "epis: 883   score: 4.0   mem len: 163305   epsilon: 0.8747    steps: 275    lr: 0.0001     reward: 1.63\n",
      "epis: 884   score: 3.0   mem len: 163531   epsilon: 0.8742    steps: 226    lr: 0.0001     reward: 1.63\n",
      "epis: 885   score: 0.0   mem len: 163654   epsilon: 0.874    steps: 123    lr: 0.0001     reward: 1.59\n",
      "epis: 886   score: 1.0   mem len: 163825   epsilon: 0.8736    steps: 171    lr: 0.0001     reward: 1.57\n",
      "epis: 887   score: 1.0   mem len: 163994   epsilon: 0.8733    steps: 169    lr: 0.0001     reward: 1.58\n",
      "epis: 888   score: 1.0   mem len: 164144   epsilon: 0.873    steps: 150    lr: 0.0001     reward: 1.59\n",
      "epis: 889   score: 2.0   mem len: 164342   epsilon: 0.8726    steps: 198    lr: 0.0001     reward: 1.61\n",
      "epis: 890   score: 4.0   mem len: 164635   epsilon: 0.872    steps: 293    lr: 0.0001     reward: 1.62\n",
      "epis: 891   score: 1.0   mem len: 164786   epsilon: 0.8717    steps: 151    lr: 0.0001     reward: 1.55\n",
      "epis: 892   score: 2.0   mem len: 164984   epsilon: 0.8713    steps: 198    lr: 0.0001     reward: 1.56\n",
      "epis: 893   score: 1.0   mem len: 165153   epsilon: 0.871    steps: 169    lr: 0.0001     reward: 1.57\n",
      "epis: 894   score: 1.0   mem len: 165304   epsilon: 0.8707    steps: 151    lr: 0.0001     reward: 1.55\n",
      "epis: 895   score: 2.0   mem len: 165485   epsilon: 0.8703    steps: 181    lr: 0.0001     reward: 1.55\n",
      "epis: 896   score: 3.0   mem len: 165750   epsilon: 0.8698    steps: 265    lr: 0.0001     reward: 1.57\n",
      "epis: 897   score: 3.0   mem len: 165976   epsilon: 0.8694    steps: 226    lr: 0.0001     reward: 1.58\n",
      "epis: 898   score: 6.0   mem len: 166330   epsilon: 0.8687    steps: 354    lr: 0.0001     reward: 1.63\n",
      "epis: 899   score: 4.0   mem len: 166606   epsilon: 0.8681    steps: 276    lr: 0.0001     reward: 1.64\n",
      "epis: 900   score: 2.0   mem len: 166808   epsilon: 0.8677    steps: 202    lr: 0.0001     reward: 1.66\n",
      "epis: 901   score: 3.0   mem len: 167057   epsilon: 0.8672    steps: 249    lr: 0.0001     reward: 1.67\n",
      "epis: 902   score: 3.0   mem len: 167285   epsilon: 0.8668    steps: 228    lr: 0.0001     reward: 1.68\n",
      "epis: 903   score: 4.0   mem len: 167584   epsilon: 0.8662    steps: 299    lr: 0.0001     reward: 1.72\n",
      "epis: 904   score: 3.0   mem len: 167852   epsilon: 0.8657    steps: 268    lr: 0.0001     reward: 1.74\n",
      "epis: 905   score: 2.0   mem len: 168070   epsilon: 0.8652    steps: 218    lr: 0.0001     reward: 1.76\n",
      "epis: 906   score: 3.0   mem len: 168298   epsilon: 0.8648    steps: 228    lr: 0.0001     reward: 1.77\n",
      "epis: 907   score: 2.0   mem len: 168498   epsilon: 0.8644    steps: 200    lr: 0.0001     reward: 1.79\n",
      "epis: 908   score: 6.0   mem len: 168845   epsilon: 0.8637    steps: 347    lr: 0.0001     reward: 1.84\n",
      "epis: 909   score: 3.0   mem len: 169057   epsilon: 0.8633    steps: 212    lr: 0.0001     reward: 1.87\n",
      "epis: 910   score: 6.0   mem len: 169405   epsilon: 0.8626    steps: 348    lr: 0.0001     reward: 1.93\n",
      "epis: 911   score: 2.0   mem len: 169603   epsilon: 0.8622    steps: 198    lr: 0.0001     reward: 1.95\n",
      "epis: 912   score: 1.0   mem len: 169772   epsilon: 0.8618    steps: 169    lr: 0.0001     reward: 1.94\n",
      "epis: 913   score: 1.0   mem len: 169940   epsilon: 0.8615    steps: 168    lr: 0.0001     reward: 1.93\n",
      "epis: 914   score: 5.0   mem len: 170274   epsilon: 0.8609    steps: 334    lr: 0.0001     reward: 1.95\n",
      "epis: 915   score: 0.0   mem len: 170397   epsilon: 0.8606    steps: 123    lr: 0.0001     reward: 1.91\n",
      "epis: 916   score: 1.0   mem len: 170549   epsilon: 0.8603    steps: 152    lr: 0.0001     reward: 1.92\n",
      "epis: 917   score: 1.0   mem len: 170718   epsilon: 0.86    steps: 169    lr: 0.0001     reward: 1.92\n",
      "epis: 918   score: 4.0   mem len: 171014   epsilon: 0.8594    steps: 296    lr: 0.0001     reward: 1.94\n",
      "epis: 919   score: 4.0   mem len: 171315   epsilon: 0.8588    steps: 301    lr: 0.0001     reward: 1.98\n",
      "epis: 920   score: 0.0   mem len: 171438   epsilon: 0.8586    steps: 123    lr: 0.0001     reward: 1.98\n",
      "epis: 921   score: 3.0   mem len: 171692   epsilon: 0.858    steps: 254    lr: 0.0001     reward: 2.0\n",
      "epis: 922   score: 2.0   mem len: 171889   epsilon: 0.8577    steps: 197    lr: 0.0001     reward: 2.01\n",
      "epis: 923   score: 3.0   mem len: 172140   epsilon: 0.8572    steps: 251    lr: 0.0001     reward: 2.03\n",
      "epis: 924   score: 4.0   mem len: 172428   epsilon: 0.8566    steps: 288    lr: 0.0001     reward: 2.05\n",
      "epis: 925   score: 0.0   mem len: 172551   epsilon: 0.8563    steps: 123    lr: 0.0001     reward: 2.03\n",
      "epis: 926   score: 4.0   mem len: 172849   epsilon: 0.8558    steps: 298    lr: 0.0001     reward: 2.05\n",
      "epis: 927   score: 1.0   mem len: 173018   epsilon: 0.8554    steps: 169    lr: 0.0001     reward: 2.03\n",
      "epis: 928   score: 1.0   mem len: 173188   epsilon: 0.8551    steps: 170    lr: 0.0001     reward: 2.02\n",
      "epis: 929   score: 1.0   mem len: 173339   epsilon: 0.8548    steps: 151    lr: 0.0001     reward: 2.0\n",
      "epis: 930   score: 2.0   mem len: 173521   epsilon: 0.8544    steps: 182    lr: 0.0001     reward: 2.02\n",
      "epis: 931   score: 2.0   mem len: 173719   epsilon: 0.854    steps: 198    lr: 0.0001     reward: 2.04\n",
      "epis: 932   score: 1.0   mem len: 173869   epsilon: 0.8537    steps: 150    lr: 0.0001     reward: 2.04\n",
      "epis: 933   score: 2.0   mem len: 174067   epsilon: 0.8533    steps: 198    lr: 0.0001     reward: 2.06\n",
      "epis: 934   score: 3.0   mem len: 174292   epsilon: 0.8529    steps: 225    lr: 0.0001     reward: 2.09\n",
      "epis: 935   score: 3.0   mem len: 174517   epsilon: 0.8525    steps: 225    lr: 0.0001     reward: 2.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 936   score: 2.0   mem len: 174699   epsilon: 0.8521    steps: 182    lr: 0.0001     reward: 2.1\n",
      "epis: 937   score: 3.0   mem len: 174946   epsilon: 0.8516    steps: 247    lr: 0.0001     reward: 2.1\n",
      "epis: 938   score: 2.0   mem len: 175147   epsilon: 0.8512    steps: 201    lr: 0.0001     reward: 2.11\n",
      "epis: 939   score: 3.0   mem len: 175391   epsilon: 0.8507    steps: 244    lr: 0.0001     reward: 2.13\n",
      "epis: 940   score: 7.0   mem len: 175801   epsilon: 0.8499    steps: 410    lr: 0.0001     reward: 2.2\n",
      "epis: 941   score: 5.0   mem len: 176114   epsilon: 0.8493    steps: 313    lr: 0.0001     reward: 2.21\n",
      "epis: 942   score: 2.0   mem len: 176336   epsilon: 0.8489    steps: 222    lr: 0.0001     reward: 2.22\n",
      "epis: 943   score: 0.0   mem len: 176459   epsilon: 0.8486    steps: 123    lr: 0.0001     reward: 2.21\n",
      "epis: 944   score: 2.0   mem len: 176639   epsilon: 0.8483    steps: 180    lr: 0.0001     reward: 2.2\n",
      "epis: 945   score: 3.0   mem len: 176883   epsilon: 0.8478    steps: 244    lr: 0.0001     reward: 2.21\n",
      "epis: 946   score: 3.0   mem len: 177112   epsilon: 0.8473    steps: 229    lr: 0.0001     reward: 2.23\n",
      "epis: 947   score: 2.0   mem len: 177328   epsilon: 0.8469    steps: 216    lr: 0.0001     reward: 2.23\n",
      "epis: 948   score: 0.0   mem len: 177451   epsilon: 0.8466    steps: 123    lr: 0.0001     reward: 2.18\n",
      "epis: 949   score: 2.0   mem len: 177651   epsilon: 0.8462    steps: 200    lr: 0.0001     reward: 2.18\n",
      "epis: 950   score: 0.0   mem len: 177774   epsilon: 0.846    steps: 123    lr: 0.0001     reward: 2.16\n",
      "epis: 951   score: 0.0   mem len: 177897   epsilon: 0.8458    steps: 123    lr: 0.0001     reward: 2.16\n",
      "epis: 952   score: 0.0   mem len: 178019   epsilon: 0.8455    steps: 122    lr: 0.0001     reward: 2.13\n",
      "epis: 953   score: 2.0   mem len: 178235   epsilon: 0.8451    steps: 216    lr: 0.0001     reward: 2.12\n",
      "epis: 954   score: 4.0   mem len: 178513   epsilon: 0.8445    steps: 278    lr: 0.0001     reward: 2.14\n",
      "epis: 955   score: 3.0   mem len: 178742   epsilon: 0.8441    steps: 229    lr: 0.0001     reward: 2.15\n",
      "epis: 956   score: 3.0   mem len: 179007   epsilon: 0.8436    steps: 265    lr: 0.0001     reward: 2.18\n",
      "epis: 957   score: 1.0   mem len: 179176   epsilon: 0.8432    steps: 169    lr: 0.0001     reward: 2.19\n",
      "epis: 958   score: 0.0   mem len: 179299   epsilon: 0.843    steps: 123    lr: 0.0001     reward: 2.19\n",
      "epis: 959   score: 2.0   mem len: 179497   epsilon: 0.8426    steps: 198    lr: 0.0001     reward: 2.21\n",
      "epis: 960   score: 4.0   mem len: 179795   epsilon: 0.842    steps: 298    lr: 0.0001     reward: 2.22\n",
      "epis: 961   score: 2.0   mem len: 179995   epsilon: 0.8416    steps: 200    lr: 0.0001     reward: 2.22\n",
      "epis: 962   score: 2.0   mem len: 180213   epsilon: 0.8412    steps: 218    lr: 0.0001     reward: 2.21\n",
      "epis: 963   score: 3.0   mem len: 180479   epsilon: 0.8406    steps: 266    lr: 0.0001     reward: 2.21\n",
      "epis: 964   score: 4.0   mem len: 180775   epsilon: 0.8401    steps: 296    lr: 0.0001     reward: 2.25\n",
      "epis: 965   score: 4.0   mem len: 181070   epsilon: 0.8395    steps: 295    lr: 0.0001     reward: 2.28\n",
      "epis: 966   score: 1.0   mem len: 181239   epsilon: 0.8391    steps: 169    lr: 0.0001     reward: 2.27\n",
      "epis: 967   score: 2.0   mem len: 181454   epsilon: 0.8387    steps: 215    lr: 0.0001     reward: 2.26\n",
      "epis: 968   score: 3.0   mem len: 181680   epsilon: 0.8383    steps: 226    lr: 0.0001     reward: 2.26\n",
      "epis: 969   score: 1.0   mem len: 181851   epsilon: 0.8379    steps: 171    lr: 0.0001     reward: 2.24\n",
      "epis: 970   score: 3.0   mem len: 182118   epsilon: 0.8374    steps: 267    lr: 0.0001     reward: 2.27\n",
      "epis: 971   score: 4.0   mem len: 182376   epsilon: 0.8369    steps: 258    lr: 0.0001     reward: 2.27\n",
      "epis: 972   score: 2.0   mem len: 182593   epsilon: 0.8365    steps: 217    lr: 0.0001     reward: 2.28\n",
      "epis: 973   score: 1.0   mem len: 182764   epsilon: 0.8361    steps: 171    lr: 0.0001     reward: 2.27\n",
      "epis: 974   score: 2.0   mem len: 182945   epsilon: 0.8358    steps: 181    lr: 0.0001     reward: 2.27\n",
      "epis: 975   score: 1.0   mem len: 183116   epsilon: 0.8354    steps: 171    lr: 0.0001     reward: 2.25\n",
      "epis: 976   score: 2.0   mem len: 183299   epsilon: 0.8351    steps: 183    lr: 0.0001     reward: 2.26\n",
      "epis: 977   score: 0.0   mem len: 183421   epsilon: 0.8348    steps: 122    lr: 0.0001     reward: 2.25\n",
      "epis: 978   score: 2.0   mem len: 183639   epsilon: 0.8344    steps: 218    lr: 0.0001     reward: 2.26\n",
      "epis: 979   score: 7.0   mem len: 184020   epsilon: 0.8336    steps: 381    lr: 0.0001     reward: 2.33\n",
      "epis: 980   score: 4.0   mem len: 184329   epsilon: 0.833    steps: 309    lr: 0.0001     reward: 2.37\n",
      "epis: 981   score: 2.0   mem len: 184510   epsilon: 0.8327    steps: 181    lr: 0.0001     reward: 2.35\n",
      "epis: 982   score: 1.0   mem len: 184660   epsilon: 0.8324    steps: 150    lr: 0.0001     reward: 2.35\n",
      "epis: 983   score: 7.0   mem len: 184981   epsilon: 0.8317    steps: 321    lr: 0.0001     reward: 2.38\n",
      "epis: 984   score: 5.0   mem len: 185313   epsilon: 0.8311    steps: 332    lr: 0.0001     reward: 2.4\n",
      "epis: 985   score: 4.0   mem len: 185588   epsilon: 0.8305    steps: 275    lr: 0.0001     reward: 2.44\n",
      "epis: 986   score: 0.0   mem len: 185710   epsilon: 0.8303    steps: 122    lr: 0.0001     reward: 2.43\n",
      "epis: 987   score: 4.0   mem len: 185986   epsilon: 0.8297    steps: 276    lr: 0.0001     reward: 2.46\n",
      "epis: 988   score: 4.0   mem len: 186225   epsilon: 0.8293    steps: 239    lr: 0.0001     reward: 2.49\n",
      "epis: 989   score: 0.0   mem len: 186348   epsilon: 0.829    steps: 123    lr: 0.0001     reward: 2.47\n",
      "epis: 990   score: 4.0   mem len: 186641   epsilon: 0.8284    steps: 293    lr: 0.0001     reward: 2.47\n",
      "epis: 991   score: 1.0   mem len: 186791   epsilon: 0.8282    steps: 150    lr: 0.0001     reward: 2.47\n",
      "epis: 992   score: 0.0   mem len: 186914   epsilon: 0.8279    steps: 123    lr: 0.0001     reward: 2.45\n",
      "epis: 993   score: 2.0   mem len: 187111   epsilon: 0.8275    steps: 197    lr: 0.0001     reward: 2.46\n",
      "epis: 994   score: 2.0   mem len: 187333   epsilon: 0.8271    steps: 222    lr: 0.0001     reward: 2.47\n",
      "epis: 995   score: 4.0   mem len: 187592   epsilon: 0.8266    steps: 259    lr: 0.0001     reward: 2.49\n",
      "epis: 996   score: 0.0   mem len: 187715   epsilon: 0.8263    steps: 123    lr: 0.0001     reward: 2.46\n",
      "epis: 997   score: 0.0   mem len: 187838   epsilon: 0.8261    steps: 123    lr: 0.0001     reward: 2.43\n",
      "epis: 998   score: 0.0   mem len: 187961   epsilon: 0.8258    steps: 123    lr: 0.0001     reward: 2.37\n",
      "epis: 999   score: 7.0   mem len: 188382   epsilon: 0.825    steps: 421    lr: 0.0001     reward: 2.4\n",
      "epis: 1000   score: 2.0   mem len: 188581   epsilon: 0.8246    steps: 199    lr: 0.0001     reward: 2.4\n",
      "epis: 1001   score: 2.0   mem len: 188781   epsilon: 0.8242    steps: 200    lr: 0.0001     reward: 2.39\n",
      "epis: 1002   score: 2.0   mem len: 188981   epsilon: 0.8238    steps: 200    lr: 0.0001     reward: 2.38\n",
      "epis: 1003   score: 1.0   mem len: 189150   epsilon: 0.8235    steps: 169    lr: 0.0001     reward: 2.35\n",
      "epis: 1004   score: 1.0   mem len: 189301   epsilon: 0.8232    steps: 151    lr: 0.0001     reward: 2.33\n",
      "epis: 1005   score: 3.0   mem len: 189546   epsilon: 0.8227    steps: 245    lr: 0.0001     reward: 2.34\n",
      "epis: 1006   score: 1.0   mem len: 189697   epsilon: 0.8224    steps: 151    lr: 0.0001     reward: 2.32\n",
      "epis: 1007   score: 2.0   mem len: 189896   epsilon: 0.822    steps: 199    lr: 0.0001     reward: 2.32\n",
      "epis: 1008   score: 3.0   mem len: 190125   epsilon: 0.8216    steps: 229    lr: 0.0001     reward: 2.29\n",
      "epis: 1009   score: 5.0   mem len: 190451   epsilon: 0.8209    steps: 326    lr: 0.0001     reward: 2.31\n",
      "epis: 1010   score: 3.0   mem len: 190696   epsilon: 0.8204    steps: 245    lr: 0.0001     reward: 2.28\n",
      "epis: 1011   score: 5.0   mem len: 191022   epsilon: 0.8198    steps: 326    lr: 0.0001     reward: 2.31\n",
      "epis: 1012   score: 3.0   mem len: 191269   epsilon: 0.8193    steps: 247    lr: 0.0001     reward: 2.33\n",
      "epis: 1013   score: 2.0   mem len: 191487   epsilon: 0.8189    steps: 218    lr: 0.0001     reward: 2.34\n",
      "epis: 1014   score: 4.0   mem len: 191783   epsilon: 0.8183    steps: 296    lr: 0.0001     reward: 2.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1015   score: 2.0   mem len: 191983   epsilon: 0.8179    steps: 200    lr: 0.0001     reward: 2.35\n",
      "epis: 1016   score: 1.0   mem len: 192153   epsilon: 0.8175    steps: 170    lr: 0.0001     reward: 2.35\n",
      "epis: 1017   score: 1.0   mem len: 192321   epsilon: 0.8172    steps: 168    lr: 0.0001     reward: 2.35\n",
      "epis: 1018   score: 4.0   mem len: 192631   epsilon: 0.8166    steps: 310    lr: 0.0001     reward: 2.35\n",
      "epis: 1019   score: 4.0   mem len: 192947   epsilon: 0.816    steps: 316    lr: 0.0001     reward: 2.35\n",
      "epis: 1020   score: 1.0   mem len: 193118   epsilon: 0.8156    steps: 171    lr: 0.0001     reward: 2.36\n",
      "epis: 1021   score: 3.0   mem len: 193345   epsilon: 0.8152    steps: 227    lr: 0.0001     reward: 2.36\n",
      "epis: 1022   score: 1.0   mem len: 193496   epsilon: 0.8149    steps: 151    lr: 0.0001     reward: 2.35\n",
      "epis: 1023   score: 2.0   mem len: 193694   epsilon: 0.8145    steps: 198    lr: 0.0001     reward: 2.34\n",
      "epis: 1024   score: 2.0   mem len: 193892   epsilon: 0.8141    steps: 198    lr: 0.0001     reward: 2.32\n",
      "epis: 1025   score: 1.0   mem len: 194043   epsilon: 0.8138    steps: 151    lr: 0.0001     reward: 2.33\n",
      "epis: 1026   score: 3.0   mem len: 194289   epsilon: 0.8133    steps: 246    lr: 0.0001     reward: 2.32\n",
      "epis: 1027   score: 2.0   mem len: 194488   epsilon: 0.8129    steps: 199    lr: 0.0001     reward: 2.33\n",
      "epis: 1028   score: 3.0   mem len: 194736   epsilon: 0.8124    steps: 248    lr: 0.0001     reward: 2.35\n",
      "epis: 1029   score: 2.0   mem len: 194934   epsilon: 0.812    steps: 198    lr: 0.0001     reward: 2.36\n",
      "epis: 1030   score: 2.0   mem len: 195131   epsilon: 0.8116    steps: 197    lr: 0.0001     reward: 2.36\n",
      "epis: 1031   score: 5.0   mem len: 195455   epsilon: 0.811    steps: 324    lr: 0.0001     reward: 2.39\n",
      "epis: 1032   score: 6.0   mem len: 195839   epsilon: 0.8102    steps: 384    lr: 0.0001     reward: 2.44\n",
      "epis: 1033   score: 1.0   mem len: 196008   epsilon: 0.8099    steps: 169    lr: 0.0001     reward: 2.43\n",
      "epis: 1034   score: 0.0   mem len: 196131   epsilon: 0.8097    steps: 123    lr: 0.0001     reward: 2.4\n",
      "epis: 1035   score: 2.0   mem len: 196331   epsilon: 0.8093    steps: 200    lr: 0.0001     reward: 2.39\n",
      "epis: 1036   score: 2.0   mem len: 196529   epsilon: 0.8089    steps: 198    lr: 0.0001     reward: 2.39\n",
      "epis: 1037   score: 1.0   mem len: 196698   epsilon: 0.8085    steps: 169    lr: 0.0001     reward: 2.37\n",
      "epis: 1038   score: 1.0   mem len: 196867   epsilon: 0.8082    steps: 169    lr: 0.0001     reward: 2.36\n",
      "epis: 1039   score: 4.0   mem len: 197162   epsilon: 0.8076    steps: 295    lr: 0.0001     reward: 2.37\n",
      "epis: 1040   score: 0.0   mem len: 197285   epsilon: 0.8074    steps: 123    lr: 0.0001     reward: 2.3\n",
      "epis: 1041   score: 1.0   mem len: 197456   epsilon: 0.807    steps: 171    lr: 0.0001     reward: 2.26\n",
      "epis: 1042   score: 1.0   mem len: 197606   epsilon: 0.8067    steps: 150    lr: 0.0001     reward: 2.25\n",
      "epis: 1043   score: 0.0   mem len: 197729   epsilon: 0.8065    steps: 123    lr: 0.0001     reward: 2.25\n",
      "epis: 1044   score: 4.0   mem len: 198024   epsilon: 0.8059    steps: 295    lr: 0.0001     reward: 2.27\n",
      "epis: 1045   score: 2.0   mem len: 198206   epsilon: 0.8056    steps: 182    lr: 0.0001     reward: 2.26\n",
      "epis: 1046   score: 2.0   mem len: 198423   epsilon: 0.8051    steps: 217    lr: 0.0001     reward: 2.25\n",
      "epis: 1047   score: 4.0   mem len: 198699   epsilon: 0.8046    steps: 276    lr: 0.0001     reward: 2.27\n",
      "epis: 1048   score: 2.0   mem len: 198900   epsilon: 0.8042    steps: 201    lr: 0.0001     reward: 2.29\n",
      "epis: 1049   score: 2.0   mem len: 199119   epsilon: 0.8037    steps: 219    lr: 0.0001     reward: 2.29\n",
      "epis: 1050   score: 4.0   mem len: 199436   epsilon: 0.8031    steps: 317    lr: 0.0001     reward: 2.33\n",
      "epis: 1051   score: 1.0   mem len: 199607   epsilon: 0.8028    steps: 171    lr: 0.0001     reward: 2.34\n",
      "epis: 1052   score: 2.0   mem len: 199822   epsilon: 0.8024    steps: 215    lr: 0.0001     reward: 2.36\n",
      "epis: 1053   score: 2.0   mem len: 200004   epsilon: 0.802    steps: 182    lr: 4e-05     reward: 2.36\n",
      "epis: 1054   score: 1.0   mem len: 200174   epsilon: 0.8017    steps: 170    lr: 4e-05     reward: 2.33\n",
      "epis: 1055   score: 4.0   mem len: 200414   epsilon: 0.8012    steps: 240    lr: 4e-05     reward: 2.34\n",
      "epis: 1056   score: 4.0   mem len: 200713   epsilon: 0.8006    steps: 299    lr: 4e-05     reward: 2.35\n",
      "epis: 1057   score: 2.0   mem len: 200932   epsilon: 0.8002    steps: 219    lr: 4e-05     reward: 2.36\n",
      "epis: 1058   score: 4.0   mem len: 201230   epsilon: 0.7996    steps: 298    lr: 4e-05     reward: 2.4\n",
      "epis: 1059   score: 1.0   mem len: 201380   epsilon: 0.7993    steps: 150    lr: 4e-05     reward: 2.39\n",
      "epis: 1060   score: 7.0   mem len: 201767   epsilon: 0.7985    steps: 387    lr: 4e-05     reward: 2.42\n",
      "epis: 1061   score: 4.0   mem len: 202060   epsilon: 0.7979    steps: 293    lr: 4e-05     reward: 2.44\n",
      "epis: 1062   score: 1.0   mem len: 202228   epsilon: 0.7976    steps: 168    lr: 4e-05     reward: 2.43\n",
      "epis: 1063   score: 2.0   mem len: 202426   epsilon: 0.7972    steps: 198    lr: 4e-05     reward: 2.42\n",
      "epis: 1064   score: 3.0   mem len: 202656   epsilon: 0.7967    steps: 230    lr: 4e-05     reward: 2.41\n",
      "epis: 1065   score: 1.0   mem len: 202825   epsilon: 0.7964    steps: 169    lr: 4e-05     reward: 2.38\n",
      "epis: 1066   score: 1.0   mem len: 202996   epsilon: 0.7961    steps: 171    lr: 4e-05     reward: 2.38\n",
      "epis: 1067   score: 9.0   mem len: 203324   epsilon: 0.7954    steps: 328    lr: 4e-05     reward: 2.45\n",
      "epis: 1068   score: 2.0   mem len: 203521   epsilon: 0.795    steps: 197    lr: 4e-05     reward: 2.44\n",
      "epis: 1069   score: 6.0   mem len: 203880   epsilon: 0.7943    steps: 359    lr: 4e-05     reward: 2.49\n",
      "epis: 1070   score: 3.0   mem len: 204147   epsilon: 0.7938    steps: 267    lr: 4e-05     reward: 2.49\n",
      "epis: 1071   score: 2.0   mem len: 204345   epsilon: 0.7934    steps: 198    lr: 4e-05     reward: 2.47\n",
      "epis: 1072   score: 2.0   mem len: 204561   epsilon: 0.793    steps: 216    lr: 4e-05     reward: 2.47\n",
      "epis: 1073   score: 1.0   mem len: 204712   epsilon: 0.7927    steps: 151    lr: 4e-05     reward: 2.47\n",
      "epis: 1074   score: 2.0   mem len: 204909   epsilon: 0.7923    steps: 197    lr: 4e-05     reward: 2.47\n",
      "epis: 1075   score: 3.0   mem len: 205156   epsilon: 0.7918    steps: 247    lr: 4e-05     reward: 2.49\n",
      "epis: 1076   score: 4.0   mem len: 205431   epsilon: 0.7912    steps: 275    lr: 4e-05     reward: 2.51\n",
      "epis: 1077   score: 3.0   mem len: 205660   epsilon: 0.7908    steps: 229    lr: 4e-05     reward: 2.54\n",
      "epis: 1078   score: 4.0   mem len: 205959   epsilon: 0.7902    steps: 299    lr: 4e-05     reward: 2.56\n",
      "epis: 1079   score: 1.0   mem len: 206128   epsilon: 0.7899    steps: 169    lr: 4e-05     reward: 2.5\n",
      "epis: 1080   score: 1.0   mem len: 206297   epsilon: 0.7895    steps: 169    lr: 4e-05     reward: 2.47\n",
      "epis: 1081   score: 3.0   mem len: 206522   epsilon: 0.7891    steps: 225    lr: 4e-05     reward: 2.48\n",
      "epis: 1082   score: 2.0   mem len: 206720   epsilon: 0.7887    steps: 198    lr: 4e-05     reward: 2.49\n",
      "epis: 1083   score: 2.0   mem len: 206918   epsilon: 0.7883    steps: 198    lr: 4e-05     reward: 2.44\n",
      "epis: 1084   score: 2.0   mem len: 207100   epsilon: 0.7879    steps: 182    lr: 4e-05     reward: 2.41\n",
      "epis: 1085   score: 4.0   mem len: 207379   epsilon: 0.7874    steps: 279    lr: 4e-05     reward: 2.41\n",
      "epis: 1086   score: 3.0   mem len: 207590   epsilon: 0.787    steps: 211    lr: 4e-05     reward: 2.44\n",
      "epis: 1087   score: 2.0   mem len: 207787   epsilon: 0.7866    steps: 197    lr: 4e-05     reward: 2.42\n",
      "epis: 1088   score: 3.0   mem len: 207997   epsilon: 0.7862    steps: 210    lr: 4e-05     reward: 2.41\n",
      "epis: 1089   score: 1.0   mem len: 208165   epsilon: 0.7858    steps: 168    lr: 4e-05     reward: 2.42\n",
      "epis: 1090   score: 7.0   mem len: 208559   epsilon: 0.7851    steps: 394    lr: 4e-05     reward: 2.45\n",
      "epis: 1091   score: 1.0   mem len: 208709   epsilon: 0.7848    steps: 150    lr: 4e-05     reward: 2.45\n",
      "epis: 1092   score: 2.0   mem len: 208927   epsilon: 0.7843    steps: 218    lr: 4e-05     reward: 2.47\n",
      "epis: 1093   score: 2.0   mem len: 209108   epsilon: 0.784    steps: 181    lr: 4e-05     reward: 2.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1094   score: 2.0   mem len: 209306   epsilon: 0.7836    steps: 198    lr: 4e-05     reward: 2.47\n",
      "epis: 1095   score: 1.0   mem len: 209457   epsilon: 0.7833    steps: 151    lr: 4e-05     reward: 2.44\n",
      "epis: 1096   score: 1.0   mem len: 209626   epsilon: 0.7829    steps: 169    lr: 4e-05     reward: 2.45\n",
      "epis: 1097   score: 7.0   mem len: 210039   epsilon: 0.7821    steps: 413    lr: 4e-05     reward: 2.52\n",
      "epis: 1098   score: 1.0   mem len: 210209   epsilon: 0.7818    steps: 170    lr: 4e-05     reward: 2.53\n",
      "epis: 1099   score: 3.0   mem len: 210439   epsilon: 0.7813    steps: 230    lr: 4e-05     reward: 2.49\n",
      "epis: 1100   score: 3.0   mem len: 210684   epsilon: 0.7808    steps: 245    lr: 4e-05     reward: 2.5\n",
      "epis: 1101   score: 1.0   mem len: 210852   epsilon: 0.7805    steps: 168    lr: 4e-05     reward: 2.49\n",
      "epis: 1102   score: 3.0   mem len: 211100   epsilon: 0.78    steps: 248    lr: 4e-05     reward: 2.5\n",
      "epis: 1103   score: 2.0   mem len: 211300   epsilon: 0.7796    steps: 200    lr: 4e-05     reward: 2.51\n",
      "epis: 1104   score: 3.0   mem len: 211531   epsilon: 0.7792    steps: 231    lr: 4e-05     reward: 2.53\n",
      "epis: 1105   score: 2.0   mem len: 211715   epsilon: 0.7788    steps: 184    lr: 4e-05     reward: 2.52\n",
      "epis: 1106   score: 1.0   mem len: 211866   epsilon: 0.7785    steps: 151    lr: 4e-05     reward: 2.52\n",
      "epis: 1107   score: 0.0   mem len: 211989   epsilon: 0.7783    steps: 123    lr: 4e-05     reward: 2.5\n",
      "epis: 1108   score: 2.0   mem len: 212169   epsilon: 0.7779    steps: 180    lr: 4e-05     reward: 2.49\n",
      "epis: 1109   score: 1.0   mem len: 212319   epsilon: 0.7776    steps: 150    lr: 4e-05     reward: 2.45\n",
      "epis: 1110   score: 3.0   mem len: 212544   epsilon: 0.7772    steps: 225    lr: 4e-05     reward: 2.45\n",
      "epis: 1111   score: 7.0   mem len: 212970   epsilon: 0.7763    steps: 426    lr: 4e-05     reward: 2.47\n",
      "epis: 1112   score: 4.0   mem len: 213266   epsilon: 0.7757    steps: 296    lr: 4e-05     reward: 2.48\n",
      "epis: 1113   score: 1.0   mem len: 213416   epsilon: 0.7754    steps: 150    lr: 4e-05     reward: 2.47\n",
      "epis: 1114   score: 2.0   mem len: 213613   epsilon: 0.775    steps: 197    lr: 4e-05     reward: 2.45\n",
      "epis: 1115   score: 9.0   mem len: 214058   epsilon: 0.7742    steps: 445    lr: 4e-05     reward: 2.52\n",
      "epis: 1116   score: 2.0   mem len: 214239   epsilon: 0.7738    steps: 181    lr: 4e-05     reward: 2.53\n",
      "epis: 1117   score: 2.0   mem len: 214437   epsilon: 0.7734    steps: 198    lr: 4e-05     reward: 2.54\n",
      "epis: 1118   score: 2.0   mem len: 214654   epsilon: 0.773    steps: 217    lr: 4e-05     reward: 2.52\n",
      "epis: 1119   score: 1.0   mem len: 214824   epsilon: 0.7726    steps: 170    lr: 4e-05     reward: 2.49\n",
      "epis: 1120   score: 4.0   mem len: 215098   epsilon: 0.7721    steps: 274    lr: 4e-05     reward: 2.52\n",
      "epis: 1121   score: 5.0   mem len: 215423   epsilon: 0.7715    steps: 325    lr: 4e-05     reward: 2.54\n",
      "epis: 1122   score: 5.0   mem len: 215771   epsilon: 0.7708    steps: 348    lr: 4e-05     reward: 2.58\n",
      "epis: 1123   score: 3.0   mem len: 216036   epsilon: 0.7702    steps: 265    lr: 4e-05     reward: 2.59\n",
      "epis: 1124   score: 0.0   mem len: 216159   epsilon: 0.77    steps: 123    lr: 4e-05     reward: 2.57\n",
      "epis: 1125   score: 1.0   mem len: 216309   epsilon: 0.7697    steps: 150    lr: 4e-05     reward: 2.57\n",
      "epis: 1126   score: 3.0   mem len: 216553   epsilon: 0.7692    steps: 244    lr: 4e-05     reward: 2.57\n",
      "epis: 1127   score: 3.0   mem len: 216799   epsilon: 0.7687    steps: 246    lr: 4e-05     reward: 2.58\n",
      "epis: 1128   score: 3.0   mem len: 217026   epsilon: 0.7683    steps: 227    lr: 4e-05     reward: 2.58\n",
      "epis: 1129   score: 5.0   mem len: 217373   epsilon: 0.7676    steps: 347    lr: 4e-05     reward: 2.61\n",
      "epis: 1130   score: 4.0   mem len: 217647   epsilon: 0.7671    steps: 274    lr: 4e-05     reward: 2.63\n",
      "epis: 1131   score: 1.0   mem len: 217818   epsilon: 0.7667    steps: 171    lr: 4e-05     reward: 2.59\n",
      "epis: 1132   score: 1.0   mem len: 217968   epsilon: 0.7664    steps: 150    lr: 4e-05     reward: 2.54\n",
      "epis: 1133   score: 3.0   mem len: 218194   epsilon: 0.766    steps: 226    lr: 4e-05     reward: 2.56\n",
      "epis: 1134   score: 5.0   mem len: 218499   epsilon: 0.7654    steps: 305    lr: 4e-05     reward: 2.61\n",
      "epis: 1135   score: 3.0   mem len: 218724   epsilon: 0.7649    steps: 225    lr: 4e-05     reward: 2.62\n",
      "epis: 1136   score: 2.0   mem len: 218922   epsilon: 0.7645    steps: 198    lr: 4e-05     reward: 2.62\n",
      "epis: 1137   score: 2.0   mem len: 219119   epsilon: 0.7641    steps: 197    lr: 4e-05     reward: 2.63\n",
      "epis: 1138   score: 1.0   mem len: 219270   epsilon: 0.7638    steps: 151    lr: 4e-05     reward: 2.63\n",
      "epis: 1139   score: 1.0   mem len: 219440   epsilon: 0.7635    steps: 170    lr: 4e-05     reward: 2.6\n",
      "epis: 1140   score: 3.0   mem len: 219666   epsilon: 0.7631    steps: 226    lr: 4e-05     reward: 2.63\n",
      "epis: 1141   score: 1.0   mem len: 219816   epsilon: 0.7628    steps: 150    lr: 4e-05     reward: 2.63\n",
      "epis: 1142   score: 2.0   mem len: 220016   epsilon: 0.7624    steps: 200    lr: 4e-05     reward: 2.64\n",
      "epis: 1143   score: 3.0   mem len: 220262   epsilon: 0.7619    steps: 246    lr: 4e-05     reward: 2.67\n",
      "epis: 1144   score: 1.0   mem len: 220413   epsilon: 0.7616    steps: 151    lr: 4e-05     reward: 2.64\n",
      "epis: 1145   score: 3.0   mem len: 220624   epsilon: 0.7612    steps: 211    lr: 4e-05     reward: 2.65\n",
      "epis: 1146   score: 1.0   mem len: 220795   epsilon: 0.7608    steps: 171    lr: 4e-05     reward: 2.64\n",
      "epis: 1147   score: 5.0   mem len: 221144   epsilon: 0.7601    steps: 349    lr: 4e-05     reward: 2.65\n",
      "epis: 1148   score: 4.0   mem len: 221418   epsilon: 0.7596    steps: 274    lr: 4e-05     reward: 2.67\n",
      "epis: 1149   score: 5.0   mem len: 221729   epsilon: 0.759    steps: 311    lr: 4e-05     reward: 2.7\n",
      "epis: 1150   score: 5.0   mem len: 222055   epsilon: 0.7583    steps: 326    lr: 4e-05     reward: 2.71\n",
      "epis: 1151   score: 1.0   mem len: 222227   epsilon: 0.758    steps: 172    lr: 4e-05     reward: 2.71\n",
      "epis: 1152   score: 2.0   mem len: 222446   epsilon: 0.7576    steps: 219    lr: 4e-05     reward: 2.71\n",
      "epis: 1153   score: 3.0   mem len: 222691   epsilon: 0.7571    steps: 245    lr: 4e-05     reward: 2.72\n",
      "epis: 1154   score: 0.0   mem len: 222814   epsilon: 0.7568    steps: 123    lr: 4e-05     reward: 2.71\n",
      "epis: 1155   score: 1.0   mem len: 222965   epsilon: 0.7565    steps: 151    lr: 4e-05     reward: 2.68\n",
      "epis: 1156   score: 3.0   mem len: 223211   epsilon: 0.756    steps: 246    lr: 4e-05     reward: 2.67\n",
      "epis: 1157   score: 2.0   mem len: 223426   epsilon: 0.7556    steps: 215    lr: 4e-05     reward: 2.67\n",
      "epis: 1158   score: 5.0   mem len: 223749   epsilon: 0.755    steps: 323    lr: 4e-05     reward: 2.68\n",
      "epis: 1159   score: 2.0   mem len: 223946   epsilon: 0.7546    steps: 197    lr: 4e-05     reward: 2.69\n",
      "epis: 1160   score: 4.0   mem len: 224220   epsilon: 0.754    steps: 274    lr: 4e-05     reward: 2.66\n",
      "epis: 1161   score: 5.0   mem len: 224545   epsilon: 0.7534    steps: 325    lr: 4e-05     reward: 2.67\n",
      "epis: 1162   score: 7.0   mem len: 224926   epsilon: 0.7526    steps: 381    lr: 4e-05     reward: 2.73\n",
      "epis: 1163   score: 3.0   mem len: 225192   epsilon: 0.7521    steps: 266    lr: 4e-05     reward: 2.74\n",
      "epis: 1164   score: 7.0   mem len: 225600   epsilon: 0.7513    steps: 408    lr: 4e-05     reward: 2.78\n",
      "epis: 1165   score: 4.0   mem len: 225877   epsilon: 0.7508    steps: 277    lr: 4e-05     reward: 2.81\n",
      "epis: 1166   score: 5.0   mem len: 226240   epsilon: 0.75    steps: 363    lr: 4e-05     reward: 2.85\n",
      "epis: 1167   score: 5.0   mem len: 226565   epsilon: 0.7494    steps: 325    lr: 4e-05     reward: 2.81\n",
      "epis: 1168   score: 2.0   mem len: 226765   epsilon: 0.749    steps: 200    lr: 4e-05     reward: 2.81\n",
      "epis: 1169   score: 2.0   mem len: 226982   epsilon: 0.7486    steps: 217    lr: 4e-05     reward: 2.77\n",
      "epis: 1170   score: 2.0   mem len: 227180   epsilon: 0.7482    steps: 198    lr: 4e-05     reward: 2.76\n",
      "epis: 1171   score: 3.0   mem len: 227410   epsilon: 0.7477    steps: 230    lr: 4e-05     reward: 2.77\n",
      "epis: 1172   score: 4.0   mem len: 227653   epsilon: 0.7472    steps: 243    lr: 4e-05     reward: 2.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1173   score: 4.0   mem len: 227927   epsilon: 0.7467    steps: 274    lr: 4e-05     reward: 2.82\n",
      "epis: 1174   score: 2.0   mem len: 228126   epsilon: 0.7463    steps: 199    lr: 4e-05     reward: 2.82\n",
      "epis: 1175   score: 5.0   mem len: 228472   epsilon: 0.7456    steps: 346    lr: 4e-05     reward: 2.84\n",
      "epis: 1176   score: 3.0   mem len: 228716   epsilon: 0.7451    steps: 244    lr: 4e-05     reward: 2.83\n",
      "epis: 1177   score: 4.0   mem len: 229012   epsilon: 0.7446    steps: 296    lr: 4e-05     reward: 2.84\n",
      "epis: 1178   score: 5.0   mem len: 229354   epsilon: 0.7439    steps: 342    lr: 4e-05     reward: 2.85\n",
      "epis: 1179   score: 4.0   mem len: 229630   epsilon: 0.7433    steps: 276    lr: 4e-05     reward: 2.88\n",
      "epis: 1180   score: 3.0   mem len: 229856   epsilon: 0.7429    steps: 226    lr: 4e-05     reward: 2.9\n",
      "epis: 1181   score: 4.0   mem len: 230154   epsilon: 0.7423    steps: 298    lr: 4e-05     reward: 2.91\n",
      "epis: 1182   score: 3.0   mem len: 230400   epsilon: 0.7418    steps: 246    lr: 4e-05     reward: 2.92\n",
      "epis: 1183   score: 6.0   mem len: 230793   epsilon: 0.741    steps: 393    lr: 4e-05     reward: 2.96\n",
      "epis: 1184   score: 3.0   mem len: 231018   epsilon: 0.7406    steps: 225    lr: 4e-05     reward: 2.97\n",
      "epis: 1185   score: 5.0   mem len: 231324   epsilon: 0.74    steps: 306    lr: 4e-05     reward: 2.98\n",
      "epis: 1186   score: 1.0   mem len: 231494   epsilon: 0.7396    steps: 170    lr: 4e-05     reward: 2.96\n",
      "epis: 1187   score: 3.0   mem len: 231759   epsilon: 0.7391    steps: 265    lr: 4e-05     reward: 2.97\n",
      "epis: 1188   score: 2.0   mem len: 231956   epsilon: 0.7387    steps: 197    lr: 4e-05     reward: 2.96\n",
      "epis: 1189   score: 5.0   mem len: 232283   epsilon: 0.7381    steps: 327    lr: 4e-05     reward: 3.0\n",
      "epis: 1190   score: 4.0   mem len: 232538   epsilon: 0.7376    steps: 255    lr: 4e-05     reward: 2.97\n",
      "epis: 1191   score: 3.0   mem len: 232766   epsilon: 0.7371    steps: 228    lr: 4e-05     reward: 2.99\n",
      "epis: 1192   score: 2.0   mem len: 232981   epsilon: 0.7367    steps: 215    lr: 4e-05     reward: 2.99\n",
      "epis: 1193   score: 0.0   mem len: 233103   epsilon: 0.7365    steps: 122    lr: 4e-05     reward: 2.97\n",
      "epis: 1194   score: 1.0   mem len: 233271   epsilon: 0.7361    steps: 168    lr: 4e-05     reward: 2.96\n",
      "epis: 1195   score: 3.0   mem len: 233497   epsilon: 0.7357    steps: 226    lr: 4e-05     reward: 2.98\n",
      "epis: 1196   score: 1.0   mem len: 233648   epsilon: 0.7354    steps: 151    lr: 4e-05     reward: 2.98\n",
      "epis: 1197   score: 3.0   mem len: 233893   epsilon: 0.7349    steps: 245    lr: 4e-05     reward: 2.94\n",
      "epis: 1198   score: 4.0   mem len: 234165   epsilon: 0.7344    steps: 272    lr: 4e-05     reward: 2.97\n",
      "epis: 1199   score: 3.0   mem len: 234408   epsilon: 0.7339    steps: 243    lr: 4e-05     reward: 2.97\n",
      "epis: 1200   score: 0.0   mem len: 234531   epsilon: 0.7336    steps: 123    lr: 4e-05     reward: 2.94\n",
      "epis: 1201   score: 4.0   mem len: 234807   epsilon: 0.7331    steps: 276    lr: 4e-05     reward: 2.97\n",
      "epis: 1202   score: 1.0   mem len: 234977   epsilon: 0.7327    steps: 170    lr: 4e-05     reward: 2.95\n",
      "epis: 1203   score: 3.0   mem len: 235246   epsilon: 0.7322    steps: 269    lr: 4e-05     reward: 2.96\n",
      "epis: 1204   score: 5.0   mem len: 235552   epsilon: 0.7316    steps: 306    lr: 4e-05     reward: 2.98\n",
      "epis: 1205   score: 1.0   mem len: 235721   epsilon: 0.7313    steps: 169    lr: 4e-05     reward: 2.97\n",
      "epis: 1206   score: 0.0   mem len: 235843   epsilon: 0.731    steps: 122    lr: 4e-05     reward: 2.96\n",
      "epis: 1207   score: 1.0   mem len: 236014   epsilon: 0.7307    steps: 171    lr: 4e-05     reward: 2.97\n",
      "epis: 1208   score: 2.0   mem len: 236231   epsilon: 0.7303    steps: 217    lr: 4e-05     reward: 2.97\n",
      "epis: 1209   score: 2.0   mem len: 236428   epsilon: 0.7299    steps: 197    lr: 4e-05     reward: 2.98\n",
      "epis: 1210   score: 8.0   mem len: 236899   epsilon: 0.7289    steps: 471    lr: 4e-05     reward: 3.03\n",
      "epis: 1211   score: 4.0   mem len: 237176   epsilon: 0.7284    steps: 277    lr: 4e-05     reward: 3.0\n",
      "epis: 1212   score: 5.0   mem len: 237472   epsilon: 0.7278    steps: 296    lr: 4e-05     reward: 3.01\n",
      "epis: 1213   score: 3.0   mem len: 237717   epsilon: 0.7273    steps: 245    lr: 4e-05     reward: 3.03\n",
      "epis: 1214   score: 4.0   mem len: 237973   epsilon: 0.7268    steps: 256    lr: 4e-05     reward: 3.05\n",
      "epis: 1215   score: 1.0   mem len: 238144   epsilon: 0.7265    steps: 171    lr: 4e-05     reward: 2.97\n",
      "epis: 1216   score: 4.0   mem len: 238419   epsilon: 0.7259    steps: 275    lr: 4e-05     reward: 2.99\n",
      "epis: 1217   score: 3.0   mem len: 238684   epsilon: 0.7254    steps: 265    lr: 4e-05     reward: 3.0\n",
      "epis: 1218   score: 3.0   mem len: 238931   epsilon: 0.7249    steps: 247    lr: 4e-05     reward: 3.01\n",
      "epis: 1219   score: 5.0   mem len: 239278   epsilon: 0.7242    steps: 347    lr: 4e-05     reward: 3.05\n",
      "epis: 1220   score: 0.0   mem len: 239401   epsilon: 0.724    steps: 123    lr: 4e-05     reward: 3.01\n",
      "epis: 1221   score: 3.0   mem len: 239627   epsilon: 0.7235    steps: 226    lr: 4e-05     reward: 2.99\n",
      "epis: 1222   score: 3.0   mem len: 239872   epsilon: 0.7231    steps: 245    lr: 4e-05     reward: 2.97\n",
      "epis: 1223   score: 8.0   mem len: 240203   epsilon: 0.7224    steps: 331    lr: 4e-05     reward: 3.02\n",
      "epis: 1224   score: 2.0   mem len: 240421   epsilon: 0.722    steps: 218    lr: 4e-05     reward: 3.04\n",
      "epis: 1225   score: 5.0   mem len: 240708   epsilon: 0.7214    steps: 287    lr: 4e-05     reward: 3.08\n",
      "epis: 1226   score: 5.0   mem len: 240994   epsilon: 0.7208    steps: 286    lr: 4e-05     reward: 3.1\n",
      "epis: 1227   score: 1.0   mem len: 241163   epsilon: 0.7205    steps: 169    lr: 4e-05     reward: 3.08\n",
      "epis: 1228   score: 3.0   mem len: 241390   epsilon: 0.72    steps: 227    lr: 4e-05     reward: 3.08\n",
      "epis: 1229   score: 3.0   mem len: 241615   epsilon: 0.7196    steps: 225    lr: 4e-05     reward: 3.06\n",
      "epis: 1230   score: 3.0   mem len: 241828   epsilon: 0.7192    steps: 213    lr: 4e-05     reward: 3.05\n",
      "epis: 1231   score: 2.0   mem len: 242025   epsilon: 0.7188    steps: 197    lr: 4e-05     reward: 3.06\n",
      "epis: 1232   score: 1.0   mem len: 242176   epsilon: 0.7185    steps: 151    lr: 4e-05     reward: 3.06\n",
      "epis: 1233   score: 4.0   mem len: 242452   epsilon: 0.7179    steps: 276    lr: 4e-05     reward: 3.07\n",
      "epis: 1234   score: 2.0   mem len: 242671   epsilon: 0.7175    steps: 219    lr: 4e-05     reward: 3.04\n",
      "epis: 1235   score: 3.0   mem len: 242899   epsilon: 0.7171    steps: 228    lr: 4e-05     reward: 3.04\n",
      "epis: 1236   score: 6.0   mem len: 243272   epsilon: 0.7163    steps: 373    lr: 4e-05     reward: 3.08\n",
      "epis: 1237   score: 6.0   mem len: 243616   epsilon: 0.7156    steps: 344    lr: 4e-05     reward: 3.12\n",
      "epis: 1238   score: 5.0   mem len: 243923   epsilon: 0.715    steps: 307    lr: 4e-05     reward: 3.16\n",
      "epis: 1239   score: 1.0   mem len: 244074   epsilon: 0.7147    steps: 151    lr: 4e-05     reward: 3.16\n",
      "epis: 1240   score: 4.0   mem len: 244369   epsilon: 0.7141    steps: 295    lr: 4e-05     reward: 3.17\n",
      "epis: 1241   score: 3.0   mem len: 244582   epsilon: 0.7137    steps: 213    lr: 4e-05     reward: 3.19\n",
      "epis: 1242   score: 9.0   mem len: 244960   epsilon: 0.713    steps: 378    lr: 4e-05     reward: 3.26\n",
      "epis: 1243   score: 3.0   mem len: 245206   epsilon: 0.7125    steps: 246    lr: 4e-05     reward: 3.26\n",
      "epis: 1244   score: 2.0   mem len: 245427   epsilon: 0.7121    steps: 221    lr: 4e-05     reward: 3.27\n",
      "epis: 1245   score: 3.0   mem len: 245673   epsilon: 0.7116    steps: 246    lr: 4e-05     reward: 3.27\n",
      "epis: 1246   score: 6.0   mem len: 246030   epsilon: 0.7109    steps: 357    lr: 4e-05     reward: 3.32\n",
      "epis: 1247   score: 6.0   mem len: 246349   epsilon: 0.7102    steps: 319    lr: 4e-05     reward: 3.33\n",
      "epis: 1248   score: 0.0   mem len: 246472   epsilon: 0.71    steps: 123    lr: 4e-05     reward: 3.29\n",
      "epis: 1249   score: 6.0   mem len: 246817   epsilon: 0.7093    steps: 345    lr: 4e-05     reward: 3.3\n",
      "epis: 1250   score: 3.0   mem len: 247042   epsilon: 0.7089    steps: 225    lr: 4e-05     reward: 3.28\n",
      "epis: 1251   score: 3.0   mem len: 247286   epsilon: 0.7084    steps: 244    lr: 4e-05     reward: 3.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1252   score: 4.0   mem len: 247564   epsilon: 0.7078    steps: 278    lr: 4e-05     reward: 3.32\n",
      "epis: 1253   score: 5.0   mem len: 247908   epsilon: 0.7071    steps: 344    lr: 4e-05     reward: 3.34\n",
      "epis: 1254   score: 0.0   mem len: 248031   epsilon: 0.7069    steps: 123    lr: 4e-05     reward: 3.34\n",
      "epis: 1255   score: 1.0   mem len: 248181   epsilon: 0.7066    steps: 150    lr: 4e-05     reward: 3.34\n",
      "epis: 1256   score: 4.0   mem len: 248476   epsilon: 0.706    steps: 295    lr: 4e-05     reward: 3.35\n",
      "epis: 1257   score: 0.0   mem len: 248598   epsilon: 0.7058    steps: 122    lr: 4e-05     reward: 3.33\n",
      "epis: 1258   score: 1.0   mem len: 248768   epsilon: 0.7054    steps: 170    lr: 4e-05     reward: 3.29\n",
      "epis: 1259   score: 3.0   mem len: 248993   epsilon: 0.705    steps: 225    lr: 4e-05     reward: 3.3\n",
      "epis: 1260   score: 3.0   mem len: 249219   epsilon: 0.7045    steps: 226    lr: 4e-05     reward: 3.29\n",
      "epis: 1261   score: 1.0   mem len: 249388   epsilon: 0.7042    steps: 169    lr: 4e-05     reward: 3.25\n",
      "epis: 1262   score: 6.0   mem len: 249760   epsilon: 0.7035    steps: 372    lr: 4e-05     reward: 3.24\n",
      "epis: 1263   score: 1.0   mem len: 249911   epsilon: 0.7032    steps: 151    lr: 4e-05     reward: 3.22\n",
      "epis: 1264   score: 2.0   mem len: 250108   epsilon: 0.7028    steps: 197    lr: 4e-05     reward: 3.17\n",
      "epis: 1265   score: 5.0   mem len: 250418   epsilon: 0.7022    steps: 310    lr: 4e-05     reward: 3.18\n",
      "epis: 1266   score: 7.0   mem len: 250864   epsilon: 0.7013    steps: 446    lr: 4e-05     reward: 3.2\n",
      "epis: 1267   score: 2.0   mem len: 251081   epsilon: 0.7009    steps: 217    lr: 4e-05     reward: 3.17\n",
      "epis: 1268   score: 0.0   mem len: 251203   epsilon: 0.7006    steps: 122    lr: 4e-05     reward: 3.15\n",
      "epis: 1269   score: 6.0   mem len: 251563   epsilon: 0.6999    steps: 360    lr: 4e-05     reward: 3.19\n",
      "epis: 1270   score: 5.0   mem len: 251866   epsilon: 0.6993    steps: 303    lr: 4e-05     reward: 3.22\n",
      "epis: 1271   score: 2.0   mem len: 252063   epsilon: 0.6989    steps: 197    lr: 4e-05     reward: 3.21\n",
      "epis: 1272   score: 3.0   mem len: 252290   epsilon: 0.6985    steps: 227    lr: 4e-05     reward: 3.2\n",
      "epis: 1273   score: 2.0   mem len: 252487   epsilon: 0.6981    steps: 197    lr: 4e-05     reward: 3.18\n",
      "epis: 1274   score: 3.0   mem len: 252737   epsilon: 0.6976    steps: 250    lr: 4e-05     reward: 3.19\n",
      "epis: 1275   score: 5.0   mem len: 253059   epsilon: 0.6969    steps: 322    lr: 4e-05     reward: 3.19\n",
      "epis: 1276   score: 5.0   mem len: 253350   epsilon: 0.6964    steps: 291    lr: 4e-05     reward: 3.21\n",
      "epis: 1277   score: 3.0   mem len: 253596   epsilon: 0.6959    steps: 246    lr: 4e-05     reward: 3.2\n",
      "epis: 1278   score: 1.0   mem len: 253767   epsilon: 0.6955    steps: 171    lr: 4e-05     reward: 3.16\n",
      "epis: 1279   score: 2.0   mem len: 253965   epsilon: 0.6951    steps: 198    lr: 4e-05     reward: 3.14\n",
      "epis: 1280   score: 1.0   mem len: 254136   epsilon: 0.6948    steps: 171    lr: 4e-05     reward: 3.12\n",
      "epis: 1281   score: 6.0   mem len: 254469   epsilon: 0.6941    steps: 333    lr: 4e-05     reward: 3.14\n",
      "epis: 1282   score: 6.0   mem len: 254844   epsilon: 0.6934    steps: 375    lr: 4e-05     reward: 3.17\n",
      "epis: 1283   score: 2.0   mem len: 255065   epsilon: 0.693    steps: 221    lr: 4e-05     reward: 3.13\n",
      "epis: 1284   score: 4.0   mem len: 255362   epsilon: 0.6924    steps: 297    lr: 4e-05     reward: 3.14\n",
      "epis: 1285   score: 1.0   mem len: 255532   epsilon: 0.692    steps: 170    lr: 4e-05     reward: 3.1\n",
      "epis: 1286   score: 2.0   mem len: 255751   epsilon: 0.6916    steps: 219    lr: 4e-05     reward: 3.11\n",
      "epis: 1287   score: 3.0   mem len: 255976   epsilon: 0.6912    steps: 225    lr: 4e-05     reward: 3.11\n",
      "epis: 1288   score: 4.0   mem len: 256271   epsilon: 0.6906    steps: 295    lr: 4e-05     reward: 3.13\n",
      "epis: 1289   score: 2.0   mem len: 256469   epsilon: 0.6902    steps: 198    lr: 4e-05     reward: 3.1\n",
      "epis: 1290   score: 7.0   mem len: 256856   epsilon: 0.6894    steps: 387    lr: 4e-05     reward: 3.13\n",
      "epis: 1291   score: 3.0   mem len: 257123   epsilon: 0.6889    steps: 267    lr: 4e-05     reward: 3.13\n",
      "epis: 1292   score: 3.0   mem len: 257349   epsilon: 0.6884    steps: 226    lr: 4e-05     reward: 3.14\n",
      "epis: 1293   score: 3.0   mem len: 257614   epsilon: 0.6879    steps: 265    lr: 4e-05     reward: 3.17\n",
      "epis: 1294   score: 3.0   mem len: 257839   epsilon: 0.6875    steps: 225    lr: 4e-05     reward: 3.19\n",
      "epis: 1295   score: 3.0   mem len: 258064   epsilon: 0.687    steps: 225    lr: 4e-05     reward: 3.19\n",
      "epis: 1296   score: 4.0   mem len: 258339   epsilon: 0.6865    steps: 275    lr: 4e-05     reward: 3.22\n",
      "epis: 1297   score: 6.0   mem len: 258711   epsilon: 0.6858    steps: 372    lr: 4e-05     reward: 3.25\n",
      "epis: 1298   score: 0.0   mem len: 258833   epsilon: 0.6855    steps: 122    lr: 4e-05     reward: 3.21\n",
      "epis: 1299   score: 4.0   mem len: 259127   epsilon: 0.6849    steps: 294    lr: 4e-05     reward: 3.22\n",
      "epis: 1300   score: 4.0   mem len: 259407   epsilon: 0.6844    steps: 280    lr: 4e-05     reward: 3.26\n",
      "epis: 1301   score: 4.0   mem len: 259682   epsilon: 0.6838    steps: 275    lr: 4e-05     reward: 3.26\n",
      "epis: 1302   score: 1.0   mem len: 259833   epsilon: 0.6835    steps: 151    lr: 4e-05     reward: 3.26\n",
      "epis: 1303   score: 1.0   mem len: 259984   epsilon: 0.6832    steps: 151    lr: 4e-05     reward: 3.24\n",
      "epis: 1304   score: 0.0   mem len: 260107   epsilon: 0.683    steps: 123    lr: 4e-05     reward: 3.19\n",
      "epis: 1305   score: 0.0   mem len: 260229   epsilon: 0.6827    steps: 122    lr: 4e-05     reward: 3.18\n",
      "epis: 1306   score: 1.0   mem len: 260398   epsilon: 0.6824    steps: 169    lr: 4e-05     reward: 3.19\n",
      "epis: 1307   score: 3.0   mem len: 260648   epsilon: 0.6819    steps: 250    lr: 4e-05     reward: 3.21\n",
      "epis: 1308   score: 5.0   mem len: 260952   epsilon: 0.6813    steps: 304    lr: 4e-05     reward: 3.24\n",
      "epis: 1309   score: 2.0   mem len: 261169   epsilon: 0.6809    steps: 217    lr: 4e-05     reward: 3.24\n",
      "epis: 1310   score: 2.0   mem len: 261388   epsilon: 0.6804    steps: 219    lr: 4e-05     reward: 3.18\n",
      "epis: 1311   score: 3.0   mem len: 261613   epsilon: 0.68    steps: 225    lr: 4e-05     reward: 3.17\n",
      "epis: 1312   score: 2.0   mem len: 261811   epsilon: 0.6796    steps: 198    lr: 4e-05     reward: 3.14\n",
      "epis: 1313   score: 4.0   mem len: 262065   epsilon: 0.6791    steps: 254    lr: 4e-05     reward: 3.15\n",
      "epis: 1314   score: 4.0   mem len: 262322   epsilon: 0.6786    steps: 257    lr: 4e-05     reward: 3.15\n",
      "epis: 1315   score: 0.0   mem len: 262444   epsilon: 0.6784    steps: 122    lr: 4e-05     reward: 3.14\n",
      "epis: 1316   score: 3.0   mem len: 262669   epsilon: 0.6779    steps: 225    lr: 4e-05     reward: 3.13\n",
      "epis: 1317   score: 5.0   mem len: 262984   epsilon: 0.6773    steps: 315    lr: 4e-05     reward: 3.15\n",
      "epis: 1318   score: 1.0   mem len: 263156   epsilon: 0.6769    steps: 172    lr: 4e-05     reward: 3.13\n",
      "epis: 1319   score: 1.0   mem len: 263327   epsilon: 0.6766    steps: 171    lr: 4e-05     reward: 3.09\n",
      "epis: 1320   score: 4.0   mem len: 263622   epsilon: 0.676    steps: 295    lr: 4e-05     reward: 3.13\n",
      "epis: 1321   score: 0.0   mem len: 263744   epsilon: 0.6758    steps: 122    lr: 4e-05     reward: 3.1\n",
      "epis: 1322   score: 3.0   mem len: 263994   epsilon: 0.6753    steps: 250    lr: 4e-05     reward: 3.1\n",
      "epis: 1323   score: 2.0   mem len: 264194   epsilon: 0.6749    steps: 200    lr: 4e-05     reward: 3.04\n",
      "epis: 1324   score: 3.0   mem len: 264442   epsilon: 0.6744    steps: 248    lr: 4e-05     reward: 3.05\n",
      "epis: 1325   score: 8.0   mem len: 264894   epsilon: 0.6735    steps: 452    lr: 4e-05     reward: 3.08\n",
      "epis: 1326   score: 3.0   mem len: 265121   epsilon: 0.6731    steps: 227    lr: 4e-05     reward: 3.06\n",
      "epis: 1327   score: 0.0   mem len: 265243   epsilon: 0.6728    steps: 122    lr: 4e-05     reward: 3.05\n",
      "epis: 1328   score: 1.0   mem len: 265394   epsilon: 0.6725    steps: 151    lr: 4e-05     reward: 3.03\n",
      "epis: 1329   score: 2.0   mem len: 265593   epsilon: 0.6721    steps: 199    lr: 4e-05     reward: 3.02\n",
      "epis: 1330   score: 3.0   mem len: 265845   epsilon: 0.6716    steps: 252    lr: 4e-05     reward: 3.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1331   score: 4.0   mem len: 266101   epsilon: 0.6711    steps: 256    lr: 4e-05     reward: 3.04\n",
      "epis: 1332   score: 5.0   mem len: 266408   epsilon: 0.6705    steps: 307    lr: 4e-05     reward: 3.08\n",
      "epis: 1333   score: 3.0   mem len: 266657   epsilon: 0.67    steps: 249    lr: 4e-05     reward: 3.07\n",
      "epis: 1334   score: 4.0   mem len: 266953   epsilon: 0.6694    steps: 296    lr: 4e-05     reward: 3.09\n",
      "epis: 1335   score: 3.0   mem len: 267162   epsilon: 0.669    steps: 209    lr: 4e-05     reward: 3.09\n",
      "epis: 1336   score: 2.0   mem len: 267380   epsilon: 0.6686    steps: 218    lr: 4e-05     reward: 3.05\n",
      "epis: 1337   score: 2.0   mem len: 267577   epsilon: 0.6682    steps: 197    lr: 4e-05     reward: 3.01\n",
      "epis: 1338   score: 3.0   mem len: 267790   epsilon: 0.6678    steps: 213    lr: 4e-05     reward: 2.99\n",
      "epis: 1339   score: 5.0   mem len: 268126   epsilon: 0.6671    steps: 336    lr: 4e-05     reward: 3.03\n",
      "epis: 1340   score: 3.0   mem len: 268371   epsilon: 0.6666    steps: 245    lr: 4e-05     reward: 3.02\n",
      "epis: 1341   score: 4.0   mem len: 268667   epsilon: 0.666    steps: 296    lr: 4e-05     reward: 3.03\n",
      "epis: 1342   score: 4.0   mem len: 268965   epsilon: 0.6654    steps: 298    lr: 4e-05     reward: 2.98\n",
      "epis: 1343   score: 3.0   mem len: 269211   epsilon: 0.665    steps: 246    lr: 4e-05     reward: 2.98\n",
      "epis: 1344   score: 2.0   mem len: 269434   epsilon: 0.6645    steps: 223    lr: 4e-05     reward: 2.98\n",
      "epis: 1345   score: 5.0   mem len: 269782   epsilon: 0.6638    steps: 348    lr: 4e-05     reward: 3.0\n",
      "epis: 1346   score: 3.0   mem len: 270007   epsilon: 0.6634    steps: 225    lr: 4e-05     reward: 2.97\n",
      "epis: 1347   score: 2.0   mem len: 270207   epsilon: 0.663    steps: 200    lr: 4e-05     reward: 2.93\n",
      "epis: 1348   score: 6.0   mem len: 270563   epsilon: 0.6623    steps: 356    lr: 4e-05     reward: 2.99\n",
      "epis: 1349   score: 3.0   mem len: 270789   epsilon: 0.6618    steps: 226    lr: 4e-05     reward: 2.96\n",
      "epis: 1350   score: 3.0   mem len: 271033   epsilon: 0.6614    steps: 244    lr: 4e-05     reward: 2.96\n",
      "epis: 1351   score: 4.0   mem len: 271324   epsilon: 0.6608    steps: 291    lr: 4e-05     reward: 2.97\n",
      "epis: 1352   score: 2.0   mem len: 271508   epsilon: 0.6604    steps: 184    lr: 4e-05     reward: 2.95\n",
      "epis: 1353   score: 3.0   mem len: 271755   epsilon: 0.6599    steps: 247    lr: 4e-05     reward: 2.93\n",
      "epis: 1354   score: 4.0   mem len: 272050   epsilon: 0.6593    steps: 295    lr: 4e-05     reward: 2.97\n",
      "epis: 1355   score: 3.0   mem len: 272296   epsilon: 0.6589    steps: 246    lr: 4e-05     reward: 2.99\n",
      "epis: 1356   score: 0.0   mem len: 272419   epsilon: 0.6586    steps: 123    lr: 4e-05     reward: 2.95\n",
      "epis: 1357   score: 1.0   mem len: 272569   epsilon: 0.6583    steps: 150    lr: 4e-05     reward: 2.96\n",
      "epis: 1358   score: 2.0   mem len: 272785   epsilon: 0.6579    steps: 216    lr: 4e-05     reward: 2.97\n",
      "epis: 1359   score: 3.0   mem len: 273030   epsilon: 0.6574    steps: 245    lr: 4e-05     reward: 2.97\n",
      "epis: 1360   score: 6.0   mem len: 273381   epsilon: 0.6567    steps: 351    lr: 4e-05     reward: 3.0\n",
      "epis: 1361   score: 3.0   mem len: 273611   epsilon: 0.6562    steps: 230    lr: 4e-05     reward: 3.02\n",
      "epis: 1362   score: 1.0   mem len: 273782   epsilon: 0.6559    steps: 171    lr: 4e-05     reward: 2.97\n",
      "epis: 1363   score: 2.0   mem len: 273998   epsilon: 0.6555    steps: 216    lr: 4e-05     reward: 2.98\n",
      "epis: 1364   score: 6.0   mem len: 274352   epsilon: 0.6548    steps: 354    lr: 4e-05     reward: 3.02\n",
      "epis: 1365   score: 4.0   mem len: 274649   epsilon: 0.6542    steps: 297    lr: 4e-05     reward: 3.01\n",
      "epis: 1366   score: 4.0   mem len: 274942   epsilon: 0.6536    steps: 293    lr: 4e-05     reward: 2.98\n",
      "epis: 1367   score: 3.0   mem len: 275190   epsilon: 0.6531    steps: 248    lr: 4e-05     reward: 2.99\n",
      "epis: 1368   score: 2.0   mem len: 275388   epsilon: 0.6527    steps: 198    lr: 4e-05     reward: 3.01\n",
      "epis: 1369   score: 6.0   mem len: 275724   epsilon: 0.6521    steps: 336    lr: 4e-05     reward: 3.01\n",
      "epis: 1370   score: 1.0   mem len: 275875   epsilon: 0.6518    steps: 151    lr: 4e-05     reward: 2.97\n",
      "epis: 1371   score: 2.0   mem len: 276073   epsilon: 0.6514    steps: 198    lr: 4e-05     reward: 2.97\n",
      "epis: 1372   score: 2.0   mem len: 276270   epsilon: 0.651    steps: 197    lr: 4e-05     reward: 2.96\n",
      "epis: 1373   score: 3.0   mem len: 276496   epsilon: 0.6505    steps: 226    lr: 4e-05     reward: 2.97\n",
      "epis: 1374   score: 3.0   mem len: 276762   epsilon: 0.65    steps: 266    lr: 4e-05     reward: 2.97\n",
      "epis: 1375   score: 4.0   mem len: 277076   epsilon: 0.6494    steps: 314    lr: 4e-05     reward: 2.96\n",
      "epis: 1376   score: 2.0   mem len: 277294   epsilon: 0.649    steps: 218    lr: 4e-05     reward: 2.93\n",
      "epis: 1377   score: 4.0   mem len: 277568   epsilon: 0.6484    steps: 274    lr: 4e-05     reward: 2.94\n",
      "epis: 1378   score: 4.0   mem len: 277863   epsilon: 0.6478    steps: 295    lr: 4e-05     reward: 2.97\n",
      "epis: 1379   score: 4.0   mem len: 278159   epsilon: 0.6472    steps: 296    lr: 4e-05     reward: 2.99\n",
      "epis: 1380   score: 2.0   mem len: 278359   epsilon: 0.6468    steps: 200    lr: 4e-05     reward: 3.0\n",
      "epis: 1381   score: 2.0   mem len: 278579   epsilon: 0.6464    steps: 220    lr: 4e-05     reward: 2.96\n",
      "epis: 1382   score: 1.0   mem len: 278749   epsilon: 0.6461    steps: 170    lr: 4e-05     reward: 2.91\n",
      "epis: 1383   score: 5.0   mem len: 279075   epsilon: 0.6454    steps: 326    lr: 4e-05     reward: 2.94\n",
      "epis: 1384   score: 3.0   mem len: 279301   epsilon: 0.645    steps: 226    lr: 4e-05     reward: 2.93\n",
      "epis: 1385   score: 5.0   mem len: 279630   epsilon: 0.6443    steps: 329    lr: 4e-05     reward: 2.97\n",
      "epis: 1386   score: 3.0   mem len: 279845   epsilon: 0.6439    steps: 215    lr: 4e-05     reward: 2.98\n",
      "epis: 1387   score: 4.0   mem len: 280120   epsilon: 0.6434    steps: 275    lr: 4e-05     reward: 2.99\n",
      "epis: 1388   score: 3.0   mem len: 280365   epsilon: 0.6429    steps: 245    lr: 4e-05     reward: 2.98\n",
      "epis: 1389   score: 4.0   mem len: 280646   epsilon: 0.6423    steps: 281    lr: 4e-05     reward: 3.0\n",
      "epis: 1390   score: 1.0   mem len: 280797   epsilon: 0.642    steps: 151    lr: 4e-05     reward: 2.94\n",
      "epis: 1391   score: 7.0   mem len: 281178   epsilon: 0.6413    steps: 381    lr: 4e-05     reward: 2.98\n",
      "epis: 1392   score: 8.0   mem len: 281650   epsilon: 0.6403    steps: 472    lr: 4e-05     reward: 3.03\n",
      "epis: 1393   score: 2.0   mem len: 281871   epsilon: 0.6399    steps: 221    lr: 4e-05     reward: 3.02\n",
      "epis: 1394   score: 2.0   mem len: 282069   epsilon: 0.6395    steps: 198    lr: 4e-05     reward: 3.01\n",
      "epis: 1395   score: 1.0   mem len: 282220   epsilon: 0.6392    steps: 151    lr: 4e-05     reward: 2.99\n",
      "epis: 1396   score: 3.0   mem len: 282448   epsilon: 0.6388    steps: 228    lr: 4e-05     reward: 2.98\n",
      "epis: 1397   score: 5.0   mem len: 282762   epsilon: 0.6381    steps: 314    lr: 4e-05     reward: 2.97\n",
      "epis: 1398   score: 6.0   mem len: 283135   epsilon: 0.6374    steps: 373    lr: 4e-05     reward: 3.03\n",
      "epis: 1399   score: 4.0   mem len: 283412   epsilon: 0.6368    steps: 277    lr: 4e-05     reward: 3.03\n",
      "epis: 1400   score: 3.0   mem len: 283637   epsilon: 0.6364    steps: 225    lr: 4e-05     reward: 3.02\n",
      "epis: 1401   score: 5.0   mem len: 283948   epsilon: 0.6358    steps: 311    lr: 4e-05     reward: 3.03\n",
      "epis: 1402   score: 4.0   mem len: 284263   epsilon: 0.6352    steps: 315    lr: 4e-05     reward: 3.06\n",
      "epis: 1403   score: 6.0   mem len: 284637   epsilon: 0.6344    steps: 374    lr: 4e-05     reward: 3.11\n",
      "epis: 1404   score: 3.0   mem len: 284865   epsilon: 0.634    steps: 228    lr: 4e-05     reward: 3.14\n",
      "epis: 1405   score: 7.0   mem len: 285247   epsilon: 0.6332    steps: 382    lr: 4e-05     reward: 3.21\n",
      "epis: 1406   score: 4.0   mem len: 285523   epsilon: 0.6327    steps: 276    lr: 4e-05     reward: 3.24\n",
      "epis: 1407   score: 2.0   mem len: 285720   epsilon: 0.6323    steps: 197    lr: 4e-05     reward: 3.23\n",
      "epis: 1408   score: 7.0   mem len: 286112   epsilon: 0.6315    steps: 392    lr: 4e-05     reward: 3.25\n",
      "epis: 1409   score: 3.0   mem len: 286325   epsilon: 0.6311    steps: 213    lr: 4e-05     reward: 3.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1410   score: 3.0   mem len: 286551   epsilon: 0.6306    steps: 226    lr: 4e-05     reward: 3.27\n",
      "epis: 1411   score: 2.0   mem len: 286751   epsilon: 0.6302    steps: 200    lr: 4e-05     reward: 3.26\n",
      "epis: 1412   score: 6.0   mem len: 287103   epsilon: 0.6295    steps: 352    lr: 4e-05     reward: 3.3\n",
      "epis: 1413   score: 5.0   mem len: 287410   epsilon: 0.6289    steps: 307    lr: 4e-05     reward: 3.31\n",
      "epis: 1414   score: 3.0   mem len: 287623   epsilon: 0.6285    steps: 213    lr: 4e-05     reward: 3.3\n",
      "epis: 1415   score: 5.0   mem len: 287934   epsilon: 0.6279    steps: 311    lr: 4e-05     reward: 3.35\n",
      "epis: 1416   score: 2.0   mem len: 288132   epsilon: 0.6275    steps: 198    lr: 4e-05     reward: 3.34\n",
      "epis: 1417   score: 7.0   mem len: 288562   epsilon: 0.6266    steps: 430    lr: 4e-05     reward: 3.36\n",
      "epis: 1418   score: 5.0   mem len: 288921   epsilon: 0.6259    steps: 359    lr: 4e-05     reward: 3.4\n",
      "epis: 1419   score: 3.0   mem len: 289146   epsilon: 0.6255    steps: 225    lr: 4e-05     reward: 3.42\n",
      "epis: 1420   score: 6.0   mem len: 289490   epsilon: 0.6248    steps: 344    lr: 4e-05     reward: 3.44\n",
      "epis: 1421   score: 3.0   mem len: 289716   epsilon: 0.6244    steps: 226    lr: 4e-05     reward: 3.47\n",
      "epis: 1422   score: 2.0   mem len: 289914   epsilon: 0.624    steps: 198    lr: 4e-05     reward: 3.46\n",
      "epis: 1423   score: 4.0   mem len: 290188   epsilon: 0.6234    steps: 274    lr: 4e-05     reward: 3.48\n",
      "epis: 1424   score: 4.0   mem len: 290485   epsilon: 0.6228    steps: 297    lr: 4e-05     reward: 3.49\n",
      "epis: 1425   score: 3.0   mem len: 290729   epsilon: 0.6224    steps: 244    lr: 4e-05     reward: 3.44\n",
      "epis: 1426   score: 2.0   mem len: 290927   epsilon: 0.622    steps: 198    lr: 4e-05     reward: 3.43\n",
      "epis: 1427   score: 4.0   mem len: 291206   epsilon: 0.6214    steps: 279    lr: 4e-05     reward: 3.47\n",
      "epis: 1428   score: 4.0   mem len: 291465   epsilon: 0.6209    steps: 259    lr: 4e-05     reward: 3.5\n",
      "epis: 1429   score: 3.0   mem len: 291712   epsilon: 0.6204    steps: 247    lr: 4e-05     reward: 3.51\n",
      "epis: 1430   score: 5.0   mem len: 292022   epsilon: 0.6198    steps: 310    lr: 4e-05     reward: 3.53\n",
      "epis: 1431   score: 8.0   mem len: 292512   epsilon: 0.6188    steps: 490    lr: 4e-05     reward: 3.57\n",
      "epis: 1432   score: 5.0   mem len: 292855   epsilon: 0.6181    steps: 343    lr: 4e-05     reward: 3.57\n",
      "epis: 1433   score: 1.0   mem len: 293005   epsilon: 0.6178    steps: 150    lr: 4e-05     reward: 3.55\n",
      "epis: 1434   score: 5.0   mem len: 293310   epsilon: 0.6172    steps: 305    lr: 4e-05     reward: 3.56\n",
      "epis: 1435   score: 3.0   mem len: 293535   epsilon: 0.6168    steps: 225    lr: 4e-05     reward: 3.56\n",
      "epis: 1436   score: 4.0   mem len: 293795   epsilon: 0.6163    steps: 260    lr: 4e-05     reward: 3.58\n",
      "epis: 1437   score: 5.0   mem len: 294104   epsilon: 0.6157    steps: 309    lr: 4e-05     reward: 3.61\n",
      "epis: 1438   score: 4.0   mem len: 294398   epsilon: 0.6151    steps: 294    lr: 4e-05     reward: 3.62\n",
      "epis: 1439   score: 5.0   mem len: 294724   epsilon: 0.6144    steps: 326    lr: 4e-05     reward: 3.62\n",
      "epis: 1440   score: 2.0   mem len: 294945   epsilon: 0.614    steps: 221    lr: 4e-05     reward: 3.61\n",
      "epis: 1441   score: 4.0   mem len: 295243   epsilon: 0.6134    steps: 298    lr: 4e-05     reward: 3.61\n",
      "epis: 1442   score: 3.0   mem len: 295488   epsilon: 0.6129    steps: 245    lr: 4e-05     reward: 3.6\n",
      "epis: 1443   score: 3.0   mem len: 295714   epsilon: 0.6125    steps: 226    lr: 4e-05     reward: 3.6\n",
      "epis: 1444   score: 3.0   mem len: 295960   epsilon: 0.612    steps: 246    lr: 4e-05     reward: 3.61\n",
      "epis: 1445   score: 5.0   mem len: 296329   epsilon: 0.6113    steps: 369    lr: 4e-05     reward: 3.61\n",
      "epis: 1446   score: 8.0   mem len: 296765   epsilon: 0.6104    steps: 436    lr: 4e-05     reward: 3.66\n",
      "epis: 1447   score: 3.0   mem len: 296991   epsilon: 0.61    steps: 226    lr: 4e-05     reward: 3.67\n",
      "epis: 1448   score: 2.0   mem len: 297188   epsilon: 0.6096    steps: 197    lr: 4e-05     reward: 3.63\n",
      "epis: 1449   score: 6.0   mem len: 297541   epsilon: 0.6089    steps: 353    lr: 4e-05     reward: 3.66\n",
      "epis: 1450   score: 2.0   mem len: 297722   epsilon: 0.6085    steps: 181    lr: 4e-05     reward: 3.65\n",
      "epis: 1451   score: 2.0   mem len: 297920   epsilon: 0.6081    steps: 198    lr: 4e-05     reward: 3.63\n",
      "epis: 1452   score: 1.0   mem len: 298091   epsilon: 0.6078    steps: 171    lr: 4e-05     reward: 3.62\n",
      "epis: 1453   score: 3.0   mem len: 298337   epsilon: 0.6073    steps: 246    lr: 4e-05     reward: 3.62\n",
      "epis: 1454   score: 3.0   mem len: 298549   epsilon: 0.6069    steps: 212    lr: 4e-05     reward: 3.61\n",
      "epis: 1455   score: 3.0   mem len: 298792   epsilon: 0.6064    steps: 243    lr: 4e-05     reward: 3.61\n",
      "epis: 1456   score: 4.0   mem len: 299066   epsilon: 0.6058    steps: 274    lr: 4e-05     reward: 3.65\n",
      "epis: 1457   score: 7.0   mem len: 299431   epsilon: 0.6051    steps: 365    lr: 4e-05     reward: 3.71\n",
      "epis: 1458   score: 2.0   mem len: 299631   epsilon: 0.6047    steps: 200    lr: 4e-05     reward: 3.71\n",
      "epis: 1459   score: 2.0   mem len: 299811   epsilon: 0.6044    steps: 180    lr: 4e-05     reward: 3.7\n",
      "epis: 1460   score: 8.0   mem len: 300257   epsilon: 0.6035    steps: 446    lr: 1.6e-05     reward: 3.72\n",
      "epis: 1461   score: 2.0   mem len: 300455   epsilon: 0.6031    steps: 198    lr: 1.6e-05     reward: 3.71\n",
      "epis: 1462   score: 7.0   mem len: 300824   epsilon: 0.6024    steps: 369    lr: 1.6e-05     reward: 3.77\n",
      "epis: 1463   score: 1.0   mem len: 300975   epsilon: 0.6021    steps: 151    lr: 1.6e-05     reward: 3.76\n",
      "epis: 1464   score: 5.0   mem len: 301282   epsilon: 0.6015    steps: 307    lr: 1.6e-05     reward: 3.75\n",
      "epis: 1465   score: 3.0   mem len: 301530   epsilon: 0.601    steps: 248    lr: 1.6e-05     reward: 3.74\n",
      "epis: 1466   score: 3.0   mem len: 301778   epsilon: 0.6005    steps: 248    lr: 1.6e-05     reward: 3.73\n",
      "epis: 1467   score: 2.0   mem len: 301975   epsilon: 0.6001    steps: 197    lr: 1.6e-05     reward: 3.72\n",
      "epis: 1468   score: 8.0   mem len: 302464   epsilon: 0.5991    steps: 489    lr: 1.6e-05     reward: 3.78\n",
      "epis: 1469   score: 3.0   mem len: 302717   epsilon: 0.5986    steps: 253    lr: 1.6e-05     reward: 3.75\n",
      "epis: 1470   score: 4.0   mem len: 302995   epsilon: 0.5981    steps: 278    lr: 1.6e-05     reward: 3.78\n",
      "epis: 1471   score: 10.0   mem len: 303539   epsilon: 0.597    steps: 544    lr: 1.6e-05     reward: 3.86\n",
      "epis: 1472   score: 2.0   mem len: 303719   epsilon: 0.5966    steps: 180    lr: 1.6e-05     reward: 3.86\n",
      "epis: 1473   score: 4.0   mem len: 303978   epsilon: 0.5961    steps: 259    lr: 1.6e-05     reward: 3.87\n",
      "epis: 1474   score: 5.0   mem len: 304303   epsilon: 0.5955    steps: 325    lr: 1.6e-05     reward: 3.89\n",
      "epis: 1475   score: 4.0   mem len: 304582   epsilon: 0.5949    steps: 279    lr: 1.6e-05     reward: 3.89\n",
      "epis: 1476   score: 5.0   mem len: 304888   epsilon: 0.5943    steps: 306    lr: 1.6e-05     reward: 3.92\n",
      "epis: 1477   score: 7.0   mem len: 305298   epsilon: 0.5935    steps: 410    lr: 1.6e-05     reward: 3.95\n",
      "epis: 1478   score: 3.0   mem len: 305544   epsilon: 0.593    steps: 246    lr: 1.6e-05     reward: 3.94\n",
      "epis: 1479   score: 3.0   mem len: 305788   epsilon: 0.5925    steps: 244    lr: 1.6e-05     reward: 3.93\n",
      "epis: 1480   score: 5.0   mem len: 306075   epsilon: 0.592    steps: 287    lr: 1.6e-05     reward: 3.96\n",
      "epis: 1481   score: 4.0   mem len: 306350   epsilon: 0.5914    steps: 275    lr: 1.6e-05     reward: 3.98\n",
      "epis: 1482   score: 3.0   mem len: 306578   epsilon: 0.591    steps: 228    lr: 1.6e-05     reward: 4.0\n",
      "epis: 1483   score: 4.0   mem len: 306822   epsilon: 0.5905    steps: 244    lr: 1.6e-05     reward: 3.99\n",
      "epis: 1484   score: 4.0   mem len: 307079   epsilon: 0.59    steps: 257    lr: 1.6e-05     reward: 4.0\n",
      "epis: 1485   score: 3.0   mem len: 307307   epsilon: 0.5895    steps: 228    lr: 1.6e-05     reward: 3.98\n",
      "epis: 1486   score: 4.0   mem len: 307601   epsilon: 0.5889    steps: 294    lr: 1.6e-05     reward: 3.99\n",
      "epis: 1487   score: 3.0   mem len: 307810   epsilon: 0.5885    steps: 209    lr: 1.6e-05     reward: 3.98\n",
      "epis: 1488   score: 4.0   mem len: 308126   epsilon: 0.5879    steps: 316    lr: 1.6e-05     reward: 3.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1489   score: 3.0   mem len: 308352   epsilon: 0.5875    steps: 226    lr: 1.6e-05     reward: 3.98\n",
      "epis: 1490   score: 2.0   mem len: 308549   epsilon: 0.5871    steps: 197    lr: 1.6e-05     reward: 3.99\n",
      "epis: 1491   score: 8.0   mem len: 308955   epsilon: 0.5863    steps: 406    lr: 1.6e-05     reward: 4.0\n",
      "epis: 1492   score: 5.0   mem len: 309281   epsilon: 0.5856    steps: 326    lr: 1.6e-05     reward: 3.97\n",
      "epis: 1493   score: 4.0   mem len: 309557   epsilon: 0.5851    steps: 276    lr: 1.6e-05     reward: 3.99\n",
      "epis: 1494   score: 6.0   mem len: 309891   epsilon: 0.5844    steps: 334    lr: 1.6e-05     reward: 4.03\n",
      "epis: 1495   score: 7.0   mem len: 310272   epsilon: 0.5837    steps: 381    lr: 1.6e-05     reward: 4.09\n",
      "epis: 1496   score: 6.0   mem len: 310628   epsilon: 0.583    steps: 356    lr: 1.6e-05     reward: 4.12\n",
      "epis: 1497   score: 8.0   mem len: 311078   epsilon: 0.5821    steps: 450    lr: 1.6e-05     reward: 4.15\n",
      "epis: 1498   score: 2.0   mem len: 311258   epsilon: 0.5817    steps: 180    lr: 1.6e-05     reward: 4.11\n",
      "epis: 1499   score: 5.0   mem len: 311607   epsilon: 0.581    steps: 349    lr: 1.6e-05     reward: 4.12\n",
      "epis: 1500   score: 8.0   mem len: 312034   epsilon: 0.5802    steps: 427    lr: 1.6e-05     reward: 4.17\n",
      "epis: 1501   score: 4.0   mem len: 312308   epsilon: 0.5796    steps: 274    lr: 1.6e-05     reward: 4.16\n",
      "epis: 1502   score: 5.0   mem len: 312650   epsilon: 0.579    steps: 342    lr: 1.6e-05     reward: 4.17\n",
      "epis: 1503   score: 3.0   mem len: 312879   epsilon: 0.5785    steps: 229    lr: 1.6e-05     reward: 4.14\n",
      "epis: 1504   score: 3.0   mem len: 313127   epsilon: 0.578    steps: 248    lr: 1.6e-05     reward: 4.14\n",
      "epis: 1505   score: 7.0   mem len: 313514   epsilon: 0.5772    steps: 387    lr: 1.6e-05     reward: 4.14\n",
      "epis: 1506   score: 7.0   mem len: 313938   epsilon: 0.5764    steps: 424    lr: 1.6e-05     reward: 4.17\n",
      "epis: 1507   score: 6.0   mem len: 314329   epsilon: 0.5756    steps: 391    lr: 1.6e-05     reward: 4.21\n",
      "epis: 1508   score: 4.0   mem len: 314621   epsilon: 0.575    steps: 292    lr: 1.6e-05     reward: 4.18\n",
      "epis: 1509   score: 2.0   mem len: 314801   epsilon: 0.5747    steps: 180    lr: 1.6e-05     reward: 4.17\n",
      "epis: 1510   score: 3.0   mem len: 315030   epsilon: 0.5742    steps: 229    lr: 1.6e-05     reward: 4.17\n",
      "epis: 1511   score: 1.0   mem len: 315199   epsilon: 0.5739    steps: 169    lr: 1.6e-05     reward: 4.16\n",
      "epis: 1512   score: 3.0   mem len: 315425   epsilon: 0.5735    steps: 226    lr: 1.6e-05     reward: 4.13\n",
      "epis: 1513   score: 5.0   mem len: 315766   epsilon: 0.5728    steps: 341    lr: 1.6e-05     reward: 4.13\n",
      "epis: 1514   score: 6.0   mem len: 316104   epsilon: 0.5721    steps: 338    lr: 1.6e-05     reward: 4.16\n",
      "epis: 1515   score: 6.0   mem len: 316479   epsilon: 0.5714    steps: 375    lr: 1.6e-05     reward: 4.17\n",
      "epis: 1516   score: 6.0   mem len: 316836   epsilon: 0.5707    steps: 357    lr: 1.6e-05     reward: 4.21\n",
      "epis: 1517   score: 5.0   mem len: 317146   epsilon: 0.57    steps: 310    lr: 1.6e-05     reward: 4.19\n",
      "epis: 1518   score: 4.0   mem len: 317385   epsilon: 0.5696    steps: 239    lr: 1.6e-05     reward: 4.18\n",
      "epis: 1519   score: 2.0   mem len: 317585   epsilon: 0.5692    steps: 200    lr: 1.6e-05     reward: 4.17\n",
      "epis: 1520   score: 11.0   mem len: 318052   epsilon: 0.5683    steps: 467    lr: 1.6e-05     reward: 4.22\n",
      "epis: 1521   score: 3.0   mem len: 318265   epsilon: 0.5678    steps: 213    lr: 1.6e-05     reward: 4.22\n",
      "epis: 1522   score: 5.0   mem len: 318592   epsilon: 0.5672    steps: 327    lr: 1.6e-05     reward: 4.25\n",
      "epis: 1523   score: 2.0   mem len: 318772   epsilon: 0.5668    steps: 180    lr: 1.6e-05     reward: 4.23\n",
      "epis: 1524   score: 2.0   mem len: 318974   epsilon: 0.5664    steps: 202    lr: 1.6e-05     reward: 4.21\n",
      "epis: 1525   score: 5.0   mem len: 319281   epsilon: 0.5658    steps: 307    lr: 1.6e-05     reward: 4.23\n",
      "epis: 1526   score: 8.0   mem len: 319682   epsilon: 0.565    steps: 401    lr: 1.6e-05     reward: 4.29\n",
      "epis: 1527   score: 3.0   mem len: 319927   epsilon: 0.5645    steps: 245    lr: 1.6e-05     reward: 4.28\n",
      "epis: 1528   score: 6.0   mem len: 320266   epsilon: 0.5639    steps: 339    lr: 1.6e-05     reward: 4.3\n",
      "epis: 1529   score: 3.0   mem len: 320512   epsilon: 0.5634    steps: 246    lr: 1.6e-05     reward: 4.3\n",
      "epis: 1530   score: 4.0   mem len: 320769   epsilon: 0.5629    steps: 257    lr: 1.6e-05     reward: 4.29\n",
      "epis: 1531   score: 7.0   mem len: 321176   epsilon: 0.5621    steps: 407    lr: 1.6e-05     reward: 4.28\n",
      "epis: 1532   score: 6.0   mem len: 321548   epsilon: 0.5613    steps: 372    lr: 1.6e-05     reward: 4.29\n",
      "epis: 1533   score: 7.0   mem len: 321953   epsilon: 0.5605    steps: 405    lr: 1.6e-05     reward: 4.35\n",
      "epis: 1534   score: 4.0   mem len: 322209   epsilon: 0.56    steps: 256    lr: 1.6e-05     reward: 4.34\n",
      "epis: 1535   score: 3.0   mem len: 322434   epsilon: 0.5596    steps: 225    lr: 1.6e-05     reward: 4.34\n",
      "epis: 1536   score: 4.0   mem len: 322729   epsilon: 0.559    steps: 295    lr: 1.6e-05     reward: 4.34\n",
      "epis: 1537   score: 4.0   mem len: 323025   epsilon: 0.5584    steps: 296    lr: 1.6e-05     reward: 4.33\n",
      "epis: 1538   score: 5.0   mem len: 323295   epsilon: 0.5579    steps: 270    lr: 1.6e-05     reward: 4.34\n",
      "epis: 1539   score: 1.0   mem len: 323464   epsilon: 0.5575    steps: 169    lr: 1.6e-05     reward: 4.3\n",
      "epis: 1540   score: 5.0   mem len: 323768   epsilon: 0.5569    steps: 304    lr: 1.6e-05     reward: 4.33\n",
      "epis: 1541   score: 6.0   mem len: 324125   epsilon: 0.5562    steps: 357    lr: 1.6e-05     reward: 4.35\n",
      "epis: 1542   score: 3.0   mem len: 324357   epsilon: 0.5558    steps: 232    lr: 1.6e-05     reward: 4.35\n",
      "epis: 1543   score: 7.0   mem len: 324734   epsilon: 0.555    steps: 377    lr: 1.6e-05     reward: 4.39\n",
      "epis: 1544   score: 3.0   mem len: 324943   epsilon: 0.5546    steps: 209    lr: 1.6e-05     reward: 4.39\n",
      "epis: 1545   score: 6.0   mem len: 325322   epsilon: 0.5539    steps: 379    lr: 1.6e-05     reward: 4.4\n",
      "epis: 1546   score: 4.0   mem len: 325599   epsilon: 0.5533    steps: 277    lr: 1.6e-05     reward: 4.36\n",
      "epis: 1547   score: 4.0   mem len: 325876   epsilon: 0.5528    steps: 277    lr: 1.6e-05     reward: 4.37\n",
      "epis: 1548   score: 6.0   mem len: 326247   epsilon: 0.552    steps: 371    lr: 1.6e-05     reward: 4.41\n",
      "epis: 1549   score: 7.0   mem len: 326633   epsilon: 0.5513    steps: 386    lr: 1.6e-05     reward: 4.42\n",
      "epis: 1550   score: 4.0   mem len: 326931   epsilon: 0.5507    steps: 298    lr: 1.6e-05     reward: 4.44\n",
      "epis: 1551   score: 7.0   mem len: 327354   epsilon: 0.5498    steps: 423    lr: 1.6e-05     reward: 4.49\n",
      "epis: 1552   score: 8.0   mem len: 327848   epsilon: 0.5489    steps: 494    lr: 1.6e-05     reward: 4.56\n",
      "epis: 1553   score: 6.0   mem len: 328228   epsilon: 0.5481    steps: 380    lr: 1.6e-05     reward: 4.59\n",
      "epis: 1554   score: 6.0   mem len: 328579   epsilon: 0.5474    steps: 351    lr: 1.6e-05     reward: 4.62\n",
      "epis: 1555   score: 4.0   mem len: 328877   epsilon: 0.5468    steps: 298    lr: 1.6e-05     reward: 4.63\n",
      "epis: 1556   score: 5.0   mem len: 329165   epsilon: 0.5463    steps: 288    lr: 1.6e-05     reward: 4.64\n",
      "epis: 1557   score: 4.0   mem len: 329439   epsilon: 0.5457    steps: 274    lr: 1.6e-05     reward: 4.61\n",
      "epis: 1558   score: 4.0   mem len: 329683   epsilon: 0.5452    steps: 244    lr: 1.6e-05     reward: 4.63\n",
      "epis: 1559   score: 5.0   mem len: 329988   epsilon: 0.5446    steps: 305    lr: 1.6e-05     reward: 4.66\n",
      "epis: 1560   score: 4.0   mem len: 330245   epsilon: 0.5441    steps: 257    lr: 1.6e-05     reward: 4.62\n",
      "epis: 1561   score: 4.0   mem len: 330501   epsilon: 0.5436    steps: 256    lr: 1.6e-05     reward: 4.64\n",
      "epis: 1562   score: 2.0   mem len: 330683   epsilon: 0.5432    steps: 182    lr: 1.6e-05     reward: 4.59\n",
      "epis: 1563   score: 3.0   mem len: 330927   epsilon: 0.5428    steps: 244    lr: 1.6e-05     reward: 4.61\n",
      "epis: 1564   score: 3.0   mem len: 331153   epsilon: 0.5423    steps: 226    lr: 1.6e-05     reward: 4.59\n",
      "epis: 1565   score: 5.0   mem len: 331472   epsilon: 0.5417    steps: 319    lr: 1.6e-05     reward: 4.61\n",
      "epis: 1566   score: 4.0   mem len: 331749   epsilon: 0.5411    steps: 277    lr: 1.6e-05     reward: 4.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1567   score: 8.0   mem len: 332181   epsilon: 0.5403    steps: 432    lr: 1.6e-05     reward: 4.68\n",
      "epis: 1568   score: 14.0   mem len: 332732   epsilon: 0.5392    steps: 551    lr: 1.6e-05     reward: 4.74\n",
      "epis: 1569   score: 8.0   mem len: 333212   epsilon: 0.5382    steps: 480    lr: 1.6e-05     reward: 4.79\n",
      "epis: 1570   score: 5.0   mem len: 333535   epsilon: 0.5376    steps: 323    lr: 1.6e-05     reward: 4.8\n",
      "epis: 1571   score: 7.0   mem len: 333882   epsilon: 0.5369    steps: 347    lr: 1.6e-05     reward: 4.77\n",
      "epis: 1572   score: 10.0   mem len: 334359   epsilon: 0.536    steps: 477    lr: 1.6e-05     reward: 4.85\n",
      "epis: 1573   score: 2.0   mem len: 334541   epsilon: 0.5356    steps: 182    lr: 1.6e-05     reward: 4.83\n",
      "epis: 1574   score: 4.0   mem len: 334800   epsilon: 0.5351    steps: 259    lr: 1.6e-05     reward: 4.82\n",
      "epis: 1575   score: 5.0   mem len: 335092   epsilon: 0.5345    steps: 292    lr: 1.6e-05     reward: 4.83\n",
      "epis: 1576   score: 3.0   mem len: 335304   epsilon: 0.5341    steps: 212    lr: 1.6e-05     reward: 4.81\n",
      "epis: 1577   score: 3.0   mem len: 335516   epsilon: 0.5337    steps: 212    lr: 1.6e-05     reward: 4.77\n",
      "epis: 1578   score: 5.0   mem len: 335825   epsilon: 0.5331    steps: 309    lr: 1.6e-05     reward: 4.79\n",
      "epis: 1579   score: 4.0   mem len: 336118   epsilon: 0.5325    steps: 293    lr: 1.6e-05     reward: 4.8\n",
      "epis: 1580   score: 4.0   mem len: 336394   epsilon: 0.5319    steps: 276    lr: 1.6e-05     reward: 4.79\n",
      "epis: 1581   score: 2.0   mem len: 336592   epsilon: 0.5315    steps: 198    lr: 1.6e-05     reward: 4.77\n",
      "epis: 1582   score: 2.0   mem len: 336790   epsilon: 0.5312    steps: 198    lr: 1.6e-05     reward: 4.76\n",
      "epis: 1583   score: 6.0   mem len: 337162   epsilon: 0.5304    steps: 372    lr: 1.6e-05     reward: 4.78\n",
      "epis: 1584   score: 4.0   mem len: 337455   epsilon: 0.5298    steps: 293    lr: 1.6e-05     reward: 4.78\n",
      "epis: 1585   score: 4.0   mem len: 337715   epsilon: 0.5293    steps: 260    lr: 1.6e-05     reward: 4.79\n",
      "epis: 1586   score: 6.0   mem len: 338054   epsilon: 0.5287    steps: 339    lr: 1.6e-05     reward: 4.81\n",
      "epis: 1587   score: 2.0   mem len: 338251   epsilon: 0.5283    steps: 197    lr: 1.6e-05     reward: 4.8\n",
      "epis: 1588   score: 6.0   mem len: 338608   epsilon: 0.5276    steps: 357    lr: 1.6e-05     reward: 4.82\n",
      "epis: 1589   score: 2.0   mem len: 338829   epsilon: 0.5271    steps: 221    lr: 1.6e-05     reward: 4.81\n",
      "epis: 1590   score: 4.0   mem len: 339087   epsilon: 0.5266    steps: 258    lr: 1.6e-05     reward: 4.83\n",
      "epis: 1591   score: 4.0   mem len: 339383   epsilon: 0.526    steps: 296    lr: 1.6e-05     reward: 4.79\n",
      "epis: 1592   score: 6.0   mem len: 339720   epsilon: 0.5254    steps: 337    lr: 1.6e-05     reward: 4.8\n",
      "epis: 1593   score: 14.0   mem len: 340293   epsilon: 0.5242    steps: 573    lr: 1.6e-05     reward: 4.9\n",
      "epis: 1594   score: 2.0   mem len: 340493   epsilon: 0.5238    steps: 200    lr: 1.6e-05     reward: 4.86\n",
      "epis: 1595   score: 5.0   mem len: 340822   epsilon: 0.5232    steps: 329    lr: 1.6e-05     reward: 4.84\n",
      "epis: 1596   score: 3.0   mem len: 341051   epsilon: 0.5227    steps: 229    lr: 1.6e-05     reward: 4.81\n",
      "epis: 1597   score: 13.0   mem len: 341548   epsilon: 0.5217    steps: 497    lr: 1.6e-05     reward: 4.86\n",
      "epis: 1598   score: 6.0   mem len: 341871   epsilon: 0.5211    steps: 323    lr: 1.6e-05     reward: 4.9\n",
      "epis: 1599   score: 4.0   mem len: 342163   epsilon: 0.5205    steps: 292    lr: 1.6e-05     reward: 4.89\n",
      "epis: 1600   score: 7.0   mem len: 342571   epsilon: 0.5197    steps: 408    lr: 1.6e-05     reward: 4.88\n",
      "epis: 1601   score: 8.0   mem len: 343026   epsilon: 0.5188    steps: 455    lr: 1.6e-05     reward: 4.92\n",
      "epis: 1602   score: 5.0   mem len: 343374   epsilon: 0.5181    steps: 348    lr: 1.6e-05     reward: 4.92\n",
      "epis: 1603   score: 7.0   mem len: 343798   epsilon: 0.5173    steps: 424    lr: 1.6e-05     reward: 4.96\n",
      "epis: 1604   score: 4.0   mem len: 344059   epsilon: 0.5168    steps: 261    lr: 1.6e-05     reward: 4.97\n",
      "epis: 1605   score: 3.0   mem len: 344272   epsilon: 0.5163    steps: 213    lr: 1.6e-05     reward: 4.93\n",
      "epis: 1606   score: 6.0   mem len: 344668   epsilon: 0.5156    steps: 396    lr: 1.6e-05     reward: 4.92\n",
      "epis: 1607   score: 2.0   mem len: 344849   epsilon: 0.5152    steps: 181    lr: 1.6e-05     reward: 4.88\n",
      "epis: 1608   score: 4.0   mem len: 345123   epsilon: 0.5147    steps: 274    lr: 1.6e-05     reward: 4.88\n",
      "epis: 1609   score: 3.0   mem len: 345336   epsilon: 0.5142    steps: 213    lr: 1.6e-05     reward: 4.89\n",
      "epis: 1610   score: 11.0   mem len: 345899   epsilon: 0.5131    steps: 563    lr: 1.6e-05     reward: 4.97\n",
      "epis: 1611   score: 3.0   mem len: 346110   epsilon: 0.5127    steps: 211    lr: 1.6e-05     reward: 4.99\n",
      "epis: 1612   score: 2.0   mem len: 346327   epsilon: 0.5123    steps: 217    lr: 1.6e-05     reward: 4.98\n",
      "epis: 1613   score: 5.0   mem len: 346672   epsilon: 0.5116    steps: 345    lr: 1.6e-05     reward: 4.98\n",
      "epis: 1614   score: 4.0   mem len: 346949   epsilon: 0.511    steps: 277    lr: 1.6e-05     reward: 4.96\n",
      "epis: 1615   score: 3.0   mem len: 347162   epsilon: 0.5106    steps: 213    lr: 1.6e-05     reward: 4.93\n",
      "epis: 1616   score: 5.0   mem len: 347466   epsilon: 0.51    steps: 304    lr: 1.6e-05     reward: 4.92\n",
      "epis: 1617   score: 4.0   mem len: 347742   epsilon: 0.5095    steps: 276    lr: 1.6e-05     reward: 4.91\n",
      "epis: 1618   score: 4.0   mem len: 348018   epsilon: 0.5089    steps: 276    lr: 1.6e-05     reward: 4.91\n",
      "epis: 1619   score: 8.0   mem len: 348424   epsilon: 0.5081    steps: 406    lr: 1.6e-05     reward: 4.97\n",
      "epis: 1620   score: 6.0   mem len: 348758   epsilon: 0.5075    steps: 334    lr: 1.6e-05     reward: 4.92\n",
      "epis: 1621   score: 3.0   mem len: 348971   epsilon: 0.507    steps: 213    lr: 1.6e-05     reward: 4.92\n",
      "epis: 1622   score: 10.0   mem len: 349455   epsilon: 0.5061    steps: 484    lr: 1.6e-05     reward: 4.97\n",
      "epis: 1623   score: 7.0   mem len: 349857   epsilon: 0.5053    steps: 402    lr: 1.6e-05     reward: 5.02\n",
      "epis: 1624   score: 6.0   mem len: 350192   epsilon: 0.5046    steps: 335    lr: 1.6e-05     reward: 5.06\n",
      "epis: 1625   score: 7.0   mem len: 350614   epsilon: 0.5038    steps: 422    lr: 1.6e-05     reward: 5.08\n",
      "epis: 1626   score: 9.0   mem len: 351098   epsilon: 0.5028    steps: 484    lr: 1.6e-05     reward: 5.09\n",
      "epis: 1627   score: 3.0   mem len: 351309   epsilon: 0.5024    steps: 211    lr: 1.6e-05     reward: 5.09\n",
      "epis: 1628   score: 4.0   mem len: 351605   epsilon: 0.5018    steps: 296    lr: 1.6e-05     reward: 5.07\n",
      "epis: 1629   score: 4.0   mem len: 351902   epsilon: 0.5012    steps: 297    lr: 1.6e-05     reward: 5.08\n",
      "epis: 1630   score: 6.0   mem len: 352296   epsilon: 0.5005    steps: 394    lr: 1.6e-05     reward: 5.1\n",
      "epis: 1631   score: 8.0   mem len: 352741   epsilon: 0.4996    steps: 445    lr: 1.6e-05     reward: 5.11\n",
      "epis: 1632   score: 5.0   mem len: 353066   epsilon: 0.4989    steps: 325    lr: 1.6e-05     reward: 5.1\n",
      "epis: 1633   score: 6.0   mem len: 353437   epsilon: 0.4982    steps: 371    lr: 1.6e-05     reward: 5.09\n",
      "epis: 1634   score: 7.0   mem len: 353858   epsilon: 0.4974    steps: 421    lr: 1.6e-05     reward: 5.12\n",
      "epis: 1635   score: 2.0   mem len: 354056   epsilon: 0.497    steps: 198    lr: 1.6e-05     reward: 5.11\n",
      "epis: 1636   score: 5.0   mem len: 354378   epsilon: 0.4963    steps: 322    lr: 1.6e-05     reward: 5.12\n",
      "epis: 1637   score: 5.0   mem len: 354668   epsilon: 0.4958    steps: 290    lr: 1.6e-05     reward: 5.13\n",
      "epis: 1638   score: 7.0   mem len: 355045   epsilon: 0.495    steps: 377    lr: 1.6e-05     reward: 5.15\n",
      "epis: 1639   score: 4.0   mem len: 355305   epsilon: 0.4945    steps: 260    lr: 1.6e-05     reward: 5.18\n",
      "epis: 1640   score: 4.0   mem len: 355562   epsilon: 0.494    steps: 257    lr: 1.6e-05     reward: 5.17\n",
      "epis: 1641   score: 3.0   mem len: 355828   epsilon: 0.4935    steps: 266    lr: 1.6e-05     reward: 5.14\n",
      "epis: 1642   score: 3.0   mem len: 356060   epsilon: 0.493    steps: 232    lr: 1.6e-05     reward: 5.14\n",
      "epis: 1643   score: 5.0   mem len: 356384   epsilon: 0.4924    steps: 324    lr: 1.6e-05     reward: 5.12\n",
      "epis: 1644   score: 3.0   mem len: 356615   epsilon: 0.4919    steps: 231    lr: 1.6e-05     reward: 5.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1645   score: 7.0   mem len: 356861   epsilon: 0.4914    steps: 246    lr: 1.6e-05     reward: 5.13\n",
      "epis: 1646   score: 5.0   mem len: 357186   epsilon: 0.4908    steps: 325    lr: 1.6e-05     reward: 5.14\n",
      "epis: 1647   score: 5.0   mem len: 357495   epsilon: 0.4902    steps: 309    lr: 1.6e-05     reward: 5.15\n",
      "epis: 1648   score: 6.0   mem len: 357851   epsilon: 0.4895    steps: 356    lr: 1.6e-05     reward: 5.15\n",
      "epis: 1649   score: 12.0   mem len: 358364   epsilon: 0.4884    steps: 513    lr: 1.6e-05     reward: 5.2\n",
      "epis: 1650   score: 2.0   mem len: 358546   epsilon: 0.4881    steps: 182    lr: 1.6e-05     reward: 5.18\n",
      "epis: 1651   score: 5.0   mem len: 358852   epsilon: 0.4875    steps: 306    lr: 1.6e-05     reward: 5.16\n",
      "epis: 1652   score: 3.0   mem len: 359065   epsilon: 0.487    steps: 213    lr: 1.6e-05     reward: 5.11\n",
      "epis: 1653   score: 3.0   mem len: 359313   epsilon: 0.4866    steps: 248    lr: 1.6e-05     reward: 5.08\n",
      "epis: 1654   score: 6.0   mem len: 359711   epsilon: 0.4858    steps: 398    lr: 1.6e-05     reward: 5.08\n",
      "epis: 1655   score: 8.0   mem len: 360113   epsilon: 0.485    steps: 402    lr: 1.6e-05     reward: 5.12\n",
      "epis: 1656   score: 6.0   mem len: 360486   epsilon: 0.4842    steps: 373    lr: 1.6e-05     reward: 5.13\n",
      "epis: 1657   score: 6.0   mem len: 360858   epsilon: 0.4835    steps: 372    lr: 1.6e-05     reward: 5.15\n",
      "epis: 1658   score: 5.0   mem len: 361163   epsilon: 0.4829    steps: 305    lr: 1.6e-05     reward: 5.16\n",
      "epis: 1659   score: 4.0   mem len: 361478   epsilon: 0.4823    steps: 315    lr: 1.6e-05     reward: 5.15\n",
      "epis: 1660   score: 3.0   mem len: 361709   epsilon: 0.4818    steps: 231    lr: 1.6e-05     reward: 5.14\n",
      "epis: 1661   score: 2.0   mem len: 361907   epsilon: 0.4814    steps: 198    lr: 1.6e-05     reward: 5.12\n",
      "epis: 1662   score: 6.0   mem len: 362261   epsilon: 0.4807    steps: 354    lr: 1.6e-05     reward: 5.16\n",
      "epis: 1663   score: 5.0   mem len: 362567   epsilon: 0.4801    steps: 306    lr: 1.6e-05     reward: 5.18\n",
      "epis: 1664   score: 12.0   mem len: 363010   epsilon: 0.4792    steps: 443    lr: 1.6e-05     reward: 5.27\n",
      "epis: 1665   score: 4.0   mem len: 363289   epsilon: 0.4787    steps: 279    lr: 1.6e-05     reward: 5.26\n",
      "epis: 1666   score: 7.0   mem len: 363690   epsilon: 0.4779    steps: 401    lr: 1.6e-05     reward: 5.29\n",
      "epis: 1667   score: 4.0   mem len: 363983   epsilon: 0.4773    steps: 293    lr: 1.6e-05     reward: 5.25\n",
      "epis: 1668   score: 4.0   mem len: 364240   epsilon: 0.4768    steps: 257    lr: 1.6e-05     reward: 5.15\n",
      "epis: 1669   score: 3.0   mem len: 364485   epsilon: 0.4763    steps: 245    lr: 1.6e-05     reward: 5.1\n",
      "epis: 1670   score: 7.0   mem len: 364900   epsilon: 0.4755    steps: 415    lr: 1.6e-05     reward: 5.12\n",
      "epis: 1671   score: 9.0   mem len: 365367   epsilon: 0.4746    steps: 467    lr: 1.6e-05     reward: 5.14\n",
      "epis: 1672   score: 4.0   mem len: 365641   epsilon: 0.474    steps: 274    lr: 1.6e-05     reward: 5.08\n",
      "epis: 1673   score: 8.0   mem len: 366108   epsilon: 0.4731    steps: 467    lr: 1.6e-05     reward: 5.14\n",
      "epis: 1674   score: 3.0   mem len: 366335   epsilon: 0.4727    steps: 227    lr: 1.6e-05     reward: 5.13\n",
      "epis: 1675   score: 8.0   mem len: 366806   epsilon: 0.4717    steps: 471    lr: 1.6e-05     reward: 5.16\n",
      "epis: 1676   score: 8.0   mem len: 367218   epsilon: 0.4709    steps: 412    lr: 1.6e-05     reward: 5.21\n",
      "epis: 1677   score: 4.0   mem len: 367494   epsilon: 0.4704    steps: 276    lr: 1.6e-05     reward: 5.22\n",
      "epis: 1678   score: 5.0   mem len: 367786   epsilon: 0.4698    steps: 292    lr: 1.6e-05     reward: 5.22\n",
      "epis: 1679   score: 7.0   mem len: 368189   epsilon: 0.469    steps: 403    lr: 1.6e-05     reward: 5.25\n",
      "epis: 1680   score: 2.0   mem len: 368388   epsilon: 0.4686    steps: 199    lr: 1.6e-05     reward: 5.23\n",
      "epis: 1681   score: 5.0   mem len: 368681   epsilon: 0.468    steps: 293    lr: 1.6e-05     reward: 5.26\n",
      "epis: 1682   score: 5.0   mem len: 368991   epsilon: 0.4674    steps: 310    lr: 1.6e-05     reward: 5.29\n",
      "epis: 1683   score: 6.0   mem len: 369363   epsilon: 0.4667    steps: 372    lr: 1.6e-05     reward: 5.29\n",
      "epis: 1684   score: 5.0   mem len: 369668   epsilon: 0.4661    steps: 305    lr: 1.6e-05     reward: 5.3\n",
      "epis: 1685   score: 3.0   mem len: 369897   epsilon: 0.4656    steps: 229    lr: 1.6e-05     reward: 5.29\n",
      "epis: 1686   score: 4.0   mem len: 370151   epsilon: 0.4651    steps: 254    lr: 1.6e-05     reward: 5.27\n",
      "epis: 1687   score: 2.0   mem len: 370348   epsilon: 0.4647    steps: 197    lr: 1.6e-05     reward: 5.27\n",
      "epis: 1688   score: 6.0   mem len: 370690   epsilon: 0.464    steps: 342    lr: 1.6e-05     reward: 5.27\n",
      "epis: 1689   score: 5.0   mem len: 371010   epsilon: 0.4634    steps: 320    lr: 1.6e-05     reward: 5.3\n",
      "epis: 1690   score: 6.0   mem len: 371353   epsilon: 0.4627    steps: 343    lr: 1.6e-05     reward: 5.32\n",
      "epis: 1691   score: 3.0   mem len: 371598   epsilon: 0.4622    steps: 245    lr: 1.6e-05     reward: 5.31\n",
      "epis: 1692   score: 4.0   mem len: 371873   epsilon: 0.4617    steps: 275    lr: 1.6e-05     reward: 5.29\n",
      "epis: 1693   score: 4.0   mem len: 372135   epsilon: 0.4612    steps: 262    lr: 1.6e-05     reward: 5.19\n",
      "epis: 1694   score: 7.0   mem len: 372495   epsilon: 0.4605    steps: 360    lr: 1.6e-05     reward: 5.24\n",
      "epis: 1695   score: 9.0   mem len: 372885   epsilon: 0.4597    steps: 390    lr: 1.6e-05     reward: 5.28\n",
      "epis: 1696   score: 3.0   mem len: 373118   epsilon: 0.4592    steps: 233    lr: 1.6e-05     reward: 5.28\n",
      "epis: 1697   score: 5.0   mem len: 373444   epsilon: 0.4586    steps: 326    lr: 1.6e-05     reward: 5.2\n",
      "epis: 1698   score: 4.0   mem len: 373716   epsilon: 0.458    steps: 272    lr: 1.6e-05     reward: 5.18\n",
      "epis: 1699   score: 4.0   mem len: 373976   epsilon: 0.4575    steps: 260    lr: 1.6e-05     reward: 5.18\n",
      "epis: 1700   score: 5.0   mem len: 374302   epsilon: 0.4569    steps: 326    lr: 1.6e-05     reward: 5.16\n",
      "epis: 1701   score: 6.0   mem len: 374644   epsilon: 0.4562    steps: 342    lr: 1.6e-05     reward: 5.14\n",
      "epis: 1702   score: 8.0   mem len: 375044   epsilon: 0.4554    steps: 400    lr: 1.6e-05     reward: 5.17\n",
      "epis: 1703   score: 7.0   mem len: 375426   epsilon: 0.4547    steps: 382    lr: 1.6e-05     reward: 5.17\n",
      "epis: 1704   score: 11.0   mem len: 375981   epsilon: 0.4536    steps: 555    lr: 1.6e-05     reward: 5.24\n",
      "epis: 1705   score: 13.0   mem len: 376553   epsilon: 0.4524    steps: 572    lr: 1.6e-05     reward: 5.34\n",
      "epis: 1706   score: 10.0   mem len: 377067   epsilon: 0.4514    steps: 514    lr: 1.6e-05     reward: 5.38\n",
      "epis: 1707   score: 5.0   mem len: 377357   epsilon: 0.4508    steps: 290    lr: 1.6e-05     reward: 5.41\n",
      "epis: 1708   score: 4.0   mem len: 377597   epsilon: 0.4504    steps: 240    lr: 1.6e-05     reward: 5.41\n",
      "epis: 1709   score: 9.0   mem len: 378050   epsilon: 0.4495    steps: 453    lr: 1.6e-05     reward: 5.47\n",
      "epis: 1710   score: 6.0   mem len: 378425   epsilon: 0.4487    steps: 375    lr: 1.6e-05     reward: 5.42\n",
      "epis: 1711   score: 5.0   mem len: 378751   epsilon: 0.4481    steps: 326    lr: 1.6e-05     reward: 5.44\n",
      "epis: 1712   score: 5.0   mem len: 379080   epsilon: 0.4474    steps: 329    lr: 1.6e-05     reward: 5.47\n",
      "epis: 1713   score: 8.0   mem len: 379519   epsilon: 0.4466    steps: 439    lr: 1.6e-05     reward: 5.5\n",
      "epis: 1714   score: 7.0   mem len: 379917   epsilon: 0.4458    steps: 398    lr: 1.6e-05     reward: 5.53\n",
      "epis: 1715   score: 6.0   mem len: 380274   epsilon: 0.4451    steps: 357    lr: 1.6e-05     reward: 5.56\n",
      "epis: 1716   score: 2.0   mem len: 380453   epsilon: 0.4447    steps: 179    lr: 1.6e-05     reward: 5.53\n",
      "epis: 1717   score: 7.0   mem len: 380877   epsilon: 0.4439    steps: 424    lr: 1.6e-05     reward: 5.56\n",
      "epis: 1718   score: 7.0   mem len: 381240   epsilon: 0.4431    steps: 363    lr: 1.6e-05     reward: 5.59\n",
      "epis: 1719   score: 3.0   mem len: 381449   epsilon: 0.4427    steps: 209    lr: 1.6e-05     reward: 5.54\n",
      "epis: 1720   score: 7.0   mem len: 381853   epsilon: 0.4419    steps: 404    lr: 1.6e-05     reward: 5.55\n",
      "epis: 1721   score: 8.0   mem len: 382280   epsilon: 0.4411    steps: 427    lr: 1.6e-05     reward: 5.6\n",
      "epis: 1722   score: 6.0   mem len: 382583   epsilon: 0.4405    steps: 303    lr: 1.6e-05     reward: 5.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1723   score: 6.0   mem len: 382918   epsilon: 0.4398    steps: 335    lr: 1.6e-05     reward: 5.55\n",
      "epis: 1724   score: 10.0   mem len: 383258   epsilon: 0.4391    steps: 340    lr: 1.6e-05     reward: 5.59\n",
      "epis: 1725   score: 5.0   mem len: 383549   epsilon: 0.4386    steps: 291    lr: 1.6e-05     reward: 5.57\n",
      "epis: 1726   score: 5.0   mem len: 383863   epsilon: 0.4379    steps: 314    lr: 1.6e-05     reward: 5.53\n",
      "epis: 1727   score: 11.0   mem len: 384286   epsilon: 0.4371    steps: 423    lr: 1.6e-05     reward: 5.61\n",
      "epis: 1728   score: 5.0   mem len: 384571   epsilon: 0.4365    steps: 285    lr: 1.6e-05     reward: 5.62\n",
      "epis: 1729   score: 6.0   mem len: 384927   epsilon: 0.4358    steps: 356    lr: 1.6e-05     reward: 5.64\n",
      "epis: 1730   score: 4.0   mem len: 385186   epsilon: 0.4353    steps: 259    lr: 1.6e-05     reward: 5.62\n",
      "epis: 1731   score: 8.0   mem len: 385664   epsilon: 0.4344    steps: 478    lr: 1.6e-05     reward: 5.62\n",
      "epis: 1732   score: 6.0   mem len: 386021   epsilon: 0.4337    steps: 357    lr: 1.6e-05     reward: 5.63\n",
      "epis: 1733   score: 5.0   mem len: 386293   epsilon: 0.4331    steps: 272    lr: 1.6e-05     reward: 5.62\n",
      "epis: 1734   score: 4.0   mem len: 386555   epsilon: 0.4326    steps: 262    lr: 1.6e-05     reward: 5.59\n",
      "epis: 1735   score: 10.0   mem len: 387042   epsilon: 0.4317    steps: 487    lr: 1.6e-05     reward: 5.67\n",
      "epis: 1736   score: 3.0   mem len: 387251   epsilon: 0.4312    steps: 209    lr: 1.6e-05     reward: 5.65\n",
      "epis: 1737   score: 4.0   mem len: 387507   epsilon: 0.4307    steps: 256    lr: 1.6e-05     reward: 5.64\n",
      "epis: 1738   score: 5.0   mem len: 387827   epsilon: 0.4301    steps: 320    lr: 1.6e-05     reward: 5.62\n",
      "epis: 1739   score: 8.0   mem len: 388275   epsilon: 0.4292    steps: 448    lr: 1.6e-05     reward: 5.66\n",
      "epis: 1740   score: 5.0   mem len: 388602   epsilon: 0.4286    steps: 327    lr: 1.6e-05     reward: 5.67\n",
      "epis: 1741   score: 5.0   mem len: 388912   epsilon: 0.428    steps: 310    lr: 1.6e-05     reward: 5.69\n",
      "epis: 1742   score: 3.0   mem len: 389140   epsilon: 0.4275    steps: 228    lr: 1.6e-05     reward: 5.69\n",
      "epis: 1743   score: 7.0   mem len: 389564   epsilon: 0.4267    steps: 424    lr: 1.6e-05     reward: 5.71\n",
      "epis: 1744   score: 5.0   mem len: 389871   epsilon: 0.4261    steps: 307    lr: 1.6e-05     reward: 5.73\n",
      "epis: 1745   score: 4.0   mem len: 390110   epsilon: 0.4256    steps: 239    lr: 1.6e-05     reward: 5.7\n",
      "epis: 1746   score: 7.0   mem len: 390537   epsilon: 0.4247    steps: 427    lr: 1.6e-05     reward: 5.72\n",
      "epis: 1747   score: 5.0   mem len: 390842   epsilon: 0.4241    steps: 305    lr: 1.6e-05     reward: 5.72\n",
      "epis: 1748   score: 4.0   mem len: 391084   epsilon: 0.4237    steps: 242    lr: 1.6e-05     reward: 5.7\n",
      "epis: 1749   score: 6.0   mem len: 391438   epsilon: 0.423    steps: 354    lr: 1.6e-05     reward: 5.64\n",
      "epis: 1750   score: 4.0   mem len: 391694   epsilon: 0.4224    steps: 256    lr: 1.6e-05     reward: 5.66\n",
      "epis: 1751   score: 8.0   mem len: 392150   epsilon: 0.4215    steps: 456    lr: 1.6e-05     reward: 5.69\n",
      "epis: 1752   score: 4.0   mem len: 392409   epsilon: 0.421    steps: 259    lr: 1.6e-05     reward: 5.7\n",
      "epis: 1753   score: 3.0   mem len: 392619   epsilon: 0.4206    steps: 210    lr: 1.6e-05     reward: 5.7\n",
      "epis: 1754   score: 5.0   mem len: 392909   epsilon: 0.42    steps: 290    lr: 1.6e-05     reward: 5.69\n",
      "epis: 1755   score: 7.0   mem len: 393303   epsilon: 0.4193    steps: 394    lr: 1.6e-05     reward: 5.68\n",
      "epis: 1756   score: 5.0   mem len: 393612   epsilon: 0.4186    steps: 309    lr: 1.6e-05     reward: 5.67\n",
      "epis: 1757   score: 4.0   mem len: 393909   epsilon: 0.4181    steps: 297    lr: 1.6e-05     reward: 5.65\n",
      "epis: 1758   score: 7.0   mem len: 394313   epsilon: 0.4173    steps: 404    lr: 1.6e-05     reward: 5.67\n",
      "epis: 1759   score: 8.0   mem len: 394752   epsilon: 0.4164    steps: 439    lr: 1.6e-05     reward: 5.71\n",
      "epis: 1760   score: 4.0   mem len: 395011   epsilon: 0.4159    steps: 259    lr: 1.6e-05     reward: 5.72\n",
      "epis: 1761   score: 9.0   mem len: 395504   epsilon: 0.4149    steps: 493    lr: 1.6e-05     reward: 5.79\n",
      "epis: 1762   score: 4.0   mem len: 395747   epsilon: 0.4144    steps: 243    lr: 1.6e-05     reward: 5.77\n",
      "epis: 1763   score: 6.0   mem len: 396129   epsilon: 0.4137    steps: 382    lr: 1.6e-05     reward: 5.78\n",
      "epis: 1764   score: 6.0   mem len: 396501   epsilon: 0.4129    steps: 372    lr: 1.6e-05     reward: 5.72\n",
      "epis: 1765   score: 5.0   mem len: 396777   epsilon: 0.4124    steps: 276    lr: 1.6e-05     reward: 5.73\n",
      "epis: 1766   score: 7.0   mem len: 397201   epsilon: 0.4115    steps: 424    lr: 1.6e-05     reward: 5.73\n",
      "epis: 1767   score: 5.0   mem len: 397507   epsilon: 0.4109    steps: 306    lr: 1.6e-05     reward: 5.74\n",
      "epis: 1768   score: 13.0   mem len: 398001   epsilon: 0.41    steps: 494    lr: 1.6e-05     reward: 5.83\n",
      "epis: 1769   score: 4.0   mem len: 398275   epsilon: 0.4094    steps: 274    lr: 1.6e-05     reward: 5.84\n",
      "epis: 1770   score: 3.0   mem len: 398486   epsilon: 0.409    steps: 211    lr: 1.6e-05     reward: 5.8\n",
      "epis: 1771   score: 6.0   mem len: 398819   epsilon: 0.4083    steps: 333    lr: 1.6e-05     reward: 5.77\n",
      "epis: 1772   score: 4.0   mem len: 399097   epsilon: 0.4078    steps: 278    lr: 1.6e-05     reward: 5.77\n",
      "epis: 1773   score: 9.0   mem len: 399604   epsilon: 0.4068    steps: 507    lr: 1.6e-05     reward: 5.78\n",
      "epis: 1774   score: 5.0   mem len: 399892   epsilon: 0.4062    steps: 288    lr: 1.6e-05     reward: 5.8\n",
      "epis: 1775   score: 6.0   mem len: 400248   epsilon: 0.4055    steps: 356    lr: 6.4e-06     reward: 5.78\n",
      "epis: 1776   score: 3.0   mem len: 400476   epsilon: 0.4051    steps: 228    lr: 6.4e-06     reward: 5.73\n",
      "epis: 1777   score: 8.0   mem len: 400921   epsilon: 0.4042    steps: 445    lr: 6.4e-06     reward: 5.77\n",
      "epis: 1778   score: 8.0   mem len: 401388   epsilon: 0.4032    steps: 467    lr: 6.4e-06     reward: 5.8\n",
      "epis: 1779   score: 8.0   mem len: 401852   epsilon: 0.4023    steps: 464    lr: 6.4e-06     reward: 5.81\n",
      "epis: 1780   score: 11.0   mem len: 402395   epsilon: 0.4013    steps: 543    lr: 6.4e-06     reward: 5.9\n",
      "epis: 1781   score: 9.0   mem len: 402738   epsilon: 0.4006    steps: 343    lr: 6.4e-06     reward: 5.94\n",
      "epis: 1782   score: 3.0   mem len: 402950   epsilon: 0.4002    steps: 212    lr: 6.4e-06     reward: 5.92\n",
      "epis: 1783   score: 6.0   mem len: 403305   epsilon: 0.3995    steps: 355    lr: 6.4e-06     reward: 5.92\n",
      "epis: 1784   score: 4.0   mem len: 403582   epsilon: 0.3989    steps: 277    lr: 6.4e-06     reward: 5.91\n",
      "epis: 1785   score: 5.0   mem len: 403908   epsilon: 0.3983    steps: 326    lr: 6.4e-06     reward: 5.93\n",
      "epis: 1786   score: 11.0   mem len: 404407   epsilon: 0.3973    steps: 499    lr: 6.4e-06     reward: 6.0\n",
      "epis: 1787   score: 3.0   mem len: 404620   epsilon: 0.3969    steps: 213    lr: 6.4e-06     reward: 6.01\n",
      "epis: 1788   score: 3.0   mem len: 404833   epsilon: 0.3964    steps: 213    lr: 6.4e-06     reward: 5.98\n",
      "epis: 1789   score: 6.0   mem len: 405172   epsilon: 0.3958    steps: 339    lr: 6.4e-06     reward: 5.99\n",
      "epis: 1790   score: 7.0   mem len: 405553   epsilon: 0.395    steps: 381    lr: 6.4e-06     reward: 6.0\n",
      "epis: 1791   score: 9.0   mem len: 406052   epsilon: 0.394    steps: 499    lr: 6.4e-06     reward: 6.06\n",
      "epis: 1792   score: 3.0   mem len: 406263   epsilon: 0.3936    steps: 211    lr: 6.4e-06     reward: 6.05\n",
      "epis: 1793   score: 5.0   mem len: 406590   epsilon: 0.3929    steps: 327    lr: 6.4e-06     reward: 6.06\n",
      "epis: 1794   score: 8.0   mem len: 407042   epsilon: 0.3921    steps: 452    lr: 6.4e-06     reward: 6.07\n",
      "epis: 1795   score: 6.0   mem len: 407396   epsilon: 0.3914    steps: 354    lr: 6.4e-06     reward: 6.04\n",
      "epis: 1796   score: 5.0   mem len: 407705   epsilon: 0.3907    steps: 309    lr: 6.4e-06     reward: 6.06\n",
      "epis: 1797   score: 6.0   mem len: 408062   epsilon: 0.39    steps: 357    lr: 6.4e-06     reward: 6.07\n",
      "epis: 1798   score: 3.0   mem len: 408273   epsilon: 0.3896    steps: 211    lr: 6.4e-06     reward: 6.06\n",
      "epis: 1799   score: 5.0   mem len: 408620   epsilon: 0.3889    steps: 347    lr: 6.4e-06     reward: 6.07\n",
      "epis: 1800   score: 7.0   mem len: 409044   epsilon: 0.3881    steps: 424    lr: 6.4e-06     reward: 6.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1801   score: 5.0   mem len: 409351   epsilon: 0.3875    steps: 307    lr: 6.4e-06     reward: 6.08\n",
      "epis: 1802   score: 3.0   mem len: 409561   epsilon: 0.3871    steps: 210    lr: 6.4e-06     reward: 6.03\n",
      "epis: 1803   score: 4.0   mem len: 409802   epsilon: 0.3866    steps: 241    lr: 6.4e-06     reward: 6.0\n",
      "epis: 1804   score: 7.0   mem len: 410207   epsilon: 0.3858    steps: 405    lr: 6.4e-06     reward: 5.96\n",
      "epis: 1805   score: 5.0   mem len: 410553   epsilon: 0.3851    steps: 346    lr: 6.4e-06     reward: 5.88\n",
      "epis: 1806   score: 10.0   mem len: 411090   epsilon: 0.384    steps: 537    lr: 6.4e-06     reward: 5.88\n",
      "epis: 1807   score: 7.0   mem len: 411484   epsilon: 0.3833    steps: 394    lr: 6.4e-06     reward: 5.9\n",
      "epis: 1808   score: 9.0   mem len: 411955   epsilon: 0.3823    steps: 471    lr: 6.4e-06     reward: 5.95\n",
      "epis: 1809   score: 4.0   mem len: 412195   epsilon: 0.3819    steps: 240    lr: 6.4e-06     reward: 5.9\n",
      "epis: 1810   score: 3.0   mem len: 412406   epsilon: 0.3814    steps: 211    lr: 6.4e-06     reward: 5.87\n",
      "epis: 1811   score: 8.0   mem len: 412850   epsilon: 0.3806    steps: 444    lr: 6.4e-06     reward: 5.9\n",
      "epis: 1812   score: 4.0   mem len: 413094   epsilon: 0.3801    steps: 244    lr: 6.4e-06     reward: 5.89\n",
      "epis: 1813   score: 6.0   mem len: 413440   epsilon: 0.3794    steps: 346    lr: 6.4e-06     reward: 5.87\n",
      "epis: 1814   score: 3.0   mem len: 413653   epsilon: 0.379    steps: 213    lr: 6.4e-06     reward: 5.83\n",
      "epis: 1815   score: 6.0   mem len: 414011   epsilon: 0.3783    steps: 358    lr: 6.4e-06     reward: 5.83\n",
      "epis: 1816   score: 7.0   mem len: 414396   epsilon: 0.3775    steps: 385    lr: 6.4e-06     reward: 5.88\n",
      "epis: 1817   score: 6.0   mem len: 414752   epsilon: 0.3768    steps: 356    lr: 6.4e-06     reward: 5.87\n",
      "epis: 1818   score: 6.0   mem len: 415089   epsilon: 0.3761    steps: 337    lr: 6.4e-06     reward: 5.86\n",
      "epis: 1819   score: 6.0   mem len: 415444   epsilon: 0.3754    steps: 355    lr: 6.4e-06     reward: 5.89\n",
      "epis: 1820   score: 10.0   mem len: 415933   epsilon: 0.3745    steps: 489    lr: 6.4e-06     reward: 5.92\n",
      "epis: 1821   score: 13.0   mem len: 416399   epsilon: 0.3735    steps: 466    lr: 6.4e-06     reward: 5.97\n",
      "epis: 1822   score: 7.0   mem len: 416802   epsilon: 0.3727    steps: 403    lr: 6.4e-06     reward: 5.98\n",
      "epis: 1823   score: 7.0   mem len: 417188   epsilon: 0.372    steps: 386    lr: 6.4e-06     reward: 5.99\n",
      "epis: 1824   score: 6.0   mem len: 417519   epsilon: 0.3713    steps: 331    lr: 6.4e-06     reward: 5.95\n",
      "epis: 1825   score: 4.0   mem len: 417815   epsilon: 0.3707    steps: 296    lr: 6.4e-06     reward: 5.94\n",
      "epis: 1826   score: 9.0   mem len: 418313   epsilon: 0.3697    steps: 498    lr: 6.4e-06     reward: 5.98\n",
      "epis: 1827   score: 6.0   mem len: 418652   epsilon: 0.3691    steps: 339    lr: 6.4e-06     reward: 5.93\n",
      "epis: 1828   score: 5.0   mem len: 418981   epsilon: 0.3684    steps: 329    lr: 6.4e-06     reward: 5.93\n",
      "epis: 1829   score: 3.0   mem len: 419193   epsilon: 0.368    steps: 212    lr: 6.4e-06     reward: 5.9\n",
      "epis: 1830   score: 6.0   mem len: 419571   epsilon: 0.3672    steps: 378    lr: 6.4e-06     reward: 5.92\n",
      "epis: 1831   score: 5.0   mem len: 419897   epsilon: 0.3666    steps: 326    lr: 6.4e-06     reward: 5.89\n",
      "epis: 1832   score: 4.0   mem len: 420188   epsilon: 0.366    steps: 291    lr: 6.4e-06     reward: 5.87\n",
      "epis: 1833   score: 3.0   mem len: 420398   epsilon: 0.3656    steps: 210    lr: 6.4e-06     reward: 5.85\n",
      "epis: 1834   score: 6.0   mem len: 420720   epsilon: 0.365    steps: 322    lr: 6.4e-06     reward: 5.87\n",
      "epis: 1835   score: 6.0   mem len: 421075   epsilon: 0.3643    steps: 355    lr: 6.4e-06     reward: 5.83\n",
      "epis: 1836   score: 7.0   mem len: 421502   epsilon: 0.3634    steps: 427    lr: 6.4e-06     reward: 5.87\n",
      "epis: 1837   score: 6.0   mem len: 421863   epsilon: 0.3627    steps: 361    lr: 6.4e-06     reward: 5.89\n",
      "epis: 1838   score: 3.0   mem len: 422075   epsilon: 0.3623    steps: 212    lr: 6.4e-06     reward: 5.87\n",
      "epis: 1839   score: 4.0   mem len: 422317   epsilon: 0.3618    steps: 242    lr: 6.4e-06     reward: 5.83\n",
      "epis: 1840   score: 11.0   mem len: 422823   epsilon: 0.3608    steps: 506    lr: 6.4e-06     reward: 5.89\n",
      "epis: 1841   score: 5.0   mem len: 423147   epsilon: 0.3602    steps: 324    lr: 6.4e-06     reward: 5.89\n",
      "epis: 1842   score: 6.0   mem len: 423498   epsilon: 0.3595    steps: 351    lr: 6.4e-06     reward: 5.92\n",
      "epis: 1843   score: 6.0   mem len: 423869   epsilon: 0.3587    steps: 371    lr: 6.4e-06     reward: 5.91\n",
      "epis: 1844   score: 8.0   mem len: 424292   epsilon: 0.3579    steps: 423    lr: 6.4e-06     reward: 5.94\n",
      "epis: 1845   score: 6.0   mem len: 424665   epsilon: 0.3572    steps: 373    lr: 6.4e-06     reward: 5.96\n",
      "epis: 1846   score: 9.0   mem len: 425111   epsilon: 0.3563    steps: 446    lr: 6.4e-06     reward: 5.98\n",
      "epis: 1847   score: 8.0   mem len: 425531   epsilon: 0.3554    steps: 420    lr: 6.4e-06     reward: 6.01\n",
      "epis: 1848   score: 10.0   mem len: 426030   epsilon: 0.3545    steps: 499    lr: 6.4e-06     reward: 6.07\n",
      "epis: 1849   score: 8.0   mem len: 426418   epsilon: 0.3537    steps: 388    lr: 6.4e-06     reward: 6.09\n",
      "epis: 1850   score: 6.0   mem len: 426790   epsilon: 0.353    steps: 372    lr: 6.4e-06     reward: 6.11\n",
      "epis: 1851   score: 4.0   mem len: 427068   epsilon: 0.3524    steps: 278    lr: 6.4e-06     reward: 6.07\n",
      "epis: 1852   score: 8.0   mem len: 427502   epsilon: 0.3515    steps: 434    lr: 6.4e-06     reward: 6.11\n",
      "epis: 1853   score: 3.0   mem len: 427711   epsilon: 0.3511    steps: 209    lr: 6.4e-06     reward: 6.11\n",
      "epis: 1854   score: 8.0   mem len: 428093   epsilon: 0.3504    steps: 382    lr: 6.4e-06     reward: 6.14\n",
      "epis: 1855   score: 9.0   mem len: 428564   epsilon: 0.3494    steps: 471    lr: 6.4e-06     reward: 6.16\n",
      "epis: 1856   score: 8.0   mem len: 428972   epsilon: 0.3486    steps: 408    lr: 6.4e-06     reward: 6.19\n",
      "epis: 1857   score: 3.0   mem len: 429221   epsilon: 0.3481    steps: 249    lr: 6.4e-06     reward: 6.18\n",
      "epis: 1858   score: 10.0   mem len: 429753   epsilon: 0.3471    steps: 532    lr: 6.4e-06     reward: 6.21\n",
      "epis: 1859   score: 4.0   mem len: 429995   epsilon: 0.3466    steps: 242    lr: 6.4e-06     reward: 6.17\n",
      "epis: 1860   score: 7.0   mem len: 430421   epsilon: 0.3458    steps: 426    lr: 6.4e-06     reward: 6.2\n",
      "epis: 1861   score: 3.0   mem len: 430667   epsilon: 0.3453    steps: 246    lr: 6.4e-06     reward: 6.14\n",
      "epis: 1862   score: 6.0   mem len: 430991   epsilon: 0.3446    steps: 324    lr: 6.4e-06     reward: 6.16\n",
      "epis: 1863   score: 4.0   mem len: 431267   epsilon: 0.3441    steps: 276    lr: 6.4e-06     reward: 6.14\n",
      "epis: 1864   score: 11.0   mem len: 431811   epsilon: 0.343    steps: 544    lr: 6.4e-06     reward: 6.19\n",
      "epis: 1865   score: 7.0   mem len: 432166   epsilon: 0.3423    steps: 355    lr: 6.4e-06     reward: 6.21\n",
      "epis: 1866   score: 5.0   mem len: 432472   epsilon: 0.3417    steps: 306    lr: 6.4e-06     reward: 6.19\n",
      "epis: 1867   score: 4.0   mem len: 432733   epsilon: 0.3412    steps: 261    lr: 6.4e-06     reward: 6.18\n",
      "epis: 1868   score: 5.0   mem len: 433040   epsilon: 0.3406    steps: 307    lr: 6.4e-06     reward: 6.1\n",
      "epis: 1869   score: 10.0   mem len: 433527   epsilon: 0.3396    steps: 487    lr: 6.4e-06     reward: 6.16\n",
      "epis: 1870   score: 5.0   mem len: 433819   epsilon: 0.339    steps: 292    lr: 6.4e-06     reward: 6.18\n",
      "epis: 1871   score: 5.0   mem len: 434110   epsilon: 0.3385    steps: 291    lr: 6.4e-06     reward: 6.17\n",
      "epis: 1872   score: 8.0   mem len: 434519   epsilon: 0.3377    steps: 409    lr: 6.4e-06     reward: 6.21\n",
      "epis: 1873   score: 4.0   mem len: 434761   epsilon: 0.3372    steps: 242    lr: 6.4e-06     reward: 6.16\n",
      "epis: 1874   score: 3.0   mem len: 434971   epsilon: 0.3368    steps: 210    lr: 6.4e-06     reward: 6.14\n",
      "epis: 1875   score: 5.0   mem len: 435278   epsilon: 0.3361    steps: 307    lr: 6.4e-06     reward: 6.13\n",
      "epis: 1876   score: 13.0   mem len: 435801   epsilon: 0.3351    steps: 523    lr: 6.4e-06     reward: 6.23\n",
      "epis: 1877   score: 7.0   mem len: 436202   epsilon: 0.3343    steps: 401    lr: 6.4e-06     reward: 6.22\n",
      "epis: 1878   score: 5.0   mem len: 436508   epsilon: 0.3337    steps: 306    lr: 6.4e-06     reward: 6.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1879   score: 5.0   mem len: 436813   epsilon: 0.3331    steps: 305    lr: 6.4e-06     reward: 6.16\n",
      "epis: 1880   score: 3.0   mem len: 437044   epsilon: 0.3327    steps: 231    lr: 6.4e-06     reward: 6.08\n",
      "epis: 1881   score: 5.0   mem len: 437367   epsilon: 0.332    steps: 323    lr: 6.4e-06     reward: 6.04\n",
      "epis: 1882   score: 7.0   mem len: 437734   epsilon: 0.3313    steps: 367    lr: 6.4e-06     reward: 6.08\n",
      "epis: 1883   score: 8.0   mem len: 438141   epsilon: 0.3305    steps: 407    lr: 6.4e-06     reward: 6.1\n",
      "epis: 1884   score: 8.0   mem len: 438422   epsilon: 0.3299    steps: 281    lr: 6.4e-06     reward: 6.14\n",
      "epis: 1885   score: 4.0   mem len: 438697   epsilon: 0.3294    steps: 275    lr: 6.4e-06     reward: 6.13\n",
      "epis: 1886   score: 10.0   mem len: 439155   epsilon: 0.3285    steps: 458    lr: 6.4e-06     reward: 6.12\n",
      "epis: 1887   score: 4.0   mem len: 439431   epsilon: 0.3279    steps: 276    lr: 6.4e-06     reward: 6.13\n",
      "epis: 1888   score: 12.0   mem len: 439921   epsilon: 0.327    steps: 490    lr: 6.4e-06     reward: 6.22\n",
      "epis: 1889   score: 6.0   mem len: 440269   epsilon: 0.3263    steps: 348    lr: 6.4e-06     reward: 6.22\n",
      "epis: 1890   score: 9.0   mem len: 440690   epsilon: 0.3254    steps: 421    lr: 6.4e-06     reward: 6.24\n",
      "epis: 1891   score: 6.0   mem len: 441066   epsilon: 0.3247    steps: 376    lr: 6.4e-06     reward: 6.21\n",
      "epis: 1892   score: 9.0   mem len: 441493   epsilon: 0.3238    steps: 427    lr: 6.4e-06     reward: 6.27\n",
      "epis: 1893   score: 6.0   mem len: 441871   epsilon: 0.3231    steps: 378    lr: 6.4e-06     reward: 6.28\n",
      "epis: 1894   score: 4.0   mem len: 442152   epsilon: 0.3225    steps: 281    lr: 6.4e-06     reward: 6.24\n",
      "epis: 1895   score: 6.0   mem len: 442507   epsilon: 0.3218    steps: 355    lr: 6.4e-06     reward: 6.24\n",
      "epis: 1896   score: 10.0   mem len: 443048   epsilon: 0.3208    steps: 541    lr: 6.4e-06     reward: 6.29\n",
      "epis: 1897   score: 10.0   mem len: 443537   epsilon: 0.3198    steps: 489    lr: 6.4e-06     reward: 6.33\n",
      "epis: 1898   score: 6.0   mem len: 443871   epsilon: 0.3191    steps: 334    lr: 6.4e-06     reward: 6.36\n",
      "epis: 1899   score: 4.0   mem len: 444115   epsilon: 0.3187    steps: 244    lr: 6.4e-06     reward: 6.35\n",
      "epis: 1900   score: 3.0   mem len: 444362   epsilon: 0.3182    steps: 247    lr: 6.4e-06     reward: 6.31\n",
      "epis: 1901   score: 13.0   mem len: 444876   epsilon: 0.3171    steps: 514    lr: 6.4e-06     reward: 6.39\n",
      "epis: 1902   score: 9.0   mem len: 445314   epsilon: 0.3163    steps: 438    lr: 6.4e-06     reward: 6.45\n",
      "epis: 1903   score: 2.0   mem len: 445511   epsilon: 0.3159    steps: 197    lr: 6.4e-06     reward: 6.43\n",
      "epis: 1904   score: 5.0   mem len: 445819   epsilon: 0.3153    steps: 308    lr: 6.4e-06     reward: 6.41\n",
      "epis: 1905   score: 8.0   mem len: 446262   epsilon: 0.3144    steps: 443    lr: 6.4e-06     reward: 6.44\n",
      "epis: 1906   score: 6.0   mem len: 446616   epsilon: 0.3137    steps: 354    lr: 6.4e-06     reward: 6.4\n",
      "epis: 1907   score: 7.0   mem len: 446984   epsilon: 0.313    steps: 368    lr: 6.4e-06     reward: 6.4\n",
      "epis: 1908   score: 5.0   mem len: 447276   epsilon: 0.3124    steps: 292    lr: 6.4e-06     reward: 6.36\n",
      "epis: 1909   score: 13.0   mem len: 447896   epsilon: 0.3112    steps: 620    lr: 6.4e-06     reward: 6.45\n",
      "epis: 1910   score: 7.0   mem len: 448296   epsilon: 0.3104    steps: 400    lr: 6.4e-06     reward: 6.49\n",
      "epis: 1911   score: 7.0   mem len: 448686   epsilon: 0.3096    steps: 390    lr: 6.4e-06     reward: 6.48\n",
      "epis: 1912   score: 4.0   mem len: 448946   epsilon: 0.3091    steps: 260    lr: 6.4e-06     reward: 6.48\n",
      "epis: 1913   score: 4.0   mem len: 449221   epsilon: 0.3085    steps: 275    lr: 6.4e-06     reward: 6.46\n",
      "epis: 1914   score: 4.0   mem len: 449481   epsilon: 0.308    steps: 260    lr: 6.4e-06     reward: 6.47\n",
      "epis: 1915   score: 8.0   mem len: 449885   epsilon: 0.3072    steps: 404    lr: 6.4e-06     reward: 6.49\n",
      "epis: 1916   score: 13.0   mem len: 450430   epsilon: 0.3061    steps: 545    lr: 6.4e-06     reward: 6.55\n",
      "epis: 1917   score: 8.0   mem len: 450866   epsilon: 0.3053    steps: 436    lr: 6.4e-06     reward: 6.57\n",
      "epis: 1918   score: 3.0   mem len: 451079   epsilon: 0.3049    steps: 213    lr: 6.4e-06     reward: 6.54\n",
      "epis: 1919   score: 6.0   mem len: 451413   epsilon: 0.3042    steps: 334    lr: 6.4e-06     reward: 6.54\n",
      "epis: 1920   score: 9.0   mem len: 451900   epsilon: 0.3032    steps: 487    lr: 6.4e-06     reward: 6.53\n",
      "epis: 1921   score: 7.0   mem len: 452305   epsilon: 0.3024    steps: 405    lr: 6.4e-06     reward: 6.47\n",
      "epis: 1922   score: 5.0   mem len: 452630   epsilon: 0.3018    steps: 325    lr: 6.4e-06     reward: 6.45\n",
      "epis: 1923   score: 7.0   mem len: 453034   epsilon: 0.301    steps: 404    lr: 6.4e-06     reward: 6.45\n",
      "epis: 1924   score: 9.0   mem len: 453511   epsilon: 0.3    steps: 477    lr: 6.4e-06     reward: 6.48\n",
      "epis: 1925   score: 6.0   mem len: 453862   epsilon: 0.2994    steps: 351    lr: 6.4e-06     reward: 6.5\n",
      "epis: 1926   score: 6.0   mem len: 454203   epsilon: 0.2987    steps: 341    lr: 6.4e-06     reward: 6.47\n",
      "epis: 1927   score: 5.0   mem len: 454476   epsilon: 0.2981    steps: 273    lr: 6.4e-06     reward: 6.46\n",
      "epis: 1928   score: 10.0   mem len: 454961   epsilon: 0.2972    steps: 485    lr: 6.4e-06     reward: 6.51\n",
      "epis: 1929   score: 4.0   mem len: 455223   epsilon: 0.2967    steps: 262    lr: 6.4e-06     reward: 6.52\n",
      "epis: 1930   score: 5.0   mem len: 455549   epsilon: 0.296    steps: 326    lr: 6.4e-06     reward: 6.51\n",
      "epis: 1931   score: 8.0   mem len: 455985   epsilon: 0.2951    steps: 436    lr: 6.4e-06     reward: 6.54\n",
      "epis: 1932   score: 9.0   mem len: 456417   epsilon: 0.2943    steps: 432    lr: 6.4e-06     reward: 6.59\n",
      "epis: 1933   score: 5.0   mem len: 456707   epsilon: 0.2937    steps: 290    lr: 6.4e-06     reward: 6.61\n",
      "epis: 1934   score: 4.0   mem len: 457004   epsilon: 0.2931    steps: 297    lr: 6.4e-06     reward: 6.59\n",
      "epis: 1935   score: 4.0   mem len: 457297   epsilon: 0.2925    steps: 293    lr: 6.4e-06     reward: 6.57\n",
      "epis: 1936   score: 7.0   mem len: 457685   epsilon: 0.2918    steps: 388    lr: 6.4e-06     reward: 6.57\n",
      "epis: 1937   score: 4.0   mem len: 457943   epsilon: 0.2913    steps: 258    lr: 6.4e-06     reward: 6.55\n",
      "epis: 1938   score: 10.0   mem len: 458395   epsilon: 0.2904    steps: 452    lr: 6.4e-06     reward: 6.62\n",
      "epis: 1939   score: 5.0   mem len: 458682   epsilon: 0.2898    steps: 287    lr: 6.4e-06     reward: 6.63\n",
      "epis: 1940   score: 7.0   mem len: 459081   epsilon: 0.289    steps: 399    lr: 6.4e-06     reward: 6.59\n",
      "epis: 1941   score: 4.0   mem len: 459376   epsilon: 0.2884    steps: 295    lr: 6.4e-06     reward: 6.58\n",
      "epis: 1942   score: 6.0   mem len: 459731   epsilon: 0.2877    steps: 355    lr: 6.4e-06     reward: 6.58\n",
      "epis: 1943   score: 10.0   mem len: 460271   epsilon: 0.2867    steps: 540    lr: 6.4e-06     reward: 6.62\n",
      "epis: 1944   score: 4.0   mem len: 460552   epsilon: 0.2861    steps: 281    lr: 6.4e-06     reward: 6.58\n",
      "epis: 1945   score: 7.0   mem len: 460957   epsilon: 0.2853    steps: 405    lr: 6.4e-06     reward: 6.59\n",
      "epis: 1946   score: 4.0   mem len: 461215   epsilon: 0.2848    steps: 258    lr: 6.4e-06     reward: 6.54\n",
      "epis: 1947   score: 10.0   mem len: 461727   epsilon: 0.2838    steps: 512    lr: 6.4e-06     reward: 6.56\n",
      "epis: 1948   score: 4.0   mem len: 461966   epsilon: 0.2833    steps: 239    lr: 6.4e-06     reward: 6.5\n",
      "epis: 1949   score: 3.0   mem len: 462176   epsilon: 0.2829    steps: 210    lr: 6.4e-06     reward: 6.45\n",
      "epis: 1950   score: 4.0   mem len: 462435   epsilon: 0.2824    steps: 259    lr: 6.4e-06     reward: 6.43\n",
      "epis: 1951   score: 5.0   mem len: 462728   epsilon: 0.2818    steps: 293    lr: 6.4e-06     reward: 6.44\n",
      "epis: 1952   score: 6.0   mem len: 463049   epsilon: 0.2812    steps: 321    lr: 6.4e-06     reward: 6.42\n",
      "epis: 1953   score: 4.0   mem len: 463311   epsilon: 0.2806    steps: 262    lr: 6.4e-06     reward: 6.43\n",
      "epis: 1954   score: 12.0   mem len: 463757   epsilon: 0.2798    steps: 446    lr: 6.4e-06     reward: 6.47\n",
      "epis: 1955   score: 10.0   mem len: 464260   epsilon: 0.2788    steps: 503    lr: 6.4e-06     reward: 6.48\n",
      "epis: 1956   score: 7.0   mem len: 464645   epsilon: 0.278    steps: 385    lr: 6.4e-06     reward: 6.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1957   score: 6.0   mem len: 465004   epsilon: 0.2773    steps: 359    lr: 6.4e-06     reward: 6.5\n",
      "epis: 1958   score: 10.0   mem len: 465533   epsilon: 0.2762    steps: 529    lr: 6.4e-06     reward: 6.5\n",
      "epis: 1959   score: 5.0   mem len: 465806   epsilon: 0.2757    steps: 273    lr: 6.4e-06     reward: 6.51\n",
      "epis: 1960   score: 4.0   mem len: 466045   epsilon: 0.2752    steps: 239    lr: 6.4e-06     reward: 6.48\n",
      "epis: 1961   score: 7.0   mem len: 466426   epsilon: 0.2745    steps: 381    lr: 6.4e-06     reward: 6.52\n",
      "epis: 1962   score: 7.0   mem len: 466789   epsilon: 0.2738    steps: 363    lr: 6.4e-06     reward: 6.53\n",
      "epis: 1963   score: 4.0   mem len: 467088   epsilon: 0.2732    steps: 299    lr: 6.4e-06     reward: 6.53\n",
      "epis: 1964   score: 8.0   mem len: 467529   epsilon: 0.2723    steps: 441    lr: 6.4e-06     reward: 6.5\n",
      "epis: 1965   score: 5.0   mem len: 467823   epsilon: 0.2717    steps: 294    lr: 6.4e-06     reward: 6.48\n",
      "epis: 1966   score: 10.0   mem len: 468316   epsilon: 0.2707    steps: 493    lr: 6.4e-06     reward: 6.53\n",
      "epis: 1967   score: 5.0   mem len: 468645   epsilon: 0.2701    steps: 329    lr: 6.4e-06     reward: 6.54\n",
      "epis: 1968   score: 5.0   mem len: 468971   epsilon: 0.2694    steps: 326    lr: 6.4e-06     reward: 6.54\n",
      "epis: 1969   score: 9.0   mem len: 469436   epsilon: 0.2685    steps: 465    lr: 6.4e-06     reward: 6.53\n",
      "epis: 1970   score: 6.0   mem len: 469789   epsilon: 0.2678    steps: 353    lr: 6.4e-06     reward: 6.54\n",
      "epis: 1971   score: 6.0   mem len: 470137   epsilon: 0.2671    steps: 348    lr: 6.4e-06     reward: 6.55\n",
      "epis: 1972   score: 5.0   mem len: 470462   epsilon: 0.2665    steps: 325    lr: 6.4e-06     reward: 6.52\n",
      "epis: 1973   score: 8.0   mem len: 470875   epsilon: 0.2657    steps: 413    lr: 6.4e-06     reward: 6.56\n",
      "epis: 1974   score: 6.0   mem len: 471195   epsilon: 0.265    steps: 320    lr: 6.4e-06     reward: 6.59\n",
      "epis: 1975   score: 3.0   mem len: 471408   epsilon: 0.2646    steps: 213    lr: 6.4e-06     reward: 6.57\n",
      "epis: 1976   score: 6.0   mem len: 471762   epsilon: 0.2639    steps: 354    lr: 6.4e-06     reward: 6.5\n",
      "epis: 1977   score: 4.0   mem len: 472023   epsilon: 0.2634    steps: 261    lr: 6.4e-06     reward: 6.47\n",
      "epis: 1978   score: 9.0   mem len: 472465   epsilon: 0.2625    steps: 442    lr: 6.4e-06     reward: 6.51\n",
      "epis: 1979   score: 5.0   mem len: 472776   epsilon: 0.2619    steps: 311    lr: 6.4e-06     reward: 6.51\n",
      "epis: 1980   score: 9.0   mem len: 473221   epsilon: 0.261    steps: 445    lr: 6.4e-06     reward: 6.57\n",
      "epis: 1981   score: 6.0   mem len: 473527   epsilon: 0.2604    steps: 306    lr: 6.4e-06     reward: 6.58\n",
      "epis: 1982   score: 4.0   mem len: 473801   epsilon: 0.2599    steps: 274    lr: 6.4e-06     reward: 6.55\n",
      "epis: 1983   score: 12.0   mem len: 474380   epsilon: 0.2587    steps: 579    lr: 6.4e-06     reward: 6.59\n",
      "epis: 1984   score: 11.0   mem len: 474900   epsilon: 0.2577    steps: 520    lr: 6.4e-06     reward: 6.62\n",
      "epis: 1985   score: 9.0   mem len: 475239   epsilon: 0.257    steps: 339    lr: 6.4e-06     reward: 6.67\n",
      "epis: 1986   score: 7.0   mem len: 475621   epsilon: 0.2563    steps: 382    lr: 6.4e-06     reward: 6.64\n",
      "epis: 1987   score: 6.0   mem len: 475956   epsilon: 0.2556    steps: 335    lr: 6.4e-06     reward: 6.66\n",
      "epis: 1988   score: 8.0   mem len: 476407   epsilon: 0.2547    steps: 451    lr: 6.4e-06     reward: 6.62\n",
      "epis: 1989   score: 8.0   mem len: 476857   epsilon: 0.2538    steps: 450    lr: 6.4e-06     reward: 6.64\n",
      "epis: 1990   score: 7.0   mem len: 477258   epsilon: 0.253    steps: 401    lr: 6.4e-06     reward: 6.62\n",
      "epis: 1991   score: 4.0   mem len: 477521   epsilon: 0.2525    steps: 263    lr: 6.4e-06     reward: 6.6\n",
      "epis: 1992   score: 13.0   mem len: 478100   epsilon: 0.2514    steps: 579    lr: 6.4e-06     reward: 6.64\n",
      "epis: 1993   score: 10.0   mem len: 478563   epsilon: 0.2504    steps: 463    lr: 6.4e-06     reward: 6.68\n",
      "epis: 1994   score: 7.0   mem len: 478959   epsilon: 0.2497    steps: 396    lr: 6.4e-06     reward: 6.71\n",
      "epis: 1995   score: 10.0   mem len: 479442   epsilon: 0.2487    steps: 483    lr: 6.4e-06     reward: 6.75\n",
      "epis: 1996   score: 4.0   mem len: 479757   epsilon: 0.2481    steps: 315    lr: 6.4e-06     reward: 6.69\n",
      "epis: 1997   score: 7.0   mem len: 480143   epsilon: 0.2473    steps: 386    lr: 6.4e-06     reward: 6.66\n",
      "epis: 1998   score: 7.0   mem len: 480546   epsilon: 0.2465    steps: 403    lr: 6.4e-06     reward: 6.67\n",
      "epis: 1999   score: 11.0   mem len: 481116   epsilon: 0.2454    steps: 570    lr: 6.4e-06     reward: 6.74\n",
      "epis: 2000   score: 7.0   mem len: 481514   epsilon: 0.2446    steps: 398    lr: 6.4e-06     reward: 6.78\n",
      "epis: 2001   score: 5.0   mem len: 481825   epsilon: 0.244    steps: 311    lr: 6.4e-06     reward: 6.7\n",
      "epis: 2002   score: 5.0   mem len: 482134   epsilon: 0.2434    steps: 309    lr: 6.4e-06     reward: 6.66\n",
      "epis: 2003   score: 6.0   mem len: 482493   epsilon: 0.2427    steps: 359    lr: 6.4e-06     reward: 6.7\n",
      "epis: 2004   score: 8.0   mem len: 482810   epsilon: 0.242    steps: 317    lr: 6.4e-06     reward: 6.73\n",
      "epis: 2005   score: 6.0   mem len: 483183   epsilon: 0.2413    steps: 373    lr: 6.4e-06     reward: 6.71\n",
      "epis: 2006   score: 9.0   mem len: 483673   epsilon: 0.2403    steps: 490    lr: 6.4e-06     reward: 6.74\n",
      "epis: 2007   score: 4.0   mem len: 483946   epsilon: 0.2398    steps: 273    lr: 6.4e-06     reward: 6.71\n",
      "epis: 2008   score: 8.0   mem len: 484384   epsilon: 0.2389    steps: 438    lr: 6.4e-06     reward: 6.74\n",
      "epis: 2009   score: 8.0   mem len: 484838   epsilon: 0.238    steps: 454    lr: 6.4e-06     reward: 6.69\n",
      "epis: 2010   score: 9.0   mem len: 485297   epsilon: 0.2371    steps: 459    lr: 6.4e-06     reward: 6.71\n",
      "epis: 2011   score: 6.0   mem len: 485633   epsilon: 0.2364    steps: 336    lr: 6.4e-06     reward: 6.7\n",
      "epis: 2012   score: 5.0   mem len: 485945   epsilon: 0.2358    steps: 312    lr: 6.4e-06     reward: 6.71\n",
      "epis: 2013   score: 4.0   mem len: 486207   epsilon: 0.2353    steps: 262    lr: 6.4e-06     reward: 6.71\n",
      "epis: 2014   score: 8.0   mem len: 486623   epsilon: 0.2345    steps: 416    lr: 6.4e-06     reward: 6.75\n",
      "epis: 2015   score: 8.0   mem len: 487059   epsilon: 0.2336    steps: 436    lr: 6.4e-06     reward: 6.75\n",
      "epis: 2016   score: 8.0   mem len: 487509   epsilon: 0.2327    steps: 450    lr: 6.4e-06     reward: 6.7\n",
      "epis: 2017   score: 7.0   mem len: 487863   epsilon: 0.232    steps: 354    lr: 6.4e-06     reward: 6.69\n",
      "epis: 2018   score: 10.0   mem len: 488360   epsilon: 0.231    steps: 497    lr: 6.4e-06     reward: 6.76\n",
      "epis: 2019   score: 5.0   mem len: 488683   epsilon: 0.2304    steps: 323    lr: 6.4e-06     reward: 6.75\n",
      "epis: 2020   score: 6.0   mem len: 489068   epsilon: 0.2296    steps: 385    lr: 6.4e-06     reward: 6.72\n",
      "epis: 2021   score: 6.0   mem len: 489425   epsilon: 0.2289    steps: 357    lr: 6.4e-06     reward: 6.71\n",
      "epis: 2022   score: 9.0   mem len: 489911   epsilon: 0.228    steps: 486    lr: 6.4e-06     reward: 6.75\n",
      "epis: 2023   score: 5.0   mem len: 490238   epsilon: 0.2273    steps: 327    lr: 6.4e-06     reward: 6.73\n",
      "epis: 2024   score: 5.0   mem len: 490565   epsilon: 0.2267    steps: 327    lr: 6.4e-06     reward: 6.69\n",
      "epis: 2025   score: 6.0   mem len: 490901   epsilon: 0.226    steps: 336    lr: 6.4e-06     reward: 6.69\n",
      "epis: 2026   score: 13.0   mem len: 491511   epsilon: 0.2248    steps: 610    lr: 6.4e-06     reward: 6.76\n",
      "epis: 2027   score: 7.0   mem len: 491915   epsilon: 0.224    steps: 404    lr: 6.4e-06     reward: 6.78\n",
      "epis: 2028   score: 5.0   mem len: 492258   epsilon: 0.2233    steps: 343    lr: 6.4e-06     reward: 6.73\n",
      "epis: 2029   score: 6.0   mem len: 492629   epsilon: 0.2226    steps: 371    lr: 6.4e-06     reward: 6.75\n",
      "epis: 2030   score: 9.0   mem len: 493135   epsilon: 0.2216    steps: 506    lr: 6.4e-06     reward: 6.79\n",
      "epis: 2031   score: 6.0   mem len: 493503   epsilon: 0.2209    steps: 368    lr: 6.4e-06     reward: 6.77\n",
      "epis: 2032   score: 5.0   mem len: 493852   epsilon: 0.2202    steps: 349    lr: 6.4e-06     reward: 6.73\n",
      "epis: 2033   score: 5.0   mem len: 494126   epsilon: 0.2196    steps: 274    lr: 6.4e-06     reward: 6.73\n",
      "epis: 2034   score: 14.0   mem len: 494597   epsilon: 0.2187    steps: 471    lr: 6.4e-06     reward: 6.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2035   score: 7.0   mem len: 494982   epsilon: 0.2179    steps: 385    lr: 6.4e-06     reward: 6.86\n",
      "epis: 2036   score: 5.0   mem len: 495287   epsilon: 0.2173    steps: 305    lr: 6.4e-06     reward: 6.84\n",
      "epis: 2037   score: 6.0   mem len: 495665   epsilon: 0.2166    steps: 378    lr: 6.4e-06     reward: 6.86\n",
      "epis: 2038   score: 12.0   mem len: 496119   epsilon: 0.2157    steps: 454    lr: 6.4e-06     reward: 6.88\n",
      "epis: 2039   score: 11.0   mem len: 496685   epsilon: 0.2146    steps: 566    lr: 6.4e-06     reward: 6.94\n",
      "epis: 2040   score: 9.0   mem len: 497143   epsilon: 0.2137    steps: 458    lr: 6.4e-06     reward: 6.96\n",
      "epis: 2041   score: 8.0   mem len: 497596   epsilon: 0.2128    steps: 453    lr: 6.4e-06     reward: 7.0\n",
      "epis: 2042   score: 8.0   mem len: 497893   epsilon: 0.2122    steps: 297    lr: 6.4e-06     reward: 7.02\n",
      "epis: 2043   score: 9.0   mem len: 498348   epsilon: 0.2113    steps: 455    lr: 6.4e-06     reward: 7.01\n",
      "epis: 2044   score: 5.0   mem len: 498654   epsilon: 0.2107    steps: 306    lr: 6.4e-06     reward: 7.02\n",
      "epis: 2045   score: 4.0   mem len: 498893   epsilon: 0.2102    steps: 239    lr: 6.4e-06     reward: 6.99\n",
      "epis: 2046   score: 7.0   mem len: 499303   epsilon: 0.2094    steps: 410    lr: 6.4e-06     reward: 7.02\n",
      "epis: 2047   score: 9.0   mem len: 499756   epsilon: 0.2085    steps: 453    lr: 6.4e-06     reward: 7.01\n",
      "epis: 2048   score: 4.0   mem len: 500037   epsilon: 0.2079    steps: 281    lr: 2.6e-06     reward: 7.01\n",
      "epis: 2049   score: 10.0   mem len: 500548   epsilon: 0.2069    steps: 511    lr: 2.6e-06     reward: 7.08\n",
      "epis: 2050   score: 9.0   mem len: 501015   epsilon: 0.206    steps: 467    lr: 2.6e-06     reward: 7.13\n",
      "epis: 2051   score: 7.0   mem len: 501421   epsilon: 0.2052    steps: 406    lr: 2.6e-06     reward: 7.15\n",
      "epis: 2052   score: 10.0   mem len: 501947   epsilon: 0.2041    steps: 526    lr: 2.6e-06     reward: 7.19\n",
      "epis: 2053   score: 7.0   mem len: 502328   epsilon: 0.2034    steps: 381    lr: 2.6e-06     reward: 7.22\n",
      "epis: 2054   score: 8.0   mem len: 502758   epsilon: 0.2025    steps: 430    lr: 2.6e-06     reward: 7.18\n",
      "epis: 2055   score: 8.0   mem len: 503182   epsilon: 0.2017    steps: 424    lr: 2.6e-06     reward: 7.16\n",
      "epis: 2056   score: 10.0   mem len: 503668   epsilon: 0.2007    steps: 486    lr: 2.6e-06     reward: 7.19\n",
      "epis: 2057   score: 5.0   mem len: 503955   epsilon: 0.2002    steps: 287    lr: 2.6e-06     reward: 7.18\n",
      "epis: 2058   score: 4.0   mem len: 504230   epsilon: 0.1996    steps: 275    lr: 2.6e-06     reward: 7.12\n",
      "epis: 2059   score: 9.0   mem len: 504709   epsilon: 0.1987    steps: 479    lr: 2.6e-06     reward: 7.16\n",
      "epis: 2060   score: 6.0   mem len: 505045   epsilon: 0.198    steps: 336    lr: 2.6e-06     reward: 7.18\n",
      "epis: 2061   score: 11.0   mem len: 505560   epsilon: 0.197    steps: 515    lr: 2.6e-06     reward: 7.22\n",
      "epis: 2062   score: 8.0   mem len: 506012   epsilon: 0.1961    steps: 452    lr: 2.6e-06     reward: 7.23\n",
      "epis: 2063   score: 6.0   mem len: 506362   epsilon: 0.1954    steps: 350    lr: 2.6e-06     reward: 7.25\n",
      "epis: 2064   score: 10.0   mem len: 506757   epsilon: 0.1946    steps: 395    lr: 2.6e-06     reward: 7.27\n",
      "epis: 2065   score: 9.0   mem len: 507278   epsilon: 0.1936    steps: 521    lr: 2.6e-06     reward: 7.31\n",
      "epis: 2066   score: 10.0   mem len: 507801   epsilon: 0.1926    steps: 523    lr: 2.6e-06     reward: 7.31\n",
      "epis: 2067   score: 6.0   mem len: 508159   epsilon: 0.1918    steps: 358    lr: 2.6e-06     reward: 7.32\n",
      "epis: 2068   score: 6.0   mem len: 508498   epsilon: 0.1912    steps: 339    lr: 2.6e-06     reward: 7.33\n",
      "epis: 2069   score: 7.0   mem len: 508900   epsilon: 0.1904    steps: 402    lr: 2.6e-06     reward: 7.31\n",
      "epis: 2070   score: 3.0   mem len: 509131   epsilon: 0.1899    steps: 231    lr: 2.6e-06     reward: 7.28\n",
      "epis: 2071   score: 7.0   mem len: 509516   epsilon: 0.1892    steps: 385    lr: 2.6e-06     reward: 7.29\n",
      "epis: 2072   score: 10.0   mem len: 510042   epsilon: 0.1881    steps: 526    lr: 2.6e-06     reward: 7.34\n",
      "epis: 2073   score: 5.0   mem len: 510329   epsilon: 0.1875    steps: 287    lr: 2.6e-06     reward: 7.31\n",
      "epis: 2074   score: 10.0   mem len: 510824   epsilon: 0.1866    steps: 495    lr: 2.6e-06     reward: 7.35\n",
      "epis: 2075   score: 7.0   mem len: 511202   epsilon: 0.1858    steps: 378    lr: 2.6e-06     reward: 7.39\n",
      "epis: 2076   score: 5.0   mem len: 511509   epsilon: 0.1852    steps: 307    lr: 2.6e-06     reward: 7.38\n",
      "epis: 2077   score: 6.0   mem len: 511832   epsilon: 0.1846    steps: 323    lr: 2.6e-06     reward: 7.4\n",
      "epis: 2078   score: 10.0   mem len: 512328   epsilon: 0.1836    steps: 496    lr: 2.6e-06     reward: 7.41\n",
      "epis: 2079   score: 8.0   mem len: 512795   epsilon: 0.1827    steps: 467    lr: 2.6e-06     reward: 7.44\n",
      "epis: 2080   score: 5.0   mem len: 513107   epsilon: 0.182    steps: 312    lr: 2.6e-06     reward: 7.4\n",
      "epis: 2081   score: 8.0   mem len: 513516   epsilon: 0.1812    steps: 409    lr: 2.6e-06     reward: 7.42\n",
      "epis: 2082   score: 11.0   mem len: 514108   epsilon: 0.1801    steps: 592    lr: 2.6e-06     reward: 7.49\n",
      "epis: 2083   score: 11.0   mem len: 514529   epsilon: 0.1792    steps: 421    lr: 2.6e-06     reward: 7.48\n",
      "epis: 2084   score: 6.0   mem len: 514899   epsilon: 0.1785    steps: 370    lr: 2.6e-06     reward: 7.43\n",
      "epis: 2085   score: 7.0   mem len: 515322   epsilon: 0.1777    steps: 423    lr: 2.6e-06     reward: 7.41\n",
      "epis: 2086   score: 11.0   mem len: 515910   epsilon: 0.1765    steps: 588    lr: 2.6e-06     reward: 7.45\n",
      "epis: 2087   score: 6.0   mem len: 516263   epsilon: 0.1758    steps: 353    lr: 2.6e-06     reward: 7.45\n",
      "epis: 2088   score: 10.0   mem len: 516754   epsilon: 0.1748    steps: 491    lr: 2.6e-06     reward: 7.47\n",
      "epis: 2089   score: 5.0   mem len: 517098   epsilon: 0.1741    steps: 344    lr: 2.6e-06     reward: 7.44\n",
      "epis: 2090   score: 9.0   mem len: 517539   epsilon: 0.1733    steps: 441    lr: 2.6e-06     reward: 7.46\n",
      "epis: 2091   score: 3.0   mem len: 517750   epsilon: 0.1729    steps: 211    lr: 2.6e-06     reward: 7.45\n",
      "epis: 2092   score: 9.0   mem len: 518228   epsilon: 0.1719    steps: 478    lr: 2.6e-06     reward: 7.41\n",
      "epis: 2093   score: 3.0   mem len: 518441   epsilon: 0.1715    steps: 213    lr: 2.6e-06     reward: 7.34\n",
      "epis: 2094   score: 6.0   mem len: 518761   epsilon: 0.1709    steps: 320    lr: 2.6e-06     reward: 7.33\n",
      "epis: 2095   score: 7.0   mem len: 519166   epsilon: 0.17    steps: 405    lr: 2.6e-06     reward: 7.3\n",
      "epis: 2096   score: 4.0   mem len: 519408   epsilon: 0.1696    steps: 242    lr: 2.6e-06     reward: 7.3\n",
      "epis: 2097   score: 5.0   mem len: 519699   epsilon: 0.169    steps: 291    lr: 2.6e-06     reward: 7.28\n",
      "epis: 2098   score: 6.0   mem len: 520052   epsilon: 0.1683    steps: 353    lr: 2.6e-06     reward: 7.27\n",
      "epis: 2099   score: 7.0   mem len: 520426   epsilon: 0.1676    steps: 374    lr: 2.6e-06     reward: 7.23\n",
      "epis: 2100   score: 8.0   mem len: 520864   epsilon: 0.1667    steps: 438    lr: 2.6e-06     reward: 7.24\n",
      "epis: 2101   score: 6.0   mem len: 521222   epsilon: 0.166    steps: 358    lr: 2.6e-06     reward: 7.25\n",
      "epis: 2102   score: 9.0   mem len: 521695   epsilon: 0.165    steps: 473    lr: 2.6e-06     reward: 7.29\n",
      "epis: 2103   score: 8.0   mem len: 522152   epsilon: 0.1641    steps: 457    lr: 2.6e-06     reward: 7.31\n",
      "epis: 2104   score: 5.0   mem len: 522444   epsilon: 0.1636    steps: 292    lr: 2.6e-06     reward: 7.28\n",
      "epis: 2105   score: 9.0   mem len: 522882   epsilon: 0.1627    steps: 438    lr: 2.6e-06     reward: 7.31\n",
      "epis: 2106   score: 8.0   mem len: 523281   epsilon: 0.1619    steps: 399    lr: 2.6e-06     reward: 7.3\n",
      "epis: 2107   score: 10.0   mem len: 523809   epsilon: 0.1609    steps: 528    lr: 2.6e-06     reward: 7.36\n",
      "epis: 2108   score: 8.0   mem len: 524214   epsilon: 0.1601    steps: 405    lr: 2.6e-06     reward: 7.36\n",
      "epis: 2109   score: 4.0   mem len: 524473   epsilon: 0.1595    steps: 259    lr: 2.6e-06     reward: 7.32\n",
      "epis: 2110   score: 6.0   mem len: 524798   epsilon: 0.1589    steps: 325    lr: 2.6e-06     reward: 7.29\n",
      "epis: 2111   score: 8.0   mem len: 525076   epsilon: 0.1583    steps: 278    lr: 2.6e-06     reward: 7.31\n",
      "epis: 2112   score: 6.0   mem len: 525446   epsilon: 0.1576    steps: 370    lr: 2.6e-06     reward: 7.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2113   score: 5.0   mem len: 525753   epsilon: 0.157    steps: 307    lr: 2.6e-06     reward: 7.33\n",
      "epis: 2114   score: 9.0   mem len: 526205   epsilon: 0.1561    steps: 452    lr: 2.6e-06     reward: 7.34\n",
      "epis: 2115   score: 5.0   mem len: 526492   epsilon: 0.1555    steps: 287    lr: 2.6e-06     reward: 7.31\n",
      "epis: 2116   score: 9.0   mem len: 526954   epsilon: 0.1546    steps: 462    lr: 2.6e-06     reward: 7.32\n",
      "epis: 2117   score: 10.0   mem len: 527433   epsilon: 0.1537    steps: 479    lr: 2.6e-06     reward: 7.35\n",
      "epis: 2118   score: 9.0   mem len: 527900   epsilon: 0.1528    steps: 467    lr: 2.6e-06     reward: 7.34\n",
      "epis: 2119   score: 8.0   mem len: 528302   epsilon: 0.152    steps: 402    lr: 2.6e-06     reward: 7.37\n",
      "epis: 2120   score: 8.0   mem len: 528714   epsilon: 0.1511    steps: 412    lr: 2.6e-06     reward: 7.39\n",
      "epis: 2121   score: 11.0   mem len: 529261   epsilon: 0.1501    steps: 547    lr: 2.6e-06     reward: 7.44\n",
      "epis: 2122   score: 7.0   mem len: 529645   epsilon: 0.1493    steps: 384    lr: 2.6e-06     reward: 7.42\n",
      "epis: 2123   score: 9.0   mem len: 530068   epsilon: 0.1485    steps: 423    lr: 2.6e-06     reward: 7.46\n",
      "epis: 2124   score: 4.0   mem len: 530342   epsilon: 0.1479    steps: 274    lr: 2.6e-06     reward: 7.45\n",
      "epis: 2125   score: 9.0   mem len: 530793   epsilon: 0.147    steps: 451    lr: 2.6e-06     reward: 7.48\n",
      "epis: 2126   score: 12.0   mem len: 531216   epsilon: 0.1462    steps: 423    lr: 2.6e-06     reward: 7.47\n",
      "epis: 2127   score: 4.0   mem len: 531492   epsilon: 0.1456    steps: 276    lr: 2.6e-06     reward: 7.44\n",
      "epis: 2128   score: 9.0   mem len: 531983   epsilon: 0.1447    steps: 491    lr: 2.6e-06     reward: 7.48\n",
      "epis: 2129   score: 9.0   mem len: 532454   epsilon: 0.1437    steps: 471    lr: 2.6e-06     reward: 7.51\n",
      "epis: 2130   score: 6.0   mem len: 532791   epsilon: 0.1431    steps: 337    lr: 2.6e-06     reward: 7.48\n",
      "epis: 2131   score: 7.0   mem len: 533199   epsilon: 0.1423    steps: 408    lr: 2.6e-06     reward: 7.49\n",
      "epis: 2132   score: 9.0   mem len: 533630   epsilon: 0.1414    steps: 431    lr: 2.6e-06     reward: 7.53\n",
      "epis: 2133   score: 8.0   mem len: 534070   epsilon: 0.1405    steps: 440    lr: 2.6e-06     reward: 7.56\n",
      "epis: 2134   score: 8.0   mem len: 534540   epsilon: 0.1396    steps: 470    lr: 2.6e-06     reward: 7.5\n",
      "epis: 2135   score: 11.0   mem len: 535076   epsilon: 0.1385    steps: 536    lr: 2.6e-06     reward: 7.54\n",
      "epis: 2136   score: 9.0   mem len: 535545   epsilon: 0.1376    steps: 469    lr: 2.6e-06     reward: 7.58\n",
      "epis: 2137   score: 11.0   mem len: 536072   epsilon: 0.1366    steps: 527    lr: 2.6e-06     reward: 7.63\n",
      "epis: 2138   score: 6.0   mem len: 536425   epsilon: 0.1359    steps: 353    lr: 2.6e-06     reward: 7.57\n",
      "epis: 2139   score: 9.0   mem len: 536864   epsilon: 0.135    steps: 439    lr: 2.6e-06     reward: 7.55\n",
      "epis: 2140   score: 8.0   mem len: 537232   epsilon: 0.1343    steps: 368    lr: 2.6e-06     reward: 7.54\n",
      "epis: 2141   score: 7.0   mem len: 537620   epsilon: 0.1335    steps: 388    lr: 2.6e-06     reward: 7.53\n",
      "epis: 2142   score: 3.0   mem len: 537852   epsilon: 0.1331    steps: 232    lr: 2.6e-06     reward: 7.48\n",
      "epis: 2143   score: 8.0   mem len: 538285   epsilon: 0.1322    steps: 433    lr: 2.6e-06     reward: 7.47\n",
      "epis: 2144   score: 10.0   mem len: 538789   epsilon: 0.1312    steps: 504    lr: 2.6e-06     reward: 7.52\n",
      "epis: 2145   score: 5.0   mem len: 539079   epsilon: 0.1306    steps: 290    lr: 2.6e-06     reward: 7.53\n",
      "epis: 2146   score: 5.0   mem len: 539405   epsilon: 0.13    steps: 326    lr: 2.6e-06     reward: 7.51\n",
      "epis: 2147   score: 9.0   mem len: 539837   epsilon: 0.1291    steps: 432    lr: 2.6e-06     reward: 7.51\n",
      "epis: 2148   score: 9.0   mem len: 540312   epsilon: 0.1282    steps: 475    lr: 2.6e-06     reward: 7.56\n",
      "epis: 2149   score: 6.0   mem len: 540654   epsilon: 0.1275    steps: 342    lr: 2.6e-06     reward: 7.52\n",
      "epis: 2150   score: 8.0   mem len: 541073   epsilon: 0.1267    steps: 419    lr: 2.6e-06     reward: 7.51\n",
      "epis: 2151   score: 6.0   mem len: 541430   epsilon: 0.126    steps: 357    lr: 2.6e-06     reward: 7.5\n",
      "epis: 2152   score: 6.0   mem len: 541740   epsilon: 0.1254    steps: 310    lr: 2.6e-06     reward: 7.46\n",
      "epis: 2153   score: 7.0   mem len: 542112   epsilon: 0.1246    steps: 372    lr: 2.6e-06     reward: 7.46\n",
      "epis: 2154   score: 4.0   mem len: 542374   epsilon: 0.1241    steps: 262    lr: 2.6e-06     reward: 7.42\n",
      "epis: 2155   score: 8.0   mem len: 542779   epsilon: 0.1233    steps: 405    lr: 2.6e-06     reward: 7.42\n",
      "epis: 2156   score: 8.0   mem len: 543076   epsilon: 0.1227    steps: 297    lr: 2.6e-06     reward: 7.4\n",
      "epis: 2157   score: 11.0   mem len: 543626   epsilon: 0.1216    steps: 550    lr: 2.6e-06     reward: 7.46\n",
      "epis: 2158   score: 9.0   mem len: 544098   epsilon: 0.1207    steps: 472    lr: 2.6e-06     reward: 7.51\n",
      "epis: 2159   score: 6.0   mem len: 544435   epsilon: 0.12    steps: 337    lr: 2.6e-06     reward: 7.48\n",
      "epis: 2160   score: 8.0   mem len: 544873   epsilon: 0.1191    steps: 438    lr: 2.6e-06     reward: 7.5\n",
      "epis: 2161   score: 9.0   mem len: 545328   epsilon: 0.1182    steps: 455    lr: 2.6e-06     reward: 7.48\n",
      "epis: 2162   score: 20.0   mem len: 545960   epsilon: 0.117    steps: 632    lr: 2.6e-06     reward: 7.6\n",
      "epis: 2163   score: 11.0   mem len: 546449   epsilon: 0.116    steps: 489    lr: 2.6e-06     reward: 7.65\n",
      "epis: 2164   score: 10.0   mem len: 546985   epsilon: 0.115    steps: 536    lr: 2.6e-06     reward: 7.65\n",
      "epis: 2165   score: 11.0   mem len: 547491   epsilon: 0.114    steps: 506    lr: 2.6e-06     reward: 7.67\n",
      "epis: 2166   score: 9.0   mem len: 547941   epsilon: 0.1131    steps: 450    lr: 2.6e-06     reward: 7.66\n",
      "epis: 2167   score: 3.0   mem len: 548154   epsilon: 0.1127    steps: 213    lr: 2.6e-06     reward: 7.63\n",
      "epis: 2168   score: 4.0   mem len: 548410   epsilon: 0.1121    steps: 256    lr: 2.6e-06     reward: 7.61\n",
      "epis: 2169   score: 5.0   mem len: 548696   epsilon: 0.1116    steps: 286    lr: 2.6e-06     reward: 7.59\n",
      "epis: 2170   score: 6.0   mem len: 549051   epsilon: 0.1109    steps: 355    lr: 2.6e-06     reward: 7.62\n",
      "epis: 2171   score: 5.0   mem len: 549359   epsilon: 0.1103    steps: 308    lr: 2.6e-06     reward: 7.6\n",
      "epis: 2172   score: 4.0   mem len: 549636   epsilon: 0.1097    steps: 277    lr: 2.6e-06     reward: 7.54\n",
      "epis: 2173   score: 9.0   mem len: 550107   epsilon: 0.1088    steps: 471    lr: 2.6e-06     reward: 7.58\n",
      "epis: 2174   score: 11.0   mem len: 550504   epsilon: 0.108    steps: 397    lr: 2.6e-06     reward: 7.59\n",
      "epis: 2175   score: 3.0   mem len: 550735   epsilon: 0.1075    steps: 231    lr: 2.6e-06     reward: 7.55\n",
      "epis: 2176   score: 7.0   mem len: 551143   epsilon: 0.1067    steps: 408    lr: 2.6e-06     reward: 7.57\n",
      "epis: 2177   score: 6.0   mem len: 551513   epsilon: 0.106    steps: 370    lr: 2.6e-06     reward: 7.57\n",
      "epis: 2178   score: 6.0   mem len: 551874   epsilon: 0.1053    steps: 361    lr: 2.6e-06     reward: 7.53\n",
      "epis: 2179   score: 6.0   mem len: 552211   epsilon: 0.1046    steps: 337    lr: 2.6e-06     reward: 7.51\n",
      "epis: 2180   score: 9.0   mem len: 552706   epsilon: 0.1036    steps: 495    lr: 2.6e-06     reward: 7.55\n",
      "epis: 2181   score: 10.0   mem len: 553203   epsilon: 0.1027    steps: 497    lr: 2.6e-06     reward: 7.57\n",
      "epis: 2182   score: 11.0   mem len: 553756   epsilon: 0.1016    steps: 553    lr: 2.6e-06     reward: 7.57\n",
      "epis: 2183   score: 5.0   mem len: 554047   epsilon: 0.101    steps: 291    lr: 2.6e-06     reward: 7.51\n",
      "epis: 2184   score: 5.0   mem len: 554359   epsilon: 0.1004    steps: 312    lr: 2.6e-06     reward: 7.5\n",
      "epis: 2185   score: 13.0   mem len: 554881   epsilon: 0.0993    steps: 522    lr: 2.6e-06     reward: 7.56\n",
      "epis: 2186   score: 8.0   mem len: 555319   epsilon: 0.0985    steps: 438    lr: 2.6e-06     reward: 7.53\n",
      "epis: 2187   score: 10.0   mem len: 555826   epsilon: 0.0975    steps: 507    lr: 2.6e-06     reward: 7.57\n",
      "epis: 2188   score: 3.0   mem len: 556058   epsilon: 0.097    steps: 232    lr: 2.6e-06     reward: 7.5\n",
      "epis: 2189   score: 7.0   mem len: 556418   epsilon: 0.0963    steps: 360    lr: 2.6e-06     reward: 7.52\n",
      "epis: 2190   score: 6.0   mem len: 556761   epsilon: 0.0956    steps: 343    lr: 2.6e-06     reward: 7.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2191   score: 15.0   mem len: 557359   epsilon: 0.0944    steps: 598    lr: 2.6e-06     reward: 7.61\n",
      "epis: 2192   score: 10.0   mem len: 557832   epsilon: 0.0935    steps: 473    lr: 2.6e-06     reward: 7.62\n",
      "epis: 2193   score: 6.0   mem len: 558186   epsilon: 0.0928    steps: 354    lr: 2.6e-06     reward: 7.65\n",
      "epis: 2194   score: 8.0   mem len: 558614   epsilon: 0.0919    steps: 428    lr: 2.6e-06     reward: 7.67\n",
      "epis: 2195   score: 6.0   mem len: 558975   epsilon: 0.0912    steps: 361    lr: 2.6e-06     reward: 7.66\n",
      "epis: 2196   score: 8.0   mem len: 559371   epsilon: 0.0904    steps: 396    lr: 2.6e-06     reward: 7.7\n",
      "epis: 2197   score: 6.0   mem len: 559725   epsilon: 0.0897    steps: 354    lr: 2.6e-06     reward: 7.71\n",
      "epis: 2198   score: 4.0   mem len: 560004   epsilon: 0.0892    steps: 279    lr: 2.6e-06     reward: 7.69\n",
      "epis: 2199   score: 3.0   mem len: 560217   epsilon: 0.0888    steps: 213    lr: 2.6e-06     reward: 7.65\n",
      "epis: 2200   score: 6.0   mem len: 560591   epsilon: 0.088    steps: 374    lr: 2.6e-06     reward: 7.63\n",
      "epis: 2201   score: 6.0   mem len: 560950   epsilon: 0.0873    steps: 359    lr: 2.6e-06     reward: 7.63\n",
      "epis: 2202   score: 9.0   mem len: 561418   epsilon: 0.0864    steps: 468    lr: 2.6e-06     reward: 7.63\n",
      "epis: 2203   score: 6.0   mem len: 561755   epsilon: 0.0857    steps: 337    lr: 2.6e-06     reward: 7.61\n",
      "epis: 2204   score: 10.0   mem len: 562251   epsilon: 0.0847    steps: 496    lr: 2.6e-06     reward: 7.66\n",
      "epis: 2205   score: 8.0   mem len: 562688   epsilon: 0.0839    steps: 437    lr: 2.6e-06     reward: 7.65\n",
      "epis: 2206   score: 11.0   mem len: 563184   epsilon: 0.0829    steps: 496    lr: 2.6e-06     reward: 7.68\n",
      "epis: 2207   score: 11.0   mem len: 563722   epsilon: 0.0818    steps: 538    lr: 2.6e-06     reward: 7.69\n",
      "epis: 2208   score: 9.0   mem len: 564197   epsilon: 0.0809    steps: 475    lr: 2.6e-06     reward: 7.7\n",
      "epis: 2209   score: 4.0   mem len: 564457   epsilon: 0.0804    steps: 260    lr: 2.6e-06     reward: 7.7\n",
      "epis: 2210   score: 5.0   mem len: 564770   epsilon: 0.0798    steps: 313    lr: 2.6e-06     reward: 7.69\n",
      "epis: 2211   score: 19.0   mem len: 565308   epsilon: 0.0787    steps: 538    lr: 2.6e-06     reward: 7.8\n",
      "epis: 2212   score: 9.0   mem len: 565808   epsilon: 0.0777    steps: 500    lr: 2.6e-06     reward: 7.83\n",
      "epis: 2213   score: 6.0   mem len: 566170   epsilon: 0.077    steps: 362    lr: 2.6e-06     reward: 7.84\n",
      "epis: 2214   score: 8.0   mem len: 566565   epsilon: 0.0762    steps: 395    lr: 2.6e-06     reward: 7.83\n",
      "epis: 2215   score: 9.0   mem len: 567017   epsilon: 0.0753    steps: 452    lr: 2.6e-06     reward: 7.87\n",
      "epis: 2216   score: 9.0   mem len: 567494   epsilon: 0.0744    steps: 477    lr: 2.6e-06     reward: 7.87\n",
      "epis: 2217   score: 7.0   mem len: 567900   epsilon: 0.0736    steps: 406    lr: 2.6e-06     reward: 7.84\n",
      "epis: 2218   score: 9.0   mem len: 568386   epsilon: 0.0726    steps: 486    lr: 2.6e-06     reward: 7.84\n",
      "epis: 2219   score: 4.0   mem len: 568644   epsilon: 0.0721    steps: 258    lr: 2.6e-06     reward: 7.8\n",
      "epis: 2220   score: 6.0   mem len: 568986   epsilon: 0.0714    steps: 342    lr: 2.6e-06     reward: 7.78\n",
      "epis: 2221   score: 7.0   mem len: 569352   epsilon: 0.0707    steps: 366    lr: 2.6e-06     reward: 7.74\n",
      "epis: 2222   score: 6.0   mem len: 569727   epsilon: 0.0699    steps: 375    lr: 2.6e-06     reward: 7.73\n",
      "epis: 2223   score: 9.0   mem len: 570229   epsilon: 0.0689    steps: 502    lr: 2.6e-06     reward: 7.73\n",
      "epis: 2224   score: 8.0   mem len: 570618   epsilon: 0.0682    steps: 389    lr: 2.6e-06     reward: 7.77\n",
      "epis: 2225   score: 9.0   mem len: 571103   epsilon: 0.0672    steps: 485    lr: 2.6e-06     reward: 7.77\n",
      "epis: 2226   score: 6.0   mem len: 571481   epsilon: 0.0665    steps: 378    lr: 2.6e-06     reward: 7.71\n",
      "epis: 2227   score: 4.0   mem len: 571742   epsilon: 0.0659    steps: 261    lr: 2.6e-06     reward: 7.71\n",
      "epis: 2228   score: 13.0   mem len: 572359   epsilon: 0.0647    steps: 617    lr: 2.6e-06     reward: 7.75\n",
      "epis: 2229   score: 6.0   mem len: 572713   epsilon: 0.064    steps: 354    lr: 2.6e-06     reward: 7.72\n",
      "epis: 2230   score: 7.0   mem len: 573114   epsilon: 0.0632    steps: 401    lr: 2.6e-06     reward: 7.73\n",
      "epis: 2231   score: 4.0   mem len: 573375   epsilon: 0.0627    steps: 261    lr: 2.6e-06     reward: 7.7\n",
      "epis: 2232   score: 9.0   mem len: 573789   epsilon: 0.0619    steps: 414    lr: 2.6e-06     reward: 7.7\n",
      "epis: 2233   score: 5.0   mem len: 574102   epsilon: 0.0613    steps: 313    lr: 2.6e-06     reward: 7.67\n",
      "epis: 2234   score: 7.0   mem len: 574459   epsilon: 0.0606    steps: 357    lr: 2.6e-06     reward: 7.66\n",
      "epis: 2235   score: 8.0   mem len: 574911   epsilon: 0.0597    steps: 452    lr: 2.6e-06     reward: 7.63\n",
      "epis: 2236   score: 12.0   mem len: 575458   epsilon: 0.0586    steps: 547    lr: 2.6e-06     reward: 7.66\n",
      "epis: 2237   score: 11.0   mem len: 575968   epsilon: 0.0576    steps: 510    lr: 2.6e-06     reward: 7.66\n",
      "epis: 2238   score: 9.0   mem len: 576406   epsilon: 0.0567    steps: 438    lr: 2.6e-06     reward: 7.69\n",
      "epis: 2239   score: 3.0   mem len: 576638   epsilon: 0.0563    steps: 232    lr: 2.6e-06     reward: 7.63\n",
      "epis: 2240   score: 10.0   mem len: 577099   epsilon: 0.0553    steps: 461    lr: 2.6e-06     reward: 7.65\n",
      "epis: 2241   score: 6.0   mem len: 577479   epsilon: 0.0546    steps: 380    lr: 2.6e-06     reward: 7.64\n",
      "epis: 2242   score: 12.0   mem len: 578036   epsilon: 0.0535    steps: 557    lr: 2.6e-06     reward: 7.73\n",
      "epis: 2243   score: 10.0   mem len: 578557   epsilon: 0.0525    steps: 521    lr: 2.6e-06     reward: 7.75\n",
      "epis: 2244   score: 7.0   mem len: 578898   epsilon: 0.0518    steps: 341    lr: 2.6e-06     reward: 7.72\n",
      "epis: 2245   score: 4.0   mem len: 579179   epsilon: 0.0512    steps: 281    lr: 2.6e-06     reward: 7.71\n",
      "epis: 2246   score: 5.0   mem len: 579468   epsilon: 0.0507    steps: 289    lr: 2.6e-06     reward: 7.71\n",
      "epis: 2247   score: 7.0   mem len: 579859   epsilon: 0.0499    steps: 391    lr: 2.6e-06     reward: 7.69\n",
      "epis: 2248   score: 9.0   mem len: 580330   epsilon: 0.0489    steps: 471    lr: 2.6e-06     reward: 7.69\n",
      "epis: 2249   score: 7.0   mem len: 580727   epsilon: 0.0482    steps: 397    lr: 2.6e-06     reward: 7.7\n",
      "epis: 2250   score: 3.0   mem len: 580959   epsilon: 0.0477    steps: 232    lr: 2.6e-06     reward: 7.65\n",
      "epis: 2251   score: 7.0   mem len: 581360   epsilon: 0.0469    steps: 401    lr: 2.6e-06     reward: 7.66\n",
      "epis: 2252   score: 6.0   mem len: 581700   epsilon: 0.0462    steps: 340    lr: 2.6e-06     reward: 7.66\n",
      "epis: 2253   score: 11.0   mem len: 582193   epsilon: 0.0453    steps: 493    lr: 2.6e-06     reward: 7.7\n",
      "epis: 2254   score: 10.0   mem len: 582696   epsilon: 0.0443    steps: 503    lr: 2.6e-06     reward: 7.76\n",
      "epis: 2255   score: 14.0   mem len: 583272   epsilon: 0.0431    steps: 576    lr: 2.6e-06     reward: 7.82\n",
      "epis: 2256   score: 7.0   mem len: 583641   epsilon: 0.0424    steps: 369    lr: 2.6e-06     reward: 7.81\n",
      "epis: 2257   score: 9.0   mem len: 584112   epsilon: 0.0415    steps: 471    lr: 2.6e-06     reward: 7.79\n",
      "epis: 2258   score: 12.0   mem len: 584554   epsilon: 0.0406    steps: 442    lr: 2.6e-06     reward: 7.82\n",
      "epis: 2259   score: 6.0   mem len: 584911   epsilon: 0.0399    steps: 357    lr: 2.6e-06     reward: 7.82\n",
      "epis: 2260   score: 11.0   mem len: 585448   epsilon: 0.0388    steps: 537    lr: 2.6e-06     reward: 7.85\n",
      "epis: 2261   score: 9.0   mem len: 585888   epsilon: 0.0379    steps: 440    lr: 2.6e-06     reward: 7.85\n",
      "epis: 2262   score: 5.0   mem len: 586214   epsilon: 0.0373    steps: 326    lr: 2.6e-06     reward: 7.7\n",
      "epis: 2263   score: 7.0   mem len: 586605   epsilon: 0.0365    steps: 391    lr: 2.6e-06     reward: 7.66\n",
      "epis: 2264   score: 7.0   mem len: 587013   epsilon: 0.0357    steps: 408    lr: 2.6e-06     reward: 7.63\n",
      "epis: 2265   score: 11.0   mem len: 587555   epsilon: 0.0346    steps: 542    lr: 2.6e-06     reward: 7.63\n",
      "epis: 2266   score: 9.0   mem len: 587969   epsilon: 0.0338    steps: 414    lr: 2.6e-06     reward: 7.63\n",
      "epis: 2267   score: 6.0   mem len: 588279   epsilon: 0.0332    steps: 310    lr: 2.6e-06     reward: 7.66\n",
      "epis: 2268   score: 7.0   mem len: 588681   epsilon: 0.0324    steps: 402    lr: 2.6e-06     reward: 7.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2269   score: 11.0   mem len: 589199   epsilon: 0.0314    steps: 518    lr: 2.6e-06     reward: 7.75\n",
      "epis: 2270   score: 5.0   mem len: 589490   epsilon: 0.0308    steps: 291    lr: 2.6e-06     reward: 7.74\n",
      "epis: 2271   score: 10.0   mem len: 589963   epsilon: 0.0299    steps: 473    lr: 2.6e-06     reward: 7.79\n",
      "epis: 2272   score: 10.0   mem len: 590428   epsilon: 0.029    steps: 465    lr: 2.6e-06     reward: 7.85\n",
      "epis: 2273   score: 6.0   mem len: 590776   epsilon: 0.0283    steps: 348    lr: 2.6e-06     reward: 7.82\n",
      "epis: 2274   score: 14.0   mem len: 591252   epsilon: 0.0273    steps: 476    lr: 2.6e-06     reward: 7.85\n",
      "epis: 2275   score: 7.0   mem len: 591645   epsilon: 0.0265    steps: 393    lr: 2.6e-06     reward: 7.89\n",
      "epis: 2276   score: 5.0   mem len: 591951   epsilon: 0.0259    steps: 306    lr: 2.6e-06     reward: 7.87\n",
      "epis: 2277   score: 4.0   mem len: 592211   epsilon: 0.0254    steps: 260    lr: 2.6e-06     reward: 7.85\n",
      "epis: 2278   score: 4.0   mem len: 592471   epsilon: 0.0249    steps: 260    lr: 2.6e-06     reward: 7.83\n",
      "epis: 2279   score: 11.0   mem len: 592985   epsilon: 0.0239    steps: 514    lr: 2.6e-06     reward: 7.88\n",
      "epis: 2280   score: 4.0   mem len: 593264   epsilon: 0.0233    steps: 279    lr: 2.6e-06     reward: 7.83\n",
      "epis: 2281   score: 13.0   mem len: 593723   epsilon: 0.0224    steps: 459    lr: 2.6e-06     reward: 7.86\n",
      "epis: 2282   score: 5.0   mem len: 594049   epsilon: 0.0218    steps: 326    lr: 2.6e-06     reward: 7.8\n",
      "epis: 2283   score: 5.0   mem len: 594362   epsilon: 0.0212    steps: 313    lr: 2.6e-06     reward: 7.8\n",
      "epis: 2284   score: 8.0   mem len: 594819   epsilon: 0.0203    steps: 457    lr: 2.6e-06     reward: 7.83\n",
      "epis: 2285   score: 4.0   mem len: 595080   epsilon: 0.0197    steps: 261    lr: 2.6e-06     reward: 7.74\n",
      "epis: 2286   score: 5.0   mem len: 595404   epsilon: 0.0191    steps: 324    lr: 2.6e-06     reward: 7.71\n",
      "epis: 2287   score: 8.0   mem len: 595832   epsilon: 0.0183    steps: 428    lr: 2.6e-06     reward: 7.69\n",
      "epis: 2288   score: 5.0   mem len: 596120   epsilon: 0.0177    steps: 288    lr: 2.6e-06     reward: 7.71\n",
      "epis: 2289   score: 5.0   mem len: 596408   epsilon: 0.0171    steps: 288    lr: 2.6e-06     reward: 7.69\n",
      "epis: 2290   score: 11.0   mem len: 596847   epsilon: 0.0162    steps: 439    lr: 2.6e-06     reward: 7.74\n",
      "epis: 2291   score: 13.0   mem len: 597461   epsilon: 0.015    steps: 614    lr: 2.6e-06     reward: 7.72\n",
      "epis: 2292   score: 8.0   mem len: 597893   epsilon: 0.0142    steps: 432    lr: 2.6e-06     reward: 7.7\n",
      "epis: 2293   score: 4.0   mem len: 598154   epsilon: 0.0137    steps: 261    lr: 2.6e-06     reward: 7.68\n",
      "epis: 2294   score: 5.0   mem len: 598463   epsilon: 0.013    steps: 309    lr: 2.6e-06     reward: 7.65\n",
      "epis: 2295   score: 5.0   mem len: 598787   epsilon: 0.0124    steps: 324    lr: 2.6e-06     reward: 7.64\n",
      "epis: 2296   score: 6.0   mem len: 599147   epsilon: 0.0117    steps: 360    lr: 2.6e-06     reward: 7.62\n",
      "epis: 2297   score: 9.0   mem len: 599607   epsilon: 0.0108    steps: 460    lr: 2.6e-06     reward: 7.65\n",
      "epis: 2298   score: 12.0   mem len: 600189   epsilon: 0.01    steps: 582    lr: 1e-06     reward: 7.73\n",
      "epis: 2299   score: 7.0   mem len: 600586   epsilon: 0.01    steps: 397    lr: 1e-06     reward: 7.77\n",
      "epis: 2300   score: 6.0   mem len: 600926   epsilon: 0.01    steps: 340    lr: 1e-06     reward: 7.77\n",
      "epis: 2301   score: 5.0   mem len: 601252   epsilon: 0.01    steps: 326    lr: 1e-06     reward: 7.76\n",
      "epis: 2302   score: 10.0   mem len: 601737   epsilon: 0.01    steps: 485    lr: 1e-06     reward: 7.77\n",
      "epis: 2303   score: 10.0   mem len: 602234   epsilon: 0.01    steps: 497    lr: 1e-06     reward: 7.81\n",
      "epis: 2304   score: 10.0   mem len: 602753   epsilon: 0.01    steps: 519    lr: 1e-06     reward: 7.81\n",
      "epis: 2305   score: 6.0   mem len: 603099   epsilon: 0.01    steps: 346    lr: 1e-06     reward: 7.79\n",
      "epis: 2306   score: 5.0   mem len: 603425   epsilon: 0.01    steps: 326    lr: 1e-06     reward: 7.73\n",
      "epis: 2307   score: 5.0   mem len: 603751   epsilon: 0.01    steps: 326    lr: 1e-06     reward: 7.67\n",
      "epis: 2308   score: 8.0   mem len: 604142   epsilon: 0.01    steps: 391    lr: 1e-06     reward: 7.66\n",
      "epis: 2309   score: 15.0   mem len: 604576   epsilon: 0.01    steps: 434    lr: 1e-06     reward: 7.77\n",
      "epis: 2310   score: 6.0   mem len: 604904   epsilon: 0.01    steps: 328    lr: 1e-06     reward: 7.78\n",
      "epis: 2311   score: 13.0   mem len: 605512   epsilon: 0.01    steps: 608    lr: 1e-06     reward: 7.72\n",
      "epis: 2312   score: 12.0   mem len: 606087   epsilon: 0.01    steps: 575    lr: 1e-06     reward: 7.75\n",
      "epis: 2313   score: 6.0   mem len: 606397   epsilon: 0.01    steps: 310    lr: 1e-06     reward: 7.75\n",
      "epis: 2314   score: 7.0   mem len: 606754   epsilon: 0.01    steps: 357    lr: 1e-06     reward: 7.74\n",
      "epis: 2315   score: 9.0   mem len: 607225   epsilon: 0.01    steps: 471    lr: 1e-06     reward: 7.74\n",
      "epis: 2316   score: 4.0   mem len: 607486   epsilon: 0.01    steps: 261    lr: 1e-06     reward: 7.69\n",
      "epis: 2317   score: 7.0   mem len: 607884   epsilon: 0.01    steps: 398    lr: 1e-06     reward: 7.69\n",
      "epis: 2318   score: 8.0   mem len: 608339   epsilon: 0.01    steps: 455    lr: 1e-06     reward: 7.68\n",
      "epis: 2319   score: 6.0   mem len: 608682   epsilon: 0.01    steps: 343    lr: 1e-06     reward: 7.7\n",
      "epis: 2320   score: 12.0   mem len: 609224   epsilon: 0.01    steps: 542    lr: 1e-06     reward: 7.76\n",
      "epis: 2321   score: 5.0   mem len: 609537   epsilon: 0.01    steps: 313    lr: 1e-06     reward: 7.74\n",
      "epis: 2322   score: 7.0   mem len: 609906   epsilon: 0.01    steps: 369    lr: 1e-06     reward: 7.75\n",
      "epis: 2323   score: 13.0   mem len: 610411   epsilon: 0.01    steps: 505    lr: 1e-06     reward: 7.79\n",
      "epis: 2324   score: 5.0   mem len: 610737   epsilon: 0.01    steps: 326    lr: 1e-06     reward: 7.76\n",
      "epis: 2325   score: 3.0   mem len: 610969   epsilon: 0.01    steps: 232    lr: 1e-06     reward: 7.7\n",
      "epis: 2326   score: 11.0   mem len: 611513   epsilon: 0.01    steps: 544    lr: 1e-06     reward: 7.75\n",
      "epis: 2327   score: 9.0   mem len: 611984   epsilon: 0.01    steps: 471    lr: 1e-06     reward: 7.8\n",
      "epis: 2328   score: 4.0   mem len: 612266   epsilon: 0.01    steps: 282    lr: 1e-06     reward: 7.71\n",
      "epis: 2329   score: 9.0   mem len: 612737   epsilon: 0.01    steps: 471    lr: 1e-06     reward: 7.74\n",
      "epis: 2330   score: 3.0   mem len: 612969   epsilon: 0.01    steps: 232    lr: 1e-06     reward: 7.7\n",
      "epis: 2331   score: 13.0   mem len: 613577   epsilon: 0.01    steps: 608    lr: 1e-06     reward: 7.79\n",
      "epis: 2332   score: 9.0   mem len: 614048   epsilon: 0.01    steps: 471    lr: 1e-06     reward: 7.79\n",
      "epis: 2333   score: 11.0   mem len: 614486   epsilon: 0.01    steps: 438    lr: 1e-06     reward: 7.85\n",
      "epis: 2334   score: 3.0   mem len: 614718   epsilon: 0.01    steps: 232    lr: 1e-06     reward: 7.81\n",
      "epis: 2335   score: 9.0   mem len: 615048   epsilon: 0.01    steps: 330    lr: 1e-06     reward: 7.82\n",
      "epis: 2336   score: 8.0   mem len: 615442   epsilon: 0.01    steps: 394    lr: 1e-06     reward: 7.78\n",
      "epis: 2337   score: 6.0   mem len: 615788   epsilon: 0.01    steps: 346    lr: 1e-06     reward: 7.73\n",
      "epis: 2338   score: 9.0   mem len: 616254   epsilon: 0.01    steps: 466    lr: 1e-06     reward: 7.73\n",
      "epis: 2339   score: 8.0   mem len: 616661   epsilon: 0.01    steps: 407    lr: 1e-06     reward: 7.78\n",
      "epis: 2340   score: 10.0   mem len: 617172   epsilon: 0.01    steps: 511    lr: 1e-06     reward: 7.78\n",
      "epis: 2341   score: 13.0   mem len: 617780   epsilon: 0.01    steps: 608    lr: 1e-06     reward: 7.85\n",
      "epis: 2342   score: 9.0   mem len: 618251   epsilon: 0.01    steps: 471    lr: 1e-06     reward: 7.82\n",
      "epis: 2343   score: 9.0   mem len: 618754   epsilon: 0.01    steps: 503    lr: 1e-06     reward: 7.81\n",
      "epis: 2344   score: 9.0   mem len: 619222   epsilon: 0.01    steps: 468    lr: 1e-06     reward: 7.83\n",
      "epis: 2345   score: 7.0   mem len: 619650   epsilon: 0.01    steps: 428    lr: 1e-06     reward: 7.86\n",
      "epis: 2346   score: 7.0   mem len: 620060   epsilon: 0.01    steps: 410    lr: 1e-06     reward: 7.88\n",
      "epis: 2347   score: 14.0   mem len: 620569   epsilon: 0.01    steps: 509    lr: 1e-06     reward: 7.95\n",
      "epis: 2348   score: 8.0   mem len: 620976   epsilon: 0.01    steps: 407    lr: 1e-06     reward: 7.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2349   score: 8.0   mem len: 621393   epsilon: 0.01    steps: 417    lr: 1e-06     reward: 7.95\n",
      "epis: 2350   score: 10.0   mem len: 621903   epsilon: 0.01    steps: 510    lr: 1e-06     reward: 8.02\n",
      "epis: 2351   score: 5.0   mem len: 622198   epsilon: 0.01    steps: 295    lr: 1e-06     reward: 8.0\n",
      "epis: 2352   score: 11.0   mem len: 622775   epsilon: 0.01    steps: 577    lr: 1e-06     reward: 8.05\n",
      "epis: 2353   score: 10.0   mem len: 623262   epsilon: 0.01    steps: 487    lr: 1e-06     reward: 8.04\n",
      "epis: 2354   score: 8.0   mem len: 623740   epsilon: 0.01    steps: 478    lr: 1e-06     reward: 8.02\n",
      "epis: 2355   score: 11.0   mem len: 624267   epsilon: 0.01    steps: 527    lr: 1e-06     reward: 7.99\n",
      "epis: 2356   score: 8.0   mem len: 624692   epsilon: 0.01    steps: 425    lr: 1e-06     reward: 8.0\n",
      "epis: 2357   score: 7.0   mem len: 625083   epsilon: 0.01    steps: 391    lr: 1e-06     reward: 7.98\n",
      "epis: 2358   score: 5.0   mem len: 625409   epsilon: 0.01    steps: 326    lr: 1e-06     reward: 7.91\n",
      "epis: 2359   score: 5.0   mem len: 625717   epsilon: 0.01    steps: 308    lr: 1e-06     reward: 7.9\n",
      "epis: 2360   score: 4.0   mem len: 625999   epsilon: 0.01    steps: 282    lr: 1e-06     reward: 7.83\n",
      "epis: 2361   score: 10.0   mem len: 626539   epsilon: 0.01    steps: 540    lr: 1e-06     reward: 7.84\n",
      "epis: 2362   score: 6.0   mem len: 626899   epsilon: 0.01    steps: 360    lr: 1e-06     reward: 7.85\n",
      "epis: 2363   score: 9.0   mem len: 627360   epsilon: 0.01    steps: 461    lr: 1e-06     reward: 7.87\n",
      "epis: 2364   score: 15.0   mem len: 627794   epsilon: 0.01    steps: 434    lr: 1e-06     reward: 7.95\n",
      "epis: 2365   score: 11.0   mem len: 628261   epsilon: 0.01    steps: 467    lr: 1e-06     reward: 7.95\n",
      "epis: 2366   score: 7.0   mem len: 628633   epsilon: 0.01    steps: 372    lr: 1e-06     reward: 7.93\n",
      "epis: 2367   score: 12.0   mem len: 629208   epsilon: 0.01    steps: 575    lr: 1e-06     reward: 7.99\n",
      "epis: 2368   score: 11.0   mem len: 629762   epsilon: 0.01    steps: 554    lr: 1e-06     reward: 8.03\n",
      "epis: 2369   score: 10.0   mem len: 630121   epsilon: 0.01    steps: 359    lr: 1e-06     reward: 8.02\n",
      "epis: 2370   score: 7.0   mem len: 630549   epsilon: 0.01    steps: 428    lr: 1e-06     reward: 8.04\n",
      "epis: 2371   score: 6.0   mem len: 630903   epsilon: 0.01    steps: 354    lr: 1e-06     reward: 8.0\n",
      "epis: 2372   score: 12.0   mem len: 631526   epsilon: 0.01    steps: 623    lr: 1e-06     reward: 8.02\n",
      "epis: 2373   score: 7.0   mem len: 631917   epsilon: 0.01    steps: 391    lr: 1e-06     reward: 8.03\n",
      "epis: 2374   score: 7.0   mem len: 632298   epsilon: 0.01    steps: 381    lr: 1e-06     reward: 7.96\n",
      "epis: 2375   score: 9.0   mem len: 632776   epsilon: 0.01    steps: 478    lr: 1e-06     reward: 7.98\n",
      "epis: 2376   score: 18.0   mem len: 633333   epsilon: 0.01    steps: 557    lr: 1e-06     reward: 8.11\n",
      "epis: 2377   score: 15.0   mem len: 633767   epsilon: 0.01    steps: 434    lr: 1e-06     reward: 8.22\n",
      "epis: 2378   score: 4.0   mem len: 634009   epsilon: 0.01    steps: 242    lr: 1e-06     reward: 8.22\n",
      "epis: 2379   score: 14.0   mem len: 634534   epsilon: 0.01    steps: 525    lr: 1e-06     reward: 8.25\n",
      "epis: 2380   score: 4.0   mem len: 634812   epsilon: 0.01    steps: 278    lr: 1e-06     reward: 8.25\n",
      "epis: 2381   score: 8.0   mem len: 635270   epsilon: 0.01    steps: 458    lr: 1e-06     reward: 8.2\n",
      "epis: 2382   score: 7.0   mem len: 635658   epsilon: 0.01    steps: 388    lr: 1e-06     reward: 8.22\n",
      "epis: 2383   score: 14.0   mem len: 636200   epsilon: 0.01    steps: 542    lr: 1e-06     reward: 8.31\n",
      "epis: 2384   score: 15.0   mem len: 636826   epsilon: 0.01    steps: 626    lr: 1e-06     reward: 8.38\n",
      "epis: 2385   score: 3.0   mem len: 637058   epsilon: 0.01    steps: 232    lr: 1e-06     reward: 8.37\n",
      "epis: 2386   score: 10.0   mem len: 637543   epsilon: 0.01    steps: 485    lr: 1e-06     reward: 8.42\n",
      "epis: 2387   score: 12.0   mem len: 638139   epsilon: 0.01    steps: 596    lr: 1e-06     reward: 8.46\n",
      "epis: 2388   score: 15.0   mem len: 638680   epsilon: 0.01    steps: 541    lr: 1e-06     reward: 8.56\n",
      "epis: 2389   score: 6.0   mem len: 639008   epsilon: 0.01    steps: 328    lr: 1e-06     reward: 8.57\n",
      "epis: 2390   score: 11.0   mem len: 639535   epsilon: 0.01    steps: 527    lr: 1e-06     reward: 8.57\n",
      "epis: 2391   score: 11.0   mem len: 640077   epsilon: 0.01    steps: 542    lr: 1e-06     reward: 8.55\n",
      "epis: 2392   score: 3.0   mem len: 640309   epsilon: 0.01    steps: 232    lr: 1e-06     reward: 8.5\n",
      "epis: 2393   score: 5.0   mem len: 640590   epsilon: 0.01    steps: 281    lr: 1e-06     reward: 8.51\n",
      "epis: 2394   score: 6.0   mem len: 640900   epsilon: 0.01    steps: 310    lr: 1e-06     reward: 8.52\n",
      "epis: 2395   score: 10.0   mem len: 641403   epsilon: 0.01    steps: 503    lr: 1e-06     reward: 8.57\n",
      "epis: 2396   score: 6.0   mem len: 641762   epsilon: 0.01    steps: 359    lr: 1e-06     reward: 8.57\n",
      "epis: 2397   score: 12.0   mem len: 642337   epsilon: 0.01    steps: 575    lr: 1e-06     reward: 8.6\n",
      "epis: 2398   score: 14.0   mem len: 642976   epsilon: 0.01    steps: 639    lr: 1e-06     reward: 8.62\n",
      "epis: 2399   score: 9.0   mem len: 643435   epsilon: 0.01    steps: 459    lr: 1e-06     reward: 8.64\n",
      "epis: 2400   score: 10.0   mem len: 643938   epsilon: 0.01    steps: 503    lr: 1e-06     reward: 8.68\n",
      "epis: 2401   score: 8.0   mem len: 644369   epsilon: 0.01    steps: 431    lr: 1e-06     reward: 8.71\n",
      "epis: 2402   score: 10.0   mem len: 644862   epsilon: 0.01    steps: 493    lr: 1e-06     reward: 8.71\n",
      "epis: 2403   score: 15.0   mem len: 645296   epsilon: 0.01    steps: 434    lr: 1e-06     reward: 8.76\n",
      "epis: 2404   score: 9.0   mem len: 645751   epsilon: 0.01    steps: 455    lr: 1e-06     reward: 8.75\n",
      "epis: 2405   score: 13.0   mem len: 646357   epsilon: 0.01    steps: 606    lr: 1e-06     reward: 8.82\n",
      "epis: 2406   score: 21.0   mem len: 647020   epsilon: 0.01    steps: 663    lr: 1e-06     reward: 8.98\n",
      "epis: 2407   score: 9.0   mem len: 647490   epsilon: 0.01    steps: 470    lr: 1e-06     reward: 9.02\n",
      "epis: 2408   score: 9.0   mem len: 647956   epsilon: 0.01    steps: 466    lr: 1e-06     reward: 9.03\n",
      "epis: 2409   score: 12.0   mem len: 648522   epsilon: 0.01    steps: 566    lr: 1e-06     reward: 9.0\n",
      "epis: 2410   score: 8.0   mem len: 648939   epsilon: 0.01    steps: 417    lr: 1e-06     reward: 9.02\n",
      "epis: 2411   score: 9.0   mem len: 649385   epsilon: 0.01    steps: 446    lr: 1e-06     reward: 8.98\n",
      "epis: 2412   score: 22.0   mem len: 650123   epsilon: 0.01    steps: 738    lr: 1e-06     reward: 9.08\n",
      "epis: 2413   score: 5.0   mem len: 650449   epsilon: 0.01    steps: 326    lr: 1e-06     reward: 9.07\n",
      "epis: 2414   score: 11.0   mem len: 650984   epsilon: 0.01    steps: 535    lr: 1e-06     reward: 9.11\n",
      "epis: 2415   score: 9.0   mem len: 651450   epsilon: 0.01    steps: 466    lr: 1e-06     reward: 9.11\n",
      "epis: 2416   score: 11.0   mem len: 651968   epsilon: 0.01    steps: 518    lr: 1e-06     reward: 9.18\n",
      "epis: 2417   score: 3.0   mem len: 652200   epsilon: 0.01    steps: 232    lr: 1e-06     reward: 9.14\n",
      "epis: 2418   score: 8.0   mem len: 652617   epsilon: 0.01    steps: 417    lr: 1e-06     reward: 9.14\n",
      "epis: 2419   score: 9.0   mem len: 653073   epsilon: 0.01    steps: 456    lr: 1e-06     reward: 9.17\n",
      "epis: 2420   score: 14.0   mem len: 653591   epsilon: 0.01    steps: 518    lr: 1e-06     reward: 9.19\n",
      "epis: 2421   score: 9.0   mem len: 654062   epsilon: 0.01    steps: 471    lr: 1e-06     reward: 9.23\n",
      "epis: 2422   score: 9.0   mem len: 654508   epsilon: 0.01    steps: 446    lr: 1e-06     reward: 9.25\n",
      "epis: 2423   score: 11.0   mem len: 655010   epsilon: 0.01    steps: 502    lr: 1e-06     reward: 9.23\n",
      "epis: 2424   score: 16.0   mem len: 655634   epsilon: 0.01    steps: 624    lr: 1e-06     reward: 9.34\n",
      "epis: 2425   score: 3.0   mem len: 655866   epsilon: 0.01    steps: 232    lr: 1e-06     reward: 9.34\n",
      "epis: 2426   score: 14.0   mem len: 656445   epsilon: 0.01    steps: 579    lr: 1e-06     reward: 9.37\n",
      "epis: 2427   score: 15.0   mem len: 656961   epsilon: 0.01    steps: 516    lr: 1e-06     reward: 9.43\n",
      "epis: 2428   score: 5.0   mem len: 657292   epsilon: 0.01    steps: 331    lr: 1e-06     reward: 9.44\n",
      "epis: 2429   score: 4.0   mem len: 657553   epsilon: 0.01    steps: 261    lr: 1e-06     reward: 9.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2430   score: 5.0   mem len: 657884   epsilon: 0.01    steps: 331    lr: 1e-06     reward: 9.41\n",
      "epis: 2431   score: 9.0   mem len: 658355   epsilon: 0.01    steps: 471    lr: 1e-06     reward: 9.37\n",
      "epis: 2432   score: 9.0   mem len: 658826   epsilon: 0.01    steps: 471    lr: 1e-06     reward: 9.37\n",
      "epis: 2433   score: 3.0   mem len: 659057   epsilon: 0.01    steps: 231    lr: 1e-06     reward: 9.29\n",
      "epis: 2434   score: 3.0   mem len: 659289   epsilon: 0.01    steps: 232    lr: 1e-06     reward: 9.29\n",
      "epis: 2435   score: 7.0   mem len: 659646   epsilon: 0.01    steps: 357    lr: 1e-06     reward: 9.27\n",
      "epis: 2436   score: 5.0   mem len: 659958   epsilon: 0.01    steps: 312    lr: 1e-06     reward: 9.24\n",
      "epis: 2437   score: 3.0   mem len: 660190   epsilon: 0.01    steps: 232    lr: 1e-06     reward: 9.21\n",
      "epis: 2438   score: 6.0   mem len: 660536   epsilon: 0.01    steps: 346    lr: 1e-06     reward: 9.18\n",
      "epis: 2439   score: 7.0   mem len: 660905   epsilon: 0.01    steps: 369    lr: 1e-06     reward: 9.17\n",
      "epis: 2440   score: 15.0   mem len: 661458   epsilon: 0.01    steps: 553    lr: 1e-06     reward: 9.22\n",
      "epis: 2441   score: 11.0   mem len: 662015   epsilon: 0.01    steps: 557    lr: 1e-06     reward: 9.2\n",
      "epis: 2442   score: 11.0   mem len: 662568   epsilon: 0.01    steps: 553    lr: 1e-06     reward: 9.22\n",
      "epis: 2443   score: 7.0   mem len: 662937   epsilon: 0.01    steps: 369    lr: 1e-06     reward: 9.2\n",
      "epis: 2444   score: 4.0   mem len: 663198   epsilon: 0.01    steps: 261    lr: 1e-06     reward: 9.15\n",
      "epis: 2445   score: 12.0   mem len: 663760   epsilon: 0.01    steps: 562    lr: 1e-06     reward: 9.2\n",
      "epis: 2446   score: 10.0   mem len: 664262   epsilon: 0.01    steps: 502    lr: 1e-06     reward: 9.23\n",
      "epis: 2447   score: 7.0   mem len: 664651   epsilon: 0.01    steps: 389    lr: 1e-06     reward: 9.16\n",
      "epis: 2448   score: 7.0   mem len: 665060   epsilon: 0.01    steps: 409    lr: 1e-06     reward: 9.15\n",
      "epis: 2449   score: 10.0   mem len: 665562   epsilon: 0.01    steps: 502    lr: 1e-06     reward: 9.17\n",
      "epis: 2450   score: 6.0   mem len: 665872   epsilon: 0.01    steps: 310    lr: 1e-06     reward: 9.13\n",
      "epis: 2451   score: 6.0   mem len: 666214   epsilon: 0.01    steps: 342    lr: 1e-06     reward: 9.14\n",
      "epis: 2452   score: 13.0   mem len: 666822   epsilon: 0.01    steps: 608    lr: 1e-06     reward: 9.16\n",
      "epis: 2453   score: 8.0   mem len: 667229   epsilon: 0.01    steps: 407    lr: 1e-06     reward: 9.14\n",
      "epis: 2454   score: 11.0   mem len: 667735   epsilon: 0.01    steps: 506    lr: 1e-06     reward: 9.17\n",
      "epis: 2455   score: 7.0   mem len: 668122   epsilon: 0.01    steps: 387    lr: 1e-06     reward: 9.13\n",
      "epis: 2456   score: 15.0   mem len: 668762   epsilon: 0.01    steps: 640    lr: 1e-06     reward: 9.2\n",
      "epis: 2457   score: 10.0   mem len: 669248   epsilon: 0.01    steps: 486    lr: 1e-06     reward: 9.23\n",
      "epis: 2458   score: 10.0   mem len: 669735   epsilon: 0.01    steps: 487    lr: 1e-06     reward: 9.28\n",
      "epis: 2459   score: 11.0   mem len: 670275   epsilon: 0.01    steps: 540    lr: 1e-06     reward: 9.34\n",
      "epis: 2460   score: 9.0   mem len: 670747   epsilon: 0.01    steps: 472    lr: 1e-06     reward: 9.39\n",
      "epis: 2461   score: 10.0   mem len: 671241   epsilon: 0.01    steps: 494    lr: 1e-06     reward: 9.39\n",
      "epis: 2462   score: 17.0   mem len: 671743   epsilon: 0.01    steps: 502    lr: 1e-06     reward: 9.5\n",
      "epis: 2463   score: 10.0   mem len: 672266   epsilon: 0.01    steps: 523    lr: 1e-06     reward: 9.51\n",
      "epis: 2464   score: 13.0   mem len: 672886   epsilon: 0.01    steps: 620    lr: 1e-06     reward: 9.49\n",
      "epis: 2465   score: 10.0   mem len: 673293   epsilon: 0.01    steps: 407    lr: 1e-06     reward: 9.48\n",
      "epis: 2466   score: 7.0   mem len: 673697   epsilon: 0.01    steps: 404    lr: 1e-06     reward: 9.48\n",
      "epis: 2467   score: 13.0   mem len: 674208   epsilon: 0.01    steps: 511    lr: 1e-06     reward: 9.49\n",
      "epis: 2468   score: 10.0   mem len: 674750   epsilon: 0.01    steps: 542    lr: 1e-06     reward: 9.48\n",
      "epis: 2469   score: 14.0   mem len: 675238   epsilon: 0.01    steps: 488    lr: 1e-06     reward: 9.52\n",
      "epis: 2470   score: 6.0   mem len: 675558   epsilon: 0.01    steps: 320    lr: 1e-06     reward: 9.51\n",
      "epis: 2471   score: 5.0   mem len: 675864   epsilon: 0.01    steps: 306    lr: 1e-06     reward: 9.5\n",
      "epis: 2472   score: 8.0   mem len: 676324   epsilon: 0.01    steps: 460    lr: 1e-06     reward: 9.46\n",
      "epis: 2473   score: 10.0   mem len: 676811   epsilon: 0.01    steps: 487    lr: 1e-06     reward: 9.49\n",
      "epis: 2474   score: 18.0   mem len: 677474   epsilon: 0.01    steps: 663    lr: 1e-06     reward: 9.6\n",
      "epis: 2475   score: 8.0   mem len: 677880   epsilon: 0.01    steps: 406    lr: 1e-06     reward: 9.59\n",
      "epis: 2476   score: 13.0   mem len: 678446   epsilon: 0.01    steps: 566    lr: 1e-06     reward: 9.54\n",
      "epis: 2477   score: 13.0   mem len: 678964   epsilon: 0.01    steps: 518    lr: 1e-06     reward: 9.52\n",
      "epis: 2478   score: 9.0   mem len: 679410   epsilon: 0.01    steps: 446    lr: 1e-06     reward: 9.57\n",
      "epis: 2479   score: 13.0   mem len: 679999   epsilon: 0.01    steps: 589    lr: 1e-06     reward: 9.56\n",
      "epis: 2480   score: 9.0   mem len: 680440   epsilon: 0.01    steps: 441    lr: 1e-06     reward: 9.61\n",
      "epis: 2481   score: 9.0   mem len: 680927   epsilon: 0.01    steps: 487    lr: 1e-06     reward: 9.62\n",
      "epis: 2482   score: 10.0   mem len: 681406   epsilon: 0.01    steps: 479    lr: 1e-06     reward: 9.65\n",
      "epis: 2483   score: 11.0   mem len: 681979   epsilon: 0.01    steps: 573    lr: 1e-06     reward: 9.62\n",
      "epis: 2484   score: 13.0   mem len: 682591   epsilon: 0.01    steps: 612    lr: 1e-06     reward: 9.6\n",
      "epis: 2485   score: 6.0   mem len: 682955   epsilon: 0.01    steps: 364    lr: 1e-06     reward: 9.63\n",
      "epis: 2486   score: 5.0   mem len: 683266   epsilon: 0.01    steps: 311    lr: 1e-06     reward: 9.58\n",
      "epis: 2487   score: 5.0   mem len: 683615   epsilon: 0.01    steps: 349    lr: 1e-06     reward: 9.51\n",
      "epis: 2488   score: 15.0   mem len: 684221   epsilon: 0.01    steps: 606    lr: 1e-06     reward: 9.51\n",
      "epis: 2489   score: 12.0   mem len: 684791   epsilon: 0.01    steps: 570    lr: 1e-06     reward: 9.57\n",
      "epis: 2490   score: 11.0   mem len: 685293   epsilon: 0.01    steps: 502    lr: 1e-06     reward: 9.57\n",
      "epis: 2491   score: 10.0   mem len: 685795   epsilon: 0.01    steps: 502    lr: 1e-06     reward: 9.56\n",
      "epis: 2492   score: 12.0   mem len: 686351   epsilon: 0.01    steps: 556    lr: 1e-06     reward: 9.65\n",
      "epis: 2493   score: 10.0   mem len: 686824   epsilon: 0.01    steps: 473    lr: 1e-06     reward: 9.7\n",
      "epis: 2494   score: 10.0   mem len: 687297   epsilon: 0.01    steps: 473    lr: 1e-06     reward: 9.74\n",
      "epis: 2495   score: 15.0   mem len: 687731   epsilon: 0.01    steps: 434    lr: 1e-06     reward: 9.79\n",
      "epis: 2496   score: 10.0   mem len: 688257   epsilon: 0.01    steps: 526    lr: 1e-06     reward: 9.83\n",
      "epis: 2497   score: 10.0   mem len: 688743   epsilon: 0.01    steps: 486    lr: 1e-06     reward: 9.81\n",
      "epis: 2498   score: 4.0   mem len: 689004   epsilon: 0.01    steps: 261    lr: 1e-06     reward: 9.71\n",
      "epis: 2499   score: 5.0   mem len: 689310   epsilon: 0.01    steps: 306    lr: 1e-06     reward: 9.67\n",
      "epis: 2500   score: 15.0   mem len: 689860   epsilon: 0.01    steps: 550    lr: 1e-06     reward: 9.72\n",
      "epis: 2501   score: 10.0   mem len: 690219   epsilon: 0.01    steps: 359    lr: 1e-06     reward: 9.74\n",
      "epis: 2502   score: 15.0   mem len: 690653   epsilon: 0.01    steps: 434    lr: 1e-06     reward: 9.79\n",
      "epis: 2503   score: 7.0   mem len: 691018   epsilon: 0.01    steps: 365    lr: 1e-06     reward: 9.71\n",
      "epis: 2504   score: 9.0   mem len: 691457   epsilon: 0.01    steps: 439    lr: 1e-06     reward: 9.71\n",
      "epis: 2505   score: 7.0   mem len: 691844   epsilon: 0.01    steps: 387    lr: 1e-06     reward: 9.65\n",
      "epis: 2506   score: 6.0   mem len: 692161   epsilon: 0.01    steps: 317    lr: 1e-06     reward: 9.5\n",
      "epis: 2507   score: 12.0   mem len: 692759   epsilon: 0.01    steps: 598    lr: 1e-06     reward: 9.53\n",
      "epis: 2508   score: 11.0   mem len: 693294   epsilon: 0.01    steps: 535    lr: 1e-06     reward: 9.55\n",
      "epis: 2509   score: 6.0   mem len: 693671   epsilon: 0.01    steps: 377    lr: 1e-06     reward: 9.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2510   score: 16.0   mem len: 694267   epsilon: 0.01    steps: 596    lr: 1e-06     reward: 9.57\n",
      "epis: 2511   score: 17.0   mem len: 694802   epsilon: 0.01    steps: 535    lr: 1e-06     reward: 9.65\n",
      "epis: 2512   score: 19.0   mem len: 695535   epsilon: 0.01    steps: 733    lr: 1e-06     reward: 9.62\n",
      "epis: 2513   score: 17.0   mem len: 696112   epsilon: 0.01    steps: 577    lr: 1e-06     reward: 9.74\n",
      "epis: 2514   score: 6.0   mem len: 696451   epsilon: 0.01    steps: 339    lr: 1e-06     reward: 9.69\n",
      "epis: 2515   score: 9.0   mem len: 696917   epsilon: 0.01    steps: 466    lr: 1e-06     reward: 9.69\n",
      "epis: 2516   score: 6.0   mem len: 697236   epsilon: 0.01    steps: 319    lr: 1e-06     reward: 9.64\n",
      "epis: 2517   score: 10.0   mem len: 697722   epsilon: 0.01    steps: 486    lr: 1e-06     reward: 9.71\n",
      "epis: 2518   score: 10.0   mem len: 698226   epsilon: 0.01    steps: 504    lr: 1e-06     reward: 9.73\n",
      "epis: 2519   score: 7.0   mem len: 698576   epsilon: 0.01    steps: 350    lr: 1e-06     reward: 9.71\n",
      "epis: 2520   score: 7.0   mem len: 698966   epsilon: 0.01    steps: 390    lr: 1e-06     reward: 9.64\n",
      "epis: 2521   score: 6.0   mem len: 699306   epsilon: 0.01    steps: 340    lr: 1e-06     reward: 9.61\n",
      "epis: 2522   score: 17.0   mem len: 699828   epsilon: 0.01    steps: 522    lr: 1e-06     reward: 9.69\n",
      "epis: 2523   score: 9.0   mem len: 700248   epsilon: 0.01    steps: 420    lr: 4e-07     reward: 9.67\n",
      "epis: 2524   score: 12.0   mem len: 700749   epsilon: 0.01    steps: 501    lr: 4e-07     reward: 9.63\n",
      "epis: 2525   score: 12.0   mem len: 701310   epsilon: 0.01    steps: 561    lr: 4e-07     reward: 9.72\n",
      "epis: 2526   score: 11.0   mem len: 701843   epsilon: 0.01    steps: 533    lr: 4e-07     reward: 9.69\n",
      "epis: 2527   score: 21.0   mem len: 702535   epsilon: 0.01    steps: 692    lr: 4e-07     reward: 9.75\n",
      "epis: 2528   score: 15.0   mem len: 702969   epsilon: 0.01    steps: 434    lr: 4e-07     reward: 9.85\n",
      "epis: 2529   score: 15.0   mem len: 703403   epsilon: 0.01    steps: 434    lr: 4e-07     reward: 9.96\n",
      "epis: 2530   score: 15.0   mem len: 703837   epsilon: 0.01    steps: 434    lr: 4e-07     reward: 10.06\n",
      "epis: 2531   score: 9.0   mem len: 704296   epsilon: 0.01    steps: 459    lr: 4e-07     reward: 10.06\n",
      "epis: 2532   score: 9.0   mem len: 704753   epsilon: 0.01    steps: 457    lr: 4e-07     reward: 10.06\n",
      "epis: 2533   score: 10.0   mem len: 705237   epsilon: 0.01    steps: 484    lr: 4e-07     reward: 10.13\n",
      "epis: 2534   score: 10.0   mem len: 705723   epsilon: 0.01    steps: 486    lr: 4e-07     reward: 10.2\n",
      "epis: 2535   score: 7.0   mem len: 706111   epsilon: 0.01    steps: 388    lr: 4e-07     reward: 10.2\n",
      "epis: 2536   score: 14.0   mem len: 706599   epsilon: 0.01    steps: 488    lr: 4e-07     reward: 10.29\n",
      "epis: 2537   score: 15.0   mem len: 707033   epsilon: 0.01    steps: 434    lr: 4e-07     reward: 10.41\n",
      "epis: 2538   score: 10.0   mem len: 707533   epsilon: 0.01    steps: 500    lr: 4e-07     reward: 10.45\n",
      "epis: 2539   score: 8.0   mem len: 707958   epsilon: 0.01    steps: 425    lr: 4e-07     reward: 10.46\n",
      "epis: 2540   score: 11.0   mem len: 708463   epsilon: 0.01    steps: 505    lr: 4e-07     reward: 10.42\n",
      "epis: 2541   score: 14.0   mem len: 709098   epsilon: 0.01    steps: 635    lr: 4e-07     reward: 10.45\n",
      "epis: 2542   score: 13.0   mem len: 709712   epsilon: 0.01    steps: 614    lr: 4e-07     reward: 10.47\n",
      "epis: 2543   score: 11.0   mem len: 710121   epsilon: 0.01    steps: 409    lr: 4e-07     reward: 10.51\n",
      "epis: 2544   score: 9.0   mem len: 710593   epsilon: 0.01    steps: 472    lr: 4e-07     reward: 10.56\n",
      "epis: 2545   score: 7.0   mem len: 710961   epsilon: 0.01    steps: 368    lr: 4e-07     reward: 10.51\n",
      "epis: 2546   score: 6.0   mem len: 711283   epsilon: 0.01    steps: 322    lr: 4e-07     reward: 10.47\n",
      "epis: 2547   score: 11.0   mem len: 711798   epsilon: 0.01    steps: 515    lr: 4e-07     reward: 10.51\n",
      "epis: 2548   score: 6.0   mem len: 712120   epsilon: 0.01    steps: 322    lr: 4e-07     reward: 10.5\n",
      "epis: 2549   score: 16.0   mem len: 712614   epsilon: 0.01    steps: 494    lr: 4e-07     reward: 10.56\n",
      "epis: 2550   score: 7.0   mem len: 712983   epsilon: 0.01    steps: 369    lr: 4e-07     reward: 10.57\n",
      "epis: 2551   score: 9.0   mem len: 713411   epsilon: 0.01    steps: 428    lr: 4e-07     reward: 10.6\n",
      "epis: 2552   score: 11.0   mem len: 713942   epsilon: 0.01    steps: 531    lr: 4e-07     reward: 10.58\n",
      "epis: 2553   score: 9.0   mem len: 714414   epsilon: 0.01    steps: 472    lr: 4e-07     reward: 10.59\n",
      "epis: 2554   score: 9.0   mem len: 714886   epsilon: 0.01    steps: 472    lr: 4e-07     reward: 10.57\n",
      "epis: 2555   score: 13.0   mem len: 715492   epsilon: 0.01    steps: 606    lr: 4e-07     reward: 10.63\n",
      "epis: 2556   score: 9.0   mem len: 715959   epsilon: 0.01    steps: 467    lr: 4e-07     reward: 10.57\n",
      "epis: 2557   score: 19.0   mem len: 716628   epsilon: 0.01    steps: 669    lr: 4e-07     reward: 10.66\n",
      "epis: 2558   score: 12.0   mem len: 717230   epsilon: 0.01    steps: 602    lr: 4e-07     reward: 10.68\n",
      "epis: 2559   score: 9.0   mem len: 717700   epsilon: 0.01    steps: 470    lr: 4e-07     reward: 10.66\n",
      "epis: 2560   score: 12.0   mem len: 718290   epsilon: 0.01    steps: 590    lr: 4e-07     reward: 10.69\n",
      "epis: 2561   score: 6.0   mem len: 718612   epsilon: 0.01    steps: 322    lr: 4e-07     reward: 10.65\n",
      "epis: 2562   score: 20.0   mem len: 719197   epsilon: 0.01    steps: 585    lr: 4e-07     reward: 10.68\n",
      "epis: 2563   score: 9.0   mem len: 719669   epsilon: 0.01    steps: 472    lr: 4e-07     reward: 10.67\n",
      "epis: 2564   score: 4.0   mem len: 719930   epsilon: 0.01    steps: 261    lr: 4e-07     reward: 10.58\n",
      "epis: 2565   score: 10.0   mem len: 720406   epsilon: 0.01    steps: 476    lr: 4e-07     reward: 10.58\n",
      "epis: 2566   score: 9.0   mem len: 720870   epsilon: 0.01    steps: 464    lr: 4e-07     reward: 10.6\n",
      "epis: 2567   score: 9.0   mem len: 721351   epsilon: 0.01    steps: 481    lr: 4e-07     reward: 10.56\n",
      "epis: 2568   score: 9.0   mem len: 721823   epsilon: 0.01    steps: 472    lr: 4e-07     reward: 10.55\n",
      "epis: 2569   score: 9.0   mem len: 722295   epsilon: 0.01    steps: 472    lr: 4e-07     reward: 10.5\n",
      "epis: 2570   score: 9.0   mem len: 722749   epsilon: 0.01    steps: 454    lr: 4e-07     reward: 10.53\n",
      "epis: 2571   score: 13.0   mem len: 723232   epsilon: 0.01    steps: 483    lr: 4e-07     reward: 10.61\n",
      "epis: 2572   score: 11.0   mem len: 723782   epsilon: 0.01    steps: 550    lr: 4e-07     reward: 10.64\n",
      "epis: 2573   score: 12.0   mem len: 724331   epsilon: 0.01    steps: 549    lr: 4e-07     reward: 10.66\n",
      "epis: 2574   score: 15.0   mem len: 724832   epsilon: 0.01    steps: 501    lr: 4e-07     reward: 10.63\n",
      "epis: 2575   score: 22.0   mem len: 725492   epsilon: 0.01    steps: 660    lr: 4e-07     reward: 10.77\n",
      "epis: 2576   score: 11.0   mem len: 726029   epsilon: 0.01    steps: 537    lr: 4e-07     reward: 10.75\n",
      "epis: 2577   score: 6.0   mem len: 726353   epsilon: 0.01    steps: 324    lr: 4e-07     reward: 10.68\n",
      "epis: 2578   score: 8.0   mem len: 726775   epsilon: 0.01    steps: 422    lr: 4e-07     reward: 10.67\n",
      "epis: 2579   score: 10.0   mem len: 727182   epsilon: 0.01    steps: 407    lr: 4e-07     reward: 10.64\n",
      "epis: 2580   score: 11.0   mem len: 727736   epsilon: 0.01    steps: 554    lr: 4e-07     reward: 10.66\n",
      "epis: 2581   score: 10.0   mem len: 728212   epsilon: 0.01    steps: 476    lr: 4e-07     reward: 10.67\n",
      "epis: 2582   score: 10.0   mem len: 728699   epsilon: 0.01    steps: 487    lr: 4e-07     reward: 10.67\n",
      "epis: 2583   score: 11.0   mem len: 729218   epsilon: 0.01    steps: 519    lr: 4e-07     reward: 10.67\n",
      "epis: 2584   score: 6.0   mem len: 729556   epsilon: 0.01    steps: 338    lr: 4e-07     reward: 10.6\n",
      "epis: 2585   score: 12.0   mem len: 730112   epsilon: 0.01    steps: 556    lr: 4e-07     reward: 10.66\n",
      "epis: 2586   score: 14.0   mem len: 730626   epsilon: 0.01    steps: 514    lr: 4e-07     reward: 10.75\n",
      "epis: 2587   score: 8.0   mem len: 731041   epsilon: 0.01    steps: 415    lr: 4e-07     reward: 10.78\n",
      "epis: 2588   score: 10.0   mem len: 731528   epsilon: 0.01    steps: 487    lr: 4e-07     reward: 10.73\n",
      "epis: 2589   score: 10.0   mem len: 732001   epsilon: 0.01    steps: 473    lr: 4e-07     reward: 10.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2590   score: 11.0   mem len: 732555   epsilon: 0.01    steps: 554    lr: 4e-07     reward: 10.71\n",
      "epis: 2591   score: 9.0   mem len: 733023   epsilon: 0.01    steps: 468    lr: 4e-07     reward: 10.7\n",
      "epis: 2592   score: 10.0   mem len: 733510   epsilon: 0.01    steps: 487    lr: 4e-07     reward: 10.68\n",
      "epis: 2593   score: 5.0   mem len: 733785   epsilon: 0.01    steps: 275    lr: 4e-07     reward: 10.63\n",
      "epis: 2594   score: 7.0   mem len: 734135   epsilon: 0.01    steps: 350    lr: 4e-07     reward: 10.6\n",
      "epis: 2595   score: 5.0   mem len: 734443   epsilon: 0.01    steps: 308    lr: 4e-07     reward: 10.5\n",
      "epis: 2596   score: 9.0   mem len: 734883   epsilon: 0.01    steps: 440    lr: 4e-07     reward: 10.49\n",
      "epis: 2597   score: 10.0   mem len: 735402   epsilon: 0.01    steps: 519    lr: 4e-07     reward: 10.49\n",
      "epis: 2598   score: 9.0   mem len: 735870   epsilon: 0.01    steps: 468    lr: 4e-07     reward: 10.54\n",
      "epis: 2599   score: 10.0   mem len: 736356   epsilon: 0.01    steps: 486    lr: 4e-07     reward: 10.59\n",
      "epis: 2600   score: 7.0   mem len: 736697   epsilon: 0.01    steps: 341    lr: 4e-07     reward: 10.51\n",
      "epis: 2601   score: 6.0   mem len: 737043   epsilon: 0.01    steps: 346    lr: 4e-07     reward: 10.47\n",
      "epis: 2602   score: 9.0   mem len: 737515   epsilon: 0.01    steps: 472    lr: 4e-07     reward: 10.41\n",
      "epis: 2603   score: 9.0   mem len: 737987   epsilon: 0.01    steps: 472    lr: 4e-07     reward: 10.43\n",
      "epis: 2604   score: 16.0   mem len: 738538   epsilon: 0.01    steps: 551    lr: 4e-07     reward: 10.5\n",
      "epis: 2605   score: 9.0   mem len: 739010   epsilon: 0.01    steps: 472    lr: 4e-07     reward: 10.52\n",
      "epis: 2606   score: 10.0   mem len: 739512   epsilon: 0.01    steps: 502    lr: 4e-07     reward: 10.56\n",
      "epis: 2607   score: 6.0   mem len: 739871   epsilon: 0.01    steps: 359    lr: 4e-07     reward: 10.5\n",
      "epis: 2608   score: 8.0   mem len: 740272   epsilon: 0.01    steps: 401    lr: 4e-07     reward: 10.47\n",
      "epis: 2609   score: 8.0   mem len: 740713   epsilon: 0.01    steps: 441    lr: 4e-07     reward: 10.49\n",
      "epis: 2610   score: 15.0   mem len: 741214   epsilon: 0.01    steps: 501    lr: 4e-07     reward: 10.48\n",
      "epis: 2611   score: 7.0   mem len: 741622   epsilon: 0.01    steps: 408    lr: 4e-07     reward: 10.38\n",
      "epis: 2612   score: 7.0   mem len: 741980   epsilon: 0.01    steps: 358    lr: 4e-07     reward: 10.26\n",
      "epis: 2613   score: 10.0   mem len: 742467   epsilon: 0.01    steps: 487    lr: 4e-07     reward: 10.19\n",
      "epis: 2614   score: 15.0   mem len: 742971   epsilon: 0.01    steps: 504    lr: 4e-07     reward: 10.28\n",
      "epis: 2615   score: 11.0   mem len: 743477   epsilon: 0.01    steps: 506    lr: 4e-07     reward: 10.3\n",
      "epis: 2616   score: 9.0   mem len: 743933   epsilon: 0.01    steps: 456    lr: 4e-07     reward: 10.33\n",
      "epis: 2617   score: 6.0   mem len: 744279   epsilon: 0.01    steps: 346    lr: 4e-07     reward: 10.29\n",
      "epis: 2618   score: 11.0   mem len: 744850   epsilon: 0.01    steps: 571    lr: 4e-07     reward: 10.3\n",
      "epis: 2619   score: 8.0   mem len: 745313   epsilon: 0.01    steps: 463    lr: 4e-07     reward: 10.31\n",
      "epis: 2620   score: 7.0   mem len: 745720   epsilon: 0.01    steps: 407    lr: 4e-07     reward: 10.31\n",
      "epis: 2621   score: 9.0   mem len: 746169   epsilon: 0.01    steps: 449    lr: 4e-07     reward: 10.34\n",
      "epis: 2622   score: 6.0   mem len: 746526   epsilon: 0.01    steps: 357    lr: 4e-07     reward: 10.23\n",
      "epis: 2623   score: 6.0   mem len: 746861   epsilon: 0.01    steps: 335    lr: 4e-07     reward: 10.2\n",
      "epis: 2624   score: 10.0   mem len: 747358   epsilon: 0.01    steps: 497    lr: 4e-07     reward: 10.18\n",
      "epis: 2625   score: 9.0   mem len: 747814   epsilon: 0.01    steps: 456    lr: 4e-07     reward: 10.15\n",
      "epis: 2626   score: 8.0   mem len: 748221   epsilon: 0.01    steps: 407    lr: 4e-07     reward: 10.12\n",
      "epis: 2627   score: 9.0   mem len: 748670   epsilon: 0.01    steps: 449    lr: 4e-07     reward: 10.0\n",
      "epis: 2628   score: 8.0   mem len: 749052   epsilon: 0.01    steps: 382    lr: 4e-07     reward: 9.93\n",
      "epis: 2629   score: 9.0   mem len: 749535   epsilon: 0.01    steps: 483    lr: 4e-07     reward: 9.87\n",
      "epis: 2630   score: 7.0   mem len: 749904   epsilon: 0.01    steps: 369    lr: 4e-07     reward: 9.79\n",
      "epis: 2631   score: 8.0   mem len: 750321   epsilon: 0.01    steps: 417    lr: 4e-07     reward: 9.78\n",
      "epis: 2632   score: 5.0   mem len: 750627   epsilon: 0.01    steps: 306    lr: 4e-07     reward: 9.74\n",
      "epis: 2633   score: 10.0   mem len: 751098   epsilon: 0.01    steps: 471    lr: 4e-07     reward: 9.74\n",
      "epis: 2634   score: 11.0   mem len: 751671   epsilon: 0.01    steps: 573    lr: 4e-07     reward: 9.75\n",
      "epis: 2635   score: 12.0   mem len: 752241   epsilon: 0.01    steps: 570    lr: 4e-07     reward: 9.8\n",
      "epis: 2636   score: 8.0   mem len: 752648   epsilon: 0.01    steps: 407    lr: 4e-07     reward: 9.74\n",
      "epis: 2637   score: 7.0   mem len: 753035   epsilon: 0.01    steps: 387    lr: 4e-07     reward: 9.66\n",
      "epis: 2638   score: 14.0   mem len: 753596   epsilon: 0.01    steps: 561    lr: 4e-07     reward: 9.7\n",
      "epis: 2639   score: 8.0   mem len: 754003   epsilon: 0.01    steps: 407    lr: 4e-07     reward: 9.7\n",
      "epis: 2640   score: 8.0   mem len: 754410   epsilon: 0.01    steps: 407    lr: 4e-07     reward: 9.67\n",
      "epis: 2641   score: 11.0   mem len: 754819   epsilon: 0.01    steps: 409    lr: 4e-07     reward: 9.64\n",
      "epis: 2642   score: 10.0   mem len: 755321   epsilon: 0.01    steps: 502    lr: 4e-07     reward: 9.61\n",
      "epis: 2643   score: 13.0   mem len: 755859   epsilon: 0.01    steps: 538    lr: 4e-07     reward: 9.63\n",
      "epis: 2644   score: 10.0   mem len: 756348   epsilon: 0.01    steps: 489    lr: 4e-07     reward: 9.64\n",
      "epis: 2645   score: 10.0   mem len: 756871   epsilon: 0.01    steps: 523    lr: 4e-07     reward: 9.67\n",
      "epis: 2646   score: 11.0   mem len: 757422   epsilon: 0.01    steps: 551    lr: 4e-07     reward: 9.72\n",
      "epis: 2647   score: 11.0   mem len: 757943   epsilon: 0.01    steps: 521    lr: 4e-07     reward: 9.72\n",
      "epis: 2648   score: 6.0   mem len: 758301   epsilon: 0.01    steps: 358    lr: 4e-07     reward: 9.72\n",
      "epis: 2649   score: 6.0   mem len: 758636   epsilon: 0.01    steps: 335    lr: 4e-07     reward: 9.62\n",
      "epis: 2650   score: 5.0   mem len: 758942   epsilon: 0.01    steps: 306    lr: 4e-07     reward: 9.6\n",
      "epis: 2651   score: 11.0   mem len: 759470   epsilon: 0.01    steps: 528    lr: 4e-07     reward: 9.62\n",
      "epis: 2652   score: 12.0   mem len: 760007   epsilon: 0.01    steps: 537    lr: 4e-07     reward: 9.63\n",
      "epis: 2653   score: 10.0   mem len: 760509   epsilon: 0.01    steps: 502    lr: 4e-07     reward: 9.64\n",
      "epis: 2654   score: 9.0   mem len: 760955   epsilon: 0.01    steps: 446    lr: 4e-07     reward: 9.64\n",
      "epis: 2655   score: 14.0   mem len: 761460   epsilon: 0.01    steps: 505    lr: 4e-07     reward: 9.65\n",
      "epis: 2656   score: 6.0   mem len: 761813   epsilon: 0.01    steps: 353    lr: 4e-07     reward: 9.62\n",
      "epis: 2657   score: 10.0   mem len: 762302   epsilon: 0.01    steps: 489    lr: 4e-07     reward: 9.53\n",
      "epis: 2658   score: 6.0   mem len: 762648   epsilon: 0.01    steps: 346    lr: 4e-07     reward: 9.47\n",
      "epis: 2659   score: 6.0   mem len: 762989   epsilon: 0.01    steps: 341    lr: 4e-07     reward: 9.44\n",
      "epis: 2660   score: 5.0   mem len: 763317   epsilon: 0.01    steps: 328    lr: 4e-07     reward: 9.37\n",
      "epis: 2661   score: 5.0   mem len: 763645   epsilon: 0.01    steps: 328    lr: 4e-07     reward: 9.36\n",
      "epis: 2662   score: 10.0   mem len: 764114   epsilon: 0.01    steps: 469    lr: 4e-07     reward: 9.26\n",
      "epis: 2663   score: 6.0   mem len: 764472   epsilon: 0.01    steps: 358    lr: 4e-07     reward: 9.23\n",
      "epis: 2664   score: 8.0   mem len: 764875   epsilon: 0.01    steps: 403    lr: 4e-07     reward: 9.27\n",
      "epis: 2665   score: 8.0   mem len: 765292   epsilon: 0.01    steps: 417    lr: 4e-07     reward: 9.25\n",
      "epis: 2666   score: 7.0   mem len: 765664   epsilon: 0.01    steps: 372    lr: 4e-07     reward: 9.23\n",
      "epis: 2667   score: 9.0   mem len: 766119   epsilon: 0.01    steps: 455    lr: 4e-07     reward: 9.23\n",
      "epis: 2668   score: 7.0   mem len: 766510   epsilon: 0.01    steps: 391    lr: 4e-07     reward: 9.21\n",
      "epis: 2669   score: 10.0   mem len: 766999   epsilon: 0.01    steps: 489    lr: 4e-07     reward: 9.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2670   score: 11.0   mem len: 767572   epsilon: 0.01    steps: 573    lr: 4e-07     reward: 9.24\n",
      "epis: 2671   score: 9.0   mem len: 768044   epsilon: 0.01    steps: 472    lr: 4e-07     reward: 9.2\n",
      "epis: 2672   score: 5.0   mem len: 768372   epsilon: 0.01    steps: 328    lr: 4e-07     reward: 9.14\n",
      "epis: 2673   score: 8.0   mem len: 768772   epsilon: 0.01    steps: 400    lr: 4e-07     reward: 9.1\n",
      "epis: 2674   score: 10.0   mem len: 769291   epsilon: 0.01    steps: 519    lr: 4e-07     reward: 9.05\n",
      "epis: 2675   score: 11.0   mem len: 769838   epsilon: 0.01    steps: 547    lr: 4e-07     reward: 8.94\n",
      "epis: 2676   score: 15.0   mem len: 770438   epsilon: 0.01    steps: 600    lr: 4e-07     reward: 8.98\n",
      "epis: 2677   score: 18.0   mem len: 771068   epsilon: 0.01    steps: 630    lr: 4e-07     reward: 9.1\n",
      "epis: 2678   score: 10.0   mem len: 771532   epsilon: 0.01    steps: 464    lr: 4e-07     reward: 9.12\n",
      "epis: 2679   score: 6.0   mem len: 771856   epsilon: 0.01    steps: 324    lr: 4e-07     reward: 9.08\n",
      "epis: 2680   score: 10.0   mem len: 772375   epsilon: 0.01    steps: 519    lr: 4e-07     reward: 9.07\n",
      "epis: 2681   score: 10.0   mem len: 772894   epsilon: 0.01    steps: 519    lr: 4e-07     reward: 9.07\n",
      "epis: 2682   score: 10.0   mem len: 773413   epsilon: 0.01    steps: 519    lr: 4e-07     reward: 9.07\n",
      "epis: 2683   score: 10.0   mem len: 773932   epsilon: 0.01    steps: 519    lr: 4e-07     reward: 9.06\n",
      "epis: 2684   score: 10.0   mem len: 774451   epsilon: 0.01    steps: 519    lr: 4e-07     reward: 9.1\n",
      "epis: 2685   score: 10.0   mem len: 774929   epsilon: 0.01    steps: 478    lr: 4e-07     reward: 9.08\n",
      "epis: 2686   score: 8.0   mem len: 775346   epsilon: 0.01    steps: 417    lr: 4e-07     reward: 9.02\n",
      "epis: 2687   score: 8.0   mem len: 775769   epsilon: 0.01    steps: 423    lr: 4e-07     reward: 9.02\n",
      "epis: 2688   score: 11.0   mem len: 776314   epsilon: 0.01    steps: 545    lr: 4e-07     reward: 9.03\n",
      "epis: 2689   score: 5.0   mem len: 776645   epsilon: 0.01    steps: 331    lr: 4e-07     reward: 8.98\n",
      "epis: 2690   score: 12.0   mem len: 777220   epsilon: 0.01    steps: 575    lr: 4e-07     reward: 8.99\n",
      "epis: 2691   score: 13.0   mem len: 777805   epsilon: 0.01    steps: 585    lr: 4e-07     reward: 9.03\n",
      "epis: 2692   score: 10.0   mem len: 778292   epsilon: 0.01    steps: 487    lr: 4e-07     reward: 9.03\n",
      "epis: 2693   score: 11.0   mem len: 778682   epsilon: 0.01    steps: 390    lr: 4e-07     reward: 9.09\n",
      "epis: 2694   score: 10.0   mem len: 779201   epsilon: 0.01    steps: 519    lr: 4e-07     reward: 9.12\n",
      "epis: 2695   score: 11.0   mem len: 779741   epsilon: 0.01    steps: 540    lr: 4e-07     reward: 9.18\n",
      "epis: 2696   score: 5.0   mem len: 780049   epsilon: 0.01    steps: 308    lr: 4e-07     reward: 9.14\n",
      "epis: 2697   score: 9.0   mem len: 780521   epsilon: 0.01    steps: 472    lr: 4e-07     reward: 9.13\n",
      "epis: 2698   score: 10.0   mem len: 781040   epsilon: 0.01    steps: 519    lr: 4e-07     reward: 9.14\n",
      "epis: 2699   score: 11.0   mem len: 781580   epsilon: 0.01    steps: 540    lr: 4e-07     reward: 9.15\n",
      "epis: 2700   score: 10.0   mem len: 782041   epsilon: 0.01    steps: 461    lr: 4e-07     reward: 9.18\n",
      "epis: 2701   score: 9.0   mem len: 782487   epsilon: 0.01    steps: 446    lr: 4e-07     reward: 9.21\n",
      "epis: 2702   score: 9.0   mem len: 782938   epsilon: 0.01    steps: 451    lr: 4e-07     reward: 9.21\n",
      "epis: 2703   score: 7.0   mem len: 783332   epsilon: 0.01    steps: 394    lr: 4e-07     reward: 9.19\n",
      "epis: 2704   score: 8.0   mem len: 783755   epsilon: 0.01    steps: 423    lr: 4e-07     reward: 9.11\n",
      "epis: 2705   score: 12.0   mem len: 784311   epsilon: 0.01    steps: 556    lr: 4e-07     reward: 9.14\n",
      "epis: 2706   score: 21.0   mem len: 784964   epsilon: 0.01    steps: 653    lr: 4e-07     reward: 9.25\n",
      "epis: 2707   score: 11.0   mem len: 785537   epsilon: 0.01    steps: 573    lr: 4e-07     reward: 9.3\n",
      "epis: 2708   score: 7.0   mem len: 785887   epsilon: 0.01    steps: 350    lr: 4e-07     reward: 9.29\n",
      "epis: 2709   score: 11.0   mem len: 786441   epsilon: 0.01    steps: 554    lr: 4e-07     reward: 9.32\n",
      "epis: 2710   score: 7.0   mem len: 786827   epsilon: 0.01    steps: 386    lr: 4e-07     reward: 9.24\n",
      "epis: 2711   score: 8.0   mem len: 787224   epsilon: 0.01    steps: 397    lr: 4e-07     reward: 9.25\n",
      "epis: 2712   score: 9.0   mem len: 787670   epsilon: 0.01    steps: 446    lr: 4e-07     reward: 9.27\n",
      "epis: 2713   score: 9.0   mem len: 788141   epsilon: 0.01    steps: 471    lr: 4e-07     reward: 9.26\n",
      "epis: 2714   score: 9.0   mem len: 788613   epsilon: 0.01    steps: 472    lr: 4e-07     reward: 9.2\n",
      "epis: 2715   score: 11.0   mem len: 789163   epsilon: 0.01    steps: 550    lr: 4e-07     reward: 9.2\n",
      "epis: 2716   score: 9.0   mem len: 789598   epsilon: 0.01    steps: 435    lr: 4e-07     reward: 9.2\n",
      "epis: 2717   score: 7.0   mem len: 789991   epsilon: 0.01    steps: 393    lr: 4e-07     reward: 9.21\n",
      "epis: 2718   score: 9.0   mem len: 790486   epsilon: 0.01    steps: 495    lr: 4e-07     reward: 9.19\n",
      "epis: 2719   score: 7.0   mem len: 790836   epsilon: 0.01    steps: 350    lr: 4e-07     reward: 9.18\n",
      "epis: 2720   score: 10.0   mem len: 791355   epsilon: 0.01    steps: 519    lr: 4e-07     reward: 9.21\n",
      "epis: 2721   score: 10.0   mem len: 791857   epsilon: 0.01    steps: 502    lr: 4e-07     reward: 9.22\n",
      "epis: 2722   score: 7.0   mem len: 792248   epsilon: 0.01    steps: 391    lr: 4e-07     reward: 9.23\n",
      "epis: 2723   score: 7.0   mem len: 792598   epsilon: 0.01    steps: 350    lr: 4e-07     reward: 9.24\n",
      "epis: 2724   score: 9.0   mem len: 793053   epsilon: 0.01    steps: 455    lr: 4e-07     reward: 9.23\n",
      "epis: 2725   score: 9.0   mem len: 793520   epsilon: 0.01    steps: 467    lr: 4e-07     reward: 9.23\n",
      "epis: 2726   score: 7.0   mem len: 793870   epsilon: 0.01    steps: 350    lr: 4e-07     reward: 9.22\n",
      "epis: 2727   score: 9.0   mem len: 794341   epsilon: 0.01    steps: 471    lr: 4e-07     reward: 9.22\n",
      "epis: 2728   score: 6.0   mem len: 794685   epsilon: 0.01    steps: 344    lr: 4e-07     reward: 9.2\n",
      "epis: 2729   score: 11.0   mem len: 795258   epsilon: 0.01    steps: 573    lr: 4e-07     reward: 9.22\n",
      "epis: 2730   score: 6.0   mem len: 795582   epsilon: 0.01    steps: 324    lr: 4e-07     reward: 9.21\n",
      "epis: 2731   score: 10.0   mem len: 796053   epsilon: 0.01    steps: 471    lr: 4e-07     reward: 9.23\n",
      "epis: 2732   score: 6.0   mem len: 796377   epsilon: 0.01    steps: 324    lr: 4e-07     reward: 9.24\n",
      "epis: 2733   score: 12.0   mem len: 797012   epsilon: 0.01    steps: 635    lr: 4e-07     reward: 9.26\n",
      "epis: 2734   score: 6.0   mem len: 797336   epsilon: 0.01    steps: 324    lr: 4e-07     reward: 9.21\n",
      "epis: 2735   score: 12.0   mem len: 797911   epsilon: 0.01    steps: 575    lr: 4e-07     reward: 9.21\n",
      "epis: 2736   score: 8.0   mem len: 798331   epsilon: 0.01    steps: 420    lr: 4e-07     reward: 9.21\n",
      "epis: 2737   score: 8.0   mem len: 798751   epsilon: 0.01    steps: 420    lr: 4e-07     reward: 9.22\n",
      "epis: 2738   score: 13.0   mem len: 799358   epsilon: 0.01    steps: 607    lr: 4e-07     reward: 9.21\n",
      "epis: 2739   score: 6.0   mem len: 799684   epsilon: 0.01    steps: 326    lr: 4e-07     reward: 9.19\n",
      "epis: 2740   score: 10.0   mem len: 800188   epsilon: 0.01    steps: 504    lr: 2e-07     reward: 9.21\n",
      "epis: 2741   score: 6.0   mem len: 800514   epsilon: 0.01    steps: 326    lr: 2e-07     reward: 9.16\n",
      "epis: 2742   score: 7.0   mem len: 800864   epsilon: 0.01    steps: 350    lr: 2e-07     reward: 9.13\n",
      "epis: 2743   score: 5.0   mem len: 801174   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 9.05\n",
      "epis: 2744   score: 8.0   mem len: 801594   epsilon: 0.01    steps: 420    lr: 2e-07     reward: 9.03\n",
      "epis: 2745   score: 7.0   mem len: 801944   epsilon: 0.01    steps: 350    lr: 2e-07     reward: 9.0\n",
      "epis: 2746   score: 6.0   mem len: 802268   epsilon: 0.01    steps: 324    lr: 2e-07     reward: 8.95\n",
      "epis: 2747   score: 6.0   mem len: 802592   epsilon: 0.01    steps: 324    lr: 2e-07     reward: 8.9\n",
      "epis: 2748   score: 5.0   mem len: 802867   epsilon: 0.01    steps: 275    lr: 2e-07     reward: 8.89\n",
      "epis: 2749   score: 5.0   mem len: 803142   epsilon: 0.01    steps: 275    lr: 2e-07     reward: 8.88\n",
      "epis: 2750   score: 11.0   mem len: 803675   epsilon: 0.01    steps: 533    lr: 2e-07     reward: 8.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2751   score: 9.0   mem len: 804146   epsilon: 0.01    steps: 471    lr: 2e-07     reward: 8.92\n",
      "epis: 2752   score: 9.0   mem len: 804618   epsilon: 0.01    steps: 472    lr: 2e-07     reward: 8.89\n",
      "epis: 2753   score: 10.0   mem len: 805122   epsilon: 0.01    steps: 504    lr: 2e-07     reward: 8.89\n",
      "epis: 2754   score: 10.0   mem len: 805626   epsilon: 0.01    steps: 504    lr: 2e-07     reward: 8.9\n",
      "epis: 2755   score: 10.0   mem len: 806130   epsilon: 0.01    steps: 504    lr: 2e-07     reward: 8.86\n",
      "epis: 2756   score: 6.0   mem len: 806454   epsilon: 0.01    steps: 324    lr: 2e-07     reward: 8.86\n",
      "epis: 2757   score: 5.0   mem len: 806729   epsilon: 0.01    steps: 275    lr: 2e-07     reward: 8.81\n",
      "epis: 2758   score: 5.0   mem len: 807004   epsilon: 0.01    steps: 275    lr: 2e-07     reward: 8.8\n",
      "epis: 2759   score: 10.0   mem len: 807498   epsilon: 0.01    steps: 494    lr: 2e-07     reward: 8.84\n",
      "epis: 2760   score: 8.0   mem len: 807908   epsilon: 0.01    steps: 410    lr: 2e-07     reward: 8.87\n",
      "epis: 2761   score: 14.0   mem len: 808531   epsilon: 0.01    steps: 623    lr: 2e-07     reward: 8.96\n",
      "epis: 2762   score: 5.0   mem len: 808806   epsilon: 0.01    steps: 275    lr: 2e-07     reward: 8.91\n",
      "epis: 2763   score: 6.0   mem len: 809132   epsilon: 0.01    steps: 326    lr: 2e-07     reward: 8.91\n",
      "epis: 2764   score: 7.0   mem len: 809482   epsilon: 0.01    steps: 350    lr: 2e-07     reward: 8.9\n",
      "epis: 2765   score: 7.0   mem len: 809832   epsilon: 0.01    steps: 350    lr: 2e-07     reward: 8.89\n",
      "epis: 2766   score: 9.0   mem len: 810345   epsilon: 0.01    steps: 513    lr: 2e-07     reward: 8.91\n",
      "epis: 2767   score: 7.0   mem len: 810697   epsilon: 0.01    steps: 352    lr: 2e-07     reward: 8.89\n",
      "epis: 2768   score: 11.0   mem len: 811207   epsilon: 0.01    steps: 510    lr: 2e-07     reward: 8.93\n",
      "epis: 2769   score: 13.0   mem len: 811828   epsilon: 0.01    steps: 621    lr: 2e-07     reward: 8.96\n",
      "epis: 2770   score: 7.0   mem len: 812178   epsilon: 0.01    steps: 350    lr: 2e-07     reward: 8.92\n",
      "epis: 2771   score: 8.0   mem len: 812624   epsilon: 0.01    steps: 446    lr: 2e-07     reward: 8.91\n",
      "epis: 2772   score: 8.0   mem len: 813070   epsilon: 0.01    steps: 446    lr: 2e-07     reward: 8.94\n",
      "epis: 2773   score: 8.0   mem len: 813516   epsilon: 0.01    steps: 446    lr: 2e-07     reward: 8.94\n",
      "epis: 2774   score: 10.0   mem len: 814020   epsilon: 0.01    steps: 504    lr: 2e-07     reward: 8.94\n",
      "epis: 2775   score: 7.0   mem len: 814370   epsilon: 0.01    steps: 350    lr: 2e-07     reward: 8.9\n",
      "epis: 2776   score: 5.0   mem len: 814678   epsilon: 0.01    steps: 308    lr: 2e-07     reward: 8.8\n",
      "epis: 2777   score: 10.0   mem len: 815180   epsilon: 0.01    steps: 502    lr: 2e-07     reward: 8.72\n",
      "epis: 2778   score: 5.0   mem len: 815490   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 8.67\n",
      "epis: 2779   score: 9.0   mem len: 815928   epsilon: 0.01    steps: 438    lr: 2e-07     reward: 8.7\n",
      "epis: 2780   score: 11.0   mem len: 816478   epsilon: 0.01    steps: 550    lr: 2e-07     reward: 8.71\n",
      "epis: 2781   score: 6.0   mem len: 816802   epsilon: 0.01    steps: 324    lr: 2e-07     reward: 8.67\n",
      "epis: 2782   score: 9.0   mem len: 817275   epsilon: 0.01    steps: 473    lr: 2e-07     reward: 8.66\n",
      "epis: 2783   score: 5.0   mem len: 817585   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 8.61\n",
      "epis: 2784   score: 5.0   mem len: 817895   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 8.56\n",
      "epis: 2785   score: 5.0   mem len: 818185   epsilon: 0.01    steps: 290    lr: 2e-07     reward: 8.51\n",
      "epis: 2786   score: 5.0   mem len: 818477   epsilon: 0.01    steps: 292    lr: 2e-07     reward: 8.48\n",
      "epis: 2787   score: 5.0   mem len: 818769   epsilon: 0.01    steps: 292    lr: 2e-07     reward: 8.45\n",
      "epis: 2788   score: 5.0   mem len: 819079   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 8.39\n",
      "epis: 2789   score: 9.0   mem len: 819517   epsilon: 0.01    steps: 438    lr: 2e-07     reward: 8.43\n",
      "epis: 2790   score: 5.0   mem len: 819827   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 8.36\n",
      "epis: 2791   score: 10.0   mem len: 820329   epsilon: 0.01    steps: 502    lr: 2e-07     reward: 8.33\n",
      "epis: 2792   score: 6.0   mem len: 820639   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 8.29\n",
      "epis: 2793   score: 9.0   mem len: 821060   epsilon: 0.01    steps: 421    lr: 2e-07     reward: 8.27\n",
      "epis: 2794   score: 9.0   mem len: 821531   epsilon: 0.01    steps: 471    lr: 2e-07     reward: 8.26\n",
      "epis: 2795   score: 9.0   mem len: 821990   epsilon: 0.01    steps: 459    lr: 2e-07     reward: 8.24\n",
      "epis: 2796   score: 11.0   mem len: 822389   epsilon: 0.01    steps: 399    lr: 2e-07     reward: 8.3\n",
      "epis: 2797   score: 6.0   mem len: 822731   epsilon: 0.01    steps: 342    lr: 2e-07     reward: 8.27\n",
      "epis: 2798   score: 6.0   mem len: 823073   epsilon: 0.01    steps: 342    lr: 2e-07     reward: 8.23\n",
      "epis: 2799   score: 7.0   mem len: 823465   epsilon: 0.01    steps: 392    lr: 2e-07     reward: 8.19\n",
      "epis: 2800   score: 10.0   mem len: 823969   epsilon: 0.01    steps: 504    lr: 2e-07     reward: 8.19\n",
      "epis: 2801   score: 8.0   mem len: 824389   epsilon: 0.01    steps: 420    lr: 2e-07     reward: 8.18\n",
      "epis: 2802   score: 5.0   mem len: 824664   epsilon: 0.01    steps: 275    lr: 2e-07     reward: 8.14\n",
      "epis: 2803   score: 9.0   mem len: 825136   epsilon: 0.01    steps: 472    lr: 2e-07     reward: 8.16\n",
      "epis: 2804   score: 9.0   mem len: 825603   epsilon: 0.01    steps: 467    lr: 2e-07     reward: 8.17\n",
      "epis: 2805   score: 7.0   mem len: 825996   epsilon: 0.01    steps: 393    lr: 2e-07     reward: 8.12\n",
      "epis: 2806   score: 10.0   mem len: 826519   epsilon: 0.01    steps: 523    lr: 2e-07     reward: 8.01\n",
      "epis: 2807   score: 10.0   mem len: 827023   epsilon: 0.01    steps: 504    lr: 2e-07     reward: 8.0\n",
      "epis: 2808   score: 5.0   mem len: 827333   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 7.98\n",
      "epis: 2809   score: 10.0   mem len: 827802   epsilon: 0.01    steps: 469    lr: 2e-07     reward: 7.97\n",
      "epis: 2810   score: 5.0   mem len: 828112   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 7.95\n",
      "epis: 2811   score: 5.0   mem len: 828422   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 7.92\n",
      "epis: 2812   score: 6.0   mem len: 828750   epsilon: 0.01    steps: 328    lr: 2e-07     reward: 7.89\n",
      "epis: 2813   score: 5.0   mem len: 829060   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 7.85\n",
      "epis: 2814   score: 5.0   mem len: 829370   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 7.81\n",
      "epis: 2815   score: 5.0   mem len: 829680   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 7.75\n",
      "epis: 2816   score: 5.0   mem len: 829990   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 7.71\n",
      "epis: 2817   score: 12.0   mem len: 830426   epsilon: 0.01    steps: 436    lr: 2e-07     reward: 7.76\n",
      "epis: 2818   score: 8.0   mem len: 830847   epsilon: 0.01    steps: 421    lr: 2e-07     reward: 7.75\n",
      "epis: 2819   score: 13.0   mem len: 831284   epsilon: 0.01    steps: 437    lr: 2e-07     reward: 7.81\n",
      "epis: 2820   score: 9.0   mem len: 831756   epsilon: 0.01    steps: 472    lr: 2e-07     reward: 7.8\n",
      "epis: 2821   score: 9.0   mem len: 832227   epsilon: 0.01    steps: 471    lr: 2e-07     reward: 7.79\n",
      "epis: 2822   score: 8.0   mem len: 832677   epsilon: 0.01    steps: 450    lr: 2e-07     reward: 7.8\n",
      "epis: 2823   score: 9.0   mem len: 833148   epsilon: 0.01    steps: 471    lr: 2e-07     reward: 7.82\n",
      "epis: 2824   score: 6.0   mem len: 833474   epsilon: 0.01    steps: 326    lr: 2e-07     reward: 7.79\n",
      "epis: 2825   score: 10.0   mem len: 833996   epsilon: 0.01    steps: 522    lr: 2e-07     reward: 7.8\n",
      "epis: 2826   score: 6.0   mem len: 834338   epsilon: 0.01    steps: 342    lr: 2e-07     reward: 7.79\n",
      "epis: 2827   score: 7.0   mem len: 834688   epsilon: 0.01    steps: 350    lr: 2e-07     reward: 7.77\n",
      "epis: 2828   score: 5.0   mem len: 834963   epsilon: 0.01    steps: 275    lr: 2e-07     reward: 7.76\n",
      "epis: 2829   score: 5.0   mem len: 835238   epsilon: 0.01    steps: 275    lr: 2e-07     reward: 7.7\n",
      "epis: 2830   score: 13.0   mem len: 835729   epsilon: 0.01    steps: 491    lr: 2e-07     reward: 7.77\n",
      "epis: 2831   score: 5.0   mem len: 836021   epsilon: 0.01    steps: 292    lr: 2e-07     reward: 7.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2832   score: 7.0   mem len: 836414   epsilon: 0.01    steps: 393    lr: 2e-07     reward: 7.73\n",
      "epis: 2833   score: 10.0   mem len: 836914   epsilon: 0.01    steps: 500    lr: 2e-07     reward: 7.71\n",
      "epis: 2834   score: 9.0   mem len: 837311   epsilon: 0.01    steps: 397    lr: 2e-07     reward: 7.74\n",
      "epis: 2835   score: 12.0   mem len: 837872   epsilon: 0.01    steps: 561    lr: 2e-07     reward: 7.74\n",
      "epis: 2836   score: 10.0   mem len: 838335   epsilon: 0.01    steps: 463    lr: 2e-07     reward: 7.76\n",
      "epis: 2837   score: 8.0   mem len: 838742   epsilon: 0.01    steps: 407    lr: 2e-07     reward: 7.76\n",
      "epis: 2838   score: 11.0   mem len: 839262   epsilon: 0.01    steps: 520    lr: 2e-07     reward: 7.74\n",
      "epis: 2839   score: 8.0   mem len: 839691   epsilon: 0.01    steps: 429    lr: 2e-07     reward: 7.76\n",
      "epis: 2840   score: 9.0   mem len: 840152   epsilon: 0.01    steps: 461    lr: 2e-07     reward: 7.75\n",
      "epis: 2841   score: 11.0   mem len: 840672   epsilon: 0.01    steps: 520    lr: 2e-07     reward: 7.8\n",
      "epis: 2842   score: 16.0   mem len: 841223   epsilon: 0.01    steps: 551    lr: 2e-07     reward: 7.89\n",
      "epis: 2843   score: 9.0   mem len: 841695   epsilon: 0.01    steps: 472    lr: 2e-07     reward: 7.93\n",
      "epis: 2844   score: 10.0   mem len: 842218   epsilon: 0.01    steps: 523    lr: 2e-07     reward: 7.95\n",
      "epis: 2845   score: 12.0   mem len: 842771   epsilon: 0.01    steps: 553    lr: 2e-07     reward: 8.0\n",
      "epis: 2846   score: 10.0   mem len: 843290   epsilon: 0.01    steps: 519    lr: 2e-07     reward: 8.04\n",
      "epis: 2847   score: 10.0   mem len: 843809   epsilon: 0.01    steps: 519    lr: 2e-07     reward: 8.08\n",
      "epis: 2848   score: 9.0   mem len: 844263   epsilon: 0.01    steps: 454    lr: 2e-07     reward: 8.12\n",
      "epis: 2849   score: 10.0   mem len: 844782   epsilon: 0.01    steps: 519    lr: 2e-07     reward: 8.17\n",
      "epis: 2850   score: 7.0   mem len: 845123   epsilon: 0.01    steps: 341    lr: 2e-07     reward: 8.13\n",
      "epis: 2851   score: 6.0   mem len: 845465   epsilon: 0.01    steps: 342    lr: 2e-07     reward: 8.1\n",
      "epis: 2852   score: 7.0   mem len: 845875   epsilon: 0.01    steps: 410    lr: 2e-07     reward: 8.08\n",
      "epis: 2853   score: 12.0   mem len: 846311   epsilon: 0.01    steps: 436    lr: 2e-07     reward: 8.1\n",
      "epis: 2854   score: 7.0   mem len: 846702   epsilon: 0.01    steps: 391    lr: 2e-07     reward: 8.07\n",
      "epis: 2855   score: 11.0   mem len: 847235   epsilon: 0.01    steps: 533    lr: 2e-07     reward: 8.08\n",
      "epis: 2856   score: 8.0   mem len: 847681   epsilon: 0.01    steps: 446    lr: 2e-07     reward: 8.1\n",
      "epis: 2857   score: 6.0   mem len: 848023   epsilon: 0.01    steps: 342    lr: 2e-07     reward: 8.11\n",
      "epis: 2858   score: 10.0   mem len: 848542   epsilon: 0.01    steps: 519    lr: 2e-07     reward: 8.16\n",
      "epis: 2859   score: 9.0   mem len: 848996   epsilon: 0.01    steps: 454    lr: 2e-07     reward: 8.15\n",
      "epis: 2860   score: 9.0   mem len: 849452   epsilon: 0.01    steps: 456    lr: 2e-07     reward: 8.16\n",
      "epis: 2861   score: 14.0   mem len: 850104   epsilon: 0.01    steps: 652    lr: 2e-07     reward: 8.16\n",
      "epis: 2862   score: 11.0   mem len: 850640   epsilon: 0.01    steps: 536    lr: 2e-07     reward: 8.22\n",
      "epis: 2863   score: 10.0   mem len: 851126   epsilon: 0.01    steps: 486    lr: 2e-07     reward: 8.26\n",
      "epis: 2864   score: 11.0   mem len: 851661   epsilon: 0.01    steps: 535    lr: 2e-07     reward: 8.3\n",
      "epis: 2865   score: 11.0   mem len: 852215   epsilon: 0.01    steps: 554    lr: 2e-07     reward: 8.34\n",
      "epis: 2866   score: 13.0   mem len: 852835   epsilon: 0.01    steps: 620    lr: 2e-07     reward: 8.38\n",
      "epis: 2867   score: 9.0   mem len: 853290   epsilon: 0.01    steps: 455    lr: 2e-07     reward: 8.4\n",
      "epis: 2868   score: 7.0   mem len: 853682   epsilon: 0.01    steps: 392    lr: 2e-07     reward: 8.36\n",
      "epis: 2869   score: 9.0   mem len: 854149   epsilon: 0.01    steps: 467    lr: 2e-07     reward: 8.32\n",
      "epis: 2870   score: 10.0   mem len: 854653   epsilon: 0.01    steps: 504    lr: 2e-07     reward: 8.35\n",
      "epis: 2871   score: 12.0   mem len: 855223   epsilon: 0.01    steps: 570    lr: 2e-07     reward: 8.39\n",
      "epis: 2872   score: 5.0   mem len: 855533   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 8.36\n",
      "epis: 2873   score: 5.0   mem len: 855843   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 8.33\n",
      "epis: 2874   score: 6.0   mem len: 856166   epsilon: 0.01    steps: 323    lr: 2e-07     reward: 8.29\n",
      "epis: 2875   score: 10.0   mem len: 856648   epsilon: 0.01    steps: 482    lr: 2e-07     reward: 8.32\n",
      "epis: 2876   score: 10.0   mem len: 857152   epsilon: 0.01    steps: 504    lr: 2e-07     reward: 8.37\n",
      "epis: 2877   score: 8.0   mem len: 857598   epsilon: 0.01    steps: 446    lr: 2e-07     reward: 8.35\n",
      "epis: 2878   score: 12.0   mem len: 858173   epsilon: 0.01    steps: 575    lr: 2e-07     reward: 8.42\n",
      "epis: 2879   score: 5.0   mem len: 858465   epsilon: 0.01    steps: 292    lr: 2e-07     reward: 8.38\n",
      "epis: 2880   score: 5.0   mem len: 858775   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 8.32\n",
      "epis: 2881   score: 6.0   mem len: 859119   epsilon: 0.01    steps: 344    lr: 2e-07     reward: 8.32\n",
      "epis: 2882   score: 7.0   mem len: 859547   epsilon: 0.01    steps: 428    lr: 2e-07     reward: 8.3\n",
      "epis: 2883   score: 10.0   mem len: 860070   epsilon: 0.01    steps: 523    lr: 2e-07     reward: 8.35\n",
      "epis: 2884   score: 9.0   mem len: 860583   epsilon: 0.01    steps: 513    lr: 2e-07     reward: 8.39\n",
      "epis: 2885   score: 10.0   mem len: 861065   epsilon: 0.01    steps: 482    lr: 2e-07     reward: 8.44\n",
      "epis: 2886   score: 10.0   mem len: 861565   epsilon: 0.01    steps: 500    lr: 2e-07     reward: 8.49\n",
      "epis: 2887   score: 5.0   mem len: 861875   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 8.49\n",
      "epis: 2888   score: 5.0   mem len: 862185   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 8.49\n",
      "epis: 2889   score: 12.0   mem len: 862715   epsilon: 0.01    steps: 530    lr: 2e-07     reward: 8.52\n",
      "epis: 2890   score: 7.0   mem len: 863107   epsilon: 0.01    steps: 392    lr: 2e-07     reward: 8.54\n",
      "epis: 2891   score: 11.0   mem len: 863506   epsilon: 0.01    steps: 399    lr: 2e-07     reward: 8.55\n",
      "epis: 2892   score: 6.0   mem len: 863848   epsilon: 0.01    steps: 342    lr: 2e-07     reward: 8.55\n",
      "epis: 2893   score: 7.0   mem len: 864261   epsilon: 0.01    steps: 413    lr: 2e-07     reward: 8.53\n",
      "epis: 2894   score: 9.0   mem len: 864687   epsilon: 0.01    steps: 426    lr: 2e-07     reward: 8.53\n",
      "epis: 2895   score: 10.0   mem len: 865206   epsilon: 0.01    steps: 519    lr: 2e-07     reward: 8.54\n",
      "epis: 2896   score: 9.0   mem len: 865646   epsilon: 0.01    steps: 440    lr: 2e-07     reward: 8.52\n",
      "epis: 2897   score: 12.0   mem len: 866225   epsilon: 0.01    steps: 579    lr: 2e-07     reward: 8.58\n",
      "epis: 2898   score: 8.0   mem len: 866662   epsilon: 0.01    steps: 437    lr: 2e-07     reward: 8.6\n",
      "epis: 2899   score: 6.0   mem len: 867002   epsilon: 0.01    steps: 340    lr: 2e-07     reward: 8.59\n",
      "epis: 2900   score: 8.0   mem len: 867425   epsilon: 0.01    steps: 423    lr: 2e-07     reward: 8.57\n",
      "epis: 2901   score: 13.0   mem len: 867862   epsilon: 0.01    steps: 437    lr: 2e-07     reward: 8.62\n",
      "epis: 2902   score: 8.0   mem len: 868285   epsilon: 0.01    steps: 423    lr: 2e-07     reward: 8.65\n",
      "epis: 2903   score: 11.0   mem len: 868805   epsilon: 0.01    steps: 520    lr: 2e-07     reward: 8.67\n",
      "epis: 2904   score: 8.0   mem len: 869238   epsilon: 0.01    steps: 433    lr: 2e-07     reward: 8.66\n",
      "epis: 2905   score: 7.0   mem len: 869667   epsilon: 0.01    steps: 429    lr: 2e-07     reward: 8.66\n",
      "epis: 2906   score: 7.0   mem len: 870043   epsilon: 0.01    steps: 376    lr: 2e-07     reward: 8.63\n",
      "epis: 2907   score: 9.0   mem len: 870497   epsilon: 0.01    steps: 454    lr: 2e-07     reward: 8.62\n",
      "epis: 2908   score: 10.0   mem len: 870999   epsilon: 0.01    steps: 502    lr: 2e-07     reward: 8.67\n",
      "epis: 2909   score: 9.0   mem len: 871469   epsilon: 0.01    steps: 470    lr: 2e-07     reward: 8.66\n",
      "epis: 2910   score: 6.0   mem len: 871779   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 8.67\n",
      "epis: 2911   score: 9.0   mem len: 872251   epsilon: 0.01    steps: 472    lr: 2e-07     reward: 8.71\n",
      "epis: 2912   score: 11.0   mem len: 872771   epsilon: 0.01    steps: 520    lr: 2e-07     reward: 8.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2913   score: 15.0   mem len: 873303   epsilon: 0.01    steps: 532    lr: 2e-07     reward: 8.86\n",
      "epis: 2914   score: 10.0   mem len: 873792   epsilon: 0.01    steps: 489    lr: 2e-07     reward: 8.91\n",
      "epis: 2915   score: 16.0   mem len: 874343   epsilon: 0.01    steps: 551    lr: 2e-07     reward: 9.02\n",
      "epis: 2916   score: 11.0   mem len: 874843   epsilon: 0.01    steps: 500    lr: 2e-07     reward: 9.08\n",
      "epis: 2917   score: 16.0   mem len: 875394   epsilon: 0.01    steps: 551    lr: 2e-07     reward: 9.12\n",
      "epis: 2918   score: 10.0   mem len: 875852   epsilon: 0.01    steps: 458    lr: 2e-07     reward: 9.14\n",
      "epis: 2919   score: 14.0   mem len: 876467   epsilon: 0.01    steps: 615    lr: 2e-07     reward: 9.15\n",
      "epis: 2920   score: 9.0   mem len: 876913   epsilon: 0.01    steps: 446    lr: 2e-07     reward: 9.15\n",
      "epis: 2921   score: 8.0   mem len: 877359   epsilon: 0.01    steps: 446    lr: 2e-07     reward: 9.14\n",
      "epis: 2922   score: 11.0   mem len: 877903   epsilon: 0.01    steps: 544    lr: 2e-07     reward: 9.17\n",
      "epis: 2923   score: 10.0   mem len: 878361   epsilon: 0.01    steps: 458    lr: 2e-07     reward: 9.18\n",
      "epis: 2924   score: 14.0   mem len: 878876   epsilon: 0.01    steps: 515    lr: 2e-07     reward: 9.26\n",
      "epis: 2925   score: 15.0   mem len: 879408   epsilon: 0.01    steps: 532    lr: 2e-07     reward: 9.31\n",
      "epis: 2926   score: 9.0   mem len: 879891   epsilon: 0.01    steps: 483    lr: 2e-07     reward: 9.34\n",
      "epis: 2927   score: 10.0   mem len: 880380   epsilon: 0.01    steps: 489    lr: 2e-07     reward: 9.37\n",
      "epis: 2928   score: 10.0   mem len: 880869   epsilon: 0.01    steps: 489    lr: 2e-07     reward: 9.42\n",
      "epis: 2929   score: 10.0   mem len: 881358   epsilon: 0.01    steps: 489    lr: 2e-07     reward: 9.47\n",
      "epis: 2930   score: 14.0   mem len: 881860   epsilon: 0.01    steps: 502    lr: 2e-07     reward: 9.48\n",
      "epis: 2931   score: 8.0   mem len: 882320   epsilon: 0.01    steps: 460    lr: 2e-07     reward: 9.51\n",
      "epis: 2932   score: 9.0   mem len: 882766   epsilon: 0.01    steps: 446    lr: 2e-07     reward: 9.53\n",
      "epis: 2933   score: 7.0   mem len: 883159   epsilon: 0.01    steps: 393    lr: 2e-07     reward: 9.5\n",
      "epis: 2934   score: 9.0   mem len: 883613   epsilon: 0.01    steps: 454    lr: 2e-07     reward: 9.5\n",
      "epis: 2935   score: 7.0   mem len: 884021   epsilon: 0.01    steps: 408    lr: 2e-07     reward: 9.45\n",
      "epis: 2936   score: 11.0   mem len: 884541   epsilon: 0.01    steps: 520    lr: 2e-07     reward: 9.46\n",
      "epis: 2937   score: 9.0   mem len: 884994   epsilon: 0.01    steps: 453    lr: 2e-07     reward: 9.47\n",
      "epis: 2938   score: 9.0   mem len: 885448   epsilon: 0.01    steps: 454    lr: 2e-07     reward: 9.45\n",
      "epis: 2939   score: 21.0   mem len: 886139   epsilon: 0.01    steps: 691    lr: 2e-07     reward: 9.58\n",
      "epis: 2940   score: 7.0   mem len: 886489   epsilon: 0.01    steps: 350    lr: 2e-07     reward: 9.56\n",
      "epis: 2941   score: 8.0   mem len: 886908   epsilon: 0.01    steps: 419    lr: 2e-07     reward: 9.53\n",
      "epis: 2942   score: 6.0   mem len: 887232   epsilon: 0.01    steps: 324    lr: 2e-07     reward: 9.43\n",
      "epis: 2943   score: 10.0   mem len: 887719   epsilon: 0.01    steps: 487    lr: 2e-07     reward: 9.44\n",
      "epis: 2944   score: 12.0   mem len: 888297   epsilon: 0.01    steps: 578    lr: 2e-07     reward: 9.46\n",
      "epis: 2945   score: 11.0   mem len: 888799   epsilon: 0.01    steps: 502    lr: 2e-07     reward: 9.45\n",
      "epis: 2946   score: 12.0   mem len: 889388   epsilon: 0.01    steps: 589    lr: 2e-07     reward: 9.47\n",
      "epis: 2947   score: 13.0   mem len: 889994   epsilon: 0.01    steps: 606    lr: 2e-07     reward: 9.5\n",
      "epis: 2948   score: 10.0   mem len: 890498   epsilon: 0.01    steps: 504    lr: 2e-07     reward: 9.51\n",
      "epis: 2949   score: 17.0   mem len: 891111   epsilon: 0.01    steps: 613    lr: 2e-07     reward: 9.58\n",
      "epis: 2950   score: 9.0   mem len: 891583   epsilon: 0.01    steps: 472    lr: 2e-07     reward: 9.6\n",
      "epis: 2951   score: 12.0   mem len: 892136   epsilon: 0.01    steps: 553    lr: 2e-07     reward: 9.66\n",
      "epis: 2952   score: 10.0   mem len: 892640   epsilon: 0.01    steps: 504    lr: 2e-07     reward: 9.69\n",
      "epis: 2953   score: 10.0   mem len: 893122   epsilon: 0.01    steps: 482    lr: 2e-07     reward: 9.67\n",
      "epis: 2954   score: 11.0   mem len: 893655   epsilon: 0.01    steps: 533    lr: 2e-07     reward: 9.71\n",
      "epis: 2955   score: 10.0   mem len: 894159   epsilon: 0.01    steps: 504    lr: 2e-07     reward: 9.7\n",
      "epis: 2956   score: 13.0   mem len: 894779   epsilon: 0.01    steps: 620    lr: 2e-07     reward: 9.75\n",
      "epis: 2957   score: 10.0   mem len: 895296   epsilon: 0.01    steps: 517    lr: 2e-07     reward: 9.79\n",
      "epis: 2958   score: 5.0   mem len: 895606   epsilon: 0.01    steps: 310    lr: 2e-07     reward: 9.74\n",
      "epis: 2959   score: 9.0   mem len: 896101   epsilon: 0.01    steps: 495    lr: 2e-07     reward: 9.74\n",
      "epis: 2960   score: 4.0   mem len: 896362   epsilon: 0.01    steps: 261    lr: 2e-07     reward: 9.69\n",
      "epis: 2961   score: 4.0   mem len: 896623   epsilon: 0.01    steps: 261    lr: 2e-07     reward: 9.59\n",
      "epis: 2962   score: 5.0   mem len: 896915   epsilon: 0.01    steps: 292    lr: 2e-07     reward: 9.53\n",
      "epis: 2963   score: 11.0   mem len: 897391   epsilon: 0.01    steps: 476    lr: 2e-07     reward: 9.54\n",
      "epis: 2964   score: 8.0   mem len: 897818   epsilon: 0.01    steps: 427    lr: 2e-07     reward: 9.51\n",
      "epis: 2965   score: 7.0   mem len: 898211   epsilon: 0.01    steps: 393    lr: 2e-07     reward: 9.47\n",
      "epis: 2966   score: 11.0   mem len: 898761   epsilon: 0.01    steps: 550    lr: 2e-07     reward: 9.45\n",
      "epis: 2967   score: 11.0   mem len: 899311   epsilon: 0.01    steps: 550    lr: 2e-07     reward: 9.47\n",
      "epis: 2968   score: 13.0   mem len: 899917   epsilon: 0.01    steps: 606    lr: 2e-07     reward: 9.53\n",
      "epis: 2969   score: 13.0   mem len: 900354   epsilon: 0.01    steps: 437    lr: 1e-07     reward: 9.57\n",
      "epis: 2970   score: 13.0   mem len: 900791   epsilon: 0.01    steps: 437    lr: 1e-07     reward: 9.6\n",
      "epis: 2971   score: 13.0   mem len: 901397   epsilon: 0.01    steps: 606    lr: 1e-07     reward: 9.61\n",
      "epis: 2972   score: 13.0   mem len: 902003   epsilon: 0.01    steps: 606    lr: 1e-07     reward: 9.69\n",
      "epis: 2973   score: 11.0   mem len: 902536   epsilon: 0.01    steps: 533    lr: 1e-07     reward: 9.75\n",
      "epis: 2974   score: 9.0   mem len: 903049   epsilon: 0.01    steps: 513    lr: 1e-07     reward: 9.78\n",
      "epis: 2975   score: 10.0   mem len: 903568   epsilon: 0.01    steps: 519    lr: 1e-07     reward: 9.78\n",
      "epis: 2976   score: 9.0   mem len: 904067   epsilon: 0.01    steps: 499    lr: 1e-07     reward: 9.77\n",
      "epis: 2977   score: 10.0   mem len: 904549   epsilon: 0.01    steps: 482    lr: 1e-07     reward: 9.79\n",
      "epis: 2978   score: 11.0   mem len: 905082   epsilon: 0.01    steps: 533    lr: 1e-07     reward: 9.78\n",
      "epis: 2979   score: 10.0   mem len: 905564   epsilon: 0.01    steps: 482    lr: 1e-07     reward: 9.83\n",
      "epis: 2980   score: 10.0   mem len: 906104   epsilon: 0.01    steps: 540    lr: 1e-07     reward: 9.88\n",
      "epis: 2981   score: 11.0   mem len: 906637   epsilon: 0.01    steps: 533    lr: 1e-07     reward: 9.93\n",
      "epis: 2982   score: 9.0   mem len: 907150   epsilon: 0.01    steps: 513    lr: 1e-07     reward: 9.95\n",
      "epis: 2983   score: 7.0   mem len: 907558   epsilon: 0.01    steps: 408    lr: 1e-07     reward: 9.92\n",
      "epis: 2984   score: 10.0   mem len: 908081   epsilon: 0.01    steps: 523    lr: 1e-07     reward: 9.93\n",
      "epis: 2985   score: 6.0   mem len: 908423   epsilon: 0.01    steps: 342    lr: 1e-07     reward: 9.89\n",
      "epis: 2986   score: 13.0   mem len: 909039   epsilon: 0.01    steps: 616    lr: 1e-07     reward: 9.92\n",
      "epis: 2987   score: 8.0   mem len: 909458   epsilon: 0.01    steps: 419    lr: 1e-07     reward: 9.95\n",
      "epis: 2988   score: 10.0   mem len: 909940   epsilon: 0.01    steps: 482    lr: 1e-07     reward: 10.0\n",
      "epis: 2989   score: 10.0   mem len: 910433   epsilon: 0.01    steps: 493    lr: 1e-07     reward: 9.98\n",
      "epis: 2990   score: 10.0   mem len: 910891   epsilon: 0.01    steps: 458    lr: 1e-07     reward: 10.01\n",
      "epis: 2991   score: 10.0   mem len: 911349   epsilon: 0.01    steps: 458    lr: 1e-07     reward: 10.0\n",
      "epis: 2992   score: 12.0   mem len: 911904   epsilon: 0.01    steps: 555    lr: 1e-07     reward: 10.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2993   score: 9.0   mem len: 912358   epsilon: 0.01    steps: 454    lr: 1e-07     reward: 10.08\n",
      "epis: 2994   score: 10.0   mem len: 912816   epsilon: 0.01    steps: 458    lr: 1e-07     reward: 10.09\n",
      "epis: 2995   score: 11.0   mem len: 913360   epsilon: 0.01    steps: 544    lr: 1e-07     reward: 10.1\n",
      "epis: 2996   score: 6.0   mem len: 913702   epsilon: 0.01    steps: 342    lr: 1e-07     reward: 10.07\n",
      "epis: 2997   score: 12.0   mem len: 914291   epsilon: 0.01    steps: 589    lr: 1e-07     reward: 10.07\n",
      "epis: 2998   score: 10.0   mem len: 914749   epsilon: 0.01    steps: 458    lr: 1e-07     reward: 10.09\n",
      "epis: 2999   score: 11.0   mem len: 915185   epsilon: 0.01    steps: 436    lr: 1e-07     reward: 10.14\n",
      "epis: 3000   score: 10.0   mem len: 915643   epsilon: 0.01    steps: 458    lr: 1e-07     reward: 10.16\n",
      "epis: 3001   score: 12.0   mem len: 916224   epsilon: 0.01    steps: 581    lr: 1e-07     reward: 10.15\n",
      "epis: 3002   score: 12.0   mem len: 916775   epsilon: 0.01    steps: 551    lr: 1e-07     reward: 10.19\n",
      "epis: 3003   score: 12.0   mem len: 917326   epsilon: 0.01    steps: 551    lr: 1e-07     reward: 10.2\n",
      "epis: 3004   score: 11.0   mem len: 917881   epsilon: 0.01    steps: 555    lr: 1e-07     reward: 10.23\n",
      "epis: 3005   score: 9.0   mem len: 918310   epsilon: 0.01    steps: 429    lr: 1e-07     reward: 10.25\n",
      "epis: 3006   score: 9.0   mem len: 918796   epsilon: 0.01    steps: 486    lr: 1e-07     reward: 10.27\n",
      "epis: 3007   score: 11.0   mem len: 919326   epsilon: 0.01    steps: 530    lr: 1e-07     reward: 10.29\n",
      "epis: 3008   score: 11.0   mem len: 919828   epsilon: 0.01    steps: 502    lr: 1e-07     reward: 10.3\n",
      "epis: 3009   score: 11.0   mem len: 920330   epsilon: 0.01    steps: 502    lr: 1e-07     reward: 10.32\n",
      "epis: 3010   score: 12.0   mem len: 920881   epsilon: 0.01    steps: 551    lr: 1e-07     reward: 10.38\n",
      "epis: 3011   score: 9.0   mem len: 921364   epsilon: 0.01    steps: 483    lr: 1e-07     reward: 10.38\n",
      "epis: 3012   score: 15.0   mem len: 921890   epsilon: 0.01    steps: 526    lr: 1e-07     reward: 10.42\n",
      "epis: 3013   score: 11.0   mem len: 922440   epsilon: 0.01    steps: 550    lr: 1e-07     reward: 10.38\n",
      "epis: 3014   score: 12.0   mem len: 923007   epsilon: 0.01    steps: 567    lr: 1e-07     reward: 10.4\n",
      "epis: 3015   score: 15.0   mem len: 923533   epsilon: 0.01    steps: 526    lr: 1e-07     reward: 10.39\n",
      "epis: 3016   score: 9.0   mem len: 924004   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 10.37\n",
      "epis: 3017   score: 9.0   mem len: 924476   epsilon: 0.01    steps: 472    lr: 1e-07     reward: 10.3\n",
      "epis: 3018   score: 9.0   mem len: 924902   epsilon: 0.01    steps: 426    lr: 1e-07     reward: 10.29\n",
      "epis: 3019   score: 9.0   mem len: 925369   epsilon: 0.01    steps: 467    lr: 1e-07     reward: 10.24\n",
      "epis: 3020   score: 8.0   mem len: 925812   epsilon: 0.01    steps: 443    lr: 1e-07     reward: 10.23\n",
      "epis: 3021   score: 8.0   mem len: 926258   epsilon: 0.01    steps: 446    lr: 1e-07     reward: 10.23\n",
      "epis: 3022   score: 10.0   mem len: 926751   epsilon: 0.01    steps: 493    lr: 1e-07     reward: 10.22\n",
      "epis: 3023   score: 8.0   mem len: 927194   epsilon: 0.01    steps: 443    lr: 1e-07     reward: 10.2\n",
      "epis: 3024   score: 11.0   mem len: 927687   epsilon: 0.01    steps: 493    lr: 1e-07     reward: 10.17\n",
      "epis: 3025   score: 9.0   mem len: 928141   epsilon: 0.01    steps: 454    lr: 1e-07     reward: 10.11\n",
      "epis: 3026   score: 11.0   mem len: 928691   epsilon: 0.01    steps: 550    lr: 1e-07     reward: 10.13\n",
      "epis: 3027   score: 10.0   mem len: 929195   epsilon: 0.01    steps: 504    lr: 1e-07     reward: 10.13\n",
      "epis: 3028   score: 10.0   mem len: 929668   epsilon: 0.01    steps: 473    lr: 1e-07     reward: 10.13\n",
      "epis: 3029   score: 9.0   mem len: 930145   epsilon: 0.01    steps: 477    lr: 1e-07     reward: 10.12\n",
      "epis: 3030   score: 6.0   mem len: 930485   epsilon: 0.01    steps: 340    lr: 1e-07     reward: 10.04\n",
      "epis: 3031   score: 11.0   mem len: 930998   epsilon: 0.01    steps: 513    lr: 1e-07     reward: 10.07\n",
      "epis: 3032   score: 10.0   mem len: 931491   epsilon: 0.01    steps: 493    lr: 1e-07     reward: 10.08\n",
      "epis: 3033   score: 13.0   mem len: 932104   epsilon: 0.01    steps: 613    lr: 1e-07     reward: 10.14\n",
      "epis: 3034   score: 10.0   mem len: 932586   epsilon: 0.01    steps: 482    lr: 1e-07     reward: 10.15\n",
      "epis: 3035   score: 10.0   mem len: 933049   epsilon: 0.01    steps: 463    lr: 1e-07     reward: 10.18\n",
      "epis: 3036   score: 11.0   mem len: 933551   epsilon: 0.01    steps: 502    lr: 1e-07     reward: 10.18\n",
      "epis: 3037   score: 12.0   mem len: 934126   epsilon: 0.01    steps: 575    lr: 1e-07     reward: 10.21\n",
      "epis: 3038   score: 10.0   mem len: 934608   epsilon: 0.01    steps: 482    lr: 1e-07     reward: 10.22\n",
      "epis: 3039   score: 13.0   mem len: 935195   epsilon: 0.01    steps: 587    lr: 1e-07     reward: 10.14\n",
      "epis: 3040   score: 10.0   mem len: 935677   epsilon: 0.01    steps: 482    lr: 1e-07     reward: 10.17\n",
      "epis: 3041   score: 5.0   mem len: 935970   epsilon: 0.01    steps: 293    lr: 1e-07     reward: 10.14\n",
      "epis: 3042   score: 13.0   mem len: 936576   epsilon: 0.01    steps: 606    lr: 1e-07     reward: 10.21\n",
      "epis: 3043   score: 13.0   mem len: 937182   epsilon: 0.01    steps: 606    lr: 1e-07     reward: 10.24\n",
      "epis: 3044   score: 11.0   mem len: 937684   epsilon: 0.01    steps: 502    lr: 1e-07     reward: 10.23\n",
      "epis: 3045   score: 10.0   mem len: 938210   epsilon: 0.01    steps: 526    lr: 1e-07     reward: 10.22\n",
      "epis: 3046   score: 6.0   mem len: 938570   epsilon: 0.01    steps: 360    lr: 1e-07     reward: 10.16\n",
      "epis: 3047   score: 13.0   mem len: 939176   epsilon: 0.01    steps: 606    lr: 1e-07     reward: 10.16\n",
      "epis: 3048   score: 12.0   mem len: 939612   epsilon: 0.01    steps: 436    lr: 1e-07     reward: 10.18\n",
      "epis: 3049   score: 13.0   mem len: 940218   epsilon: 0.01    steps: 606    lr: 1e-07     reward: 10.14\n",
      "epis: 3050   score: 12.0   mem len: 940654   epsilon: 0.01    steps: 436    lr: 1e-07     reward: 10.17\n",
      "epis: 3051   score: 12.0   mem len: 941090   epsilon: 0.01    steps: 436    lr: 1e-07     reward: 10.17\n",
      "epis: 3052   score: 10.0   mem len: 941561   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 10.17\n",
      "epis: 3053   score: 11.0   mem len: 942071   epsilon: 0.01    steps: 510    lr: 1e-07     reward: 10.18\n",
      "epis: 3054   score: 11.0   mem len: 942598   epsilon: 0.01    steps: 527    lr: 1e-07     reward: 10.18\n",
      "epis: 3055   score: 9.0   mem len: 943139   epsilon: 0.01    steps: 541    lr: 1e-07     reward: 10.17\n",
      "epis: 3056   score: 9.0   mem len: 943593   epsilon: 0.01    steps: 454    lr: 1e-07     reward: 10.13\n",
      "epis: 3057   score: 11.0   mem len: 944092   epsilon: 0.01    steps: 499    lr: 1e-07     reward: 10.14\n",
      "epis: 3058   score: 11.0   mem len: 944491   epsilon: 0.01    steps: 399    lr: 1e-07     reward: 10.2\n",
      "epis: 3059   score: 10.0   mem len: 945006   epsilon: 0.01    steps: 515    lr: 1e-07     reward: 10.21\n",
      "epis: 3060   score: 9.0   mem len: 945452   epsilon: 0.01    steps: 446    lr: 1e-07     reward: 10.26\n",
      "epis: 3061   score: 10.0   mem len: 945934   epsilon: 0.01    steps: 482    lr: 1e-07     reward: 10.32\n",
      "epis: 3062   score: 10.0   mem len: 946497   epsilon: 0.01    steps: 563    lr: 1e-07     reward: 10.37\n",
      "epis: 3063   score: 9.0   mem len: 946951   epsilon: 0.01    steps: 454    lr: 1e-07     reward: 10.35\n",
      "epis: 3064   score: 9.0   mem len: 947405   epsilon: 0.01    steps: 454    lr: 1e-07     reward: 10.36\n",
      "epis: 3065   score: 12.0   mem len: 948003   epsilon: 0.01    steps: 598    lr: 1e-07     reward: 10.41\n",
      "epis: 3066   score: 10.0   mem len: 948461   epsilon: 0.01    steps: 458    lr: 1e-07     reward: 10.4\n",
      "epis: 3067   score: 9.0   mem len: 948907   epsilon: 0.01    steps: 446    lr: 1e-07     reward: 10.38\n",
      "epis: 3068   score: 4.0   mem len: 949153   epsilon: 0.01    steps: 246    lr: 1e-07     reward: 10.29\n",
      "epis: 3069   score: 13.0   mem len: 949759   epsilon: 0.01    steps: 606    lr: 1e-07     reward: 10.29\n",
      "epis: 3070   score: 13.0   mem len: 950365   epsilon: 0.01    steps: 606    lr: 1e-07     reward: 10.29\n",
      "epis: 3071   score: 11.0   mem len: 950864   epsilon: 0.01    steps: 499    lr: 1e-07     reward: 10.27\n",
      "epis: 3072   score: 10.0   mem len: 951339   epsilon: 0.01    steps: 475    lr: 1e-07     reward: 10.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 3073   score: 9.0   mem len: 951793   epsilon: 0.01    steps: 454    lr: 1e-07     reward: 10.22\n",
      "epis: 3074   score: 9.0   mem len: 952247   epsilon: 0.01    steps: 454    lr: 1e-07     reward: 10.22\n",
      "epis: 3075   score: 18.0   mem len: 952908   epsilon: 0.01    steps: 661    lr: 1e-07     reward: 10.3\n",
      "epis: 3076   score: 15.0   mem len: 953434   epsilon: 0.01    steps: 526    lr: 1e-07     reward: 10.36\n",
      "epis: 3077   score: 14.0   mem len: 953918   epsilon: 0.01    steps: 484    lr: 1e-07     reward: 10.4\n",
      "epis: 3078   score: 15.0   mem len: 954444   epsilon: 0.01    steps: 526    lr: 1e-07     reward: 10.44\n",
      "epis: 3079   score: 15.0   mem len: 954970   epsilon: 0.01    steps: 526    lr: 1e-07     reward: 10.49\n",
      "epis: 3080   score: 11.0   mem len: 955490   epsilon: 0.01    steps: 520    lr: 1e-07     reward: 10.5\n",
      "epis: 3081   score: 6.0   mem len: 955832   epsilon: 0.01    steps: 342    lr: 1e-07     reward: 10.45\n",
      "epis: 3082   score: 23.0   mem len: 956432   epsilon: 0.01    steps: 600    lr: 1e-07     reward: 10.59\n",
      "epis: 3083   score: 13.0   mem len: 957028   epsilon: 0.01    steps: 596    lr: 1e-07     reward: 10.65\n",
      "epis: 3084   score: 12.0   mem len: 957589   epsilon: 0.01    steps: 561    lr: 1e-07     reward: 10.67\n",
      "epis: 3085   score: 16.0   mem len: 958140   epsilon: 0.01    steps: 551    lr: 1e-07     reward: 10.77\n",
      "epis: 3086   score: 6.0   mem len: 958518   epsilon: 0.01    steps: 378    lr: 1e-07     reward: 10.7\n",
      "epis: 3087   score: 10.0   mem len: 959004   epsilon: 0.01    steps: 486    lr: 1e-07     reward: 10.72\n",
      "epis: 3088   score: 11.0   mem len: 959541   epsilon: 0.01    steps: 537    lr: 1e-07     reward: 10.73\n",
      "epis: 3089   score: 9.0   mem len: 960031   epsilon: 0.01    steps: 490    lr: 1e-07     reward: 10.72\n",
      "epis: 3090   score: 11.0   mem len: 960584   epsilon: 0.01    steps: 553    lr: 1e-07     reward: 10.73\n",
      "epis: 3091   score: 13.0   mem len: 961049   epsilon: 0.01    steps: 465    lr: 1e-07     reward: 10.76\n",
      "epis: 3092   score: 13.0   mem len: 961514   epsilon: 0.01    steps: 465    lr: 1e-07     reward: 10.77\n",
      "epis: 3093   score: 15.0   mem len: 961939   epsilon: 0.01    steps: 425    lr: 1e-07     reward: 10.83\n",
      "epis: 3094   score: 13.0   mem len: 962404   epsilon: 0.01    steps: 465    lr: 1e-07     reward: 10.86\n",
      "epis: 3095   score: 11.0   mem len: 962885   epsilon: 0.01    steps: 481    lr: 1e-07     reward: 10.86\n",
      "epis: 3096   score: 9.0   mem len: 963339   epsilon: 0.01    steps: 454    lr: 1e-07     reward: 10.89\n",
      "epis: 3097   score: 9.0   mem len: 963793   epsilon: 0.01    steps: 454    lr: 1e-07     reward: 10.86\n",
      "epis: 3098   score: 9.0   mem len: 964249   epsilon: 0.01    steps: 456    lr: 1e-07     reward: 10.85\n",
      "epis: 3099   score: 14.0   mem len: 964751   epsilon: 0.01    steps: 502    lr: 1e-07     reward: 10.88\n",
      "epis: 3100   score: 8.0   mem len: 965214   epsilon: 0.01    steps: 463    lr: 1e-07     reward: 10.86\n",
      "epis: 3101   score: 15.0   mem len: 965740   epsilon: 0.01    steps: 526    lr: 1e-07     reward: 10.89\n",
      "epis: 3102   score: 15.0   mem len: 966266   epsilon: 0.01    steps: 526    lr: 1e-07     reward: 10.92\n",
      "epis: 3103   score: 14.0   mem len: 966768   epsilon: 0.01    steps: 502    lr: 1e-07     reward: 10.94\n",
      "epis: 3104   score: 10.0   mem len: 967239   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 10.93\n",
      "epis: 3105   score: 12.0   mem len: 967836   epsilon: 0.01    steps: 597    lr: 1e-07     reward: 10.96\n",
      "epis: 3106   score: 12.0   mem len: 968431   epsilon: 0.01    steps: 595    lr: 1e-07     reward: 10.99\n",
      "epis: 3107   score: 10.0   mem len: 968902   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 10.98\n",
      "epis: 3108   score: 12.0   mem len: 969472   epsilon: 0.01    steps: 570    lr: 1e-07     reward: 10.99\n",
      "epis: 3109   score: 5.0   mem len: 969822   epsilon: 0.01    steps: 350    lr: 1e-07     reward: 10.93\n",
      "epis: 3110   score: 5.0   mem len: 970130   epsilon: 0.01    steps: 308    lr: 1e-07     reward: 10.86\n",
      "epis: 3111   score: 14.0   mem len: 970674   epsilon: 0.01    steps: 544    lr: 1e-07     reward: 10.91\n",
      "epis: 3112   score: 12.0   mem len: 971160   epsilon: 0.01    steps: 486    lr: 1e-07     reward: 10.88\n",
      "epis: 3113   score: 12.0   mem len: 971596   epsilon: 0.01    steps: 436    lr: 1e-07     reward: 10.89\n",
      "epis: 3114   score: 12.0   mem len: 972032   epsilon: 0.01    steps: 436    lr: 1e-07     reward: 10.89\n",
      "epis: 3115   score: 10.0   mem len: 972521   epsilon: 0.01    steps: 489    lr: 1e-07     reward: 10.84\n",
      "epis: 3116   score: 18.0   mem len: 973191   epsilon: 0.01    steps: 670    lr: 1e-07     reward: 10.93\n",
      "epis: 3117   score: 16.0   mem len: 973741   epsilon: 0.01    steps: 550    lr: 1e-07     reward: 11.0\n",
      "epis: 3118   score: 16.0   mem len: 974292   epsilon: 0.01    steps: 551    lr: 1e-07     reward: 11.07\n",
      "epis: 3119   score: 14.0   mem len: 974794   epsilon: 0.01    steps: 502    lr: 1e-07     reward: 11.12\n",
      "epis: 3120   score: 10.0   mem len: 975265   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 11.14\n",
      "epis: 3121   score: 5.0   mem len: 975575   epsilon: 0.01    steps: 310    lr: 1e-07     reward: 11.11\n",
      "epis: 3122   score: 12.0   mem len: 976170   epsilon: 0.01    steps: 595    lr: 1e-07     reward: 11.13\n",
      "epis: 3123   score: 12.0   mem len: 976765   epsilon: 0.01    steps: 595    lr: 1e-07     reward: 11.17\n",
      "epis: 3124   score: 13.0   mem len: 977373   epsilon: 0.01    steps: 608    lr: 1e-07     reward: 11.19\n",
      "epis: 3125   score: 10.0   mem len: 977844   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 11.2\n",
      "epis: 3126   score: 9.0   mem len: 978315   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 11.18\n",
      "epis: 3127   score: 13.0   mem len: 978878   epsilon: 0.01    steps: 563    lr: 1e-07     reward: 11.21\n",
      "epis: 3128   score: 12.0   mem len: 979314   epsilon: 0.01    steps: 436    lr: 1e-07     reward: 11.23\n",
      "epis: 3129   score: 5.0   mem len: 979642   epsilon: 0.01    steps: 328    lr: 1e-07     reward: 11.19\n",
      "epis: 3130   score: 10.0   mem len: 980131   epsilon: 0.01    steps: 489    lr: 1e-07     reward: 11.23\n",
      "epis: 3131   score: 9.0   mem len: 980583   epsilon: 0.01    steps: 452    lr: 1e-07     reward: 11.21\n",
      "epis: 3132   score: 7.0   mem len: 980962   epsilon: 0.01    steps: 379    lr: 1e-07     reward: 11.18\n",
      "epis: 3133   score: 15.0   mem len: 981494   epsilon: 0.01    steps: 532    lr: 1e-07     reward: 11.2\n",
      "epis: 3134   score: 12.0   mem len: 982089   epsilon: 0.01    steps: 595    lr: 1e-07     reward: 11.22\n",
      "epis: 3135   score: 10.0   mem len: 982560   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 11.22\n",
      "epis: 3136   score: 10.0   mem len: 983031   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 11.21\n",
      "epis: 3137   score: 6.0   mem len: 983388   epsilon: 0.01    steps: 357    lr: 1e-07     reward: 11.15\n",
      "epis: 3138   score: 14.0   mem len: 983890   epsilon: 0.01    steps: 502    lr: 1e-07     reward: 11.19\n",
      "epis: 3139   score: 8.0   mem len: 984371   epsilon: 0.01    steps: 481    lr: 1e-07     reward: 11.14\n",
      "epis: 3140   score: 9.0   mem len: 984844   epsilon: 0.01    steps: 473    lr: 1e-07     reward: 11.13\n",
      "epis: 3141   score: 15.0   mem len: 985372   epsilon: 0.01    steps: 528    lr: 1e-07     reward: 11.23\n",
      "epis: 3142   score: 16.0   mem len: 985923   epsilon: 0.01    steps: 551    lr: 1e-07     reward: 11.26\n",
      "epis: 3143   score: 8.0   mem len: 986333   epsilon: 0.01    steps: 410    lr: 1e-07     reward: 11.21\n",
      "epis: 3144   score: 11.0   mem len: 986861   epsilon: 0.01    steps: 528    lr: 1e-07     reward: 11.21\n",
      "epis: 3145   score: 15.0   mem len: 987395   epsilon: 0.01    steps: 534    lr: 1e-07     reward: 11.26\n",
      "epis: 3146   score: 7.0   mem len: 987785   epsilon: 0.01    steps: 390    lr: 1e-07     reward: 11.27\n",
      "epis: 3147   score: 14.0   mem len: 988287   epsilon: 0.01    steps: 502    lr: 1e-07     reward: 11.28\n",
      "epis: 3148   score: 13.0   mem len: 988834   epsilon: 0.01    steps: 547    lr: 1e-07     reward: 11.29\n",
      "epis: 3149   score: 9.0   mem len: 989288   epsilon: 0.01    steps: 454    lr: 1e-07     reward: 11.25\n",
      "epis: 3150   score: 9.0   mem len: 989742   epsilon: 0.01    steps: 454    lr: 1e-07     reward: 11.22\n",
      "epis: 3151   score: 12.0   mem len: 990337   epsilon: 0.01    steps: 595    lr: 1e-07     reward: 11.22\n",
      "epis: 3152   score: 9.0   mem len: 990808   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 11.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 3153   score: 9.0   mem len: 991258   epsilon: 0.01    steps: 450    lr: 1e-07     reward: 11.19\n",
      "epis: 3154   score: 10.0   mem len: 991729   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 11.18\n",
      "epis: 3155   score: 10.0   mem len: 992200   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 11.19\n",
      "epis: 3156   score: 10.0   mem len: 992671   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 11.2\n",
      "epis: 3157   score: 10.0   mem len: 993142   epsilon: 0.01    steps: 471    lr: 1e-07     reward: 11.19\n",
      "epis: 3158   score: 8.0   mem len: 993544   epsilon: 0.01    steps: 402    lr: 1e-07     reward: 11.16\n",
      "epis: 3159   score: 12.0   mem len: 994089   epsilon: 0.01    steps: 545    lr: 1e-07     reward: 11.18\n",
      "epis: 3160   score: 16.0   mem len: 994640   epsilon: 0.01    steps: 551    lr: 1e-07     reward: 11.25\n",
      "epis: 3161   score: 11.0   mem len: 995197   epsilon: 0.01    steps: 557    lr: 1e-07     reward: 11.26\n",
      "epis: 3162   score: 16.0   mem len: 995826   epsilon: 0.01    steps: 629    lr: 1e-07     reward: 11.32\n",
      "epis: 3163   score: 11.0   mem len: 996348   epsilon: 0.01    steps: 522    lr: 1e-07     reward: 11.34\n",
      "epis: 3164   score: 14.0   mem len: 996850   epsilon: 0.01    steps: 502    lr: 1e-07     reward: 11.39\n",
      "epis: 3165   score: 16.0   mem len: 997403   epsilon: 0.01    steps: 553    lr: 1e-07     reward: 11.43\n",
      "epis: 3166   score: 11.0   mem len: 997923   epsilon: 0.01    steps: 520    lr: 1e-07     reward: 11.44\n",
      "epis: 3167   score: 16.0   mem len: 998474   epsilon: 0.01    steps: 551    lr: 1e-07     reward: 11.51\n",
      "epis: 3168   score: 16.0   mem len: 999009   epsilon: 0.01    steps: 535    lr: 1e-07     reward: 11.63\n",
      "epis: 3169   score: 7.0   mem len: 999416   epsilon: 0.01    steps: 407    lr: 1e-07     reward: 11.57\n",
      "epis: 3170   score: 9.0   mem len: 999870   epsilon: 0.01    steps: 454    lr: 1e-07     reward: 11.53\n",
      "epis: 3171   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 472    lr: 0.0     reward: 11.51\n",
      "epis: 3172   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 11.5\n",
      "epis: 3173   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 11.5\n",
      "epis: 3174   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 11.5\n",
      "epis: 3175   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 368    lr: 0.0     reward: 11.39\n",
      "epis: 3176   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 480    lr: 0.0     reward: 11.32\n",
      "epis: 3177   score: 16.0   mem len: 1000000   epsilon: 0.01    steps: 551    lr: 0.0     reward: 11.34\n",
      "epis: 3178   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 575    lr: 0.0     reward: 11.31\n",
      "epis: 3179   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 11.25\n",
      "epis: 3180   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 502    lr: 0.0     reward: 11.28\n",
      "epis: 3181   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 11.31\n",
      "epis: 3182   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 620    lr: 0.0     reward: 11.21\n",
      "epis: 3183   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 575    lr: 0.0     reward: 11.2\n",
      "epis: 3184   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 11.2\n",
      "epis: 3185   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 11.16\n",
      "epis: 3186   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 467    lr: 0.0     reward: 11.19\n",
      "epis: 3187   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 11.21\n",
      "epis: 3188   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 502    lr: 0.0     reward: 11.21\n",
      "epis: 3189   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 508    lr: 0.0     reward: 11.22\n",
      "epis: 3190   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 443    lr: 0.0     reward: 11.19\n",
      "epis: 3191   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 588    lr: 0.0     reward: 11.21\n",
      "epis: 3192   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 571    lr: 0.0     reward: 11.2\n",
      "epis: 3193   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 439    lr: 0.0     reward: 11.13\n",
      "epis: 3194   score: 5.0   mem len: 1000000   epsilon: 0.01    steps: 328    lr: 0.0     reward: 11.05\n",
      "epis: 3195   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 526    lr: 0.0     reward: 11.09\n",
      "epis: 3196   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 438    lr: 0.0     reward: 11.08\n",
      "epis: 3197   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 461    lr: 0.0     reward: 11.07\n",
      "epis: 3198   score: 17.0   mem len: 1000000   epsilon: 0.01    steps: 684    lr: 0.0     reward: 11.15\n",
      "epis: 3199   score: 5.0   mem len: 1000000   epsilon: 0.01    steps: 328    lr: 0.0     reward: 11.06\n",
      "epis: 3200   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 502    lr: 0.0     reward: 11.09\n",
      "epis: 3201   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 409    lr: 0.0     reward: 11.01\n",
      "epis: 3202   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 471    lr: 0.0     reward: 10.95\n",
      "epis: 3203   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 471    lr: 0.0     reward: 10.91\n",
      "epis: 3204   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 471    lr: 0.0     reward: 10.91\n",
      "epis: 3205   score: 5.0   mem len: 1000000   epsilon: 0.01    steps: 328    lr: 0.0     reward: 10.84\n",
      "epis: 3206   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 471    lr: 0.0     reward: 10.82\n",
      "epis: 3207   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 456    lr: 0.0     reward: 10.81\n",
      "epis: 3208   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 495    lr: 0.0     reward: 10.83\n",
      "epis: 3209   score: 5.0   mem len: 1000000   epsilon: 0.01    steps: 291    lr: 0.0     reward: 10.83\n",
      "epis: 3210   score: 5.0   mem len: 1000000   epsilon: 0.01    steps: 291    lr: 0.0     reward: 10.83\n",
      "epis: 3211   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 510    lr: 0.0     reward: 10.83\n",
      "epis: 3212   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 510    lr: 0.0     reward: 10.85\n",
      "epis: 3213   score: 5.0   mem len: 1000000   epsilon: 0.01    steps: 291    lr: 0.0     reward: 10.78\n",
      "epis: 3214   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 518    lr: 0.0     reward: 10.77\n",
      "epis: 3215   score: 5.0   mem len: 1000000   epsilon: 0.01    steps: 328    lr: 0.0     reward: 10.72\n",
      "epis: 3216   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.61\n",
      "epis: 3217   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.52\n",
      "epis: 3218   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.43\n",
      "epis: 3219   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.36\n",
      "epis: 3220   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 514    lr: 0.0     reward: 10.37\n",
      "epis: 3221   score: 16.0   mem len: 1000000   epsilon: 0.01    steps: 624    lr: 0.0     reward: 10.48\n",
      "epis: 3222   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 461    lr: 0.0     reward: 10.47\n",
      "epis: 3223   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.42\n",
      "epis: 3224   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.36\n",
      "epis: 3225   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.33\n",
      "epis: 3226   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.31\n",
      "epis: 3227   score: 5.0   mem len: 1000000   epsilon: 0.01    steps: 291    lr: 0.0     reward: 10.23\n",
      "epis: 3228   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.18\n",
      "epis: 3229   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 459    lr: 0.0     reward: 10.21\n",
      "epis: 3230   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 459    lr: 0.0     reward: 10.19\n",
      "epis: 3231   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 459    lr: 0.0     reward: 10.18\n",
      "epis: 3232   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 551    lr: 0.0     reward: 10.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 3233   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.14\n",
      "epis: 3234   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 608    lr: 0.0     reward: 10.15\n",
      "epis: 3235   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 597    lr: 0.0     reward: 10.18\n",
      "epis: 3236   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.15\n",
      "epis: 3237   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 437    lr: 0.0     reward: 10.17\n",
      "epis: 3238   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 476    lr: 0.0     reward: 10.12\n",
      "epis: 3239   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.11\n",
      "epis: 3240   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.09\n",
      "epis: 3241   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 459    lr: 0.0     reward: 10.02\n",
      "epis: 3242   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 387    lr: 0.0     reward: 9.93\n",
      "epis: 3243   score: 5.0   mem len: 1000000   epsilon: 0.01    steps: 291    lr: 0.0     reward: 9.9\n",
      "epis: 3244   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 9.86\n",
      "epis: 3245   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 9.78\n",
      "epis: 3246   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 9.83\n",
      "epis: 3247   score: 16.0   mem len: 1000000   epsilon: 0.01    steps: 596    lr: 0.0     reward: 9.85\n",
      "epis: 3248   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 403    lr: 0.0     reward: 9.79\n",
      "epis: 3249   score: 16.0   mem len: 1000000   epsilon: 0.01    steps: 596    lr: 0.0     reward: 9.86\n",
      "epis: 3250   score: 16.0   mem len: 1000000   epsilon: 0.01    steps: 596    lr: 0.0     reward: 9.93\n",
      "epis: 3251   score: 16.0   mem len: 1000000   epsilon: 0.01    steps: 551    lr: 0.0     reward: 9.97\n",
      "epis: 3252   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 502    lr: 0.0     reward: 10.02\n",
      "epis: 3253   score: 16.0   mem len: 1000000   epsilon: 0.01    steps: 553    lr: 0.0     reward: 10.09\n",
      "epis: 3254   score: 16.0   mem len: 1000000   epsilon: 0.01    steps: 553    lr: 0.0     reward: 10.15\n",
      "epis: 3255   score: 16.0   mem len: 1000000   epsilon: 0.01    steps: 553    lr: 0.0     reward: 10.21\n",
      "epis: 3256   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 528    lr: 0.0     reward: 10.26\n",
      "epis: 3257   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 581    lr: 0.0     reward: 10.31\n",
      "epis: 3258   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 582    lr: 0.0     reward: 10.38\n",
      "epis: 3259   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 583    lr: 0.0     reward: 10.38\n",
      "epis: 3260   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.31\n",
      "epis: 3261   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 472    lr: 0.0     reward: 10.29\n",
      "epis: 3262   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 505    lr: 0.0     reward: 10.23\n",
      "epis: 3263   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 500    lr: 0.0     reward: 10.22\n",
      "epis: 3264   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.17\n",
      "epis: 3265   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.1\n",
      "epis: 3266   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 487    lr: 0.0     reward: 10.09\n",
      "epis: 3267   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.02\n",
      "epis: 3268   score: 16.0   mem len: 1000000   epsilon: 0.01    steps: 621    lr: 0.0     reward: 10.02\n",
      "epis: 3269   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 10.07\n",
      "epis: 3270   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 545    lr: 0.0     reward: 10.13\n",
      "epis: 3271   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 467    lr: 0.0     reward: 10.13\n",
      "epis: 3272   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 487    lr: 0.0     reward: 10.14\n",
      "epis: 3273   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 10.17\n",
      "epis: 3274   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 10.2\n",
      "epis: 3275   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 487    lr: 0.0     reward: 10.23\n",
      "epis: 3276   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 10.27\n",
      "epis: 3277   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 523    lr: 0.0     reward: 10.21\n",
      "epis: 3278   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 443    lr: 0.0     reward: 10.17\n",
      "epis: 3279   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 553    lr: 0.0     reward: 10.19\n",
      "epis: 3280   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 517    lr: 0.0     reward: 10.15\n",
      "epis: 3281   score: 6.0   mem len: 1000000   epsilon: 0.01    steps: 360    lr: 0.0     reward: 10.12\n",
      "epis: 3282   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 592    lr: 0.0     reward: 10.11\n",
      "epis: 3283   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 471    lr: 0.0     reward: 10.08\n",
      "epis: 3284   score: 6.0   mem len: 1000000   epsilon: 0.01    steps: 340    lr: 0.0     reward: 10.02\n",
      "epis: 3285   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 456    lr: 0.0     reward: 9.99\n",
      "epis: 3286   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 608    lr: 0.0     reward: 10.03\n",
      "epis: 3287   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 10.03\n",
      "epis: 3288   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 597    lr: 0.0     reward: 10.04\n",
      "epis: 3289   score: 6.0   mem len: 1000000   epsilon: 0.01    steps: 341    lr: 0.0     reward: 10.0\n",
      "epis: 3290   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 10.04\n",
      "epis: 3291   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 10.01\n",
      "epis: 3292   score: 6.0   mem len: 1000000   epsilon: 0.01    steps: 360    lr: 0.0     reward: 9.95\n",
      "epis: 3293   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 428    lr: 0.0     reward: 9.95\n",
      "epis: 3294   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 10.02\n",
      "epis: 3295   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 399    lr: 0.0     reward: 9.98\n",
      "epis: 3296   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 502    lr: 0.0     reward: 10.01\n",
      "epis: 3297   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 10.05\n",
      "epis: 3298   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 437    lr: 0.0     reward: 10.01\n",
      "epis: 3299   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 608    lr: 0.0     reward: 10.09\n",
      "epis: 3300   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 10.1\n",
      "epis: 3301   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 10.15\n",
      "epis: 3302   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 573    lr: 0.0     reward: 10.17\n",
      "epis: 3303   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 10.19\n",
      "epis: 3304   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 537    lr: 0.0     reward: 10.2\n",
      "epis: 3305   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 10.27\n",
      "epis: 3306   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 10.29\n",
      "epis: 3307   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 10.32\n",
      "epis: 3308   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 10.3\n",
      "epis: 3309   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 544    lr: 0.0     reward: 10.37\n",
      "epis: 3310   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 10.44\n",
      "epis: 3311   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 502    lr: 0.0     reward: 10.41\n",
      "epis: 3312   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 10.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 3313   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 10.46\n",
      "epis: 3314   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 445    lr: 0.0     reward: 10.43\n",
      "epis: 3315   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 10.5\n",
      "epis: 3316   score: 4.0   mem len: 1000000   epsilon: 0.01    steps: 246    lr: 0.0     reward: 10.47\n",
      "epis: 3317   score: 4.0   mem len: 1000000   epsilon: 0.01    steps: 246    lr: 0.0     reward: 10.44\n",
      "epis: 3318   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 10.49\n",
      "epis: 3319   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 10.54\n",
      "epis: 3320   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 502    lr: 0.0     reward: 10.54\n",
      "epis: 3321   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 437    lr: 0.0     reward: 10.51\n",
      "epis: 3322   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 437    lr: 0.0     reward: 10.53\n",
      "epis: 3323   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 437    lr: 0.0     reward: 10.59\n",
      "epis: 3324   score: 6.0   mem len: 1000000   epsilon: 0.01    steps: 325    lr: 0.0     reward: 10.58\n",
      "epis: 3325   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 437    lr: 0.0     reward: 10.64\n",
      "epis: 3326   score: 4.0   mem len: 1000000   epsilon: 0.01    steps: 246    lr: 0.0     reward: 10.61\n",
      "epis: 3327   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 391    lr: 0.0     reward: 10.63\n",
      "epis: 3328   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 438    lr: 0.0     reward: 10.64\n",
      "epis: 3329   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 511    lr: 0.0     reward: 10.67\n",
      "epis: 3330   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 467    lr: 0.0     reward: 10.68\n",
      "epis: 3331   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 471    lr: 0.0     reward: 10.69\n",
      "epis: 3332   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 10.7\n",
      "epis: 3333   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 443    lr: 0.0     reward: 10.71\n",
      "epis: 3334   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 490    lr: 0.0     reward: 10.67\n",
      "epis: 3335   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 391    lr: 0.0     reward: 10.63\n",
      "epis: 3336   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 10.68\n",
      "epis: 3337   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 396    lr: 0.0     reward: 10.68\n",
      "epis: 3338   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 10.71\n",
      "epis: 3339   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 10.76\n",
      "epis: 3340   score: 5.0   mem len: 1000000   epsilon: 0.01    steps: 292    lr: 0.0     reward: 10.74\n",
      "epis: 3341   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 471    lr: 0.0     reward: 10.76\n",
      "epis: 3342   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 518    lr: 0.0     reward: 10.8\n",
      "epis: 3343   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 10.87\n",
      "epis: 3344   score: 4.0   mem len: 1000000   epsilon: 0.01    steps: 260    lr: 0.0     reward: 10.84\n",
      "epis: 3345   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 471    lr: 0.0     reward: 10.86\n",
      "epis: 3346   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 10.86\n",
      "epis: 3347   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.79\n",
      "epis: 3348   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.81\n",
      "epis: 3349   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 518    lr: 0.0     reward: 10.76\n",
      "epis: 3350   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.69\n",
      "epis: 3351   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 551    lr: 0.0     reward: 10.65\n",
      "epis: 3352   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 526    lr: 0.0     reward: 10.66\n",
      "epis: 3353   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 520    lr: 0.0     reward: 10.61\n",
      "epis: 3354   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 526    lr: 0.0     reward: 10.6\n",
      "epis: 3355   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 526    lr: 0.0     reward: 10.59\n",
      "epis: 3356   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.53\n",
      "epis: 3357   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.47\n",
      "epis: 3358   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 486    lr: 0.0     reward: 10.42\n",
      "epis: 3359   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.39\n",
      "epis: 3360   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 538    lr: 0.0     reward: 10.41\n",
      "epis: 3361   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.41\n",
      "epis: 3362   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 526    lr: 0.0     reward: 10.46\n",
      "epis: 3363   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.45\n",
      "epis: 3364   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.45\n",
      "epis: 3365   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.45\n",
      "epis: 3366   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.44\n",
      "epis: 3367   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.44\n",
      "epis: 3368   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 545    lr: 0.0     reward: 10.39\n",
      "epis: 3369   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 489    lr: 0.0     reward: 10.37\n",
      "epis: 3370   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 582    lr: 0.0     reward: 10.34\n",
      "epis: 3371   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 437    lr: 0.0     reward: 10.38\n",
      "epis: 3372   score: 4.0   mem len: 1000000   epsilon: 0.01    steps: 246    lr: 0.0     reward: 10.32\n",
      "epis: 3373   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 478    lr: 0.0     reward: 10.3\n",
      "epis: 3374   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 443    lr: 0.0     reward: 10.26\n",
      "epis: 3375   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 393    lr: 0.0     reward: 10.23\n",
      "epis: 3376   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 518    lr: 0.0     reward: 10.21\n",
      "epis: 3377   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 518    lr: 0.0     reward: 10.22\n",
      "epis: 3378   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 487    lr: 0.0     reward: 10.24\n",
      "epis: 3379   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 477    lr: 0.0     reward: 10.23\n",
      "epis: 3380   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.22\n",
      "epis: 3381   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.25\n",
      "epis: 3382   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 534    lr: 0.0     reward: 10.25\n",
      "epis: 3383   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 10.28\n",
      "epis: 3384   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 10.34\n",
      "epis: 3385   score: 5.0   mem len: 1000000   epsilon: 0.01    steps: 292    lr: 0.0     reward: 10.3\n",
      "epis: 3386   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 10.29\n",
      "epis: 3387   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 10.29\n",
      "epis: 3388   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 613    lr: 0.0     reward: 10.3\n",
      "epis: 3389   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.33\n",
      "epis: 3390   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 10.33\n",
      "epis: 3391   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 10.33\n",
      "epis: 3392   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 10.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 3393   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 10.4\n",
      "epis: 3394   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 472    lr: 0.0     reward: 10.37\n"
     ]
    }
   ],
   "source": [
    "rewards, episodes = [], []\n",
    "best_eval_reward = 0\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "    step = 0\n",
    "    state = env.reset()\n",
    "    next_state = state\n",
    "    life = number_lives\n",
    "\n",
    "    get_init_state(history, state, HISTORY_SIZE)\n",
    "\n",
    "    while not done:\n",
    "        step += 1\n",
    "        frame += 1\n",
    "\n",
    "        # Perform a fire action if ball is no longer on screen to continue onto next life\n",
    "        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "            action = 0\n",
    "        else:\n",
    "            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "        state = next_state\n",
    "        next_state, reward, done, _, info = env.step(action + 1)\n",
    "        \n",
    "        frame_next_state = get_frame(next_state)\n",
    "        history[4, :, :] = frame_next_state\n",
    "        terminal_state = check_live(life, info['lives'])\n",
    "\n",
    "        life = info['lives']\n",
    "        r = reward\n",
    "\n",
    "        # Store the transition in memory \n",
    "        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "        # Start training after random sample generation\n",
    "        if(frame >= train_frame):\n",
    "            agent.train_policy_net(frame)\n",
    "            # Update the target network only for Double DQN only\n",
    "            if double_dqn and (frame % update_target_network_frequency)== 0:\n",
    "                agent.update_target_net()\n",
    "        score += reward\n",
    "        history[:4, :, :] = history[1:, :, :]\n",
    "            \n",
    "        if done:\n",
    "            evaluation_reward.append(score)\n",
    "            rewards.append(np.mean(evaluation_reward))\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, rewards, 'b')\n",
    "            pylab.xlabel('Episodes')\n",
    "            pylab.ylabel('Rewards') \n",
    "            pylab.title('Episodes vs Reward')\n",
    "            pylab.savefig(\"./save_graph/breakout_double_dqn.png\") # save graph for training visualization\n",
    "            \n",
    "            # every episode, plot the play time\n",
    "            print(\"epis:\", e, \"  score:\", score, \"  mem len:\",\n",
    "                  len(agent.memory), \"  epsilon:\", round(agent.epsilon, 4), \"   steps:\", step,\n",
    "                  \"   lr:\", round(agent.optimizer.param_groups[0]['lr'], 7), \"    reward:\", round(np.mean(evaluation_reward), 2))\n",
    "\n",
    "            # if the mean of scores of last 100 episode is bigger than 5 save model\n",
    "            ### Change this save condition to whatever you prefer ###\n",
    "            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n",
    "                torch.save(agent.policy_net, \"./save_model/breakout_double_dqn.pth\")\n",
    "                best_eval_reward = np.mean(evaluation_reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Agent Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BE AWARE THIS CODE BELOW MAY CRASH THE KERNEL IF YOU RUN THE SAME CELL TWICE.\n",
    "\n",
    "Please save your model before running this portion of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.policy_net, \"./save_model/breakout_double_dqn_latest.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import RecordVideo # If importing monitor raises issues, try using `from gym.wrappers import RecordVideo`\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "# Displaying the game live\n",
    "def show_state(env, step=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    ipythondisplay.display(plt.gcf())\n",
    "    \n",
    "# Recording the game and replaying the game afterwards\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else: \n",
    "        print(\"Could not find video\")\n",
    "    \n",
    "\n",
    "def wrap_env(env):\n",
    "    env = RecordVideo(env, './video')\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = Display(visible=0, size=(300, 200))\n",
    "display.start()\n",
    "\n",
    "# Load agent\n",
    "# agent.load_policy_net(\"./save_model/breakout_dqn.pth\")\n",
    "agent.epsilon = 0.0 # Set agent to only exploit the best action\n",
    "\n",
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "env = wrap_env(env)\n",
    "\n",
    "done = False\n",
    "score = 0\n",
    "step = 0\n",
    "state = env.reset()\n",
    "next_state = state\n",
    "life = number_lives\n",
    "history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "get_init_state(history, state)\n",
    "\n",
    "while not done:\n",
    "    \n",
    "    # Render breakout\n",
    "    env.render()\n",
    "#     show_state(env,step) # uncommenting this provides another way to visualize the game\n",
    "\n",
    "    step += 1\n",
    "    frame += 1\n",
    "\n",
    "    # Perform a fire action if ball is no longer on screen\n",
    "    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "        action = 0\n",
    "    else:\n",
    "        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "    state = next_state\n",
    "    \n",
    "    next_state, reward, done, _, info = env.step(action + 1)\n",
    "        \n",
    "    frame_next_state = get_frame(next_state)\n",
    "    history[4, :, :] = frame_next_state\n",
    "    terminal_state = check_live(life, info['ale.lives'])\n",
    "        \n",
    "    life = info['ale.lives']\n",
    "    r = np.clip(reward, -1, 1) \n",
    "    r = reward\n",
    "\n",
    "    # Store the transition in memory \n",
    "    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "    # Start training after random sample generation\n",
    "    score += reward\n",
    "    \n",
    "    history[:4, :, :] = history[1:, :, :]\n",
    "env.close()\n",
    "show_video()\n",
    "display.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
