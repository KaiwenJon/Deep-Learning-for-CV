{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install gym pyvirtualdisplay\n",
    "!sudo apt-get install -y xvfb python-opengl ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade setuptools --user\n",
    "!pip3 install ez_setup \n",
    "!pip3 install gym[atari] \n",
    "!pip3 install gym[accept-rom-license] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import gym\n",
    "import torch\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from utils import find_max_lives, check_live, get_frame, get_init_state\n",
    "from model import DQN\n",
    "from config import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://www.gymlibrary.dev/environments/atari/breakout/. \n",
    "\n",
    "In breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_lives = find_max_lives(env)\n",
    "state_size = env.observation_space.shape\n",
    "action_size = 3 #fire, left, and right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DQN Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n",
    "\n",
    "__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n",
    "\n",
    "__Frame__ : Number of frames processed in total.\n",
    "\n",
    "__Memory Size__ : The current size of the replay memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_dqn = False # set to True if using double DQN agent\n",
    "\n",
    "if double_dqn:\n",
    "    from agent_double import Agent\n",
    "else:\n",
    "    from agent import Agent\n",
    "\n",
    "agent = Agent(action_size)\n",
    "evaluation_reward = deque(maxlen=evaluation_reward_length)\n",
    "frame = 0\n",
    "memory_size = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_309641/1376515593.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
      "/tmp/ipykernel_309641/1376515593.py:20: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 0   score: 2.0   mem len: 218   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 2.0\n",
      "epis: 1   score: 1.0   mem len: 369   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.5\n",
      "epis: 2   score: 2.0   mem len: 567   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.67\n",
      "epis: 3   score: 1.0   mem len: 739   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.5\n",
      "epis: 4   score: 1.0   mem len: 889   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.4\n",
      "epis: 5   score: 1.0   mem len: 1039   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.33\n",
      "epis: 6   score: 0.0   mem len: 1162   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.14\n",
      "epis: 7   score: 0.0   mem len: 1284   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.0\n",
      "epis: 8   score: 0.0   mem len: 1407   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 0.89\n",
      "epis: 9   score: 2.0   mem len: 1625   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.0\n",
      "epis: 10   score: 2.0   mem len: 1822   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.09\n",
      "epis: 11   score: 2.0   mem len: 2019   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.17\n",
      "epis: 12   score: 0.0   mem len: 2141   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.08\n",
      "epis: 13   score: 2.0   mem len: 2359   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.14\n",
      "epis: 14   score: 2.0   mem len: 2560   epsilon: 1.0    steps: 201    lr: 0.0001     reward: 1.2\n",
      "epis: 15   score: 3.0   mem len: 2803   epsilon: 1.0    steps: 243    lr: 0.0001     reward: 1.31\n",
      "epis: 16   score: 2.0   mem len: 3001   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.35\n",
      "epis: 17   score: 2.0   mem len: 3199   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.39\n",
      "epis: 18   score: 2.0   mem len: 3400   epsilon: 1.0    steps: 201    lr: 0.0001     reward: 1.42\n",
      "epis: 19   score: 1.0   mem len: 3569   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.4\n",
      "epis: 20   score: 1.0   mem len: 3737   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.38\n",
      "epis: 21   score: 8.0   mem len: 4106   epsilon: 1.0    steps: 369    lr: 0.0001     reward: 1.68\n",
      "epis: 22   score: 2.0   mem len: 4304   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.7\n",
      "epis: 23   score: 2.0   mem len: 4502   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.71\n",
      "epis: 24   score: 0.0   mem len: 4625   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.64\n",
      "epis: 25   score: 2.0   mem len: 4841   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.65\n",
      "epis: 26   score: 2.0   mem len: 5039   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.67\n",
      "epis: 27   score: 0.0   mem len: 5162   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.61\n",
      "epis: 28   score: 1.0   mem len: 5332   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.59\n",
      "epis: 29   score: 1.0   mem len: 5501   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.57\n",
      "epis: 30   score: 0.0   mem len: 5624   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.52\n",
      "epis: 31   score: 3.0   mem len: 5876   epsilon: 1.0    steps: 252    lr: 0.0001     reward: 1.56\n",
      "epis: 32   score: 2.0   mem len: 6058   epsilon: 1.0    steps: 182    lr: 0.0001     reward: 1.58\n",
      "epis: 33   score: 0.0   mem len: 6180   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.53\n",
      "epis: 34   score: 1.0   mem len: 6350   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.51\n",
      "epis: 35   score: 1.0   mem len: 6519   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.5\n",
      "epis: 36   score: 0.0   mem len: 6641   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.46\n",
      "epis: 37   score: 2.0   mem len: 6838   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.47\n",
      "epis: 38   score: 2.0   mem len: 7036   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.49\n",
      "epis: 39   score: 1.0   mem len: 7208   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.48\n",
      "epis: 40   score: 3.0   mem len: 7475   epsilon: 1.0    steps: 267    lr: 0.0001     reward: 1.51\n",
      "epis: 41   score: 3.0   mem len: 7703   epsilon: 1.0    steps: 228    lr: 0.0001     reward: 1.55\n",
      "epis: 42   score: 3.0   mem len: 7931   epsilon: 1.0    steps: 228    lr: 0.0001     reward: 1.58\n",
      "epis: 43   score: 0.0   mem len: 8054   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.55\n",
      "epis: 44   score: 1.0   mem len: 8225   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.53\n",
      "epis: 45   score: 3.0   mem len: 8475   epsilon: 1.0    steps: 250    lr: 0.0001     reward: 1.57\n",
      "epis: 46   score: 2.0   mem len: 8675   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.57\n",
      "epis: 47   score: 1.0   mem len: 8844   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.56\n",
      "epis: 48   score: 1.0   mem len: 9013   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.55\n",
      "epis: 49   score: 4.0   mem len: 9309   epsilon: 1.0    steps: 296    lr: 0.0001     reward: 1.6\n",
      "epis: 50   score: 2.0   mem len: 9528   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.61\n",
      "epis: 51   score: 1.0   mem len: 9679   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.6\n",
      "epis: 52   score: 0.0   mem len: 9801   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.57\n",
      "epis: 53   score: 2.0   mem len: 10001   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.57\n",
      "epis: 54   score: 2.0   mem len: 10199   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.58\n",
      "epis: 55   score: 0.0   mem len: 10321   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.55\n",
      "epis: 56   score: 2.0   mem len: 10519   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.56\n",
      "epis: 57   score: 2.0   mem len: 10717   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.57\n",
      "epis: 58   score: 1.0   mem len: 10886   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.56\n",
      "epis: 59   score: 2.0   mem len: 11104   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.57\n",
      "epis: 60   score: 1.0   mem len: 11273   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.56\n",
      "epis: 61   score: 3.0   mem len: 11499   epsilon: 1.0    steps: 226    lr: 0.0001     reward: 1.58\n",
      "epis: 62   score: 1.0   mem len: 11671   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.57\n",
      "epis: 63   score: 0.0   mem len: 11793   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.55\n",
      "epis: 64   score: 2.0   mem len: 12010   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.55\n",
      "epis: 65   score: 2.0   mem len: 12208   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.56\n",
      "epis: 66   score: 1.0   mem len: 12379   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.55\n",
      "epis: 67   score: 4.0   mem len: 12657   epsilon: 1.0    steps: 278    lr: 0.0001     reward: 1.59\n",
      "epis: 68   score: 2.0   mem len: 12855   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.59\n",
      "epis: 69   score: 4.0   mem len: 13132   epsilon: 1.0    steps: 277    lr: 0.0001     reward: 1.63\n",
      "epis: 70   score: 1.0   mem len: 13301   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.62\n",
      "epis: 71   score: 1.0   mem len: 13452   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.61\n",
      "epis: 72   score: 3.0   mem len: 13683   epsilon: 1.0    steps: 231    lr: 0.0001     reward: 1.63\n",
      "epis: 73   score: 0.0   mem len: 13805   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.61\n",
      "epis: 74   score: 1.0   mem len: 13955   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.6\n",
      "epis: 75   score: 1.0   mem len: 14127   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.59\n",
      "epis: 76   score: 2.0   mem len: 14344   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.6\n",
      "epis: 77   score: 0.0   mem len: 14467   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.58\n",
      "epis: 78   score: 2.0   mem len: 14690   epsilon: 1.0    steps: 223    lr: 0.0001     reward: 1.58\n",
      "epis: 79   score: 2.0   mem len: 14910   epsilon: 1.0    steps: 220    lr: 0.0001     reward: 1.59\n",
      "epis: 80   score: 2.0   mem len: 15108   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.59\n",
      "epis: 81   score: 0.0   mem len: 15231   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.57\n",
      "epis: 82   score: 0.0   mem len: 15353   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.55\n",
      "epis: 83   score: 2.0   mem len: 15554   epsilon: 1.0    steps: 201    lr: 0.0001     reward: 1.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 84   score: 0.0   mem len: 15676   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.54\n",
      "epis: 85   score: 1.0   mem len: 15845   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.53\n",
      "epis: 86   score: 0.0   mem len: 15968   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.52\n",
      "epis: 87   score: 2.0   mem len: 16189   epsilon: 1.0    steps: 221    lr: 0.0001     reward: 1.52\n",
      "epis: 88   score: 0.0   mem len: 16312   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.51\n",
      "epis: 89   score: 1.0   mem len: 16480   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.5\n",
      "epis: 90   score: 0.0   mem len: 16602   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.48\n",
      "epis: 91   score: 0.0   mem len: 16725   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.47\n",
      "epis: 92   score: 3.0   mem len: 16996   epsilon: 1.0    steps: 271    lr: 0.0001     reward: 1.48\n",
      "epis: 93   score: 1.0   mem len: 17147   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.48\n",
      "epis: 94   score: 1.0   mem len: 17297   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.47\n",
      "epis: 95   score: 0.0   mem len: 17420   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.46\n",
      "epis: 96   score: 2.0   mem len: 17618   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.46\n",
      "epis: 97   score: 3.0   mem len: 17845   epsilon: 1.0    steps: 227    lr: 0.0001     reward: 1.48\n",
      "epis: 98   score: 0.0   mem len: 17967   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.46\n",
      "epis: 99   score: 1.0   mem len: 18118   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.46\n",
      "epis: 100   score: 3.0   mem len: 18385   epsilon: 1.0    steps: 267    lr: 0.0001     reward: 1.47\n",
      "epis: 101   score: 4.0   mem len: 18677   epsilon: 1.0    steps: 292    lr: 0.0001     reward: 1.5\n",
      "epis: 102   score: 0.0   mem len: 18799   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.48\n",
      "epis: 103   score: 2.0   mem len: 18997   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.49\n",
      "epis: 104   score: 1.0   mem len: 19167   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.49\n",
      "epis: 105   score: 3.0   mem len: 19397   epsilon: 1.0    steps: 230    lr: 0.0001     reward: 1.51\n",
      "epis: 106   score: 4.0   mem len: 19692   epsilon: 1.0    steps: 295    lr: 0.0001     reward: 1.55\n",
      "epis: 107   score: 3.0   mem len: 19939   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.58\n",
      "epis: 108   score: 2.0   mem len: 20136   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.6\n",
      "epis: 109   score: 1.0   mem len: 20287   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.59\n",
      "epis: 110   score: 2.0   mem len: 20505   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.59\n",
      "epis: 111   score: 2.0   mem len: 20723   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.59\n",
      "epis: 112   score: 0.0   mem len: 20846   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.59\n",
      "epis: 113   score: 3.0   mem len: 21090   epsilon: 1.0    steps: 244    lr: 0.0001     reward: 1.6\n",
      "epis: 114   score: 6.0   mem len: 21443   epsilon: 1.0    steps: 353    lr: 0.0001     reward: 1.64\n",
      "epis: 115   score: 2.0   mem len: 21662   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.63\n",
      "epis: 116   score: 0.0   mem len: 21785   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.61\n",
      "epis: 117   score: 1.0   mem len: 21954   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.6\n",
      "epis: 118   score: 2.0   mem len: 22151   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.6\n",
      "epis: 119   score: 0.0   mem len: 22273   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.59\n",
      "epis: 120   score: 0.0   mem len: 22395   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.58\n",
      "epis: 121   score: 1.0   mem len: 22564   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.51\n",
      "epis: 122   score: 1.0   mem len: 22732   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.5\n",
      "epis: 123   score: 0.0   mem len: 22854   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.48\n",
      "epis: 124   score: 1.0   mem len: 23024   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.49\n",
      "epis: 125   score: 3.0   mem len: 23267   epsilon: 1.0    steps: 243    lr: 0.0001     reward: 1.5\n",
      "epis: 126   score: 2.0   mem len: 23485   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.5\n",
      "epis: 127   score: 0.0   mem len: 23607   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.5\n",
      "epis: 128   score: 1.0   mem len: 23759   epsilon: 1.0    steps: 152    lr: 0.0001     reward: 1.5\n",
      "epis: 129   score: 0.0   mem len: 23882   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.49\n",
      "epis: 130   score: 2.0   mem len: 24080   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.51\n",
      "epis: 131   score: 1.0   mem len: 24231   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.49\n",
      "epis: 132   score: 3.0   mem len: 24463   epsilon: 1.0    steps: 232    lr: 0.0001     reward: 1.5\n",
      "epis: 133   score: 2.0   mem len: 24680   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.52\n",
      "epis: 134   score: 1.0   mem len: 24831   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.52\n",
      "epis: 135   score: 1.0   mem len: 25002   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.52\n",
      "epis: 136   score: 2.0   mem len: 25221   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.54\n",
      "epis: 137   score: 1.0   mem len: 25372   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.53\n",
      "epis: 138   score: 2.0   mem len: 25589   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.53\n",
      "epis: 139   score: 2.0   mem len: 25807   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.54\n",
      "epis: 140   score: 0.0   mem len: 25930   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.51\n",
      "epis: 141   score: 3.0   mem len: 26196   epsilon: 1.0    steps: 266    lr: 0.0001     reward: 1.51\n",
      "epis: 142   score: 2.0   mem len: 26397   epsilon: 1.0    steps: 201    lr: 0.0001     reward: 1.5\n",
      "epis: 143   score: 3.0   mem len: 26623   epsilon: 1.0    steps: 226    lr: 0.0001     reward: 1.53\n",
      "epis: 144   score: 4.0   mem len: 26924   epsilon: 1.0    steps: 301    lr: 0.0001     reward: 1.56\n",
      "epis: 145   score: 1.0   mem len: 27093   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.54\n",
      "epis: 146   score: 0.0   mem len: 27215   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.52\n",
      "epis: 147   score: 0.0   mem len: 27338   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.51\n",
      "epis: 148   score: 0.0   mem len: 27460   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.5\n",
      "epis: 149   score: 0.0   mem len: 27583   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.46\n",
      "epis: 150   score: 0.0   mem len: 27705   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.44\n",
      "epis: 151   score: 0.0   mem len: 27828   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 152   score: 0.0   mem len: 27951   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 153   score: 0.0   mem len: 28073   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.41\n",
      "epis: 154   score: 2.0   mem len: 28271   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.41\n",
      "epis: 155   score: 3.0   mem len: 28496   epsilon: 1.0    steps: 225    lr: 0.0001     reward: 1.44\n",
      "epis: 156   score: 5.0   mem len: 28839   epsilon: 1.0    steps: 343    lr: 0.0001     reward: 1.47\n",
      "epis: 157   score: 0.0   mem len: 28962   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.45\n",
      "epis: 158   score: 0.0   mem len: 29085   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.44\n",
      "epis: 159   score: 2.0   mem len: 29264   epsilon: 1.0    steps: 179    lr: 0.0001     reward: 1.44\n",
      "epis: 160   score: 1.0   mem len: 29433   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.44\n",
      "epis: 161   score: 2.0   mem len: 29632   epsilon: 1.0    steps: 199    lr: 0.0001     reward: 1.43\n",
      "epis: 162   score: 0.0   mem len: 29755   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.42\n",
      "epis: 163   score: 0.0   mem len: 29877   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.42\n",
      "epis: 164   score: 2.0   mem len: 30095   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.42\n",
      "epis: 165   score: 2.0   mem len: 30292   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.42\n",
      "epis: 166   score: 4.0   mem len: 30584   epsilon: 1.0    steps: 292    lr: 0.0001     reward: 1.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 167   score: 3.0   mem len: 30814   epsilon: 1.0    steps: 230    lr: 0.0001     reward: 1.44\n",
      "epis: 168   score: 1.0   mem len: 30982   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.43\n",
      "epis: 169   score: 1.0   mem len: 31134   epsilon: 1.0    steps: 152    lr: 0.0001     reward: 1.4\n",
      "epis: 170   score: 0.0   mem len: 31257   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.39\n",
      "epis: 171   score: 2.0   mem len: 31454   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.4\n",
      "epis: 172   score: 3.0   mem len: 31700   epsilon: 1.0    steps: 246    lr: 0.0001     reward: 1.4\n",
      "epis: 173   score: 2.0   mem len: 31897   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.42\n",
      "epis: 174   score: 0.0   mem len: 32020   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.41\n",
      "epis: 175   score: 0.0   mem len: 32143   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 176   score: 1.0   mem len: 32294   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.39\n",
      "epis: 177   score: 1.0   mem len: 32466   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.4\n",
      "epis: 178   score: 1.0   mem len: 32635   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.39\n",
      "epis: 179   score: 4.0   mem len: 32933   epsilon: 1.0    steps: 298    lr: 0.0001     reward: 1.41\n",
      "epis: 180   score: 2.0   mem len: 33114   epsilon: 1.0    steps: 181    lr: 0.0001     reward: 1.41\n",
      "epis: 181   score: 2.0   mem len: 33333   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.43\n",
      "epis: 182   score: 1.0   mem len: 33502   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.44\n",
      "epis: 183   score: 1.0   mem len: 33673   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.43\n",
      "epis: 184   score: 3.0   mem len: 33898   epsilon: 1.0    steps: 225    lr: 0.0001     reward: 1.46\n",
      "epis: 185   score: 1.0   mem len: 34069   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.46\n",
      "epis: 186   score: 2.0   mem len: 34266   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.48\n",
      "epis: 187   score: 1.0   mem len: 34438   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.47\n",
      "epis: 188   score: 3.0   mem len: 34686   epsilon: 1.0    steps: 248    lr: 0.0001     reward: 1.5\n",
      "epis: 189   score: 0.0   mem len: 34809   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.49\n",
      "epis: 190   score: 0.0   mem len: 34931   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.49\n",
      "epis: 191   score: 2.0   mem len: 35147   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.51\n",
      "epis: 192   score: 3.0   mem len: 35414   epsilon: 1.0    steps: 267    lr: 0.0001     reward: 1.51\n",
      "epis: 193   score: 0.0   mem len: 35536   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.5\n",
      "epis: 194   score: 3.0   mem len: 35783   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.52\n",
      "epis: 195   score: 2.0   mem len: 36000   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.54\n",
      "epis: 196   score: 2.0   mem len: 36197   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.54\n",
      "epis: 197   score: 4.0   mem len: 36493   epsilon: 1.0    steps: 296    lr: 0.0001     reward: 1.55\n",
      "epis: 198   score: 0.0   mem len: 36615   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.55\n",
      "epis: 199   score: 0.0   mem len: 36738   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.54\n",
      "epis: 200   score: 1.0   mem len: 36906   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.52\n",
      "epis: 201   score: 0.0   mem len: 37028   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.48\n",
      "epis: 202   score: 2.0   mem len: 37244   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.5\n",
      "epis: 203   score: 2.0   mem len: 37443   epsilon: 1.0    steps: 199    lr: 0.0001     reward: 1.5\n",
      "epis: 204   score: 4.0   mem len: 37720   epsilon: 1.0    steps: 277    lr: 0.0001     reward: 1.53\n",
      "epis: 205   score: 3.0   mem len: 37946   epsilon: 1.0    steps: 226    lr: 0.0001     reward: 1.53\n",
      "epis: 206   score: 1.0   mem len: 38117   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.5\n",
      "epis: 207   score: 1.0   mem len: 38287   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.48\n",
      "epis: 208   score: 1.0   mem len: 38456   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.47\n",
      "epis: 209   score: 1.0   mem len: 38625   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.47\n",
      "epis: 210   score: 0.0   mem len: 38748   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.45\n",
      "epis: 211   score: 2.0   mem len: 38946   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.45\n",
      "epis: 212   score: 1.0   mem len: 39097   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.46\n",
      "epis: 213   score: 1.0   mem len: 39248   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.44\n",
      "epis: 214   score: 4.0   mem len: 39527   epsilon: 1.0    steps: 279    lr: 0.0001     reward: 1.42\n",
      "epis: 215   score: 0.0   mem len: 39649   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.4\n",
      "epis: 216   score: 1.0   mem len: 39799   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.41\n",
      "epis: 217   score: 0.0   mem len: 39921   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.4\n",
      "epis: 218   score: 0.0   mem len: 40043   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.38\n",
      "epis: 219   score: 3.0   mem len: 40274   epsilon: 1.0    steps: 231    lr: 0.0001     reward: 1.41\n",
      "epis: 220   score: 1.0   mem len: 40425   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.42\n",
      "epis: 221   score: 0.0   mem len: 40548   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.41\n",
      "epis: 222   score: 1.0   mem len: 40717   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.41\n",
      "epis: 223   score: 2.0   mem len: 40935   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.43\n",
      "epis: 224   score: 0.0   mem len: 41057   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.42\n",
      "epis: 225   score: 0.0   mem len: 41180   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.39\n",
      "epis: 226   score: 0.0   mem len: 41302   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.37\n",
      "epis: 227   score: 1.0   mem len: 41473   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.38\n",
      "epis: 228   score: 2.0   mem len: 41693   epsilon: 1.0    steps: 220    lr: 0.0001     reward: 1.39\n",
      "epis: 229   score: 0.0   mem len: 41816   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.39\n",
      "epis: 230   score: 3.0   mem len: 42082   epsilon: 1.0    steps: 266    lr: 0.0001     reward: 1.4\n",
      "epis: 231   score: 6.0   mem len: 42427   epsilon: 1.0    steps: 345    lr: 0.0001     reward: 1.45\n",
      "epis: 232   score: 0.0   mem len: 42549   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.42\n",
      "epis: 233   score: 4.0   mem len: 42806   epsilon: 1.0    steps: 257    lr: 0.0001     reward: 1.44\n",
      "epis: 234   score: 3.0   mem len: 43054   epsilon: 1.0    steps: 248    lr: 0.0001     reward: 1.46\n",
      "epis: 235   score: 0.0   mem len: 43177   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.45\n",
      "epis: 236   score: 6.0   mem len: 43518   epsilon: 1.0    steps: 341    lr: 0.0001     reward: 1.49\n",
      "epis: 237   score: 2.0   mem len: 43715   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.5\n",
      "epis: 238   score: 2.0   mem len: 43895   epsilon: 1.0    steps: 180    lr: 0.0001     reward: 1.5\n",
      "epis: 239   score: 2.0   mem len: 44112   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.5\n",
      "epis: 240   score: 3.0   mem len: 44356   epsilon: 1.0    steps: 244    lr: 0.0001     reward: 1.53\n",
      "epis: 241   score: 1.0   mem len: 44524   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.51\n",
      "epis: 242   score: 0.0   mem len: 44647   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.49\n",
      "epis: 243   score: 2.0   mem len: 44865   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.48\n",
      "epis: 244   score: 1.0   mem len: 45035   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.45\n",
      "epis: 245   score: 1.0   mem len: 45204   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.45\n",
      "epis: 246   score: 3.0   mem len: 45450   epsilon: 1.0    steps: 246    lr: 0.0001     reward: 1.48\n",
      "epis: 247   score: 2.0   mem len: 45632   epsilon: 1.0    steps: 182    lr: 0.0001     reward: 1.5\n",
      "epis: 248   score: 0.0   mem len: 45755   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.5\n",
      "epis: 249   score: 2.0   mem len: 45952   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 250   score: 1.0   mem len: 46102   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.53\n",
      "epis: 251   score: 0.0   mem len: 46225   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.53\n",
      "epis: 252   score: 0.0   mem len: 46348   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.53\n",
      "epis: 253   score: 1.0   mem len: 46498   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.54\n",
      "epis: 254   score: 2.0   mem len: 46678   epsilon: 1.0    steps: 180    lr: 0.0001     reward: 1.54\n",
      "epis: 255   score: 0.0   mem len: 46800   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.51\n",
      "epis: 256   score: 3.0   mem len: 47029   epsilon: 1.0    steps: 229    lr: 0.0001     reward: 1.49\n",
      "epis: 257   score: 1.0   mem len: 47197   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.5\n",
      "epis: 258   score: 1.0   mem len: 47369   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.51\n",
      "epis: 259   score: 0.0   mem len: 47491   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.49\n",
      "epis: 260   score: 5.0   mem len: 47854   epsilon: 1.0    steps: 363    lr: 0.0001     reward: 1.53\n",
      "epis: 261   score: 1.0   mem len: 48004   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.52\n",
      "epis: 262   score: 1.0   mem len: 48173   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.53\n",
      "epis: 263   score: 4.0   mem len: 48451   epsilon: 1.0    steps: 278    lr: 0.0001     reward: 1.57\n",
      "epis: 264   score: 1.0   mem len: 48621   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.56\n",
      "epis: 265   score: 0.0   mem len: 48743   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.54\n",
      "epis: 266   score: 3.0   mem len: 49010   epsilon: 1.0    steps: 267    lr: 0.0001     reward: 1.53\n",
      "epis: 267   score: 0.0   mem len: 49133   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.5\n",
      "epis: 268   score: 3.0   mem len: 49358   epsilon: 1.0    steps: 225    lr: 0.0001     reward: 1.52\n",
      "epis: 269   score: 2.0   mem len: 49556   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.53\n",
      "epis: 270   score: 0.0   mem len: 49678   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.53\n",
      "epis: 271   score: 2.0   mem len: 49865   epsilon: 1.0    steps: 187    lr: 0.0001     reward: 1.53\n",
      "epis: 272   score: 1.0   mem len: 50034   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.51\n",
      "epis: 273   score: 1.0   mem len: 50203   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.5\n",
      "epis: 274   score: 2.0   mem len: 50424   epsilon: 1.0    steps: 221    lr: 0.0001     reward: 1.52\n",
      "epis: 275   score: 0.0   mem len: 50547   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.52\n",
      "epis: 276   score: 0.0   mem len: 50670   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.51\n",
      "epis: 277   score: 0.0   mem len: 50793   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.5\n",
      "epis: 278   score: 0.0   mem len: 50915   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.49\n",
      "epis: 279   score: 0.0   mem len: 51038   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.45\n",
      "epis: 280   score: 2.0   mem len: 51236   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.45\n",
      "epis: 281   score: 1.0   mem len: 51405   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.44\n",
      "epis: 282   score: 3.0   mem len: 51632   epsilon: 1.0    steps: 227    lr: 0.0001     reward: 1.46\n",
      "epis: 283   score: 3.0   mem len: 51877   epsilon: 1.0    steps: 245    lr: 0.0001     reward: 1.48\n",
      "epis: 284   score: 5.0   mem len: 52201   epsilon: 1.0    steps: 324    lr: 0.0001     reward: 1.5\n",
      "epis: 285   score: 0.0   mem len: 52324   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.49\n",
      "epis: 286   score: 2.0   mem len: 52540   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.49\n",
      "epis: 287   score: 2.0   mem len: 52737   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.5\n",
      "epis: 288   score: 1.0   mem len: 52905   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.48\n",
      "epis: 289   score: 1.0   mem len: 53076   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.49\n",
      "epis: 290   score: 0.0   mem len: 53199   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.49\n",
      "epis: 291   score: 2.0   mem len: 53396   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.49\n",
      "epis: 292   score: 2.0   mem len: 53593   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.48\n",
      "epis: 293   score: 2.0   mem len: 53791   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.5\n",
      "epis: 294   score: 4.0   mem len: 54108   epsilon: 1.0    steps: 317    lr: 0.0001     reward: 1.51\n",
      "epis: 295   score: 2.0   mem len: 54308   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.51\n",
      "epis: 296   score: 2.0   mem len: 54508   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.51\n",
      "epis: 297   score: 0.0   mem len: 54631   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.47\n",
      "epis: 298   score: 0.0   mem len: 54754   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.47\n",
      "epis: 299   score: 1.0   mem len: 54905   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.48\n",
      "epis: 300   score: 1.0   mem len: 55076   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.48\n",
      "epis: 301   score: 5.0   mem len: 55372   epsilon: 1.0    steps: 296    lr: 0.0001     reward: 1.53\n",
      "epis: 302   score: 0.0   mem len: 55495   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.51\n",
      "epis: 303   score: 1.0   mem len: 55664   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.5\n",
      "epis: 304   score: 2.0   mem len: 55865   epsilon: 1.0    steps: 201    lr: 0.0001     reward: 1.48\n",
      "epis: 305   score: 0.0   mem len: 55988   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.45\n",
      "epis: 306   score: 10.0   mem len: 56435   epsilon: 1.0    steps: 447    lr: 0.0001     reward: 1.54\n",
      "epis: 307   score: 1.0   mem len: 56586   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.54\n",
      "epis: 308   score: 0.0   mem len: 56708   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.53\n",
      "epis: 309   score: 0.0   mem len: 56831   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.52\n",
      "epis: 310   score: 4.0   mem len: 57090   epsilon: 1.0    steps: 259    lr: 0.0001     reward: 1.56\n",
      "epis: 311   score: 0.0   mem len: 57212   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.54\n",
      "epis: 312   score: 1.0   mem len: 57381   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.54\n",
      "epis: 313   score: 3.0   mem len: 57629   epsilon: 1.0    steps: 248    lr: 0.0001     reward: 1.56\n",
      "epis: 314   score: 2.0   mem len: 57826   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.54\n",
      "epis: 315   score: 2.0   mem len: 58026   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.56\n",
      "epis: 316   score: 0.0   mem len: 58148   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.55\n",
      "epis: 317   score: 1.0   mem len: 58299   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.56\n",
      "epis: 318   score: 0.0   mem len: 58422   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.56\n",
      "epis: 319   score: 1.0   mem len: 58573   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.54\n",
      "epis: 320   score: 1.0   mem len: 58724   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.54\n",
      "epis: 321   score: 1.0   mem len: 58894   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.55\n",
      "epis: 322   score: 0.0   mem len: 59017   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.54\n",
      "epis: 323   score: 4.0   mem len: 59295   epsilon: 1.0    steps: 278    lr: 0.0001     reward: 1.56\n",
      "epis: 324   score: 1.0   mem len: 59445   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.57\n",
      "epis: 325   score: 2.0   mem len: 59661   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.59\n",
      "epis: 326   score: 1.0   mem len: 59811   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.6\n",
      "epis: 327   score: 1.0   mem len: 59983   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.6\n",
      "epis: 328   score: 0.0   mem len: 60106   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.58\n",
      "epis: 329   score: 1.0   mem len: 60275   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.59\n",
      "epis: 330   score: 1.0   mem len: 60446   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.57\n",
      "epis: 331   score: 0.0   mem len: 60569   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.51\n",
      "epis: 332   score: 2.0   mem len: 60767   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 333   score: 0.0   mem len: 60890   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.49\n",
      "epis: 334   score: 2.0   mem len: 61109   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.48\n",
      "epis: 335   score: 3.0   mem len: 61356   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.51\n",
      "epis: 336   score: 0.0   mem len: 61479   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.45\n",
      "epis: 337   score: 1.0   mem len: 61651   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.44\n",
      "epis: 338   score: 2.0   mem len: 61867   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.44\n",
      "epis: 339   score: 0.0   mem len: 61990   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.42\n",
      "epis: 340   score: 2.0   mem len: 62188   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.41\n",
      "epis: 341   score: 0.0   mem len: 62311   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 342   score: 0.0   mem len: 62434   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 343   score: 0.0   mem len: 62557   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.38\n",
      "epis: 344   score: 3.0   mem len: 62803   epsilon: 1.0    steps: 246    lr: 0.0001     reward: 1.4\n",
      "epis: 345   score: 2.0   mem len: 63001   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.41\n",
      "epis: 346   score: 1.0   mem len: 63170   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.39\n",
      "epis: 347   score: 1.0   mem len: 63338   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.38\n",
      "epis: 348   score: 3.0   mem len: 63585   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.41\n",
      "epis: 349   score: 0.0   mem len: 63707   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.39\n",
      "epis: 350   score: 0.0   mem len: 63830   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.38\n",
      "epis: 351   score: 3.0   mem len: 64077   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.41\n",
      "epis: 352   score: 0.0   mem len: 64199   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.41\n",
      "epis: 353   score: 3.0   mem len: 64448   epsilon: 1.0    steps: 249    lr: 0.0001     reward: 1.43\n",
      "epis: 354   score: 3.0   mem len: 64695   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.44\n",
      "epis: 355   score: 0.0   mem len: 64818   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.44\n",
      "epis: 356   score: 1.0   mem len: 64986   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.42\n",
      "epis: 357   score: 5.0   mem len: 65324   epsilon: 1.0    steps: 338    lr: 0.0001     reward: 1.46\n",
      "epis: 358   score: 0.0   mem len: 65447   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.45\n",
      "epis: 359   score: 4.0   mem len: 65726   epsilon: 1.0    steps: 279    lr: 0.0001     reward: 1.49\n",
      "epis: 360   score: 1.0   mem len: 65877   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.45\n",
      "epis: 361   score: 0.0   mem len: 65999   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.44\n",
      "epis: 362   score: 5.0   mem len: 66286   epsilon: 1.0    steps: 287    lr: 0.0001     reward: 1.48\n",
      "epis: 363   score: 0.0   mem len: 66408   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.44\n",
      "epis: 364   score: 0.0   mem len: 66531   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 365   score: 1.0   mem len: 66682   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.44\n",
      "epis: 366   score: 2.0   mem len: 66880   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.43\n",
      "epis: 367   score: 3.0   mem len: 67105   epsilon: 1.0    steps: 225    lr: 0.0001     reward: 1.46\n",
      "epis: 368   score: 0.0   mem len: 67227   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.43\n",
      "epis: 369   score: 3.0   mem len: 67453   epsilon: 1.0    steps: 226    lr: 0.0001     reward: 1.44\n",
      "epis: 370   score: 0.0   mem len: 67575   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.44\n",
      "epis: 371   score: 1.0   mem len: 67744   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.43\n",
      "epis: 372   score: 2.0   mem len: 67945   epsilon: 1.0    steps: 201    lr: 0.0001     reward: 1.44\n",
      "epis: 373   score: 2.0   mem len: 68143   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.45\n",
      "epis: 374   score: 1.0   mem len: 68294   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.44\n",
      "epis: 375   score: 3.0   mem len: 68522   epsilon: 1.0    steps: 228    lr: 0.0001     reward: 1.47\n",
      "epis: 376   score: 1.0   mem len: 68692   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.48\n",
      "epis: 377   score: 1.0   mem len: 68861   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.49\n",
      "epis: 378   score: 4.0   mem len: 69156   epsilon: 1.0    steps: 295    lr: 0.0001     reward: 1.53\n",
      "epis: 379   score: 2.0   mem len: 69378   epsilon: 1.0    steps: 222    lr: 0.0001     reward: 1.55\n",
      "epis: 380   score: 2.0   mem len: 69560   epsilon: 1.0    steps: 182    lr: 0.0001     reward: 1.55\n",
      "epis: 381   score: 0.0   mem len: 69683   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.54\n",
      "epis: 382   score: 3.0   mem len: 69930   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.54\n",
      "epis: 383   score: 1.0   mem len: 70081   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.52\n",
      "epis: 384   score: 2.0   mem len: 70281   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.49\n",
      "epis: 385   score: 1.0   mem len: 70432   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.5\n",
      "epis: 386   score: 2.0   mem len: 70649   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.5\n",
      "epis: 387   score: 3.0   mem len: 70896   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.51\n",
      "epis: 388   score: 0.0   mem len: 71019   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.5\n",
      "epis: 389   score: 1.0   mem len: 71170   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.5\n",
      "epis: 390   score: 1.0   mem len: 71321   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.51\n",
      "epis: 391   score: 1.0   mem len: 71471   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.5\n",
      "epis: 392   score: 0.0   mem len: 71594   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.48\n",
      "epis: 393   score: 1.0   mem len: 71745   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.47\n",
      "epis: 394   score: 1.0   mem len: 71896   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.44\n",
      "epis: 395   score: 3.0   mem len: 72141   epsilon: 1.0    steps: 245    lr: 0.0001     reward: 1.45\n",
      "epis: 396   score: 2.0   mem len: 72338   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.45\n",
      "epis: 397   score: 4.0   mem len: 72617   epsilon: 1.0    steps: 279    lr: 0.0001     reward: 1.49\n",
      "epis: 398   score: 0.0   mem len: 72740   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.49\n",
      "epis: 399   score: 0.0   mem len: 72863   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.48\n",
      "epis: 400   score: 1.0   mem len: 73032   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.48\n",
      "epis: 401   score: 0.0   mem len: 73155   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 402   score: 0.0   mem len: 73278   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 403   score: 2.0   mem len: 73475   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.44\n",
      "epis: 404   score: 0.0   mem len: 73598   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.42\n",
      "epis: 405   score: 1.0   mem len: 73768   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.43\n",
      "epis: 406   score: 1.0   mem len: 73937   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.34\n",
      "epis: 407   score: 2.0   mem len: 74155   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.35\n",
      "epis: 408   score: 0.0   mem len: 74277   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.35\n",
      "epis: 409   score: 2.0   mem len: 74474   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.37\n",
      "epis: 410   score: 0.0   mem len: 74597   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.33\n",
      "epis: 411   score: 1.0   mem len: 74765   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.34\n",
      "epis: 412   score: 0.0   mem len: 74888   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.33\n",
      "epis: 413   score: 2.0   mem len: 75106   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.32\n",
      "epis: 414   score: 1.0   mem len: 75274   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.31\n",
      "epis: 415   score: 0.0   mem len: 75397   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 416   score: 0.0   mem len: 75520   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.29\n",
      "epis: 417   score: 4.0   mem len: 75817   epsilon: 1.0    steps: 297    lr: 0.0001     reward: 1.32\n",
      "epis: 418   score: 4.0   mem len: 76096   epsilon: 1.0    steps: 279    lr: 0.0001     reward: 1.36\n",
      "epis: 419   score: 3.0   mem len: 76321   epsilon: 1.0    steps: 225    lr: 0.0001     reward: 1.38\n",
      "epis: 420   score: 0.0   mem len: 76444   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.37\n",
      "epis: 421   score: 0.0   mem len: 76566   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.36\n",
      "epis: 422   score: 0.0   mem len: 76689   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.36\n",
      "epis: 423   score: 0.0   mem len: 76811   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.32\n",
      "epis: 424   score: 0.0   mem len: 76934   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.31\n",
      "epis: 425   score: 0.0   mem len: 77056   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.29\n",
      "epis: 426   score: 0.0   mem len: 77179   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.28\n",
      "epis: 427   score: 0.0   mem len: 77301   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.27\n",
      "epis: 428   score: 0.0   mem len: 77424   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.27\n",
      "epis: 429   score: 2.0   mem len: 77622   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.28\n",
      "epis: 430   score: 0.0   mem len: 77745   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.27\n",
      "epis: 431   score: 2.0   mem len: 77964   epsilon: 1.0    steps: 219    lr: 0.0001     reward: 1.29\n",
      "epis: 432   score: 2.0   mem len: 78162   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.29\n",
      "epis: 433   score: 0.0   mem len: 78284   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.29\n",
      "epis: 434   score: 3.0   mem len: 78549   epsilon: 1.0    steps: 265    lr: 0.0001     reward: 1.3\n",
      "epis: 435   score: 3.0   mem len: 78795   epsilon: 1.0    steps: 246    lr: 0.0001     reward: 1.3\n",
      "epis: 436   score: 0.0   mem len: 78918   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.3\n",
      "epis: 437   score: 2.0   mem len: 79135   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.31\n",
      "epis: 438   score: 0.0   mem len: 79258   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.29\n",
      "epis: 439   score: 0.0   mem len: 79380   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.29\n",
      "epis: 440   score: 4.0   mem len: 79675   epsilon: 1.0    steps: 295    lr: 0.0001     reward: 1.31\n",
      "epis: 441   score: 1.0   mem len: 79826   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.32\n",
      "epis: 442   score: 0.0   mem len: 79949   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.32\n",
      "epis: 443   score: 3.0   mem len: 80216   epsilon: 1.0    steps: 267    lr: 0.0001     reward: 1.35\n",
      "epis: 444   score: 1.0   mem len: 80366   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.33\n",
      "epis: 445   score: 1.0   mem len: 80536   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.32\n",
      "epis: 446   score: 3.0   mem len: 80762   epsilon: 1.0    steps: 226    lr: 0.0001     reward: 1.34\n",
      "epis: 447   score: 0.0   mem len: 80885   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.33\n",
      "epis: 448   score: 4.0   mem len: 81146   epsilon: 1.0    steps: 261    lr: 0.0001     reward: 1.34\n",
      "epis: 449   score: 1.0   mem len: 81316   epsilon: 1.0    steps: 170    lr: 0.0001     reward: 1.35\n",
      "epis: 450   score: 0.0   mem len: 81439   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.35\n",
      "epis: 451   score: 0.0   mem len: 81561   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.32\n",
      "epis: 452   score: 1.0   mem len: 81711   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.33\n",
      "epis: 453   score: 2.0   mem len: 81911   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.32\n",
      "epis: 454   score: 2.0   mem len: 82109   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.31\n",
      "epis: 455   score: 3.0   mem len: 82374   epsilon: 1.0    steps: 265    lr: 0.0001     reward: 1.34\n",
      "epis: 456   score: 0.0   mem len: 82497   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.33\n",
      "epis: 457   score: 2.0   mem len: 82712   epsilon: 1.0    steps: 215    lr: 0.0001     reward: 1.3\n",
      "epis: 458   score: 2.0   mem len: 82909   epsilon: 1.0    steps: 197    lr: 0.0001     reward: 1.32\n",
      "epis: 459   score: 2.0   mem len: 83111   epsilon: 1.0    steps: 202    lr: 0.0001     reward: 1.3\n",
      "epis: 460   score: 2.0   mem len: 83293   epsilon: 1.0    steps: 182    lr: 0.0001     reward: 1.31\n",
      "epis: 461   score: 1.0   mem len: 83444   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.32\n",
      "epis: 462   score: 3.0   mem len: 83691   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.3\n",
      "epis: 463   score: 0.0   mem len: 83813   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.3\n",
      "epis: 464   score: 1.0   mem len: 83964   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.31\n",
      "epis: 465   score: 0.0   mem len: 84086   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.3\n",
      "epis: 466   score: 2.0   mem len: 84304   epsilon: 1.0    steps: 218    lr: 0.0001     reward: 1.3\n",
      "epis: 467   score: 1.0   mem len: 84475   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.28\n",
      "epis: 468   score: 1.0   mem len: 84646   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.29\n",
      "epis: 469   score: 1.0   mem len: 84815   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.27\n",
      "epis: 470   score: 1.0   mem len: 84966   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.28\n",
      "epis: 471   score: 3.0   mem len: 85194   epsilon: 1.0    steps: 228    lr: 0.0001     reward: 1.3\n",
      "epis: 472   score: 2.0   mem len: 85394   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.3\n",
      "epis: 473   score: 3.0   mem len: 85639   epsilon: 1.0    steps: 245    lr: 0.0001     reward: 1.31\n",
      "epis: 474   score: 3.0   mem len: 85887   epsilon: 1.0    steps: 248    lr: 0.0001     reward: 1.33\n",
      "epis: 475   score: 0.0   mem len: 86009   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.3\n",
      "epis: 476   score: 1.0   mem len: 86178   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.3\n",
      "epis: 477   score: 0.0   mem len: 86301   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.29\n",
      "epis: 478   score: 3.0   mem len: 86530   epsilon: 1.0    steps: 229    lr: 0.0001     reward: 1.28\n",
      "epis: 479   score: 2.0   mem len: 86732   epsilon: 1.0    steps: 202    lr: 0.0001     reward: 1.28\n",
      "epis: 480   score: 2.0   mem len: 86952   epsilon: 1.0    steps: 220    lr: 0.0001     reward: 1.28\n",
      "epis: 481   score: 0.0   mem len: 87075   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.28\n",
      "epis: 482   score: 2.0   mem len: 87276   epsilon: 1.0    steps: 201    lr: 0.0001     reward: 1.27\n",
      "epis: 483   score: 0.0   mem len: 87398   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.26\n",
      "epis: 484   score: 1.0   mem len: 87550   epsilon: 1.0    steps: 152    lr: 0.0001     reward: 1.25\n",
      "epis: 485   score: 2.0   mem len: 87748   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.26\n",
      "epis: 486   score: 1.0   mem len: 87917   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.25\n",
      "epis: 487   score: 1.0   mem len: 88068   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.23\n",
      "epis: 488   score: 1.0   mem len: 88218   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.24\n",
      "epis: 489   score: 2.0   mem len: 88398   epsilon: 1.0    steps: 180    lr: 0.0001     reward: 1.25\n",
      "epis: 490   score: 1.0   mem len: 88549   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.25\n",
      "epis: 491   score: 2.0   mem len: 88749   epsilon: 1.0    steps: 200    lr: 0.0001     reward: 1.26\n",
      "epis: 492   score: 5.0   mem len: 89115   epsilon: 1.0    steps: 366    lr: 0.0001     reward: 1.31\n",
      "epis: 493   score: 1.0   mem len: 89284   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.31\n",
      "epis: 494   score: 1.0   mem len: 89456   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.31\n",
      "epis: 495   score: 1.0   mem len: 89625   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.29\n",
      "epis: 496   score: 1.0   mem len: 89794   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.28\n",
      "epis: 497   score: 2.0   mem len: 90010   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.26\n",
      "epis: 498   score: 0.0   mem len: 90133   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 499   score: 3.0   mem len: 90381   epsilon: 1.0    steps: 248    lr: 0.0001     reward: 1.29\n",
      "epis: 500   score: 1.0   mem len: 90531   epsilon: 1.0    steps: 150    lr: 0.0001     reward: 1.29\n",
      "epis: 501   score: 0.0   mem len: 90653   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.29\n",
      "epis: 502   score: 3.0   mem len: 90900   epsilon: 1.0    steps: 247    lr: 0.0001     reward: 1.32\n",
      "epis: 503   score: 1.0   mem len: 91069   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.31\n",
      "epis: 504   score: 1.0   mem len: 91240   epsilon: 1.0    steps: 171    lr: 0.0001     reward: 1.32\n",
      "epis: 505   score: 0.0   mem len: 91363   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.31\n",
      "epis: 506   score: 4.0   mem len: 91622   epsilon: 1.0    steps: 259    lr: 0.0001     reward: 1.34\n",
      "epis: 507   score: 3.0   mem len: 91868   epsilon: 1.0    steps: 246    lr: 0.0001     reward: 1.35\n",
      "epis: 508   score: 0.0   mem len: 91991   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.35\n",
      "epis: 509   score: 3.0   mem len: 92237   epsilon: 1.0    steps: 246    lr: 0.0001     reward: 1.36\n",
      "epis: 510   score: 2.0   mem len: 92435   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.38\n",
      "epis: 511   score: 2.0   mem len: 92633   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.39\n",
      "epis: 512   score: 0.0   mem len: 92755   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.39\n",
      "epis: 513   score: 0.0   mem len: 92878   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.37\n",
      "epis: 514   score: 1.0   mem len: 93047   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.37\n",
      "epis: 515   score: 0.0   mem len: 93170   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.37\n",
      "epis: 516   score: 1.0   mem len: 93321   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.38\n",
      "epis: 517   score: 0.0   mem len: 93444   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.34\n",
      "epis: 518   score: 0.0   mem len: 93567   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.3\n",
      "epis: 519   score: 0.0   mem len: 93690   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.27\n",
      "epis: 520   score: 1.0   mem len: 93841   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.28\n",
      "epis: 521   score: 2.0   mem len: 94039   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.3\n",
      "epis: 522   score: 1.0   mem len: 94190   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.31\n",
      "epis: 523   score: 1.0   mem len: 94341   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.32\n",
      "epis: 524   score: 2.0   mem len: 94557   epsilon: 1.0    steps: 216    lr: 0.0001     reward: 1.34\n",
      "epis: 525   score: 0.0   mem len: 94680   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.34\n",
      "epis: 526   score: 4.0   mem len: 94955   epsilon: 1.0    steps: 275    lr: 0.0001     reward: 1.38\n",
      "epis: 527   score: 0.0   mem len: 95078   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.38\n",
      "epis: 528   score: 3.0   mem len: 95326   epsilon: 1.0    steps: 248    lr: 0.0001     reward: 1.41\n",
      "epis: 529   score: 1.0   mem len: 95495   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.4\n",
      "epis: 530   score: 5.0   mem len: 95820   epsilon: 1.0    steps: 325    lr: 0.0001     reward: 1.45\n",
      "epis: 531   score: 0.0   mem len: 95943   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 532   score: 1.0   mem len: 96115   epsilon: 1.0    steps: 172    lr: 0.0001     reward: 1.42\n",
      "epis: 533   score: 2.0   mem len: 96336   epsilon: 1.0    steps: 221    lr: 0.0001     reward: 1.44\n",
      "epis: 534   score: 2.0   mem len: 96516   epsilon: 1.0    steps: 180    lr: 0.0001     reward: 1.43\n",
      "epis: 535   score: 1.0   mem len: 96684   epsilon: 1.0    steps: 168    lr: 0.0001     reward: 1.41\n",
      "epis: 536   score: 0.0   mem len: 96807   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.41\n",
      "epis: 537   score: 0.0   mem len: 96929   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.39\n",
      "epis: 538   score: 0.0   mem len: 97051   epsilon: 1.0    steps: 122    lr: 0.0001     reward: 1.39\n",
      "epis: 539   score: 3.0   mem len: 97277   epsilon: 1.0    steps: 226    lr: 0.0001     reward: 1.42\n",
      "epis: 540   score: 3.0   mem len: 97508   epsilon: 1.0    steps: 231    lr: 0.0001     reward: 1.41\n",
      "epis: 541   score: 3.0   mem len: 97753   epsilon: 1.0    steps: 245    lr: 0.0001     reward: 1.43\n",
      "epis: 542   score: 2.0   mem len: 97970   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.45\n",
      "epis: 543   score: 1.0   mem len: 98139   epsilon: 1.0    steps: 169    lr: 0.0001     reward: 1.43\n",
      "epis: 544   score: 2.0   mem len: 98337   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.44\n",
      "epis: 545   score: 2.0   mem len: 98552   epsilon: 1.0    steps: 215    lr: 0.0001     reward: 1.45\n",
      "epis: 546   score: 2.0   mem len: 98769   epsilon: 1.0    steps: 217    lr: 0.0001     reward: 1.44\n",
      "epis: 547   score: 0.0   mem len: 98892   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.44\n",
      "epis: 548   score: 1.0   mem len: 99043   epsilon: 1.0    steps: 151    lr: 0.0001     reward: 1.41\n",
      "epis: 549   score: 0.0   mem len: 99166   epsilon: 1.0    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 550   score: 2.0   mem len: 99364   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.42\n",
      "epis: 551   score: 2.0   mem len: 99562   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.44\n",
      "epis: 552   score: 2.0   mem len: 99760   epsilon: 1.0    steps: 198    lr: 0.0001     reward: 1.45\n",
      "epis: 553   score: 2.0   mem len: 99940   epsilon: 1.0    steps: 180    lr: 0.0001     reward: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiwenjon/Documents/Spring2023/Deep-Learning-for-CV/spring2023/MP5/assignment5_materials/assignment5_materials/memory.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sample = np.array(sample)\n",
      "/home/kaiwenjon/Documents/Spring2023/Deep-Learning-for-CV/spring2023/MP5/assignment5_materials/assignment5_materials/agent.py:76: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mini_batch = np.array(mini_batch).transpose()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 554   score: 2.0   mem len: 100137   epsilon: 0.9997    steps: 197    lr: 0.0001     reward: 1.45\n",
      "epis: 555   score: 0.0   mem len: 100260   epsilon: 0.9995    steps: 123    lr: 0.0001     reward: 1.42\n",
      "epis: 556   score: 1.0   mem len: 100411   epsilon: 0.9992    steps: 151    lr: 0.0001     reward: 1.43\n",
      "epis: 557   score: 4.0   mem len: 100687   epsilon: 0.9986    steps: 276    lr: 0.0001     reward: 1.45\n",
      "epis: 558   score: 3.0   mem len: 100955   epsilon: 0.9981    steps: 268    lr: 0.0001     reward: 1.46\n",
      "epis: 559   score: 0.0   mem len: 101078   epsilon: 0.9979    steps: 123    lr: 0.0001     reward: 1.44\n",
      "epis: 560   score: 0.0   mem len: 101201   epsilon: 0.9976    steps: 123    lr: 0.0001     reward: 1.42\n",
      "epis: 561   score: 2.0   mem len: 101419   epsilon: 0.9972    steps: 218    lr: 0.0001     reward: 1.43\n",
      "epis: 562   score: 1.0   mem len: 101570   epsilon: 0.9969    steps: 151    lr: 0.0001     reward: 1.41\n",
      "epis: 563   score: 2.0   mem len: 101767   epsilon: 0.9965    steps: 197    lr: 0.0001     reward: 1.43\n",
      "epis: 564   score: 1.0   mem len: 101935   epsilon: 0.9962    steps: 168    lr: 0.0001     reward: 1.43\n",
      "epis: 565   score: 2.0   mem len: 102132   epsilon: 0.9958    steps: 197    lr: 0.0001     reward: 1.45\n",
      "epis: 566   score: 1.0   mem len: 102301   epsilon: 0.9954    steps: 169    lr: 0.0001     reward: 1.44\n",
      "epis: 567   score: 1.0   mem len: 102469   epsilon: 0.9951    steps: 168    lr: 0.0001     reward: 1.44\n",
      "epis: 568   score: 0.0   mem len: 102592   epsilon: 0.9949    steps: 123    lr: 0.0001     reward: 1.43\n",
      "epis: 569   score: 0.0   mem len: 102715   epsilon: 0.9946    steps: 123    lr: 0.0001     reward: 1.42\n",
      "epis: 570   score: 5.0   mem len: 103059   epsilon: 0.9939    steps: 344    lr: 0.0001     reward: 1.46\n",
      "epis: 571   score: 4.0   mem len: 103334   epsilon: 0.9934    steps: 275    lr: 0.0001     reward: 1.47\n",
      "epis: 572   score: 2.0   mem len: 103531   epsilon: 0.993    steps: 197    lr: 0.0001     reward: 1.47\n",
      "epis: 573   score: 0.0   mem len: 103654   epsilon: 0.9928    steps: 123    lr: 0.0001     reward: 1.44\n",
      "epis: 574   score: 3.0   mem len: 103902   epsilon: 0.9923    steps: 248    lr: 0.0001     reward: 1.44\n",
      "epis: 575   score: 1.0   mem len: 104073   epsilon: 0.9919    steps: 171    lr: 0.0001     reward: 1.45\n",
      "epis: 576   score: 0.0   mem len: 104195   epsilon: 0.9917    steps: 122    lr: 0.0001     reward: 1.44\n",
      "epis: 577   score: 0.0   mem len: 104317   epsilon: 0.9915    steps: 122    lr: 0.0001     reward: 1.44\n",
      "epis: 578   score: 0.0   mem len: 104440   epsilon: 0.9912    steps: 123    lr: 0.0001     reward: 1.41\n",
      "epis: 579   score: 1.0   mem len: 104609   epsilon: 0.9909    steps: 169    lr: 0.0001     reward: 1.4\n",
      "epis: 580   score: 0.0   mem len: 104732   epsilon: 0.9906    steps: 123    lr: 0.0001     reward: 1.38\n",
      "epis: 581   score: 1.0   mem len: 104904   epsilon: 0.9903    steps: 172    lr: 0.0001     reward: 1.39\n",
      "epis: 582   score: 1.0   mem len: 105074   epsilon: 0.99    steps: 170    lr: 0.0001     reward: 1.38\n",
      "epis: 583   score: 1.0   mem len: 105226   epsilon: 0.9897    steps: 152    lr: 0.0001     reward: 1.39\n",
      "epis: 584   score: 1.0   mem len: 105395   epsilon: 0.9893    steps: 169    lr: 0.0001     reward: 1.39\n",
      "epis: 585   score: 1.0   mem len: 105546   epsilon: 0.989    steps: 151    lr: 0.0001     reward: 1.38\n",
      "epis: 586   score: 0.0   mem len: 105669   epsilon: 0.9888    steps: 123    lr: 0.0001     reward: 1.37\n",
      "epis: 587   score: 0.0   mem len: 105792   epsilon: 0.9885    steps: 123    lr: 0.0001     reward: 1.36\n",
      "epis: 588   score: 2.0   mem len: 105992   epsilon: 0.9881    steps: 200    lr: 0.0001     reward: 1.37\n",
      "epis: 589   score: 0.0   mem len: 106114   epsilon: 0.9879    steps: 122    lr: 0.0001     reward: 1.35\n",
      "epis: 590   score: 3.0   mem len: 106359   epsilon: 0.9874    steps: 245    lr: 0.0001     reward: 1.37\n",
      "epis: 591   score: 3.0   mem len: 106625   epsilon: 0.9869    steps: 266    lr: 0.0001     reward: 1.38\n",
      "epis: 592   score: 0.0   mem len: 106748   epsilon: 0.9866    steps: 123    lr: 0.0001     reward: 1.33\n",
      "epis: 593   score: 3.0   mem len: 106977   epsilon: 0.9862    steps: 229    lr: 0.0001     reward: 1.35\n",
      "epis: 594   score: 1.0   mem len: 107146   epsilon: 0.9858    steps: 169    lr: 0.0001     reward: 1.35\n",
      "epis: 595   score: 1.0   mem len: 107315   epsilon: 0.9855    steps: 169    lr: 0.0001     reward: 1.35\n",
      "epis: 596   score: 2.0   mem len: 107513   epsilon: 0.9851    steps: 198    lr: 0.0001     reward: 1.36\n",
      "epis: 597   score: 1.0   mem len: 107684   epsilon: 0.9848    steps: 171    lr: 0.0001     reward: 1.35\n",
      "epis: 598   score: 1.0   mem len: 107834   epsilon: 0.9845    steps: 150    lr: 0.0001     reward: 1.36\n",
      "epis: 599   score: 1.0   mem len: 107984   epsilon: 0.9842    steps: 150    lr: 0.0001     reward: 1.34\n",
      "epis: 600   score: 2.0   mem len: 108184   epsilon: 0.9838    steps: 200    lr: 0.0001     reward: 1.35\n",
      "epis: 601   score: 2.0   mem len: 108382   epsilon: 0.9834    steps: 198    lr: 0.0001     reward: 1.37\n",
      "epis: 602   score: 0.0   mem len: 108505   epsilon: 0.9832    steps: 123    lr: 0.0001     reward: 1.34\n",
      "epis: 603   score: 4.0   mem len: 108819   epsilon: 0.9825    steps: 314    lr: 0.0001     reward: 1.37\n",
      "epis: 604   score: 1.0   mem len: 108970   epsilon: 0.9822    steps: 151    lr: 0.0001     reward: 1.37\n",
      "epis: 605   score: 1.0   mem len: 109139   epsilon: 0.9819    steps: 169    lr: 0.0001     reward: 1.38\n",
      "epis: 606   score: 4.0   mem len: 109434   epsilon: 0.9813    steps: 295    lr: 0.0001     reward: 1.38\n",
      "epis: 607   score: 1.0   mem len: 109603   epsilon: 0.981    steps: 169    lr: 0.0001     reward: 1.36\n",
      "epis: 608   score: 2.0   mem len: 109803   epsilon: 0.9806    steps: 200    lr: 0.0001     reward: 1.38\n",
      "epis: 609   score: 3.0   mem len: 110073   epsilon: 0.9801    steps: 270    lr: 0.0001     reward: 1.38\n",
      "epis: 610   score: 6.0   mem len: 110401   epsilon: 0.9794    steps: 328    lr: 0.0001     reward: 1.42\n",
      "epis: 611   score: 0.0   mem len: 110524   epsilon: 0.9792    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 612   score: 3.0   mem len: 110736   epsilon: 0.9787    steps: 212    lr: 0.0001     reward: 1.43\n",
      "epis: 613   score: 3.0   mem len: 110981   epsilon: 0.9783    steps: 245    lr: 0.0001     reward: 1.46\n",
      "epis: 614   score: 0.0   mem len: 111103   epsilon: 0.978    steps: 122    lr: 0.0001     reward: 1.45\n",
      "epis: 615   score: 1.0   mem len: 111272   epsilon: 0.9777    steps: 169    lr: 0.0001     reward: 1.46\n",
      "epis: 616   score: 1.0   mem len: 111423   epsilon: 0.9774    steps: 151    lr: 0.0001     reward: 1.46\n",
      "epis: 617   score: 3.0   mem len: 111688   epsilon: 0.9769    steps: 265    lr: 0.0001     reward: 1.49\n",
      "epis: 618   score: 1.0   mem len: 111858   epsilon: 0.9765    steps: 170    lr: 0.0001     reward: 1.5\n",
      "epis: 619   score: 4.0   mem len: 112116   epsilon: 0.976    steps: 258    lr: 0.0001     reward: 1.54\n",
      "epis: 620   score: 4.0   mem len: 112371   epsilon: 0.9755    steps: 255    lr: 0.0001     reward: 1.57\n",
      "epis: 621   score: 1.0   mem len: 112522   epsilon: 0.9752    steps: 151    lr: 0.0001     reward: 1.56\n",
      "epis: 622   score: 3.0   mem len: 112769   epsilon: 0.9747    steps: 247    lr: 0.0001     reward: 1.58\n",
      "epis: 623   score: 4.0   mem len: 113086   epsilon: 0.9741    steps: 317    lr: 0.0001     reward: 1.61\n",
      "epis: 624   score: 3.0   mem len: 113314   epsilon: 0.9736    steps: 228    lr: 0.0001     reward: 1.62\n",
      "epis: 625   score: 0.0   mem len: 113437   epsilon: 0.9734    steps: 123    lr: 0.0001     reward: 1.62\n",
      "epis: 626   score: 1.0   mem len: 113608   epsilon: 0.9731    steps: 171    lr: 0.0001     reward: 1.59\n",
      "epis: 627   score: 1.0   mem len: 113759   epsilon: 0.9728    steps: 151    lr: 0.0001     reward: 1.6\n",
      "epis: 628   score: 2.0   mem len: 113957   epsilon: 0.9724    steps: 198    lr: 0.0001     reward: 1.59\n",
      "epis: 629   score: 0.0   mem len: 114080   epsilon: 0.9721    steps: 123    lr: 0.0001     reward: 1.58\n",
      "epis: 630   score: 3.0   mem len: 114324   epsilon: 0.9716    steps: 244    lr: 0.0001     reward: 1.56\n",
      "epis: 631   score: 0.0   mem len: 114446   epsilon: 0.9714    steps: 122    lr: 0.0001     reward: 1.56\n",
      "epis: 632   score: 0.0   mem len: 114569   epsilon: 0.9712    steps: 123    lr: 0.0001     reward: 1.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 633   score: 2.0   mem len: 114790   epsilon: 0.9707    steps: 221    lr: 0.0001     reward: 1.55\n",
      "epis: 634   score: 3.0   mem len: 115025   epsilon: 0.9702    steps: 235    lr: 0.0001     reward: 1.56\n",
      "epis: 635   score: 1.0   mem len: 115193   epsilon: 0.9699    steps: 168    lr: 0.0001     reward: 1.56\n",
      "epis: 636   score: 0.0   mem len: 115316   epsilon: 0.9697    steps: 123    lr: 0.0001     reward: 1.56\n",
      "epis: 637   score: 3.0   mem len: 115584   epsilon: 0.9691    steps: 268    lr: 0.0001     reward: 1.59\n",
      "epis: 638   score: 1.0   mem len: 115752   epsilon: 0.9688    steps: 168    lr: 0.0001     reward: 1.6\n",
      "epis: 639   score: 2.0   mem len: 115949   epsilon: 0.9684    steps: 197    lr: 0.0001     reward: 1.59\n",
      "epis: 640   score: 0.0   mem len: 116071   epsilon: 0.9682    steps: 122    lr: 0.0001     reward: 1.56\n",
      "epis: 641   score: 1.0   mem len: 116242   epsilon: 0.9678    steps: 171    lr: 0.0001     reward: 1.54\n",
      "epis: 642   score: 1.0   mem len: 116412   epsilon: 0.9675    steps: 170    lr: 0.0001     reward: 1.53\n",
      "epis: 643   score: 0.0   mem len: 116535   epsilon: 0.9673    steps: 123    lr: 0.0001     reward: 1.52\n",
      "epis: 644   score: 0.0   mem len: 116658   epsilon: 0.967    steps: 123    lr: 0.0001     reward: 1.5\n",
      "epis: 645   score: 0.0   mem len: 116781   epsilon: 0.9668    steps: 123    lr: 0.0001     reward: 1.48\n",
      "epis: 646   score: 0.0   mem len: 116904   epsilon: 0.9665    steps: 123    lr: 0.0001     reward: 1.46\n",
      "epis: 647   score: 2.0   mem len: 117083   epsilon: 0.9662    steps: 179    lr: 0.0001     reward: 1.48\n",
      "epis: 648   score: 1.0   mem len: 117255   epsilon: 0.9658    steps: 172    lr: 0.0001     reward: 1.48\n",
      "epis: 649   score: 3.0   mem len: 117524   epsilon: 0.9653    steps: 269    lr: 0.0001     reward: 1.51\n",
      "epis: 650   score: 0.0   mem len: 117647   epsilon: 0.9651    steps: 123    lr: 0.0001     reward: 1.49\n",
      "epis: 651   score: 1.0   mem len: 117797   epsilon: 0.9648    steps: 150    lr: 0.0001     reward: 1.48\n",
      "epis: 652   score: 4.0   mem len: 118093   epsilon: 0.9642    steps: 296    lr: 0.0001     reward: 1.5\n",
      "epis: 653   score: 1.0   mem len: 118263   epsilon: 0.9638    steps: 170    lr: 0.0001     reward: 1.49\n",
      "epis: 654   score: 0.0   mem len: 118386   epsilon: 0.9636    steps: 123    lr: 0.0001     reward: 1.47\n",
      "epis: 655   score: 2.0   mem len: 118604   epsilon: 0.9632    steps: 218    lr: 0.0001     reward: 1.49\n",
      "epis: 656   score: 5.0   mem len: 118912   epsilon: 0.9626    steps: 308    lr: 0.0001     reward: 1.53\n",
      "epis: 657   score: 3.0   mem len: 119182   epsilon: 0.962    steps: 270    lr: 0.0001     reward: 1.52\n",
      "epis: 658   score: 1.0   mem len: 119351   epsilon: 0.9617    steps: 169    lr: 0.0001     reward: 1.5\n",
      "epis: 659   score: 2.0   mem len: 119549   epsilon: 0.9613    steps: 198    lr: 0.0001     reward: 1.52\n",
      "epis: 660   score: 1.0   mem len: 119718   epsilon: 0.961    steps: 169    lr: 0.0001     reward: 1.53\n",
      "epis: 661   score: 2.0   mem len: 119934   epsilon: 0.9605    steps: 216    lr: 0.0001     reward: 1.53\n",
      "epis: 662   score: 0.0   mem len: 120056   epsilon: 0.9603    steps: 122    lr: 0.0001     reward: 1.52\n",
      "epis: 663   score: 1.0   mem len: 120207   epsilon: 0.96    steps: 151    lr: 0.0001     reward: 1.51\n",
      "epis: 664   score: 2.0   mem len: 120405   epsilon: 0.9596    steps: 198    lr: 0.0001     reward: 1.52\n",
      "epis: 665   score: 2.0   mem len: 120602   epsilon: 0.9592    steps: 197    lr: 0.0001     reward: 1.52\n",
      "epis: 666   score: 1.0   mem len: 120772   epsilon: 0.9589    steps: 170    lr: 0.0001     reward: 1.52\n",
      "epis: 667   score: 2.0   mem len: 120970   epsilon: 0.9585    steps: 198    lr: 0.0001     reward: 1.53\n",
      "epis: 668   score: 1.0   mem len: 121120   epsilon: 0.9582    steps: 150    lr: 0.0001     reward: 1.54\n",
      "epis: 669   score: 2.0   mem len: 121302   epsilon: 0.9578    steps: 182    lr: 0.0001     reward: 1.56\n",
      "epis: 670   score: 0.0   mem len: 121424   epsilon: 0.9576    steps: 122    lr: 0.0001     reward: 1.51\n",
      "epis: 671   score: 2.0   mem len: 121642   epsilon: 0.9571    steps: 218    lr: 0.0001     reward: 1.49\n",
      "epis: 672   score: 0.0   mem len: 121765   epsilon: 0.9569    steps: 123    lr: 0.0001     reward: 1.47\n",
      "epis: 673   score: 0.0   mem len: 121888   epsilon: 0.9567    steps: 123    lr: 0.0001     reward: 1.47\n",
      "epis: 674   score: 0.0   mem len: 122010   epsilon: 0.9564    steps: 122    lr: 0.0001     reward: 1.44\n",
      "epis: 675   score: 3.0   mem len: 122261   epsilon: 0.9559    steps: 251    lr: 0.0001     reward: 1.46\n",
      "epis: 676   score: 1.0   mem len: 122429   epsilon: 0.9556    steps: 168    lr: 0.0001     reward: 1.47\n",
      "epis: 677   score: 0.0   mem len: 122551   epsilon: 0.9553    steps: 122    lr: 0.0001     reward: 1.47\n",
      "epis: 678   score: 2.0   mem len: 122767   epsilon: 0.9549    steps: 216    lr: 0.0001     reward: 1.49\n",
      "epis: 679   score: 0.0   mem len: 122890   epsilon: 0.9547    steps: 123    lr: 0.0001     reward: 1.48\n",
      "epis: 680   score: 1.0   mem len: 123059   epsilon: 0.9543    steps: 169    lr: 0.0001     reward: 1.49\n",
      "epis: 681   score: 0.0   mem len: 123182   epsilon: 0.9541    steps: 123    lr: 0.0001     reward: 1.48\n",
      "epis: 682   score: 1.0   mem len: 123332   epsilon: 0.9538    steps: 150    lr: 0.0001     reward: 1.48\n",
      "epis: 683   score: 1.0   mem len: 123503   epsilon: 0.9535    steps: 171    lr: 0.0001     reward: 1.48\n",
      "epis: 684   score: 1.0   mem len: 123672   epsilon: 0.9531    steps: 169    lr: 0.0001     reward: 1.48\n",
      "epis: 685   score: 4.0   mem len: 123964   epsilon: 0.9525    steps: 292    lr: 0.0001     reward: 1.51\n",
      "epis: 686   score: 0.0   mem len: 124087   epsilon: 0.9523    steps: 123    lr: 0.0001     reward: 1.51\n",
      "epis: 687   score: 0.0   mem len: 124210   epsilon: 0.9521    steps: 123    lr: 0.0001     reward: 1.51\n",
      "epis: 688   score: 1.0   mem len: 124361   epsilon: 0.9518    steps: 151    lr: 0.0001     reward: 1.5\n",
      "epis: 689   score: 1.0   mem len: 124532   epsilon: 0.9514    steps: 171    lr: 0.0001     reward: 1.51\n",
      "epis: 690   score: 2.0   mem len: 124730   epsilon: 0.951    steps: 198    lr: 0.0001     reward: 1.5\n",
      "epis: 691   score: 3.0   mem len: 124942   epsilon: 0.9506    steps: 212    lr: 0.0001     reward: 1.5\n",
      "epis: 692   score: 2.0   mem len: 125140   epsilon: 0.9502    steps: 198    lr: 0.0001     reward: 1.52\n",
      "epis: 693   score: 3.0   mem len: 125389   epsilon: 0.9497    steps: 249    lr: 0.0001     reward: 1.52\n",
      "epis: 694   score: 1.0   mem len: 125557   epsilon: 0.9494    steps: 168    lr: 0.0001     reward: 1.52\n",
      "epis: 695   score: 0.0   mem len: 125680   epsilon: 0.9492    steps: 123    lr: 0.0001     reward: 1.51\n",
      "epis: 696   score: 0.0   mem len: 125803   epsilon: 0.9489    steps: 123    lr: 0.0001     reward: 1.49\n",
      "epis: 697   score: 0.0   mem len: 125926   epsilon: 0.9487    steps: 123    lr: 0.0001     reward: 1.48\n",
      "epis: 698   score: 0.0   mem len: 126049   epsilon: 0.9484    steps: 123    lr: 0.0001     reward: 1.47\n",
      "epis: 699   score: 0.0   mem len: 126172   epsilon: 0.9482    steps: 123    lr: 0.0001     reward: 1.46\n",
      "epis: 700   score: 1.0   mem len: 126342   epsilon: 0.9478    steps: 170    lr: 0.0001     reward: 1.45\n",
      "epis: 701   score: 1.0   mem len: 126493   epsilon: 0.9475    steps: 151    lr: 0.0001     reward: 1.44\n",
      "epis: 702   score: 2.0   mem len: 126692   epsilon: 0.9471    steps: 199    lr: 0.0001     reward: 1.46\n",
      "epis: 703   score: 2.0   mem len: 126889   epsilon: 0.9468    steps: 197    lr: 0.0001     reward: 1.44\n",
      "epis: 704   score: 0.0   mem len: 127011   epsilon: 0.9465    steps: 122    lr: 0.0001     reward: 1.43\n",
      "epis: 705   score: 2.0   mem len: 127226   epsilon: 0.9461    steps: 215    lr: 0.0001     reward: 1.44\n",
      "epis: 706   score: 1.0   mem len: 127395   epsilon: 0.9458    steps: 169    lr: 0.0001     reward: 1.41\n",
      "epis: 707   score: 0.0   mem len: 127518   epsilon: 0.9455    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 708   score: 1.0   mem len: 127687   epsilon: 0.9452    steps: 169    lr: 0.0001     reward: 1.39\n",
      "epis: 709   score: 1.0   mem len: 127859   epsilon: 0.9448    steps: 172    lr: 0.0001     reward: 1.37\n",
      "epis: 710   score: 0.0   mem len: 127982   epsilon: 0.9446    steps: 123    lr: 0.0001     reward: 1.31\n",
      "epis: 711   score: 0.0   mem len: 128105   epsilon: 0.9444    steps: 123    lr: 0.0001     reward: 1.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 712   score: 3.0   mem len: 128316   epsilon: 0.9439    steps: 211    lr: 0.0001     reward: 1.31\n",
      "epis: 713   score: 3.0   mem len: 128545   epsilon: 0.9435    steps: 229    lr: 0.0001     reward: 1.31\n",
      "epis: 714   score: 1.0   mem len: 128695   epsilon: 0.9432    steps: 150    lr: 0.0001     reward: 1.32\n",
      "epis: 715   score: 2.0   mem len: 128913   epsilon: 0.9428    steps: 218    lr: 0.0001     reward: 1.33\n",
      "epis: 716   score: 2.0   mem len: 129111   epsilon: 0.9424    steps: 198    lr: 0.0001     reward: 1.34\n",
      "epis: 717   score: 1.0   mem len: 129280   epsilon: 0.942    steps: 169    lr: 0.0001     reward: 1.32\n",
      "epis: 718   score: 1.0   mem len: 129431   epsilon: 0.9417    steps: 151    lr: 0.0001     reward: 1.32\n",
      "epis: 719   score: 2.0   mem len: 129648   epsilon: 0.9413    steps: 217    lr: 0.0001     reward: 1.3\n",
      "epis: 720   score: 1.0   mem len: 129816   epsilon: 0.941    steps: 168    lr: 0.0001     reward: 1.27\n",
      "epis: 721   score: 0.0   mem len: 129939   epsilon: 0.9407    steps: 123    lr: 0.0001     reward: 1.26\n",
      "epis: 722   score: 1.0   mem len: 130107   epsilon: 0.9404    steps: 168    lr: 0.0001     reward: 1.24\n",
      "epis: 723   score: 1.0   mem len: 130257   epsilon: 0.9401    steps: 150    lr: 0.0001     reward: 1.21\n",
      "epis: 724   score: 3.0   mem len: 130522   epsilon: 0.9396    steps: 265    lr: 0.0001     reward: 1.21\n",
      "epis: 725   score: 1.0   mem len: 130692   epsilon: 0.9392    steps: 170    lr: 0.0001     reward: 1.22\n",
      "epis: 726   score: 1.0   mem len: 130843   epsilon: 0.9389    steps: 151    lr: 0.0001     reward: 1.22\n",
      "epis: 727   score: 2.0   mem len: 131043   epsilon: 0.9385    steps: 200    lr: 0.0001     reward: 1.23\n",
      "epis: 728   score: 0.0   mem len: 131166   epsilon: 0.9383    steps: 123    lr: 0.0001     reward: 1.21\n",
      "epis: 729   score: 1.0   mem len: 131337   epsilon: 0.938    steps: 171    lr: 0.0001     reward: 1.22\n",
      "epis: 730   score: 2.0   mem len: 131555   epsilon: 0.9375    steps: 218    lr: 0.0001     reward: 1.21\n",
      "epis: 731   score: 3.0   mem len: 131802   epsilon: 0.937    steps: 247    lr: 0.0001     reward: 1.24\n",
      "epis: 732   score: 1.0   mem len: 131972   epsilon: 0.9367    steps: 170    lr: 0.0001     reward: 1.25\n",
      "epis: 733   score: 1.0   mem len: 132123   epsilon: 0.9364    steps: 151    lr: 0.0001     reward: 1.24\n",
      "epis: 734   score: 2.0   mem len: 132339   epsilon: 0.936    steps: 216    lr: 0.0001     reward: 1.23\n",
      "epis: 735   score: 0.0   mem len: 132461   epsilon: 0.9357    steps: 122    lr: 0.0001     reward: 1.22\n",
      "epis: 736   score: 2.0   mem len: 132659   epsilon: 0.9353    steps: 198    lr: 0.0001     reward: 1.24\n",
      "epis: 737   score: 2.0   mem len: 132878   epsilon: 0.9349    steps: 219    lr: 0.0001     reward: 1.23\n",
      "epis: 738   score: 3.0   mem len: 133140   epsilon: 0.9344    steps: 262    lr: 0.0001     reward: 1.25\n",
      "epis: 739   score: 0.0   mem len: 133263   epsilon: 0.9341    steps: 123    lr: 0.0001     reward: 1.23\n",
      "epis: 740   score: 0.0   mem len: 133385   epsilon: 0.9339    steps: 122    lr: 0.0001     reward: 1.23\n",
      "epis: 741   score: 0.0   mem len: 133508   epsilon: 0.9337    steps: 123    lr: 0.0001     reward: 1.22\n",
      "epis: 742   score: 2.0   mem len: 133730   epsilon: 0.9332    steps: 222    lr: 0.0001     reward: 1.23\n",
      "epis: 743   score: 0.0   mem len: 133853   epsilon: 0.933    steps: 123    lr: 0.0001     reward: 1.23\n",
      "epis: 744   score: 2.0   mem len: 134071   epsilon: 0.9325    steps: 218    lr: 0.0001     reward: 1.25\n",
      "epis: 745   score: 5.0   mem len: 134401   epsilon: 0.9319    steps: 330    lr: 0.0001     reward: 1.3\n",
      "epis: 746   score: 2.0   mem len: 134619   epsilon: 0.9315    steps: 218    lr: 0.0001     reward: 1.32\n",
      "epis: 747   score: 1.0   mem len: 134788   epsilon: 0.9311    steps: 169    lr: 0.0001     reward: 1.31\n",
      "epis: 748   score: 0.0   mem len: 134910   epsilon: 0.9309    steps: 122    lr: 0.0001     reward: 1.3\n",
      "epis: 749   score: 0.0   mem len: 135033   epsilon: 0.9306    steps: 123    lr: 0.0001     reward: 1.27\n",
      "epis: 750   score: 0.0   mem len: 135155   epsilon: 0.9304    steps: 122    lr: 0.0001     reward: 1.27\n",
      "epis: 751   score: 1.0   mem len: 135327   epsilon: 0.9301    steps: 172    lr: 0.0001     reward: 1.27\n",
      "epis: 752   score: 1.0   mem len: 135496   epsilon: 0.9297    steps: 169    lr: 0.0001     reward: 1.24\n",
      "epis: 753   score: 1.0   mem len: 135667   epsilon: 0.9294    steps: 171    lr: 0.0001     reward: 1.24\n",
      "epis: 754   score: 2.0   mem len: 135864   epsilon: 0.929    steps: 197    lr: 0.0001     reward: 1.26\n",
      "epis: 755   score: 1.0   mem len: 136032   epsilon: 0.9287    steps: 168    lr: 0.0001     reward: 1.25\n",
      "epis: 756   score: 0.0   mem len: 136155   epsilon: 0.9284    steps: 123    lr: 0.0001     reward: 1.2\n",
      "epis: 757   score: 0.0   mem len: 136278   epsilon: 0.9282    steps: 123    lr: 0.0001     reward: 1.17\n",
      "epis: 758   score: 0.0   mem len: 136401   epsilon: 0.9279    steps: 123    lr: 0.0001     reward: 1.16\n",
      "epis: 759   score: 0.0   mem len: 136523   epsilon: 0.9277    steps: 122    lr: 0.0001     reward: 1.14\n",
      "epis: 760   score: 3.0   mem len: 136733   epsilon: 0.9273    steps: 210    lr: 0.0001     reward: 1.16\n",
      "epis: 761   score: 3.0   mem len: 136979   epsilon: 0.9268    steps: 246    lr: 0.0001     reward: 1.17\n",
      "epis: 762   score: 0.0   mem len: 137102   epsilon: 0.9265    steps: 123    lr: 0.0001     reward: 1.17\n",
      "epis: 763   score: 0.0   mem len: 137224   epsilon: 0.9263    steps: 122    lr: 0.0001     reward: 1.16\n",
      "epis: 764   score: 0.0   mem len: 137347   epsilon: 0.9261    steps: 123    lr: 0.0001     reward: 1.14\n",
      "epis: 765   score: 1.0   mem len: 137498   epsilon: 0.9258    steps: 151    lr: 0.0001     reward: 1.13\n",
      "epis: 766   score: 2.0   mem len: 137716   epsilon: 0.9253    steps: 218    lr: 0.0001     reward: 1.14\n",
      "epis: 767   score: 0.0   mem len: 137838   epsilon: 0.9251    steps: 122    lr: 0.0001     reward: 1.12\n",
      "epis: 768   score: 2.0   mem len: 138035   epsilon: 0.9247    steps: 197    lr: 0.0001     reward: 1.13\n",
      "epis: 769   score: 1.0   mem len: 138186   epsilon: 0.9244    steps: 151    lr: 0.0001     reward: 1.12\n",
      "epis: 770   score: 0.0   mem len: 138309   epsilon: 0.9241    steps: 123    lr: 0.0001     reward: 1.12\n",
      "epis: 771   score: 0.0   mem len: 138432   epsilon: 0.9239    steps: 123    lr: 0.0001     reward: 1.1\n",
      "epis: 772   score: 4.0   mem len: 138749   epsilon: 0.9233    steps: 317    lr: 0.0001     reward: 1.14\n",
      "epis: 773   score: 2.0   mem len: 138971   epsilon: 0.9228    steps: 222    lr: 0.0001     reward: 1.16\n",
      "epis: 774   score: 0.0   mem len: 139094   epsilon: 0.9226    steps: 123    lr: 0.0001     reward: 1.16\n",
      "epis: 775   score: 0.0   mem len: 139217   epsilon: 0.9223    steps: 123    lr: 0.0001     reward: 1.13\n",
      "epis: 776   score: 0.0   mem len: 139340   epsilon: 0.9221    steps: 123    lr: 0.0001     reward: 1.12\n",
      "epis: 777   score: 0.0   mem len: 139462   epsilon: 0.9219    steps: 122    lr: 0.0001     reward: 1.12\n",
      "epis: 778   score: 4.0   mem len: 139739   epsilon: 0.9213    steps: 277    lr: 0.0001     reward: 1.14\n",
      "epis: 779   score: 5.0   mem len: 140084   epsilon: 0.9206    steps: 345    lr: 0.0001     reward: 1.19\n",
      "epis: 780   score: 2.0   mem len: 140281   epsilon: 0.9202    steps: 197    lr: 0.0001     reward: 1.2\n",
      "epis: 781   score: 4.0   mem len: 140576   epsilon: 0.9197    steps: 295    lr: 0.0001     reward: 1.24\n",
      "epis: 782   score: 0.0   mem len: 140699   epsilon: 0.9194    steps: 123    lr: 0.0001     reward: 1.23\n",
      "epis: 783   score: 1.0   mem len: 140868   epsilon: 0.9191    steps: 169    lr: 0.0001     reward: 1.23\n",
      "epis: 784   score: 1.0   mem len: 141019   epsilon: 0.9188    steps: 151    lr: 0.0001     reward: 1.23\n",
      "epis: 785   score: 0.0   mem len: 141142   epsilon: 0.9185    steps: 123    lr: 0.0001     reward: 1.19\n",
      "epis: 786   score: 0.0   mem len: 141265   epsilon: 0.9183    steps: 123    lr: 0.0001     reward: 1.19\n",
      "epis: 787   score: 2.0   mem len: 141483   epsilon: 0.9179    steps: 218    lr: 0.0001     reward: 1.21\n",
      "epis: 788   score: 3.0   mem len: 141751   epsilon: 0.9173    steps: 268    lr: 0.0001     reward: 1.23\n",
      "epis: 789   score: 4.0   mem len: 141999   epsilon: 0.9168    steps: 248    lr: 0.0001     reward: 1.26\n",
      "epis: 790   score: 3.0   mem len: 142266   epsilon: 0.9163    steps: 267    lr: 0.0001     reward: 1.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 791   score: 2.0   mem len: 142463   epsilon: 0.9159    steps: 197    lr: 0.0001     reward: 1.26\n",
      "epis: 792   score: 4.0   mem len: 142735   epsilon: 0.9154    steps: 272    lr: 0.0001     reward: 1.28\n",
      "epis: 793   score: 1.0   mem len: 142905   epsilon: 0.915    steps: 170    lr: 0.0001     reward: 1.26\n",
      "epis: 794   score: 2.0   mem len: 143103   epsilon: 0.9147    steps: 198    lr: 0.0001     reward: 1.27\n",
      "epis: 795   score: 4.0   mem len: 143381   epsilon: 0.9141    steps: 278    lr: 0.0001     reward: 1.31\n",
      "epis: 796   score: 1.0   mem len: 143532   epsilon: 0.9138    steps: 151    lr: 0.0001     reward: 1.32\n",
      "epis: 797   score: 0.0   mem len: 143654   epsilon: 0.9136    steps: 122    lr: 0.0001     reward: 1.32\n",
      "epis: 798   score: 0.0   mem len: 143776   epsilon: 0.9133    steps: 122    lr: 0.0001     reward: 1.32\n",
      "epis: 799   score: 1.0   mem len: 143946   epsilon: 0.913    steps: 170    lr: 0.0001     reward: 1.33\n",
      "epis: 800   score: 2.0   mem len: 144144   epsilon: 0.9126    steps: 198    lr: 0.0001     reward: 1.34\n",
      "epis: 801   score: 3.0   mem len: 144387   epsilon: 0.9121    steps: 243    lr: 0.0001     reward: 1.36\n",
      "epis: 802   score: 0.0   mem len: 144510   epsilon: 0.9119    steps: 123    lr: 0.0001     reward: 1.34\n",
      "epis: 803   score: 0.0   mem len: 144633   epsilon: 0.9116    steps: 123    lr: 0.0001     reward: 1.32\n",
      "epis: 804   score: 2.0   mem len: 144851   epsilon: 0.9112    steps: 218    lr: 0.0001     reward: 1.34\n",
      "epis: 805   score: 4.0   mem len: 145127   epsilon: 0.9106    steps: 276    lr: 0.0001     reward: 1.36\n",
      "epis: 806   score: 4.0   mem len: 145419   epsilon: 0.9101    steps: 292    lr: 0.0001     reward: 1.39\n",
      "epis: 807   score: 2.0   mem len: 145617   epsilon: 0.9097    steps: 198    lr: 0.0001     reward: 1.41\n",
      "epis: 808   score: 0.0   mem len: 145740   epsilon: 0.9094    steps: 123    lr: 0.0001     reward: 1.4\n",
      "epis: 809   score: 3.0   mem len: 145965   epsilon: 0.909    steps: 225    lr: 0.0001     reward: 1.42\n",
      "epis: 810   score: 1.0   mem len: 146134   epsilon: 0.9087    steps: 169    lr: 0.0001     reward: 1.43\n",
      "epis: 811   score: 3.0   mem len: 146381   epsilon: 0.9082    steps: 247    lr: 0.0001     reward: 1.46\n",
      "epis: 812   score: 4.0   mem len: 146698   epsilon: 0.9075    steps: 317    lr: 0.0001     reward: 1.47\n",
      "epis: 813   score: 3.0   mem len: 146943   epsilon: 0.9071    steps: 245    lr: 0.0001     reward: 1.47\n",
      "epis: 814   score: 4.0   mem len: 147236   epsilon: 0.9065    steps: 293    lr: 0.0001     reward: 1.5\n",
      "epis: 815   score: 0.0   mem len: 147358   epsilon: 0.9062    steps: 122    lr: 0.0001     reward: 1.48\n",
      "epis: 816   score: 2.0   mem len: 147576   epsilon: 0.9058    steps: 218    lr: 0.0001     reward: 1.48\n",
      "epis: 817   score: 2.0   mem len: 147775   epsilon: 0.9054    steps: 199    lr: 0.0001     reward: 1.49\n",
      "epis: 818   score: 0.0   mem len: 147898   epsilon: 0.9052    steps: 123    lr: 0.0001     reward: 1.48\n",
      "epis: 819   score: 2.0   mem len: 148098   epsilon: 0.9048    steps: 200    lr: 0.0001     reward: 1.48\n",
      "epis: 820   score: 1.0   mem len: 148249   epsilon: 0.9045    steps: 151    lr: 0.0001     reward: 1.48\n",
      "epis: 821   score: 3.0   mem len: 148513   epsilon: 0.9039    steps: 264    lr: 0.0001     reward: 1.51\n",
      "epis: 822   score: 1.0   mem len: 148664   epsilon: 0.9036    steps: 151    lr: 0.0001     reward: 1.51\n",
      "epis: 823   score: 1.0   mem len: 148836   epsilon: 0.9033    steps: 172    lr: 0.0001     reward: 1.51\n",
      "epis: 824   score: 2.0   mem len: 149035   epsilon: 0.9029    steps: 199    lr: 0.0001     reward: 1.5\n",
      "epis: 825   score: 1.0   mem len: 149205   epsilon: 0.9026    steps: 170    lr: 0.0001     reward: 1.5\n",
      "epis: 826   score: 4.0   mem len: 149485   epsilon: 0.902    steps: 280    lr: 0.0001     reward: 1.53\n",
      "epis: 827   score: 4.0   mem len: 149759   epsilon: 0.9015    steps: 274    lr: 0.0001     reward: 1.55\n",
      "epis: 828   score: 0.0   mem len: 149882   epsilon: 0.9012    steps: 123    lr: 0.0001     reward: 1.55\n",
      "epis: 829   score: 3.0   mem len: 150149   epsilon: 0.9007    steps: 267    lr: 0.0001     reward: 1.57\n",
      "epis: 830   score: 6.0   mem len: 150509   epsilon: 0.9    steps: 360    lr: 0.0001     reward: 1.61\n",
      "epis: 831   score: 3.0   mem len: 150740   epsilon: 0.8995    steps: 231    lr: 0.0001     reward: 1.61\n",
      "epis: 832   score: 1.0   mem len: 150911   epsilon: 0.8992    steps: 171    lr: 0.0001     reward: 1.61\n",
      "epis: 833   score: 3.0   mem len: 151155   epsilon: 0.8987    steps: 244    lr: 0.0001     reward: 1.63\n",
      "epis: 834   score: 0.0   mem len: 151277   epsilon: 0.8985    steps: 122    lr: 0.0001     reward: 1.61\n",
      "epis: 835   score: 0.0   mem len: 151400   epsilon: 0.8982    steps: 123    lr: 0.0001     reward: 1.61\n",
      "epis: 836   score: 1.0   mem len: 151551   epsilon: 0.8979    steps: 151    lr: 0.0001     reward: 1.6\n",
      "epis: 837   score: 2.0   mem len: 151770   epsilon: 0.8975    steps: 219    lr: 0.0001     reward: 1.6\n",
      "epis: 838   score: 5.0   mem len: 152097   epsilon: 0.8968    steps: 327    lr: 0.0001     reward: 1.62\n",
      "epis: 839   score: 1.0   mem len: 152265   epsilon: 0.8965    steps: 168    lr: 0.0001     reward: 1.63\n",
      "epis: 840   score: 2.0   mem len: 152463   epsilon: 0.8961    steps: 198    lr: 0.0001     reward: 1.65\n",
      "epis: 841   score: 0.0   mem len: 152586   epsilon: 0.8959    steps: 123    lr: 0.0001     reward: 1.65\n",
      "epis: 842   score: 1.0   mem len: 152758   epsilon: 0.8955    steps: 172    lr: 0.0001     reward: 1.64\n",
      "epis: 843   score: 3.0   mem len: 153005   epsilon: 0.895    steps: 247    lr: 0.0001     reward: 1.67\n",
      "epis: 844   score: 6.0   mem len: 153383   epsilon: 0.8943    steps: 378    lr: 0.0001     reward: 1.71\n",
      "epis: 845   score: 1.0   mem len: 153552   epsilon: 0.894    steps: 169    lr: 0.0001     reward: 1.67\n",
      "epis: 846   score: 1.0   mem len: 153721   epsilon: 0.8936    steps: 169    lr: 0.0001     reward: 1.66\n",
      "epis: 847   score: 0.0   mem len: 153844   epsilon: 0.8934    steps: 123    lr: 0.0001     reward: 1.65\n",
      "epis: 848   score: 0.0   mem len: 153967   epsilon: 0.8931    steps: 123    lr: 0.0001     reward: 1.65\n",
      "epis: 849   score: 2.0   mem len: 154184   epsilon: 0.8927    steps: 217    lr: 0.0001     reward: 1.67\n",
      "epis: 850   score: 2.0   mem len: 154402   epsilon: 0.8923    steps: 218    lr: 0.0001     reward: 1.69\n",
      "epis: 851   score: 0.0   mem len: 154525   epsilon: 0.892    steps: 123    lr: 0.0001     reward: 1.68\n",
      "epis: 852   score: 1.0   mem len: 154695   epsilon: 0.8917    steps: 170    lr: 0.0001     reward: 1.68\n",
      "epis: 853   score: 2.0   mem len: 154910   epsilon: 0.8913    steps: 215    lr: 0.0001     reward: 1.69\n",
      "epis: 854   score: 4.0   mem len: 155169   epsilon: 0.8908    steps: 259    lr: 0.0001     reward: 1.71\n",
      "epis: 855   score: 4.0   mem len: 155428   epsilon: 0.8903    steps: 259    lr: 0.0001     reward: 1.74\n",
      "epis: 856   score: 4.0   mem len: 155688   epsilon: 0.8897    steps: 260    lr: 0.0001     reward: 1.78\n",
      "epis: 857   score: 1.0   mem len: 155858   epsilon: 0.8894    steps: 170    lr: 0.0001     reward: 1.79\n",
      "epis: 858   score: 0.0   mem len: 155981   epsilon: 0.8892    steps: 123    lr: 0.0001     reward: 1.79\n",
      "epis: 859   score: 4.0   mem len: 156274   epsilon: 0.8886    steps: 293    lr: 0.0001     reward: 1.83\n",
      "epis: 860   score: 2.0   mem len: 156472   epsilon: 0.8882    steps: 198    lr: 0.0001     reward: 1.82\n",
      "epis: 861   score: 1.0   mem len: 156623   epsilon: 0.8879    steps: 151    lr: 0.0001     reward: 1.8\n",
      "epis: 862   score: 3.0   mem len: 156869   epsilon: 0.8874    steps: 246    lr: 0.0001     reward: 1.83\n",
      "epis: 863   score: 2.0   mem len: 157049   epsilon: 0.887    steps: 180    lr: 0.0001     reward: 1.85\n",
      "epis: 864   score: 3.0   mem len: 157275   epsilon: 0.8866    steps: 226    lr: 0.0001     reward: 1.88\n",
      "epis: 865   score: 1.0   mem len: 157445   epsilon: 0.8863    steps: 170    lr: 0.0001     reward: 1.88\n",
      "epis: 866   score: 2.0   mem len: 157666   epsilon: 0.8858    steps: 221    lr: 0.0001     reward: 1.88\n",
      "epis: 867   score: 0.0   mem len: 157789   epsilon: 0.8856    steps: 123    lr: 0.0001     reward: 1.88\n",
      "epis: 868   score: 1.0   mem len: 157957   epsilon: 0.8852    steps: 168    lr: 0.0001     reward: 1.87\n",
      "epis: 869   score: 3.0   mem len: 158205   epsilon: 0.8848    steps: 248    lr: 0.0001     reward: 1.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 870   score: 0.0   mem len: 158327   epsilon: 0.8845    steps: 122    lr: 0.0001     reward: 1.89\n",
      "epis: 871   score: 2.0   mem len: 158543   epsilon: 0.8841    steps: 216    lr: 0.0001     reward: 1.91\n",
      "epis: 872   score: 2.0   mem len: 158761   epsilon: 0.8837    steps: 218    lr: 0.0001     reward: 1.89\n",
      "epis: 873   score: 1.0   mem len: 158933   epsilon: 0.8833    steps: 172    lr: 0.0001     reward: 1.88\n",
      "epis: 874   score: 2.0   mem len: 159132   epsilon: 0.8829    steps: 199    lr: 0.0001     reward: 1.9\n",
      "epis: 875   score: 2.0   mem len: 159313   epsilon: 0.8826    steps: 181    lr: 0.0001     reward: 1.92\n",
      "epis: 876   score: 6.0   mem len: 159668   epsilon: 0.8819    steps: 355    lr: 0.0001     reward: 1.98\n",
      "epis: 877   score: 4.0   mem len: 159919   epsilon: 0.8814    steps: 251    lr: 0.0001     reward: 2.02\n",
      "epis: 878   score: 3.0   mem len: 160183   epsilon: 0.8808    steps: 264    lr: 0.0001     reward: 2.01\n",
      "epis: 879   score: 3.0   mem len: 160451   epsilon: 0.8803    steps: 268    lr: 0.0001     reward: 1.99\n",
      "epis: 880   score: 2.0   mem len: 160649   epsilon: 0.8799    steps: 198    lr: 0.0001     reward: 1.99\n",
      "epis: 881   score: 1.0   mem len: 160800   epsilon: 0.8796    steps: 151    lr: 0.0001     reward: 1.96\n",
      "epis: 882   score: 1.0   mem len: 160951   epsilon: 0.8793    steps: 151    lr: 0.0001     reward: 1.97\n",
      "epis: 883   score: 1.0   mem len: 161119   epsilon: 0.879    steps: 168    lr: 0.0001     reward: 1.97\n",
      "epis: 884   score: 3.0   mem len: 161364   epsilon: 0.8785    steps: 245    lr: 0.0001     reward: 1.99\n",
      "epis: 885   score: 1.0   mem len: 161534   epsilon: 0.8782    steps: 170    lr: 0.0001     reward: 2.0\n",
      "epis: 886   score: 1.0   mem len: 161686   epsilon: 0.8779    steps: 152    lr: 0.0001     reward: 2.01\n",
      "epis: 887   score: 4.0   mem len: 161964   epsilon: 0.8773    steps: 278    lr: 0.0001     reward: 2.03\n",
      "epis: 888   score: 3.0   mem len: 162210   epsilon: 0.8768    steps: 246    lr: 0.0001     reward: 2.03\n",
      "epis: 889   score: 1.0   mem len: 162361   epsilon: 0.8765    steps: 151    lr: 0.0001     reward: 2.0\n",
      "epis: 890   score: 3.0   mem len: 162612   epsilon: 0.876    steps: 251    lr: 0.0001     reward: 2.0\n",
      "epis: 891   score: 0.0   mem len: 162735   epsilon: 0.8758    steps: 123    lr: 0.0001     reward: 1.98\n",
      "epis: 892   score: 6.0   mem len: 163093   epsilon: 0.8751    steps: 358    lr: 0.0001     reward: 2.0\n",
      "epis: 893   score: 3.0   mem len: 163340   epsilon: 0.8746    steps: 247    lr: 0.0001     reward: 2.02\n",
      "epis: 894   score: 3.0   mem len: 163568   epsilon: 0.8741    steps: 228    lr: 0.0001     reward: 2.03\n",
      "epis: 895   score: 3.0   mem len: 163817   epsilon: 0.8736    steps: 249    lr: 0.0001     reward: 2.02\n",
      "epis: 896   score: 3.0   mem len: 164045   epsilon: 0.8732    steps: 228    lr: 0.0001     reward: 2.04\n",
      "epis: 897   score: 2.0   mem len: 164243   epsilon: 0.8728    steps: 198    lr: 0.0001     reward: 2.06\n",
      "epis: 898   score: 1.0   mem len: 164412   epsilon: 0.8725    steps: 169    lr: 0.0001     reward: 2.07\n",
      "epis: 899   score: 1.0   mem len: 164582   epsilon: 0.8721    steps: 170    lr: 0.0001     reward: 2.07\n",
      "epis: 900   score: 4.0   mem len: 164860   epsilon: 0.8716    steps: 278    lr: 0.0001     reward: 2.09\n",
      "epis: 901   score: 1.0   mem len: 165029   epsilon: 0.8712    steps: 169    lr: 0.0001     reward: 2.07\n",
      "epis: 902   score: 1.0   mem len: 165180   epsilon: 0.8709    steps: 151    lr: 0.0001     reward: 2.08\n",
      "epis: 903   score: 2.0   mem len: 165398   epsilon: 0.8705    steps: 218    lr: 0.0001     reward: 2.1\n",
      "epis: 904   score: 1.0   mem len: 165566   epsilon: 0.8702    steps: 168    lr: 0.0001     reward: 2.09\n",
      "epis: 905   score: 3.0   mem len: 165809   epsilon: 0.8697    steps: 243    lr: 0.0001     reward: 2.08\n",
      "epis: 906   score: 4.0   mem len: 166068   epsilon: 0.8692    steps: 259    lr: 0.0001     reward: 2.08\n",
      "epis: 907   score: 4.0   mem len: 166323   epsilon: 0.8687    steps: 255    lr: 0.0001     reward: 2.1\n",
      "epis: 908   score: 3.0   mem len: 166568   epsilon: 0.8682    steps: 245    lr: 0.0001     reward: 2.13\n",
      "epis: 909   score: 2.0   mem len: 166787   epsilon: 0.8678    steps: 219    lr: 0.0001     reward: 2.12\n",
      "epis: 910   score: 3.0   mem len: 167012   epsilon: 0.8673    steps: 225    lr: 0.0001     reward: 2.14\n",
      "epis: 911   score: 1.0   mem len: 167163   epsilon: 0.867    steps: 151    lr: 0.0001     reward: 2.12\n",
      "epis: 912   score: 1.0   mem len: 167332   epsilon: 0.8667    steps: 169    lr: 0.0001     reward: 2.09\n",
      "epis: 913   score: 0.0   mem len: 167455   epsilon: 0.8664    steps: 123    lr: 0.0001     reward: 2.06\n",
      "epis: 914   score: 2.0   mem len: 167673   epsilon: 0.866    steps: 218    lr: 0.0001     reward: 2.04\n",
      "epis: 915   score: 4.0   mem len: 167954   epsilon: 0.8654    steps: 281    lr: 0.0001     reward: 2.08\n",
      "epis: 916   score: 3.0   mem len: 168221   epsilon: 0.8649    steps: 267    lr: 0.0001     reward: 2.09\n",
      "epis: 917   score: 1.0   mem len: 168374   epsilon: 0.8646    steps: 153    lr: 0.0001     reward: 2.08\n",
      "epis: 918   score: 1.0   mem len: 168542   epsilon: 0.8643    steps: 168    lr: 0.0001     reward: 2.09\n",
      "epis: 919   score: 3.0   mem len: 168772   epsilon: 0.8638    steps: 230    lr: 0.0001     reward: 2.1\n",
      "epis: 920   score: 3.0   mem len: 169042   epsilon: 0.8633    steps: 270    lr: 0.0001     reward: 2.12\n",
      "epis: 921   score: 1.0   mem len: 169192   epsilon: 0.863    steps: 150    lr: 0.0001     reward: 2.1\n",
      "epis: 922   score: 1.0   mem len: 169344   epsilon: 0.8627    steps: 152    lr: 0.0001     reward: 2.1\n",
      "epis: 923   score: 1.0   mem len: 169497   epsilon: 0.8624    steps: 153    lr: 0.0001     reward: 2.1\n",
      "epis: 924   score: 1.0   mem len: 169647   epsilon: 0.8621    steps: 150    lr: 0.0001     reward: 2.09\n",
      "epis: 925   score: 0.0   mem len: 169770   epsilon: 0.8619    steps: 123    lr: 0.0001     reward: 2.08\n",
      "epis: 926   score: 1.0   mem len: 169940   epsilon: 0.8615    steps: 170    lr: 0.0001     reward: 2.05\n",
      "epis: 927   score: 1.0   mem len: 170109   epsilon: 0.8612    steps: 169    lr: 0.0001     reward: 2.02\n",
      "epis: 928   score: 4.0   mem len: 170376   epsilon: 0.8607    steps: 267    lr: 0.0001     reward: 2.06\n",
      "epis: 929   score: 4.0   mem len: 170670   epsilon: 0.8601    steps: 294    lr: 0.0001     reward: 2.07\n",
      "epis: 930   score: 2.0   mem len: 170868   epsilon: 0.8597    steps: 198    lr: 0.0001     reward: 2.03\n",
      "epis: 931   score: 1.0   mem len: 171037   epsilon: 0.8593    steps: 169    lr: 0.0001     reward: 2.01\n",
      "epis: 932   score: 1.0   mem len: 171188   epsilon: 0.859    steps: 151    lr: 0.0001     reward: 2.01\n",
      "epis: 933   score: 0.0   mem len: 171311   epsilon: 0.8588    steps: 123    lr: 0.0001     reward: 1.98\n",
      "epis: 934   score: 2.0   mem len: 171528   epsilon: 0.8584    steps: 217    lr: 0.0001     reward: 2.0\n",
      "epis: 935   score: 2.0   mem len: 171707   epsilon: 0.858    steps: 179    lr: 0.0001     reward: 2.02\n",
      "epis: 936   score: 0.0   mem len: 171829   epsilon: 0.8578    steps: 122    lr: 0.0001     reward: 2.01\n",
      "epis: 937   score: 1.0   mem len: 171998   epsilon: 0.8574    steps: 169    lr: 0.0001     reward: 2.0\n",
      "epis: 938   score: 4.0   mem len: 172295   epsilon: 0.8569    steps: 297    lr: 0.0001     reward: 1.99\n",
      "epis: 939   score: 5.0   mem len: 172645   epsilon: 0.8562    steps: 350    lr: 0.0001     reward: 2.03\n",
      "epis: 940   score: 3.0   mem len: 172892   epsilon: 0.8557    steps: 247    lr: 0.0001     reward: 2.04\n",
      "epis: 941   score: 1.0   mem len: 173043   epsilon: 0.8554    steps: 151    lr: 0.0001     reward: 2.05\n",
      "epis: 942   score: 2.0   mem len: 173240   epsilon: 0.855    steps: 197    lr: 0.0001     reward: 2.06\n",
      "epis: 943   score: 3.0   mem len: 173489   epsilon: 0.8545    steps: 249    lr: 0.0001     reward: 2.06\n",
      "epis: 944   score: 2.0   mem len: 173708   epsilon: 0.8541    steps: 219    lr: 0.0001     reward: 2.02\n",
      "epis: 945   score: 0.0   mem len: 173831   epsilon: 0.8538    steps: 123    lr: 0.0001     reward: 2.01\n",
      "epis: 946   score: 1.0   mem len: 174001   epsilon: 0.8535    steps: 170    lr: 0.0001     reward: 2.01\n",
      "epis: 947   score: 2.0   mem len: 174198   epsilon: 0.8531    steps: 197    lr: 0.0001     reward: 2.03\n",
      "epis: 948   score: 1.0   mem len: 174349   epsilon: 0.8528    steps: 151    lr: 0.0001     reward: 2.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 949   score: 5.0   mem len: 174655   epsilon: 0.8522    steps: 306    lr: 0.0001     reward: 2.07\n",
      "epis: 950   score: 3.0   mem len: 174881   epsilon: 0.8517    steps: 226    lr: 0.0001     reward: 2.08\n",
      "epis: 951   score: 6.0   mem len: 175292   epsilon: 0.8509    steps: 411    lr: 0.0001     reward: 2.14\n",
      "epis: 952   score: 3.0   mem len: 175539   epsilon: 0.8504    steps: 247    lr: 0.0001     reward: 2.16\n",
      "epis: 953   score: 2.0   mem len: 175737   epsilon: 0.85    steps: 198    lr: 0.0001     reward: 2.16\n",
      "epis: 954   score: 0.0   mem len: 175860   epsilon: 0.8498    steps: 123    lr: 0.0001     reward: 2.12\n",
      "epis: 955   score: 3.0   mem len: 176086   epsilon: 0.8493    steps: 226    lr: 0.0001     reward: 2.11\n",
      "epis: 956   score: 1.0   mem len: 176255   epsilon: 0.849    steps: 169    lr: 0.0001     reward: 2.08\n",
      "epis: 957   score: 0.0   mem len: 176378   epsilon: 0.8488    steps: 123    lr: 0.0001     reward: 2.07\n",
      "epis: 958   score: 2.0   mem len: 176577   epsilon: 0.8484    steps: 199    lr: 0.0001     reward: 2.09\n",
      "epis: 959   score: 3.0   mem len: 176803   epsilon: 0.8479    steps: 226    lr: 0.0001     reward: 2.08\n",
      "epis: 960   score: 3.0   mem len: 177069   epsilon: 0.8474    steps: 266    lr: 0.0001     reward: 2.09\n",
      "epis: 961   score: 1.0   mem len: 177240   epsilon: 0.8471    steps: 171    lr: 0.0001     reward: 2.09\n",
      "epis: 962   score: 3.0   mem len: 177486   epsilon: 0.8466    steps: 246    lr: 0.0001     reward: 2.09\n",
      "epis: 963   score: 2.0   mem len: 177665   epsilon: 0.8462    steps: 179    lr: 0.0001     reward: 2.09\n",
      "epis: 964   score: 4.0   mem len: 177919   epsilon: 0.8457    steps: 254    lr: 0.0001     reward: 2.1\n",
      "epis: 965   score: 0.0   mem len: 178041   epsilon: 0.8455    steps: 122    lr: 0.0001     reward: 2.09\n",
      "epis: 966   score: 4.0   mem len: 178337   epsilon: 0.8449    steps: 296    lr: 0.0001     reward: 2.11\n",
      "epis: 967   score: 5.0   mem len: 178663   epsilon: 0.8442    steps: 326    lr: 0.0001     reward: 2.16\n",
      "epis: 968   score: 0.0   mem len: 178786   epsilon: 0.844    steps: 123    lr: 0.0001     reward: 2.15\n",
      "epis: 969   score: 1.0   mem len: 178936   epsilon: 0.8437    steps: 150    lr: 0.0001     reward: 2.13\n",
      "epis: 970   score: 0.0   mem len: 179059   epsilon: 0.8435    steps: 123    lr: 0.0001     reward: 2.13\n",
      "epis: 971   score: 4.0   mem len: 179350   epsilon: 0.8429    steps: 291    lr: 0.0001     reward: 2.15\n",
      "epis: 972   score: 2.0   mem len: 179532   epsilon: 0.8425    steps: 182    lr: 0.0001     reward: 2.15\n",
      "epis: 973   score: 4.0   mem len: 179811   epsilon: 0.842    steps: 279    lr: 0.0001     reward: 2.18\n",
      "epis: 974   score: 1.0   mem len: 179962   epsilon: 0.8417    steps: 151    lr: 0.0001     reward: 2.17\n",
      "epis: 975   score: 5.0   mem len: 180329   epsilon: 0.8409    steps: 367    lr: 0.0001     reward: 2.2\n",
      "epis: 976   score: 2.0   mem len: 180509   epsilon: 0.8406    steps: 180    lr: 0.0001     reward: 2.16\n",
      "epis: 977   score: 6.0   mem len: 180864   epsilon: 0.8399    steps: 355    lr: 0.0001     reward: 2.18\n",
      "epis: 978   score: 1.0   mem len: 181015   epsilon: 0.8396    steps: 151    lr: 0.0001     reward: 2.16\n",
      "epis: 979   score: 3.0   mem len: 181260   epsilon: 0.8391    steps: 245    lr: 0.0001     reward: 2.16\n",
      "epis: 980   score: 1.0   mem len: 181430   epsilon: 0.8388    steps: 170    lr: 0.0001     reward: 2.15\n",
      "epis: 981   score: 2.0   mem len: 181648   epsilon: 0.8383    steps: 218    lr: 0.0001     reward: 2.16\n",
      "epis: 982   score: 3.0   mem len: 181859   epsilon: 0.8379    steps: 211    lr: 0.0001     reward: 2.18\n",
      "epis: 983   score: 0.0   mem len: 181981   epsilon: 0.8377    steps: 122    lr: 0.0001     reward: 2.17\n",
      "epis: 984   score: 2.0   mem len: 182181   epsilon: 0.8373    steps: 200    lr: 0.0001     reward: 2.16\n",
      "epis: 985   score: 3.0   mem len: 182412   epsilon: 0.8368    steps: 231    lr: 0.0001     reward: 2.18\n",
      "epis: 986   score: 2.0   mem len: 182610   epsilon: 0.8364    steps: 198    lr: 0.0001     reward: 2.19\n",
      "epis: 987   score: 2.0   mem len: 182828   epsilon: 0.836    steps: 218    lr: 0.0001     reward: 2.17\n",
      "epis: 988   score: 0.0   mem len: 182951   epsilon: 0.8358    steps: 123    lr: 0.0001     reward: 2.14\n",
      "epis: 989   score: 5.0   mem len: 183274   epsilon: 0.8351    steps: 323    lr: 0.0001     reward: 2.18\n",
      "epis: 990   score: 4.0   mem len: 183568   epsilon: 0.8345    steps: 294    lr: 0.0001     reward: 2.19\n",
      "epis: 991   score: 2.0   mem len: 183768   epsilon: 0.8341    steps: 200    lr: 0.0001     reward: 2.21\n",
      "epis: 992   score: 3.0   mem len: 183998   epsilon: 0.8337    steps: 230    lr: 0.0001     reward: 2.18\n",
      "epis: 993   score: 4.0   mem len: 184257   epsilon: 0.8332    steps: 259    lr: 0.0001     reward: 2.19\n",
      "epis: 994   score: 0.0   mem len: 184380   epsilon: 0.8329    steps: 123    lr: 0.0001     reward: 2.16\n",
      "epis: 995   score: 1.0   mem len: 184530   epsilon: 0.8326    steps: 150    lr: 0.0001     reward: 2.14\n",
      "epis: 996   score: 0.0   mem len: 184652   epsilon: 0.8324    steps: 122    lr: 0.0001     reward: 2.11\n",
      "epis: 997   score: 1.0   mem len: 184823   epsilon: 0.832    steps: 171    lr: 0.0001     reward: 2.1\n",
      "epis: 998   score: 4.0   mem len: 185140   epsilon: 0.8314    steps: 317    lr: 0.0001     reward: 2.13\n",
      "epis: 999   score: 1.0   mem len: 185311   epsilon: 0.8311    steps: 171    lr: 0.0001     reward: 2.13\n",
      "epis: 1000   score: 2.0   mem len: 185529   epsilon: 0.8307    steps: 218    lr: 0.0001     reward: 2.11\n",
      "epis: 1001   score: 0.0   mem len: 185652   epsilon: 0.8304    steps: 123    lr: 0.0001     reward: 2.1\n",
      "epis: 1002   score: 8.0   mem len: 186063   epsilon: 0.8296    steps: 411    lr: 0.0001     reward: 2.17\n",
      "epis: 1003   score: 3.0   mem len: 186293   epsilon: 0.8291    steps: 230    lr: 0.0001     reward: 2.18\n",
      "epis: 1004   score: 0.0   mem len: 186415   epsilon: 0.8289    steps: 122    lr: 0.0001     reward: 2.17\n",
      "epis: 1005   score: 4.0   mem len: 186690   epsilon: 0.8284    steps: 275    lr: 0.0001     reward: 2.18\n",
      "epis: 1006   score: 2.0   mem len: 186905   epsilon: 0.8279    steps: 215    lr: 0.0001     reward: 2.16\n",
      "epis: 1007   score: 5.0   mem len: 187234   epsilon: 0.8273    steps: 329    lr: 0.0001     reward: 2.17\n",
      "epis: 1008   score: 4.0   mem len: 187510   epsilon: 0.8267    steps: 276    lr: 0.0001     reward: 2.18\n",
      "epis: 1009   score: 2.0   mem len: 187692   epsilon: 0.8264    steps: 182    lr: 0.0001     reward: 2.18\n",
      "epis: 1010   score: 0.0   mem len: 187815   epsilon: 0.8261    steps: 123    lr: 0.0001     reward: 2.15\n",
      "epis: 1011   score: 2.0   mem len: 188013   epsilon: 0.8257    steps: 198    lr: 0.0001     reward: 2.16\n",
      "epis: 1012   score: 3.0   mem len: 188277   epsilon: 0.8252    steps: 264    lr: 0.0001     reward: 2.18\n",
      "epis: 1013   score: 0.0   mem len: 188399   epsilon: 0.825    steps: 122    lr: 0.0001     reward: 2.18\n",
      "epis: 1014   score: 5.0   mem len: 188744   epsilon: 0.8243    steps: 345    lr: 0.0001     reward: 2.21\n",
      "epis: 1015   score: 0.0   mem len: 188867   epsilon: 0.824    steps: 123    lr: 0.0001     reward: 2.17\n",
      "epis: 1016   score: 5.0   mem len: 189234   epsilon: 0.8233    steps: 367    lr: 0.0001     reward: 2.19\n",
      "epis: 1017   score: 2.0   mem len: 189434   epsilon: 0.8229    steps: 200    lr: 0.0001     reward: 2.2\n",
      "epis: 1018   score: 0.0   mem len: 189557   epsilon: 0.8227    steps: 123    lr: 0.0001     reward: 2.19\n",
      "epis: 1019   score: 1.0   mem len: 189708   epsilon: 0.8224    steps: 151    lr: 0.0001     reward: 2.17\n",
      "epis: 1020   score: 0.0   mem len: 189831   epsilon: 0.8221    steps: 123    lr: 0.0001     reward: 2.14\n",
      "epis: 1021   score: 2.0   mem len: 190012   epsilon: 0.8218    steps: 181    lr: 0.0001     reward: 2.15\n",
      "epis: 1022   score: 2.0   mem len: 190210   epsilon: 0.8214    steps: 198    lr: 0.0001     reward: 2.16\n",
      "epis: 1023   score: 2.0   mem len: 190408   epsilon: 0.821    steps: 198    lr: 0.0001     reward: 2.17\n",
      "epis: 1024   score: 5.0   mem len: 190751   epsilon: 0.8203    steps: 343    lr: 0.0001     reward: 2.21\n",
      "epis: 1025   score: 1.0   mem len: 190902   epsilon: 0.82    steps: 151    lr: 0.0001     reward: 2.22\n",
      "epis: 1026   score: 2.0   mem len: 191121   epsilon: 0.8196    steps: 219    lr: 0.0001     reward: 2.23\n",
      "epis: 1027   score: 3.0   mem len: 191352   epsilon: 0.8191    steps: 231    lr: 0.0001     reward: 2.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1028   score: 5.0   mem len: 191693   epsilon: 0.8184    steps: 341    lr: 0.0001     reward: 2.26\n",
      "epis: 1029   score: 2.0   mem len: 191891   epsilon: 0.8181    steps: 198    lr: 0.0001     reward: 2.24\n",
      "epis: 1030   score: 1.0   mem len: 192059   epsilon: 0.8177    steps: 168    lr: 0.0001     reward: 2.23\n",
      "epis: 1031   score: 6.0   mem len: 192380   epsilon: 0.8171    steps: 321    lr: 0.0001     reward: 2.28\n",
      "epis: 1032   score: 2.0   mem len: 192579   epsilon: 0.8167    steps: 199    lr: 0.0001     reward: 2.29\n",
      "epis: 1033   score: 2.0   mem len: 192777   epsilon: 0.8163    steps: 198    lr: 0.0001     reward: 2.31\n",
      "epis: 1034   score: 0.0   mem len: 192900   epsilon: 0.8161    steps: 123    lr: 0.0001     reward: 2.29\n",
      "epis: 1035   score: 3.0   mem len: 193146   epsilon: 0.8156    steps: 246    lr: 0.0001     reward: 2.3\n",
      "epis: 1036   score: 0.0   mem len: 193269   epsilon: 0.8153    steps: 123    lr: 0.0001     reward: 2.3\n",
      "epis: 1037   score: 1.0   mem len: 193420   epsilon: 0.815    steps: 151    lr: 0.0001     reward: 2.3\n",
      "epis: 1038   score: 9.0   mem len: 193850   epsilon: 0.8142    steps: 430    lr: 0.0001     reward: 2.35\n",
      "epis: 1039   score: 3.0   mem len: 194096   epsilon: 0.8137    steps: 246    lr: 0.0001     reward: 2.33\n",
      "epis: 1040   score: 5.0   mem len: 194441   epsilon: 0.813    steps: 345    lr: 0.0001     reward: 2.35\n",
      "epis: 1041   score: 4.0   mem len: 194734   epsilon: 0.8124    steps: 293    lr: 0.0001     reward: 2.38\n",
      "epis: 1042   score: 5.0   mem len: 195077   epsilon: 0.8117    steps: 343    lr: 0.0001     reward: 2.41\n",
      "epis: 1043   score: 0.0   mem len: 195200   epsilon: 0.8115    steps: 123    lr: 0.0001     reward: 2.38\n",
      "epis: 1044   score: 3.0   mem len: 195428   epsilon: 0.8111    steps: 228    lr: 0.0001     reward: 2.39\n",
      "epis: 1045   score: 2.0   mem len: 195630   epsilon: 0.8107    steps: 202    lr: 0.0001     reward: 2.41\n",
      "epis: 1046   score: 1.0   mem len: 195780   epsilon: 0.8104    steps: 150    lr: 0.0001     reward: 2.41\n",
      "epis: 1047   score: 4.0   mem len: 196078   epsilon: 0.8098    steps: 298    lr: 0.0001     reward: 2.43\n",
      "epis: 1048   score: 5.0   mem len: 196407   epsilon: 0.8091    steps: 329    lr: 0.0001     reward: 2.47\n",
      "epis: 1049   score: 1.0   mem len: 196558   epsilon: 0.8088    steps: 151    lr: 0.0001     reward: 2.43\n",
      "epis: 1050   score: 3.0   mem len: 196783   epsilon: 0.8084    steps: 225    lr: 0.0001     reward: 2.43\n",
      "epis: 1051   score: 0.0   mem len: 196906   epsilon: 0.8081    steps: 123    lr: 0.0001     reward: 2.37\n",
      "epis: 1052   score: 2.0   mem len: 197104   epsilon: 0.8077    steps: 198    lr: 0.0001     reward: 2.36\n",
      "epis: 1053   score: 4.0   mem len: 197376   epsilon: 0.8072    steps: 272    lr: 0.0001     reward: 2.38\n",
      "epis: 1054   score: 2.0   mem len: 197594   epsilon: 0.8068    steps: 218    lr: 0.0001     reward: 2.4\n",
      "epis: 1055   score: 2.0   mem len: 197811   epsilon: 0.8063    steps: 217    lr: 0.0001     reward: 2.39\n",
      "epis: 1056   score: 2.0   mem len: 198009   epsilon: 0.8059    steps: 198    lr: 0.0001     reward: 2.4\n",
      "epis: 1057   score: 3.0   mem len: 198257   epsilon: 0.8054    steps: 248    lr: 0.0001     reward: 2.43\n",
      "epis: 1058   score: 1.0   mem len: 198428   epsilon: 0.8051    steps: 171    lr: 0.0001     reward: 2.42\n",
      "epis: 1059   score: 5.0   mem len: 198751   epsilon: 0.8045    steps: 323    lr: 0.0001     reward: 2.44\n",
      "epis: 1060   score: 1.0   mem len: 198904   epsilon: 0.8042    steps: 153    lr: 0.0001     reward: 2.42\n",
      "epis: 1061   score: 2.0   mem len: 199101   epsilon: 0.8038    steps: 197    lr: 0.0001     reward: 2.43\n",
      "epis: 1062   score: 4.0   mem len: 199400   epsilon: 0.8032    steps: 299    lr: 0.0001     reward: 2.44\n",
      "epis: 1063   score: 1.0   mem len: 199569   epsilon: 0.8029    steps: 169    lr: 0.0001     reward: 2.43\n",
      "epis: 1064   score: 1.0   mem len: 199720   epsilon: 0.8026    steps: 151    lr: 0.0001     reward: 2.4\n",
      "epis: 1065   score: 3.0   mem len: 199951   epsilon: 0.8021    steps: 231    lr: 0.0001     reward: 2.43\n",
      "epis: 1066   score: 1.0   mem len: 200120   epsilon: 0.8018    steps: 169    lr: 4e-05     reward: 2.4\n",
      "epis: 1067   score: 2.0   mem len: 200318   epsilon: 0.8014    steps: 198    lr: 4e-05     reward: 2.37\n",
      "epis: 1068   score: 3.0   mem len: 200543   epsilon: 0.8009    steps: 225    lr: 4e-05     reward: 2.4\n",
      "epis: 1069   score: 0.0   mem len: 200666   epsilon: 0.8007    steps: 123    lr: 4e-05     reward: 2.39\n",
      "epis: 1070   score: 0.0   mem len: 200789   epsilon: 0.8004    steps: 123    lr: 4e-05     reward: 2.39\n",
      "epis: 1071   score: 4.0   mem len: 201085   epsilon: 0.7998    steps: 296    lr: 4e-05     reward: 2.39\n",
      "epis: 1072   score: 2.0   mem len: 201304   epsilon: 0.7994    steps: 219    lr: 4e-05     reward: 2.39\n",
      "epis: 1073   score: 4.0   mem len: 201620   epsilon: 0.7988    steps: 316    lr: 4e-05     reward: 2.39\n",
      "epis: 1074   score: 3.0   mem len: 201886   epsilon: 0.7983    steps: 266    lr: 4e-05     reward: 2.41\n",
      "epis: 1075   score: 2.0   mem len: 202104   epsilon: 0.7978    steps: 218    lr: 4e-05     reward: 2.38\n",
      "epis: 1076   score: 4.0   mem len: 202417   epsilon: 0.7972    steps: 313    lr: 4e-05     reward: 2.4\n",
      "epis: 1077   score: 2.0   mem len: 202599   epsilon: 0.7969    steps: 182    lr: 4e-05     reward: 2.36\n",
      "epis: 1078   score: 2.0   mem len: 202817   epsilon: 0.7964    steps: 218    lr: 4e-05     reward: 2.37\n",
      "epis: 1079   score: 2.0   mem len: 203014   epsilon: 0.796    steps: 197    lr: 4e-05     reward: 2.36\n",
      "epis: 1080   score: 5.0   mem len: 203376   epsilon: 0.7953    steps: 362    lr: 4e-05     reward: 2.4\n",
      "epis: 1081   score: 3.0   mem len: 203622   epsilon: 0.7948    steps: 246    lr: 4e-05     reward: 2.41\n",
      "epis: 1082   score: 4.0   mem len: 203875   epsilon: 0.7943    steps: 253    lr: 4e-05     reward: 2.42\n",
      "epis: 1083   score: 4.0   mem len: 204133   epsilon: 0.7938    steps: 258    lr: 4e-05     reward: 2.46\n",
      "epis: 1084   score: 3.0   mem len: 204361   epsilon: 0.7934    steps: 228    lr: 4e-05     reward: 2.47\n",
      "epis: 1085   score: 2.0   mem len: 204561   epsilon: 0.793    steps: 200    lr: 4e-05     reward: 2.46\n",
      "epis: 1086   score: 2.0   mem len: 204778   epsilon: 0.7925    steps: 217    lr: 4e-05     reward: 2.46\n",
      "epis: 1087   score: 4.0   mem len: 205044   epsilon: 0.792    steps: 266    lr: 4e-05     reward: 2.48\n",
      "epis: 1088   score: 2.0   mem len: 205244   epsilon: 0.7916    steps: 200    lr: 4e-05     reward: 2.5\n",
      "epis: 1089   score: 3.0   mem len: 205512   epsilon: 0.7911    steps: 268    lr: 4e-05     reward: 2.48\n",
      "epis: 1090   score: 4.0   mem len: 205789   epsilon: 0.7905    steps: 277    lr: 4e-05     reward: 2.48\n",
      "epis: 1091   score: 2.0   mem len: 205970   epsilon: 0.7902    steps: 181    lr: 4e-05     reward: 2.48\n",
      "epis: 1092   score: 4.0   mem len: 206246   epsilon: 0.7896    steps: 276    lr: 4e-05     reward: 2.49\n",
      "epis: 1093   score: 5.0   mem len: 206571   epsilon: 0.789    steps: 325    lr: 4e-05     reward: 2.5\n",
      "epis: 1094   score: 3.0   mem len: 206797   epsilon: 0.7885    steps: 226    lr: 4e-05     reward: 2.53\n",
      "epis: 1095   score: 0.0   mem len: 206919   epsilon: 0.7883    steps: 122    lr: 4e-05     reward: 2.52\n",
      "epis: 1096   score: 0.0   mem len: 207042   epsilon: 0.7881    steps: 123    lr: 4e-05     reward: 2.52\n",
      "epis: 1097   score: 7.0   mem len: 207446   epsilon: 0.7873    steps: 404    lr: 4e-05     reward: 2.58\n",
      "epis: 1098   score: 1.0   mem len: 207597   epsilon: 0.787    steps: 151    lr: 4e-05     reward: 2.55\n",
      "epis: 1099   score: 0.0   mem len: 207719   epsilon: 0.7867    steps: 122    lr: 4e-05     reward: 2.54\n",
      "epis: 1100   score: 3.0   mem len: 207952   epsilon: 0.7863    steps: 233    lr: 4e-05     reward: 2.55\n",
      "epis: 1101   score: 4.0   mem len: 208196   epsilon: 0.7858    steps: 244    lr: 4e-05     reward: 2.59\n",
      "epis: 1102   score: 5.0   mem len: 208497   epsilon: 0.7852    steps: 301    lr: 4e-05     reward: 2.56\n",
      "epis: 1103   score: 3.0   mem len: 208744   epsilon: 0.7847    steps: 247    lr: 4e-05     reward: 2.56\n",
      "epis: 1104   score: 6.0   mem len: 209108   epsilon: 0.784    steps: 364    lr: 4e-05     reward: 2.62\n",
      "epis: 1105   score: 2.0   mem len: 209308   epsilon: 0.7836    steps: 200    lr: 4e-05     reward: 2.6\n",
      "epis: 1106   score: 1.0   mem len: 209480   epsilon: 0.7832    steps: 172    lr: 4e-05     reward: 2.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1107   score: 6.0   mem len: 209831   epsilon: 0.7825    steps: 351    lr: 4e-05     reward: 2.6\n",
      "epis: 1108   score: 3.0   mem len: 210062   epsilon: 0.7821    steps: 231    lr: 4e-05     reward: 2.59\n",
      "epis: 1109   score: 2.0   mem len: 210243   epsilon: 0.7817    steps: 181    lr: 4e-05     reward: 2.59\n",
      "epis: 1110   score: 4.0   mem len: 210521   epsilon: 0.7812    steps: 278    lr: 4e-05     reward: 2.63\n",
      "epis: 1111   score: 4.0   mem len: 210813   epsilon: 0.7806    steps: 292    lr: 4e-05     reward: 2.65\n",
      "epis: 1112   score: 3.0   mem len: 211038   epsilon: 0.7801    steps: 225    lr: 4e-05     reward: 2.65\n",
      "epis: 1113   score: 8.0   mem len: 211506   epsilon: 0.7792    steps: 468    lr: 4e-05     reward: 2.73\n",
      "epis: 1114   score: 2.0   mem len: 211723   epsilon: 0.7788    steps: 217    lr: 4e-05     reward: 2.7\n",
      "epis: 1115   score: 7.0   mem len: 212115   epsilon: 0.778    steps: 392    lr: 4e-05     reward: 2.77\n",
      "epis: 1116   score: 1.0   mem len: 212285   epsilon: 0.7777    steps: 170    lr: 4e-05     reward: 2.73\n",
      "epis: 1117   score: 4.0   mem len: 212580   epsilon: 0.7771    steps: 295    lr: 4e-05     reward: 2.75\n",
      "epis: 1118   score: 3.0   mem len: 212826   epsilon: 0.7766    steps: 246    lr: 4e-05     reward: 2.78\n",
      "epis: 1119   score: 4.0   mem len: 213140   epsilon: 0.776    steps: 314    lr: 4e-05     reward: 2.81\n",
      "epis: 1120   score: 5.0   mem len: 213447   epsilon: 0.7754    steps: 307    lr: 4e-05     reward: 2.86\n",
      "epis: 1121   score: 2.0   mem len: 213629   epsilon: 0.775    steps: 182    lr: 4e-05     reward: 2.86\n",
      "epis: 1122   score: 2.0   mem len: 213829   epsilon: 0.7746    steps: 200    lr: 4e-05     reward: 2.86\n",
      "epis: 1123   score: 1.0   mem len: 213998   epsilon: 0.7743    steps: 169    lr: 4e-05     reward: 2.85\n",
      "epis: 1124   score: 3.0   mem len: 214228   epsilon: 0.7738    steps: 230    lr: 4e-05     reward: 2.83\n",
      "epis: 1125   score: 3.0   mem len: 214454   epsilon: 0.7734    steps: 226    lr: 4e-05     reward: 2.85\n",
      "epis: 1126   score: 4.0   mem len: 214731   epsilon: 0.7728    steps: 277    lr: 4e-05     reward: 2.87\n",
      "epis: 1127   score: 2.0   mem len: 214928   epsilon: 0.7724    steps: 197    lr: 4e-05     reward: 2.86\n",
      "epis: 1128   score: 3.0   mem len: 215138   epsilon: 0.772    steps: 210    lr: 4e-05     reward: 2.84\n",
      "epis: 1129   score: 4.0   mem len: 215439   epsilon: 0.7714    steps: 301    lr: 4e-05     reward: 2.86\n",
      "epis: 1130   score: 5.0   mem len: 215747   epsilon: 0.7708    steps: 308    lr: 4e-05     reward: 2.9\n",
      "epis: 1131   score: 6.0   mem len: 216100   epsilon: 0.7701    steps: 353    lr: 4e-05     reward: 2.9\n",
      "epis: 1132   score: 7.0   mem len: 216522   epsilon: 0.7693    steps: 422    lr: 4e-05     reward: 2.95\n",
      "epis: 1133   score: 1.0   mem len: 216673   epsilon: 0.769    steps: 151    lr: 4e-05     reward: 2.94\n",
      "epis: 1134   score: 2.0   mem len: 216873   epsilon: 0.7686    steps: 200    lr: 4e-05     reward: 2.96\n",
      "epis: 1135   score: 2.0   mem len: 217074   epsilon: 0.7682    steps: 201    lr: 4e-05     reward: 2.95\n",
      "epis: 1136   score: 2.0   mem len: 217295   epsilon: 0.7678    steps: 221    lr: 4e-05     reward: 2.97\n",
      "epis: 1137   score: 2.0   mem len: 217475   epsilon: 0.7674    steps: 180    lr: 4e-05     reward: 2.98\n",
      "epis: 1138   score: 3.0   mem len: 217722   epsilon: 0.7669    steps: 247    lr: 4e-05     reward: 2.92\n",
      "epis: 1139   score: 2.0   mem len: 217920   epsilon: 0.7665    steps: 198    lr: 4e-05     reward: 2.91\n",
      "epis: 1140   score: 3.0   mem len: 218172   epsilon: 0.766    steps: 252    lr: 4e-05     reward: 2.89\n",
      "epis: 1141   score: 4.0   mem len: 218446   epsilon: 0.7655    steps: 274    lr: 4e-05     reward: 2.89\n",
      "epis: 1142   score: 5.0   mem len: 218791   epsilon: 0.7648    steps: 345    lr: 4e-05     reward: 2.89\n",
      "epis: 1143   score: 2.0   mem len: 218991   epsilon: 0.7644    steps: 200    lr: 4e-05     reward: 2.91\n",
      "epis: 1144   score: 4.0   mem len: 219290   epsilon: 0.7638    steps: 299    lr: 4e-05     reward: 2.92\n",
      "epis: 1145   score: 5.0   mem len: 219609   epsilon: 0.7632    steps: 319    lr: 4e-05     reward: 2.95\n",
      "epis: 1146   score: 0.0   mem len: 219732   epsilon: 0.7629    steps: 123    lr: 4e-05     reward: 2.94\n",
      "epis: 1147   score: 4.0   mem len: 220009   epsilon: 0.7624    steps: 277    lr: 4e-05     reward: 2.94\n",
      "epis: 1148   score: 5.0   mem len: 220304   epsilon: 0.7618    steps: 295    lr: 4e-05     reward: 2.94\n",
      "epis: 1149   score: 5.0   mem len: 220610   epsilon: 0.7612    steps: 306    lr: 4e-05     reward: 2.98\n",
      "epis: 1150   score: 2.0   mem len: 220827   epsilon: 0.7608    steps: 217    lr: 4e-05     reward: 2.97\n",
      "epis: 1151   score: 4.0   mem len: 221089   epsilon: 0.7602    steps: 262    lr: 4e-05     reward: 3.01\n",
      "epis: 1152   score: 2.0   mem len: 221287   epsilon: 0.7598    steps: 198    lr: 4e-05     reward: 3.01\n",
      "epis: 1153   score: 4.0   mem len: 221547   epsilon: 0.7593    steps: 260    lr: 4e-05     reward: 3.01\n",
      "epis: 1154   score: 3.0   mem len: 221757   epsilon: 0.7589    steps: 210    lr: 4e-05     reward: 3.02\n",
      "epis: 1155   score: 1.0   mem len: 221908   epsilon: 0.7586    steps: 151    lr: 4e-05     reward: 3.01\n",
      "epis: 1156   score: 3.0   mem len: 222152   epsilon: 0.7581    steps: 244    lr: 4e-05     reward: 3.02\n",
      "epis: 1157   score: 7.0   mem len: 222523   epsilon: 0.7574    steps: 371    lr: 4e-05     reward: 3.06\n",
      "epis: 1158   score: 2.0   mem len: 222723   epsilon: 0.757    steps: 200    lr: 4e-05     reward: 3.07\n",
      "epis: 1159   score: 6.0   mem len: 223080   epsilon: 0.7563    steps: 357    lr: 4e-05     reward: 3.08\n",
      "epis: 1160   score: 6.0   mem len: 223437   epsilon: 0.7556    steps: 357    lr: 4e-05     reward: 3.13\n",
      "epis: 1161   score: 1.0   mem len: 223588   epsilon: 0.7553    steps: 151    lr: 4e-05     reward: 3.12\n",
      "epis: 1162   score: 3.0   mem len: 223857   epsilon: 0.7548    steps: 269    lr: 4e-05     reward: 3.11\n",
      "epis: 1163   score: 3.0   mem len: 224126   epsilon: 0.7542    steps: 269    lr: 4e-05     reward: 3.13\n",
      "epis: 1164   score: 3.0   mem len: 224393   epsilon: 0.7537    steps: 267    lr: 4e-05     reward: 3.15\n",
      "epis: 1165   score: 2.0   mem len: 224591   epsilon: 0.7533    steps: 198    lr: 4e-05     reward: 3.14\n",
      "epis: 1166   score: 8.0   mem len: 225018   epsilon: 0.7525    steps: 427    lr: 4e-05     reward: 3.21\n",
      "epis: 1167   score: 6.0   mem len: 225341   epsilon: 0.7518    steps: 323    lr: 4e-05     reward: 3.25\n",
      "epis: 1168   score: 1.0   mem len: 225510   epsilon: 0.7515    steps: 169    lr: 4e-05     reward: 3.23\n",
      "epis: 1169   score: 10.0   mem len: 225938   epsilon: 0.7506    steps: 428    lr: 4e-05     reward: 3.33\n",
      "epis: 1170   score: 6.0   mem len: 226352   epsilon: 0.7498    steps: 414    lr: 4e-05     reward: 3.39\n",
      "epis: 1171   score: 4.0   mem len: 226627   epsilon: 0.7493    steps: 275    lr: 4e-05     reward: 3.39\n",
      "epis: 1172   score: 8.0   mem len: 227082   epsilon: 0.7484    steps: 455    lr: 4e-05     reward: 3.45\n",
      "epis: 1173   score: 4.0   mem len: 227339   epsilon: 0.7479    steps: 257    lr: 4e-05     reward: 3.45\n",
      "epis: 1174   score: 4.0   mem len: 227616   epsilon: 0.7473    steps: 277    lr: 4e-05     reward: 3.46\n",
      "epis: 1175   score: 3.0   mem len: 227846   epsilon: 0.7469    steps: 230    lr: 4e-05     reward: 3.47\n",
      "epis: 1176   score: 5.0   mem len: 228212   epsilon: 0.7461    steps: 366    lr: 4e-05     reward: 3.48\n",
      "epis: 1177   score: 4.0   mem len: 228487   epsilon: 0.7456    steps: 275    lr: 4e-05     reward: 3.5\n",
      "epis: 1178   score: 2.0   mem len: 228684   epsilon: 0.7452    steps: 197    lr: 4e-05     reward: 3.5\n",
      "epis: 1179   score: 5.0   mem len: 229011   epsilon: 0.7446    steps: 327    lr: 4e-05     reward: 3.53\n",
      "epis: 1180   score: 1.0   mem len: 229162   epsilon: 0.7443    steps: 151    lr: 4e-05     reward: 3.49\n",
      "epis: 1181   score: 5.0   mem len: 229510   epsilon: 0.7436    steps: 348    lr: 4e-05     reward: 3.51\n",
      "epis: 1182   score: 6.0   mem len: 229885   epsilon: 0.7428    steps: 375    lr: 4e-05     reward: 3.53\n",
      "epis: 1183   score: 4.0   mem len: 230126   epsilon: 0.7423    steps: 241    lr: 4e-05     reward: 3.53\n",
      "epis: 1184   score: 3.0   mem len: 230335   epsilon: 0.7419    steps: 209    lr: 4e-05     reward: 3.53\n",
      "epis: 1185   score: 6.0   mem len: 230707   epsilon: 0.7412    steps: 372    lr: 4e-05     reward: 3.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1186   score: 2.0   mem len: 230906   epsilon: 0.7408    steps: 199    lr: 4e-05     reward: 3.57\n",
      "epis: 1187   score: 2.0   mem len: 231088   epsilon: 0.7404    steps: 182    lr: 4e-05     reward: 3.55\n",
      "epis: 1188   score: 8.0   mem len: 231520   epsilon: 0.7396    steps: 432    lr: 4e-05     reward: 3.61\n",
      "epis: 1189   score: 4.0   mem len: 231812   epsilon: 0.739    steps: 292    lr: 4e-05     reward: 3.62\n",
      "epis: 1190   score: 1.0   mem len: 231981   epsilon: 0.7387    steps: 169    lr: 4e-05     reward: 3.59\n",
      "epis: 1191   score: 2.0   mem len: 232163   epsilon: 0.7383    steps: 182    lr: 4e-05     reward: 3.59\n",
      "epis: 1192   score: 5.0   mem len: 232485   epsilon: 0.7377    steps: 322    lr: 4e-05     reward: 3.6\n",
      "epis: 1193   score: 2.0   mem len: 232683   epsilon: 0.7373    steps: 198    lr: 4e-05     reward: 3.57\n",
      "epis: 1194   score: 5.0   mem len: 233009   epsilon: 0.7366    steps: 326    lr: 4e-05     reward: 3.59\n",
      "epis: 1195   score: 4.0   mem len: 233266   epsilon: 0.7361    steps: 257    lr: 4e-05     reward: 3.63\n",
      "epis: 1196   score: 2.0   mem len: 233463   epsilon: 0.7357    steps: 197    lr: 4e-05     reward: 3.65\n",
      "epis: 1197   score: 9.0   mem len: 233831   epsilon: 0.735    steps: 368    lr: 4e-05     reward: 3.67\n",
      "epis: 1198   score: 1.0   mem len: 233982   epsilon: 0.7347    steps: 151    lr: 4e-05     reward: 3.67\n",
      "epis: 1199   score: 4.0   mem len: 234276   epsilon: 0.7341    steps: 294    lr: 4e-05     reward: 3.71\n",
      "epis: 1200   score: 4.0   mem len: 234553   epsilon: 0.7336    steps: 277    lr: 4e-05     reward: 3.72\n",
      "epis: 1201   score: 10.0   mem len: 235006   epsilon: 0.7327    steps: 453    lr: 4e-05     reward: 3.78\n",
      "epis: 1202   score: 3.0   mem len: 235257   epsilon: 0.7322    steps: 251    lr: 4e-05     reward: 3.76\n",
      "epis: 1203   score: 7.0   mem len: 235692   epsilon: 0.7313    steps: 435    lr: 4e-05     reward: 3.8\n",
      "epis: 1204   score: 5.0   mem len: 236060   epsilon: 0.7306    steps: 368    lr: 4e-05     reward: 3.79\n",
      "epis: 1205   score: 5.0   mem len: 236386   epsilon: 0.73    steps: 326    lr: 4e-05     reward: 3.82\n",
      "epis: 1206   score: 7.0   mem len: 236649   epsilon: 0.7294    steps: 263    lr: 4e-05     reward: 3.88\n",
      "epis: 1207   score: 2.0   mem len: 236851   epsilon: 0.729    steps: 202    lr: 4e-05     reward: 3.84\n",
      "epis: 1208   score: 3.0   mem len: 237097   epsilon: 0.7285    steps: 246    lr: 4e-05     reward: 3.84\n",
      "epis: 1209   score: 6.0   mem len: 237471   epsilon: 0.7278    steps: 374    lr: 4e-05     reward: 3.88\n",
      "epis: 1210   score: 2.0   mem len: 237669   epsilon: 0.7274    steps: 198    lr: 4e-05     reward: 3.86\n",
      "epis: 1211   score: 3.0   mem len: 237878   epsilon: 0.727    steps: 209    lr: 4e-05     reward: 3.85\n",
      "epis: 1212   score: 4.0   mem len: 238137   epsilon: 0.7265    steps: 259    lr: 4e-05     reward: 3.86\n",
      "epis: 1213   score: 4.0   mem len: 238414   epsilon: 0.7259    steps: 277    lr: 4e-05     reward: 3.82\n",
      "epis: 1214   score: 4.0   mem len: 238731   epsilon: 0.7253    steps: 317    lr: 4e-05     reward: 3.84\n",
      "epis: 1215   score: 3.0   mem len: 238944   epsilon: 0.7249    steps: 213    lr: 4e-05     reward: 3.8\n",
      "epis: 1216   score: 5.0   mem len: 239251   epsilon: 0.7243    steps: 307    lr: 4e-05     reward: 3.84\n",
      "epis: 1217   score: 3.0   mem len: 239476   epsilon: 0.7238    steps: 225    lr: 4e-05     reward: 3.83\n",
      "epis: 1218   score: 4.0   mem len: 239755   epsilon: 0.7233    steps: 279    lr: 4e-05     reward: 3.84\n",
      "epis: 1219   score: 2.0   mem len: 239954   epsilon: 0.7229    steps: 199    lr: 4e-05     reward: 3.82\n",
      "epis: 1220   score: 3.0   mem len: 240198   epsilon: 0.7224    steps: 244    lr: 4e-05     reward: 3.8\n",
      "epis: 1221   score: 9.0   mem len: 240682   epsilon: 0.7214    steps: 484    lr: 4e-05     reward: 3.87\n",
      "epis: 1222   score: 0.0   mem len: 240805   epsilon: 0.7212    steps: 123    lr: 4e-05     reward: 3.85\n",
      "epis: 1223   score: 2.0   mem len: 241027   epsilon: 0.7208    steps: 222    lr: 4e-05     reward: 3.86\n",
      "epis: 1224   score: 6.0   mem len: 241389   epsilon: 0.72    steps: 362    lr: 4e-05     reward: 3.89\n",
      "epis: 1225   score: 5.0   mem len: 241714   epsilon: 0.7194    steps: 325    lr: 4e-05     reward: 3.91\n",
      "epis: 1226   score: 5.0   mem len: 242031   epsilon: 0.7188    steps: 317    lr: 4e-05     reward: 3.92\n",
      "epis: 1227   score: 3.0   mem len: 242276   epsilon: 0.7183    steps: 245    lr: 4e-05     reward: 3.93\n",
      "epis: 1228   score: 1.0   mem len: 242447   epsilon: 0.718    steps: 171    lr: 4e-05     reward: 3.91\n",
      "epis: 1229   score: 5.0   mem len: 242755   epsilon: 0.7173    steps: 308    lr: 4e-05     reward: 3.92\n",
      "epis: 1230   score: 3.0   mem len: 243004   epsilon: 0.7169    steps: 249    lr: 4e-05     reward: 3.9\n",
      "epis: 1231   score: 5.0   mem len: 243333   epsilon: 0.7162    steps: 329    lr: 4e-05     reward: 3.89\n",
      "epis: 1232   score: 6.0   mem len: 243710   epsilon: 0.7155    steps: 377    lr: 4e-05     reward: 3.88\n",
      "epis: 1233   score: 3.0   mem len: 243957   epsilon: 0.715    steps: 247    lr: 4e-05     reward: 3.9\n",
      "epis: 1234   score: 4.0   mem len: 244275   epsilon: 0.7143    steps: 318    lr: 4e-05     reward: 3.92\n",
      "epis: 1235   score: 3.0   mem len: 244504   epsilon: 0.7139    steps: 229    lr: 4e-05     reward: 3.93\n",
      "epis: 1236   score: 6.0   mem len: 244877   epsilon: 0.7131    steps: 373    lr: 4e-05     reward: 3.97\n",
      "epis: 1237   score: 5.0   mem len: 245197   epsilon: 0.7125    steps: 320    lr: 4e-05     reward: 4.0\n",
      "epis: 1238   score: 3.0   mem len: 245442   epsilon: 0.712    steps: 245    lr: 4e-05     reward: 4.0\n",
      "epis: 1239   score: 2.0   mem len: 245641   epsilon: 0.7116    steps: 199    lr: 4e-05     reward: 4.0\n",
      "epis: 1240   score: 3.0   mem len: 245868   epsilon: 0.7112    steps: 227    lr: 4e-05     reward: 4.0\n",
      "epis: 1241   score: 5.0   mem len: 246176   epsilon: 0.7106    steps: 308    lr: 4e-05     reward: 4.01\n",
      "epis: 1242   score: 3.0   mem len: 246421   epsilon: 0.7101    steps: 245    lr: 4e-05     reward: 3.99\n",
      "epis: 1243   score: 3.0   mem len: 246634   epsilon: 0.7097    steps: 213    lr: 4e-05     reward: 4.0\n",
      "epis: 1244   score: 1.0   mem len: 246803   epsilon: 0.7093    steps: 169    lr: 4e-05     reward: 3.97\n",
      "epis: 1245   score: 3.0   mem len: 247051   epsilon: 0.7088    steps: 248    lr: 4e-05     reward: 3.95\n",
      "epis: 1246   score: 1.0   mem len: 247219   epsilon: 0.7085    steps: 168    lr: 4e-05     reward: 3.96\n",
      "epis: 1247   score: 4.0   mem len: 247494   epsilon: 0.708    steps: 275    lr: 4e-05     reward: 3.96\n",
      "epis: 1248   score: 6.0   mem len: 247885   epsilon: 0.7072    steps: 391    lr: 4e-05     reward: 3.97\n",
      "epis: 1249   score: 5.0   mem len: 248201   epsilon: 0.7066    steps: 316    lr: 4e-05     reward: 3.97\n",
      "epis: 1250   score: 6.0   mem len: 248505   epsilon: 0.706    steps: 304    lr: 4e-05     reward: 4.01\n",
      "epis: 1251   score: 4.0   mem len: 248800   epsilon: 0.7054    steps: 295    lr: 4e-05     reward: 4.01\n",
      "epis: 1252   score: 5.0   mem len: 249125   epsilon: 0.7047    steps: 325    lr: 4e-05     reward: 4.04\n",
      "epis: 1253   score: 5.0   mem len: 249432   epsilon: 0.7041    steps: 307    lr: 4e-05     reward: 4.05\n",
      "epis: 1254   score: 4.0   mem len: 249709   epsilon: 0.7036    steps: 277    lr: 4e-05     reward: 4.06\n",
      "epis: 1255   score: 6.0   mem len: 250058   epsilon: 0.7029    steps: 349    lr: 4e-05     reward: 4.11\n",
      "epis: 1256   score: 6.0   mem len: 250455   epsilon: 0.7021    steps: 397    lr: 4e-05     reward: 4.14\n",
      "epis: 1257   score: 2.0   mem len: 250652   epsilon: 0.7017    steps: 197    lr: 4e-05     reward: 4.09\n",
      "epis: 1258   score: 5.0   mem len: 250961   epsilon: 0.7011    steps: 309    lr: 4e-05     reward: 4.12\n",
      "epis: 1259   score: 5.0   mem len: 251304   epsilon: 0.7004    steps: 343    lr: 4e-05     reward: 4.11\n",
      "epis: 1260   score: 3.0   mem len: 251552   epsilon: 0.6999    steps: 248    lr: 4e-05     reward: 4.08\n",
      "epis: 1261   score: 6.0   mem len: 251907   epsilon: 0.6992    steps: 355    lr: 4e-05     reward: 4.13\n",
      "epis: 1262   score: 5.0   mem len: 252214   epsilon: 0.6986    steps: 307    lr: 4e-05     reward: 4.15\n",
      "epis: 1263   score: 3.0   mem len: 252424   epsilon: 0.6982    steps: 210    lr: 4e-05     reward: 4.15\n",
      "epis: 1264   score: 4.0   mem len: 252697   epsilon: 0.6977    steps: 273    lr: 4e-05     reward: 4.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1265   score: 2.0   mem len: 252894   epsilon: 0.6973    steps: 197    lr: 4e-05     reward: 4.16\n",
      "epis: 1266   score: 4.0   mem len: 253137   epsilon: 0.6968    steps: 243    lr: 4e-05     reward: 4.12\n",
      "epis: 1267   score: 6.0   mem len: 253494   epsilon: 0.6961    steps: 357    lr: 4e-05     reward: 4.12\n",
      "epis: 1268   score: 3.0   mem len: 253723   epsilon: 0.6956    steps: 229    lr: 4e-05     reward: 4.14\n",
      "epis: 1269   score: 3.0   mem len: 253971   epsilon: 0.6951    steps: 248    lr: 4e-05     reward: 4.07\n",
      "epis: 1270   score: 4.0   mem len: 254246   epsilon: 0.6946    steps: 275    lr: 4e-05     reward: 4.05\n",
      "epis: 1271   score: 4.0   mem len: 254539   epsilon: 0.694    steps: 293    lr: 4e-05     reward: 4.05\n",
      "epis: 1272   score: 3.0   mem len: 254788   epsilon: 0.6935    steps: 249    lr: 4e-05     reward: 4.0\n",
      "epis: 1273   score: 2.0   mem len: 254986   epsilon: 0.6931    steps: 198    lr: 4e-05     reward: 3.98\n",
      "epis: 1274   score: 3.0   mem len: 255230   epsilon: 0.6926    steps: 244    lr: 4e-05     reward: 3.97\n",
      "epis: 1275   score: 6.0   mem len: 255601   epsilon: 0.6919    steps: 371    lr: 4e-05     reward: 4.0\n",
      "epis: 1276   score: 6.0   mem len: 255920   epsilon: 0.6913    steps: 319    lr: 4e-05     reward: 4.01\n",
      "epis: 1277   score: 9.0   mem len: 256414   epsilon: 0.6903    steps: 494    lr: 4e-05     reward: 4.06\n",
      "epis: 1278   score: 4.0   mem len: 256654   epsilon: 0.6898    steps: 240    lr: 4e-05     reward: 4.08\n",
      "epis: 1279   score: 1.0   mem len: 256805   epsilon: 0.6895    steps: 151    lr: 4e-05     reward: 4.04\n",
      "epis: 1280   score: 1.0   mem len: 256974   epsilon: 0.6892    steps: 169    lr: 4e-05     reward: 4.04\n",
      "epis: 1281   score: 6.0   mem len: 257332   epsilon: 0.6885    steps: 358    lr: 4e-05     reward: 4.05\n",
      "epis: 1282   score: 3.0   mem len: 257580   epsilon: 0.688    steps: 248    lr: 4e-05     reward: 4.02\n",
      "epis: 1283   score: 1.0   mem len: 257731   epsilon: 0.6877    steps: 151    lr: 4e-05     reward: 3.99\n",
      "epis: 1284   score: 6.0   mem len: 258081   epsilon: 0.687    steps: 350    lr: 4e-05     reward: 4.02\n",
      "epis: 1285   score: 8.0   mem len: 258489   epsilon: 0.6862    steps: 408    lr: 4e-05     reward: 4.04\n",
      "epis: 1286   score: 3.0   mem len: 258717   epsilon: 0.6857    steps: 228    lr: 4e-05     reward: 4.05\n",
      "epis: 1287   score: 6.0   mem len: 259109   epsilon: 0.685    steps: 392    lr: 4e-05     reward: 4.09\n",
      "epis: 1288   score: 2.0   mem len: 259329   epsilon: 0.6845    steps: 220    lr: 4e-05     reward: 4.03\n",
      "epis: 1289   score: 2.0   mem len: 259526   epsilon: 0.6841    steps: 197    lr: 4e-05     reward: 4.01\n",
      "epis: 1290   score: 2.0   mem len: 259724   epsilon: 0.6837    steps: 198    lr: 4e-05     reward: 4.02\n",
      "epis: 1291   score: 9.0   mem len: 260176   epsilon: 0.6828    steps: 452    lr: 4e-05     reward: 4.09\n",
      "epis: 1292   score: 6.0   mem len: 260555   epsilon: 0.6821    steps: 379    lr: 4e-05     reward: 4.1\n",
      "epis: 1293   score: 9.0   mem len: 261034   epsilon: 0.6812    steps: 479    lr: 4e-05     reward: 4.17\n",
      "epis: 1294   score: 4.0   mem len: 261309   epsilon: 0.6806    steps: 275    lr: 4e-05     reward: 4.16\n",
      "epis: 1295   score: 5.0   mem len: 261634   epsilon: 0.68    steps: 325    lr: 4e-05     reward: 4.17\n",
      "epis: 1296   score: 2.0   mem len: 261850   epsilon: 0.6795    steps: 216    lr: 4e-05     reward: 4.17\n",
      "epis: 1297   score: 3.0   mem len: 262094   epsilon: 0.6791    steps: 244    lr: 4e-05     reward: 4.11\n",
      "epis: 1298   score: 5.0   mem len: 262400   epsilon: 0.6784    steps: 306    lr: 4e-05     reward: 4.15\n",
      "epis: 1299   score: 5.0   mem len: 262690   epsilon: 0.6779    steps: 290    lr: 4e-05     reward: 4.16\n",
      "epis: 1300   score: 4.0   mem len: 262968   epsilon: 0.6773    steps: 278    lr: 4e-05     reward: 4.16\n",
      "epis: 1301   score: 8.0   mem len: 263349   epsilon: 0.6766    steps: 381    lr: 4e-05     reward: 4.14\n",
      "epis: 1302   score: 7.0   mem len: 263727   epsilon: 0.6758    steps: 378    lr: 4e-05     reward: 4.18\n",
      "epis: 1303   score: 6.0   mem len: 264085   epsilon: 0.6751    steps: 358    lr: 4e-05     reward: 4.17\n",
      "epis: 1304   score: 2.0   mem len: 264286   epsilon: 0.6747    steps: 201    lr: 4e-05     reward: 4.14\n",
      "epis: 1305   score: 2.0   mem len: 264468   epsilon: 0.6744    steps: 182    lr: 4e-05     reward: 4.11\n",
      "epis: 1306   score: 3.0   mem len: 264696   epsilon: 0.6739    steps: 228    lr: 4e-05     reward: 4.07\n",
      "epis: 1307   score: 8.0   mem len: 265147   epsilon: 0.673    steps: 451    lr: 4e-05     reward: 4.13\n",
      "epis: 1308   score: 6.0   mem len: 265466   epsilon: 0.6724    steps: 319    lr: 4e-05     reward: 4.16\n",
      "epis: 1309   score: 6.0   mem len: 265843   epsilon: 0.6716    steps: 377    lr: 4e-05     reward: 4.16\n",
      "epis: 1310   score: 5.0   mem len: 266149   epsilon: 0.671    steps: 306    lr: 4e-05     reward: 4.19\n",
      "epis: 1311   score: 7.0   mem len: 266517   epsilon: 0.6703    steps: 368    lr: 4e-05     reward: 4.23\n",
      "epis: 1312   score: 3.0   mem len: 266730   epsilon: 0.6699    steps: 213    lr: 4e-05     reward: 4.22\n",
      "epis: 1313   score: 5.0   mem len: 267074   epsilon: 0.6692    steps: 344    lr: 4e-05     reward: 4.23\n",
      "epis: 1314   score: 3.0   mem len: 267282   epsilon: 0.6688    steps: 208    lr: 4e-05     reward: 4.22\n",
      "epis: 1315   score: 6.0   mem len: 267648   epsilon: 0.6681    steps: 366    lr: 4e-05     reward: 4.25\n",
      "epis: 1316   score: 2.0   mem len: 267866   epsilon: 0.6676    steps: 218    lr: 4e-05     reward: 4.22\n",
      "epis: 1317   score: 3.0   mem len: 268113   epsilon: 0.6671    steps: 247    lr: 4e-05     reward: 4.22\n",
      "epis: 1318   score: 7.0   mem len: 268505   epsilon: 0.6664    steps: 392    lr: 4e-05     reward: 4.25\n",
      "epis: 1319   score: 10.0   mem len: 269070   epsilon: 0.6652    steps: 565    lr: 4e-05     reward: 4.33\n",
      "epis: 1320   score: 1.0   mem len: 269221   epsilon: 0.6649    steps: 151    lr: 4e-05     reward: 4.31\n",
      "epis: 1321   score: 4.0   mem len: 269479   epsilon: 0.6644    steps: 258    lr: 4e-05     reward: 4.26\n",
      "epis: 1322   score: 1.0   mem len: 269651   epsilon: 0.6641    steps: 172    lr: 4e-05     reward: 4.27\n",
      "epis: 1323   score: 5.0   mem len: 269974   epsilon: 0.6634    steps: 323    lr: 4e-05     reward: 4.3\n",
      "epis: 1324   score: 4.0   mem len: 270229   epsilon: 0.6629    steps: 255    lr: 4e-05     reward: 4.28\n",
      "epis: 1325   score: 3.0   mem len: 270455   epsilon: 0.6625    steps: 226    lr: 4e-05     reward: 4.26\n",
      "epis: 1326   score: 2.0   mem len: 270673   epsilon: 0.6621    steps: 218    lr: 4e-05     reward: 4.23\n",
      "epis: 1327   score: 4.0   mem len: 270934   epsilon: 0.6615    steps: 261    lr: 4e-05     reward: 4.24\n",
      "epis: 1328   score: 5.0   mem len: 271260   epsilon: 0.6609    steps: 326    lr: 4e-05     reward: 4.28\n",
      "epis: 1329   score: 5.0   mem len: 271584   epsilon: 0.6603    steps: 324    lr: 4e-05     reward: 4.28\n",
      "epis: 1330   score: 3.0   mem len: 271813   epsilon: 0.6598    steps: 229    lr: 4e-05     reward: 4.28\n",
      "epis: 1331   score: 3.0   mem len: 272042   epsilon: 0.6594    steps: 229    lr: 4e-05     reward: 4.26\n",
      "epis: 1332   score: 13.0   mem len: 272528   epsilon: 0.6584    steps: 486    lr: 4e-05     reward: 4.33\n",
      "epis: 1333   score: 6.0   mem len: 272889   epsilon: 0.6577    steps: 361    lr: 4e-05     reward: 4.36\n",
      "epis: 1334   score: 5.0   mem len: 273195   epsilon: 0.6571    steps: 306    lr: 4e-05     reward: 4.37\n",
      "epis: 1335   score: 4.0   mem len: 273475   epsilon: 0.6565    steps: 280    lr: 4e-05     reward: 4.38\n",
      "epis: 1336   score: 1.0   mem len: 273625   epsilon: 0.6562    steps: 150    lr: 4e-05     reward: 4.33\n",
      "epis: 1337   score: 4.0   mem len: 273885   epsilon: 0.6557    steps: 260    lr: 4e-05     reward: 4.32\n",
      "epis: 1338   score: 5.0   mem len: 274214   epsilon: 0.6551    steps: 329    lr: 4e-05     reward: 4.34\n",
      "epis: 1339   score: 5.0   mem len: 274530   epsilon: 0.6544    steps: 316    lr: 4e-05     reward: 4.37\n",
      "epis: 1340   score: 3.0   mem len: 274779   epsilon: 0.6539    steps: 249    lr: 4e-05     reward: 4.37\n",
      "epis: 1341   score: 3.0   mem len: 275026   epsilon: 0.6534    steps: 247    lr: 4e-05     reward: 4.35\n",
      "epis: 1342   score: 5.0   mem len: 275338   epsilon: 0.6528    steps: 312    lr: 4e-05     reward: 4.37\n",
      "epis: 1343   score: 7.0   mem len: 275715   epsilon: 0.6521    steps: 377    lr: 4e-05     reward: 4.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1344   score: 7.0   mem len: 276119   epsilon: 0.6513    steps: 404    lr: 4e-05     reward: 4.47\n",
      "epis: 1345   score: 8.0   mem len: 276558   epsilon: 0.6504    steps: 439    lr: 4e-05     reward: 4.52\n",
      "epis: 1346   score: 11.0   mem len: 277034   epsilon: 0.6495    steps: 476    lr: 4e-05     reward: 4.62\n",
      "epis: 1347   score: 2.0   mem len: 277232   epsilon: 0.6491    steps: 198    lr: 4e-05     reward: 4.6\n",
      "epis: 1348   score: 3.0   mem len: 277477   epsilon: 0.6486    steps: 245    lr: 4e-05     reward: 4.57\n",
      "epis: 1349   score: 4.0   mem len: 277718   epsilon: 0.6481    steps: 241    lr: 4e-05     reward: 4.56\n",
      "epis: 1350   score: 6.0   mem len: 278091   epsilon: 0.6474    steps: 373    lr: 4e-05     reward: 4.56\n",
      "epis: 1351   score: 11.0   mem len: 278516   epsilon: 0.6465    steps: 425    lr: 4e-05     reward: 4.63\n",
      "epis: 1352   score: 7.0   mem len: 278888   epsilon: 0.6458    steps: 372    lr: 4e-05     reward: 4.65\n",
      "epis: 1353   score: 2.0   mem len: 279086   epsilon: 0.6454    steps: 198    lr: 4e-05     reward: 4.62\n",
      "epis: 1354   score: 1.0   mem len: 279255   epsilon: 0.6451    steps: 169    lr: 4e-05     reward: 4.59\n",
      "epis: 1355   score: 4.0   mem len: 279530   epsilon: 0.6445    steps: 275    lr: 4e-05     reward: 4.57\n",
      "epis: 1356   score: 3.0   mem len: 279759   epsilon: 0.6441    steps: 229    lr: 4e-05     reward: 4.54\n",
      "epis: 1357   score: 6.0   mem len: 280094   epsilon: 0.6434    steps: 335    lr: 4e-05     reward: 4.58\n",
      "epis: 1358   score: 4.0   mem len: 280352   epsilon: 0.6429    steps: 258    lr: 4e-05     reward: 4.57\n",
      "epis: 1359   score: 7.0   mem len: 280772   epsilon: 0.6421    steps: 420    lr: 4e-05     reward: 4.59\n",
      "epis: 1360   score: 7.0   mem len: 281161   epsilon: 0.6413    steps: 389    lr: 4e-05     reward: 4.63\n",
      "epis: 1361   score: 4.0   mem len: 281420   epsilon: 0.6408    steps: 259    lr: 4e-05     reward: 4.61\n",
      "epis: 1362   score: 5.0   mem len: 281708   epsilon: 0.6402    steps: 288    lr: 4e-05     reward: 4.61\n",
      "epis: 1363   score: 3.0   mem len: 281958   epsilon: 0.6397    steps: 250    lr: 4e-05     reward: 4.61\n",
      "epis: 1364   score: 4.0   mem len: 282253   epsilon: 0.6391    steps: 295    lr: 4e-05     reward: 4.61\n",
      "epis: 1365   score: 6.0   mem len: 282609   epsilon: 0.6384    steps: 356    lr: 4e-05     reward: 4.65\n",
      "epis: 1366   score: 6.0   mem len: 282945   epsilon: 0.6378    steps: 336    lr: 4e-05     reward: 4.67\n",
      "epis: 1367   score: 7.0   mem len: 283347   epsilon: 0.637    steps: 402    lr: 4e-05     reward: 4.68\n",
      "epis: 1368   score: 4.0   mem len: 283622   epsilon: 0.6364    steps: 275    lr: 4e-05     reward: 4.69\n",
      "epis: 1369   score: 3.0   mem len: 283852   epsilon: 0.636    steps: 230    lr: 4e-05     reward: 4.69\n",
      "epis: 1370   score: 4.0   mem len: 284094   epsilon: 0.6355    steps: 242    lr: 4e-05     reward: 4.69\n",
      "epis: 1371   score: 6.0   mem len: 284452   epsilon: 0.6348    steps: 358    lr: 4e-05     reward: 4.71\n",
      "epis: 1372   score: 10.0   mem len: 284836   epsilon: 0.634    steps: 384    lr: 4e-05     reward: 4.78\n",
      "epis: 1373   score: 6.0   mem len: 285197   epsilon: 0.6333    steps: 361    lr: 4e-05     reward: 4.82\n",
      "epis: 1374   score: 8.0   mem len: 285609   epsilon: 0.6325    steps: 412    lr: 4e-05     reward: 4.87\n",
      "epis: 1375   score: 6.0   mem len: 285944   epsilon: 0.6318    steps: 335    lr: 4e-05     reward: 4.87\n",
      "epis: 1376   score: 2.0   mem len: 286124   epsilon: 0.6315    steps: 180    lr: 4e-05     reward: 4.83\n",
      "epis: 1377   score: 7.0   mem len: 286508   epsilon: 0.6307    steps: 384    lr: 4e-05     reward: 4.81\n",
      "epis: 1378   score: 7.0   mem len: 286948   epsilon: 0.6298    steps: 440    lr: 4e-05     reward: 4.84\n",
      "epis: 1379   score: 6.0   mem len: 287301   epsilon: 0.6291    steps: 353    lr: 4e-05     reward: 4.89\n",
      "epis: 1380   score: 4.0   mem len: 287575   epsilon: 0.6286    steps: 274    lr: 4e-05     reward: 4.92\n",
      "epis: 1381   score: 6.0   mem len: 287953   epsilon: 0.6279    steps: 378    lr: 4e-05     reward: 4.92\n",
      "epis: 1382   score: 7.0   mem len: 288295   epsilon: 0.6272    steps: 342    lr: 4e-05     reward: 4.96\n",
      "epis: 1383   score: 4.0   mem len: 288590   epsilon: 0.6266    steps: 295    lr: 4e-05     reward: 4.99\n",
      "epis: 1384   score: 3.0   mem len: 288837   epsilon: 0.6261    steps: 247    lr: 4e-05     reward: 4.96\n",
      "epis: 1385   score: 5.0   mem len: 289182   epsilon: 0.6254    steps: 345    lr: 4e-05     reward: 4.93\n",
      "epis: 1386   score: 4.0   mem len: 289457   epsilon: 0.6249    steps: 275    lr: 4e-05     reward: 4.94\n",
      "epis: 1387   score: 6.0   mem len: 289808   epsilon: 0.6242    steps: 351    lr: 4e-05     reward: 4.94\n",
      "epis: 1388   score: 3.0   mem len: 290054   epsilon: 0.6237    steps: 246    lr: 4e-05     reward: 4.95\n",
      "epis: 1389   score: 4.0   mem len: 290312   epsilon: 0.6232    steps: 258    lr: 4e-05     reward: 4.97\n",
      "epis: 1390   score: 4.0   mem len: 290611   epsilon: 0.6226    steps: 299    lr: 4e-05     reward: 4.99\n",
      "epis: 1391   score: 3.0   mem len: 290824   epsilon: 0.6222    steps: 213    lr: 4e-05     reward: 4.93\n",
      "epis: 1392   score: 3.0   mem len: 291053   epsilon: 0.6217    steps: 229    lr: 4e-05     reward: 4.9\n",
      "epis: 1393   score: 3.0   mem len: 291280   epsilon: 0.6213    steps: 227    lr: 4e-05     reward: 4.84\n",
      "epis: 1394   score: 2.0   mem len: 291477   epsilon: 0.6209    steps: 197    lr: 4e-05     reward: 4.82\n",
      "epis: 1395   score: 9.0   mem len: 291959   epsilon: 0.6199    steps: 482    lr: 4e-05     reward: 4.86\n",
      "epis: 1396   score: 5.0   mem len: 292282   epsilon: 0.6193    steps: 323    lr: 4e-05     reward: 4.89\n",
      "epis: 1397   score: 6.0   mem len: 292603   epsilon: 0.6186    steps: 321    lr: 4e-05     reward: 4.92\n",
      "epis: 1398   score: 5.0   mem len: 292928   epsilon: 0.618    steps: 325    lr: 4e-05     reward: 4.92\n",
      "epis: 1399   score: 4.0   mem len: 293206   epsilon: 0.6175    steps: 278    lr: 4e-05     reward: 4.91\n",
      "epis: 1400   score: 7.0   mem len: 293588   epsilon: 0.6167    steps: 382    lr: 4e-05     reward: 4.94\n",
      "epis: 1401   score: 6.0   mem len: 293941   epsilon: 0.616    steps: 353    lr: 4e-05     reward: 4.92\n",
      "epis: 1402   score: 6.0   mem len: 294338   epsilon: 0.6152    steps: 397    lr: 4e-05     reward: 4.91\n",
      "epis: 1403   score: 2.0   mem len: 294555   epsilon: 0.6148    steps: 217    lr: 4e-05     reward: 4.87\n",
      "epis: 1404   score: 8.0   mem len: 294960   epsilon: 0.614    steps: 405    lr: 4e-05     reward: 4.93\n",
      "epis: 1405   score: 6.0   mem len: 295334   epsilon: 0.6132    steps: 374    lr: 4e-05     reward: 4.97\n",
      "epis: 1406   score: 6.0   mem len: 295724   epsilon: 0.6125    steps: 390    lr: 4e-05     reward: 5.0\n",
      "epis: 1407   score: 11.0   mem len: 296120   epsilon: 0.6117    steps: 396    lr: 4e-05     reward: 5.03\n",
      "epis: 1408   score: 9.0   mem len: 296644   epsilon: 0.6106    steps: 524    lr: 4e-05     reward: 5.06\n",
      "epis: 1409   score: 5.0   mem len: 296988   epsilon: 0.61    steps: 344    lr: 4e-05     reward: 5.05\n",
      "epis: 1410   score: 4.0   mem len: 297283   epsilon: 0.6094    steps: 295    lr: 4e-05     reward: 5.04\n",
      "epis: 1411   score: 5.0   mem len: 297628   epsilon: 0.6087    steps: 345    lr: 4e-05     reward: 5.02\n",
      "epis: 1412   score: 2.0   mem len: 297846   epsilon: 0.6083    steps: 218    lr: 4e-05     reward: 5.01\n",
      "epis: 1413   score: 4.0   mem len: 298139   epsilon: 0.6077    steps: 293    lr: 4e-05     reward: 5.0\n",
      "epis: 1414   score: 9.0   mem len: 298615   epsilon: 0.6067    steps: 476    lr: 4e-05     reward: 5.06\n",
      "epis: 1415   score: 4.0   mem len: 298871   epsilon: 0.6062    steps: 256    lr: 4e-05     reward: 5.04\n",
      "epis: 1416   score: 4.0   mem len: 299147   epsilon: 0.6057    steps: 276    lr: 4e-05     reward: 5.06\n",
      "epis: 1417   score: 5.0   mem len: 299428   epsilon: 0.6051    steps: 281    lr: 4e-05     reward: 5.08\n",
      "epis: 1418   score: 7.0   mem len: 299809   epsilon: 0.6044    steps: 381    lr: 4e-05     reward: 5.08\n",
      "epis: 1419   score: 10.0   mem len: 300331   epsilon: 0.6033    steps: 522    lr: 1.6e-05     reward: 5.08\n",
      "epis: 1420   score: 6.0   mem len: 300688   epsilon: 0.6026    steps: 357    lr: 1.6e-05     reward: 5.13\n",
      "epis: 1421   score: 6.0   mem len: 301036   epsilon: 0.6019    steps: 348    lr: 1.6e-05     reward: 5.15\n",
      "epis: 1422   score: 3.0   mem len: 301303   epsilon: 0.6014    steps: 267    lr: 1.6e-05     reward: 5.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1423   score: 4.0   mem len: 301566   epsilon: 0.6009    steps: 263    lr: 1.6e-05     reward: 5.16\n",
      "epis: 1424   score: 7.0   mem len: 301923   epsilon: 0.6002    steps: 357    lr: 1.6e-05     reward: 5.19\n",
      "epis: 1425   score: 6.0   mem len: 302279   epsilon: 0.5995    steps: 356    lr: 1.6e-05     reward: 5.22\n",
      "epis: 1426   score: 6.0   mem len: 302671   epsilon: 0.5987    steps: 392    lr: 1.6e-05     reward: 5.26\n",
      "epis: 1427   score: 6.0   mem len: 303033   epsilon: 0.598    steps: 362    lr: 1.6e-05     reward: 5.28\n",
      "epis: 1428   score: 12.0   mem len: 303590   epsilon: 0.5969    steps: 557    lr: 1.6e-05     reward: 5.35\n",
      "epis: 1429   score: 6.0   mem len: 304004   epsilon: 0.5961    steps: 414    lr: 1.6e-05     reward: 5.36\n",
      "epis: 1430   score: 7.0   mem len: 304379   epsilon: 0.5953    steps: 375    lr: 1.6e-05     reward: 5.4\n",
      "epis: 1431   score: 5.0   mem len: 304703   epsilon: 0.5947    steps: 324    lr: 1.6e-05     reward: 5.42\n",
      "epis: 1432   score: 5.0   mem len: 305016   epsilon: 0.5941    steps: 313    lr: 1.6e-05     reward: 5.34\n",
      "epis: 1433   score: 5.0   mem len: 305340   epsilon: 0.5934    steps: 324    lr: 1.6e-05     reward: 5.33\n",
      "epis: 1434   score: 4.0   mem len: 305616   epsilon: 0.5929    steps: 276    lr: 1.6e-05     reward: 5.32\n",
      "epis: 1435   score: 3.0   mem len: 305863   epsilon: 0.5924    steps: 247    lr: 1.6e-05     reward: 5.31\n",
      "epis: 1436   score: 5.0   mem len: 306173   epsilon: 0.5918    steps: 310    lr: 1.6e-05     reward: 5.35\n",
      "epis: 1437   score: 6.0   mem len: 306526   epsilon: 0.5911    steps: 353    lr: 1.6e-05     reward: 5.37\n",
      "epis: 1438   score: 2.0   mem len: 306743   epsilon: 0.5906    steps: 217    lr: 1.6e-05     reward: 5.34\n",
      "epis: 1439   score: 5.0   mem len: 307029   epsilon: 0.5901    steps: 286    lr: 1.6e-05     reward: 5.34\n",
      "epis: 1440   score: 9.0   mem len: 307552   epsilon: 0.589    steps: 523    lr: 1.6e-05     reward: 5.4\n",
      "epis: 1441   score: 4.0   mem len: 307842   epsilon: 0.5885    steps: 290    lr: 1.6e-05     reward: 5.41\n",
      "epis: 1442   score: 8.0   mem len: 308251   epsilon: 0.5877    steps: 409    lr: 1.6e-05     reward: 5.44\n",
      "epis: 1443   score: 5.0   mem len: 308565   epsilon: 0.587    steps: 314    lr: 1.6e-05     reward: 5.42\n",
      "epis: 1444   score: 4.0   mem len: 308826   epsilon: 0.5865    steps: 261    lr: 1.6e-05     reward: 5.39\n",
      "epis: 1445   score: 6.0   mem len: 309165   epsilon: 0.5859    steps: 339    lr: 1.6e-05     reward: 5.37\n",
      "epis: 1446   score: 4.0   mem len: 309462   epsilon: 0.5853    steps: 297    lr: 1.6e-05     reward: 5.3\n",
      "epis: 1447   score: 5.0   mem len: 309790   epsilon: 0.5846    steps: 328    lr: 1.6e-05     reward: 5.33\n",
      "epis: 1448   score: 8.0   mem len: 310121   epsilon: 0.584    steps: 331    lr: 1.6e-05     reward: 5.38\n",
      "epis: 1449   score: 4.0   mem len: 310416   epsilon: 0.5834    steps: 295    lr: 1.6e-05     reward: 5.38\n",
      "epis: 1450   score: 8.0   mem len: 310866   epsilon: 0.5825    steps: 450    lr: 1.6e-05     reward: 5.4\n",
      "epis: 1451   score: 5.0   mem len: 311229   epsilon: 0.5818    steps: 363    lr: 1.6e-05     reward: 5.34\n",
      "epis: 1452   score: 1.0   mem len: 311380   epsilon: 0.5815    steps: 151    lr: 1.6e-05     reward: 5.28\n",
      "epis: 1453   score: 6.0   mem len: 311759   epsilon: 0.5807    steps: 379    lr: 1.6e-05     reward: 5.32\n",
      "epis: 1454   score: 3.0   mem len: 311987   epsilon: 0.5803    steps: 228    lr: 1.6e-05     reward: 5.34\n",
      "epis: 1455   score: 2.0   mem len: 312186   epsilon: 0.5799    steps: 199    lr: 1.6e-05     reward: 5.32\n",
      "epis: 1456   score: 8.0   mem len: 312622   epsilon: 0.579    steps: 436    lr: 1.6e-05     reward: 5.37\n",
      "epis: 1457   score: 7.0   mem len: 313024   epsilon: 0.5782    steps: 402    lr: 1.6e-05     reward: 5.38\n",
      "epis: 1458   score: 6.0   mem len: 313367   epsilon: 0.5775    steps: 343    lr: 1.6e-05     reward: 5.4\n",
      "epis: 1459   score: 2.0   mem len: 313568   epsilon: 0.5771    steps: 201    lr: 1.6e-05     reward: 5.35\n",
      "epis: 1460   score: 4.0   mem len: 313846   epsilon: 0.5766    steps: 278    lr: 1.6e-05     reward: 5.32\n",
      "epis: 1461   score: 6.0   mem len: 314193   epsilon: 0.5759    steps: 347    lr: 1.6e-05     reward: 5.34\n",
      "epis: 1462   score: 5.0   mem len: 314483   epsilon: 0.5753    steps: 290    lr: 1.6e-05     reward: 5.34\n",
      "epis: 1463   score: 8.0   mem len: 314883   epsilon: 0.5745    steps: 400    lr: 1.6e-05     reward: 5.39\n",
      "epis: 1464   score: 5.0   mem len: 315178   epsilon: 0.5739    steps: 295    lr: 1.6e-05     reward: 5.4\n",
      "epis: 1465   score: 3.0   mem len: 315389   epsilon: 0.5735    steps: 211    lr: 1.6e-05     reward: 5.37\n",
      "epis: 1466   score: 8.0   mem len: 315846   epsilon: 0.5726    steps: 457    lr: 1.6e-05     reward: 5.39\n",
      "epis: 1467   score: 6.0   mem len: 316236   epsilon: 0.5719    steps: 390    lr: 1.6e-05     reward: 5.38\n",
      "epis: 1468   score: 4.0   mem len: 316531   epsilon: 0.5713    steps: 295    lr: 1.6e-05     reward: 5.38\n",
      "epis: 1469   score: 2.0   mem len: 316750   epsilon: 0.5708    steps: 219    lr: 1.6e-05     reward: 5.37\n",
      "epis: 1470   score: 5.0   mem len: 317062   epsilon: 0.5702    steps: 312    lr: 1.6e-05     reward: 5.38\n",
      "epis: 1471   score: 7.0   mem len: 317405   epsilon: 0.5695    steps: 343    lr: 1.6e-05     reward: 5.39\n",
      "epis: 1472   score: 4.0   mem len: 317663   epsilon: 0.569    steps: 258    lr: 1.6e-05     reward: 5.33\n",
      "epis: 1473   score: 5.0   mem len: 317971   epsilon: 0.5684    steps: 308    lr: 1.6e-05     reward: 5.32\n",
      "epis: 1474   score: 3.0   mem len: 318183   epsilon: 0.568    steps: 212    lr: 1.6e-05     reward: 5.27\n",
      "epis: 1475   score: 8.0   mem len: 318630   epsilon: 0.5671    steps: 447    lr: 1.6e-05     reward: 5.29\n",
      "epis: 1476   score: 5.0   mem len: 318971   epsilon: 0.5664    steps: 341    lr: 1.6e-05     reward: 5.32\n",
      "epis: 1477   score: 8.0   mem len: 319413   epsilon: 0.5656    steps: 442    lr: 1.6e-05     reward: 5.33\n",
      "epis: 1478   score: 5.0   mem len: 319722   epsilon: 0.5649    steps: 309    lr: 1.6e-05     reward: 5.31\n",
      "epis: 1479   score: 6.0   mem len: 320116   epsilon: 0.5642    steps: 394    lr: 1.6e-05     reward: 5.31\n",
      "epis: 1480   score: 4.0   mem len: 320410   epsilon: 0.5636    steps: 294    lr: 1.6e-05     reward: 5.31\n",
      "epis: 1481   score: 9.0   mem len: 320756   epsilon: 0.5629    steps: 346    lr: 1.6e-05     reward: 5.34\n",
      "epis: 1482   score: 8.0   mem len: 321226   epsilon: 0.562    steps: 470    lr: 1.6e-05     reward: 5.35\n",
      "epis: 1483   score: 7.0   mem len: 321594   epsilon: 0.5612    steps: 368    lr: 1.6e-05     reward: 5.38\n",
      "epis: 1484   score: 10.0   mem len: 322094   epsilon: 0.5603    steps: 500    lr: 1.6e-05     reward: 5.45\n",
      "epis: 1485   score: 8.0   mem len: 322583   epsilon: 0.5593    steps: 489    lr: 1.6e-05     reward: 5.48\n",
      "epis: 1486   score: 6.0   mem len: 322904   epsilon: 0.5586    steps: 321    lr: 1.6e-05     reward: 5.5\n",
      "epis: 1487   score: 5.0   mem len: 323211   epsilon: 0.558    steps: 307    lr: 1.6e-05     reward: 5.49\n",
      "epis: 1488   score: 5.0   mem len: 323483   epsilon: 0.5575    steps: 272    lr: 1.6e-05     reward: 5.51\n",
      "epis: 1489   score: 8.0   mem len: 323814   epsilon: 0.5568    steps: 331    lr: 1.6e-05     reward: 5.55\n",
      "epis: 1490   score: 4.0   mem len: 324072   epsilon: 0.5563    steps: 258    lr: 1.6e-05     reward: 5.55\n",
      "epis: 1491   score: 4.0   mem len: 324332   epsilon: 0.5558    steps: 260    lr: 1.6e-05     reward: 5.56\n",
      "epis: 1492   score: 8.0   mem len: 324751   epsilon: 0.555    steps: 419    lr: 1.6e-05     reward: 5.61\n",
      "epis: 1493   score: 9.0   mem len: 325222   epsilon: 0.5541    steps: 471    lr: 1.6e-05     reward: 5.67\n",
      "epis: 1494   score: 9.0   mem len: 325586   epsilon: 0.5533    steps: 364    lr: 1.6e-05     reward: 5.74\n",
      "epis: 1495   score: 9.0   mem len: 326062   epsilon: 0.5524    steps: 476    lr: 1.6e-05     reward: 5.74\n",
      "epis: 1496   score: 2.0   mem len: 326280   epsilon: 0.552    steps: 218    lr: 1.6e-05     reward: 5.71\n",
      "epis: 1497   score: 7.0   mem len: 326731   epsilon: 0.5511    steps: 451    lr: 1.6e-05     reward: 5.72\n",
      "epis: 1498   score: 8.0   mem len: 327200   epsilon: 0.5501    steps: 469    lr: 1.6e-05     reward: 5.75\n",
      "epis: 1499   score: 4.0   mem len: 327492   epsilon: 0.5496    steps: 292    lr: 1.6e-05     reward: 5.75\n",
      "epis: 1500   score: 6.0   mem len: 327863   epsilon: 0.5488    steps: 371    lr: 1.6e-05     reward: 5.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1501   score: 5.0   mem len: 328204   epsilon: 0.5482    steps: 341    lr: 1.6e-05     reward: 5.73\n",
      "epis: 1502   score: 6.0   mem len: 328532   epsilon: 0.5475    steps: 328    lr: 1.6e-05     reward: 5.73\n",
      "epis: 1503   score: 3.0   mem len: 328761   epsilon: 0.5471    steps: 229    lr: 1.6e-05     reward: 5.74\n",
      "epis: 1504   score: 6.0   mem len: 329125   epsilon: 0.5463    steps: 364    lr: 1.6e-05     reward: 5.72\n",
      "epis: 1505   score: 6.0   mem len: 329502   epsilon: 0.5456    steps: 377    lr: 1.6e-05     reward: 5.72\n",
      "epis: 1506   score: 5.0   mem len: 329817   epsilon: 0.545    steps: 315    lr: 1.6e-05     reward: 5.71\n",
      "epis: 1507   score: 11.0   mem len: 330377   epsilon: 0.5439    steps: 560    lr: 1.6e-05     reward: 5.71\n",
      "epis: 1508   score: 4.0   mem len: 330619   epsilon: 0.5434    steps: 242    lr: 1.6e-05     reward: 5.66\n",
      "epis: 1509   score: 2.0   mem len: 330800   epsilon: 0.543    steps: 181    lr: 1.6e-05     reward: 5.63\n",
      "epis: 1510   score: 10.0   mem len: 331319   epsilon: 0.542    steps: 519    lr: 1.6e-05     reward: 5.69\n",
      "epis: 1511   score: 6.0   mem len: 331697   epsilon: 0.5412    steps: 378    lr: 1.6e-05     reward: 5.7\n",
      "epis: 1512   score: 6.0   mem len: 332094   epsilon: 0.5405    steps: 397    lr: 1.6e-05     reward: 5.74\n",
      "epis: 1513   score: 13.0   mem len: 332589   epsilon: 0.5395    steps: 495    lr: 1.6e-05     reward: 5.83\n",
      "epis: 1514   score: 4.0   mem len: 332863   epsilon: 0.5389    steps: 274    lr: 1.6e-05     reward: 5.78\n",
      "epis: 1515   score: 11.0   mem len: 333398   epsilon: 0.5379    steps: 535    lr: 1.6e-05     reward: 5.85\n",
      "epis: 1516   score: 5.0   mem len: 333742   epsilon: 0.5372    steps: 344    lr: 1.6e-05     reward: 5.86\n",
      "epis: 1517   score: 4.0   mem len: 334017   epsilon: 0.5366    steps: 275    lr: 1.6e-05     reward: 5.85\n",
      "epis: 1518   score: 9.0   mem len: 334395   epsilon: 0.5359    steps: 378    lr: 1.6e-05     reward: 5.87\n",
      "epis: 1519   score: 4.0   mem len: 334675   epsilon: 0.5353    steps: 280    lr: 1.6e-05     reward: 5.81\n",
      "epis: 1520   score: 10.0   mem len: 335175   epsilon: 0.5344    steps: 500    lr: 1.6e-05     reward: 5.85\n",
      "epis: 1521   score: 9.0   mem len: 335660   epsilon: 0.5334    steps: 485    lr: 1.6e-05     reward: 5.88\n",
      "epis: 1522   score: 8.0   mem len: 336085   epsilon: 0.5325    steps: 425    lr: 1.6e-05     reward: 5.93\n",
      "epis: 1523   score: 6.0   mem len: 336403   epsilon: 0.5319    steps: 318    lr: 1.6e-05     reward: 5.95\n",
      "epis: 1524   score: 11.0   mem len: 336908   epsilon: 0.5309    steps: 505    lr: 1.6e-05     reward: 5.99\n",
      "epis: 1525   score: 11.0   mem len: 337416   epsilon: 0.5299    steps: 508    lr: 1.6e-05     reward: 6.04\n",
      "epis: 1526   score: 5.0   mem len: 337722   epsilon: 0.5293    steps: 306    lr: 1.6e-05     reward: 6.03\n",
      "epis: 1527   score: 10.0   mem len: 338237   epsilon: 0.5283    steps: 515    lr: 1.6e-05     reward: 6.07\n",
      "epis: 1528   score: 5.0   mem len: 338567   epsilon: 0.5276    steps: 330    lr: 1.6e-05     reward: 6.0\n",
      "epis: 1529   score: 12.0   mem len: 339137   epsilon: 0.5265    steps: 570    lr: 1.6e-05     reward: 6.06\n",
      "epis: 1530   score: 5.0   mem len: 339430   epsilon: 0.5259    steps: 293    lr: 1.6e-05     reward: 6.04\n",
      "epis: 1531   score: 5.0   mem len: 339738   epsilon: 0.5253    steps: 308    lr: 1.6e-05     reward: 6.04\n",
      "epis: 1532   score: 8.0   mem len: 340196   epsilon: 0.5244    steps: 458    lr: 1.6e-05     reward: 6.07\n",
      "epis: 1533   score: 6.0   mem len: 340539   epsilon: 0.5237    steps: 343    lr: 1.6e-05     reward: 6.08\n",
      "epis: 1534   score: 5.0   mem len: 340861   epsilon: 0.5231    steps: 322    lr: 1.6e-05     reward: 6.09\n",
      "epis: 1535   score: 7.0   mem len: 341270   epsilon: 0.5223    steps: 409    lr: 1.6e-05     reward: 6.13\n",
      "epis: 1536   score: 10.0   mem len: 341794   epsilon: 0.5212    steps: 524    lr: 1.6e-05     reward: 6.18\n",
      "epis: 1537   score: 6.0   mem len: 342114   epsilon: 0.5206    steps: 320    lr: 1.6e-05     reward: 6.18\n",
      "epis: 1538   score: 6.0   mem len: 342443   epsilon: 0.52    steps: 329    lr: 1.6e-05     reward: 6.22\n",
      "epis: 1539   score: 4.0   mem len: 342743   epsilon: 0.5194    steps: 300    lr: 1.6e-05     reward: 6.21\n",
      "epis: 1540   score: 9.0   mem len: 343204   epsilon: 0.5185    steps: 461    lr: 1.6e-05     reward: 6.21\n",
      "epis: 1541   score: 11.0   mem len: 343572   epsilon: 0.5177    steps: 368    lr: 1.6e-05     reward: 6.28\n",
      "epis: 1542   score: 9.0   mem len: 344058   epsilon: 0.5168    steps: 486    lr: 1.6e-05     reward: 6.29\n",
      "epis: 1543   score: 6.0   mem len: 344430   epsilon: 0.516    steps: 372    lr: 1.6e-05     reward: 6.3\n",
      "epis: 1544   score: 7.0   mem len: 344831   epsilon: 0.5152    steps: 401    lr: 1.6e-05     reward: 6.33\n",
      "epis: 1545   score: 10.0   mem len: 345319   epsilon: 0.5143    steps: 488    lr: 1.6e-05     reward: 6.37\n",
      "epis: 1546   score: 6.0   mem len: 345710   epsilon: 0.5135    steps: 391    lr: 1.6e-05     reward: 6.39\n",
      "epis: 1547   score: 3.0   mem len: 345959   epsilon: 0.513    steps: 249    lr: 1.6e-05     reward: 6.37\n",
      "epis: 1548   score: 7.0   mem len: 346335   epsilon: 0.5123    steps: 376    lr: 1.6e-05     reward: 6.36\n",
      "epis: 1549   score: 1.0   mem len: 346487   epsilon: 0.512    steps: 152    lr: 1.6e-05     reward: 6.33\n",
      "epis: 1550   score: 8.0   mem len: 346922   epsilon: 0.5111    steps: 435    lr: 1.6e-05     reward: 6.33\n",
      "epis: 1551   score: 6.0   mem len: 347260   epsilon: 0.5104    steps: 338    lr: 1.6e-05     reward: 6.34\n",
      "epis: 1552   score: 12.0   mem len: 347751   epsilon: 0.5095    steps: 491    lr: 1.6e-05     reward: 6.45\n",
      "epis: 1553   score: 9.0   mem len: 348252   epsilon: 0.5085    steps: 501    lr: 1.6e-05     reward: 6.48\n",
      "epis: 1554   score: 8.0   mem len: 348674   epsilon: 0.5076    steps: 422    lr: 1.6e-05     reward: 6.53\n",
      "epis: 1555   score: 10.0   mem len: 349196   epsilon: 0.5066    steps: 522    lr: 1.6e-05     reward: 6.61\n",
      "epis: 1556   score: 4.0   mem len: 349439   epsilon: 0.5061    steps: 243    lr: 1.6e-05     reward: 6.57\n",
      "epis: 1557   score: 12.0   mem len: 350038   epsilon: 0.5049    steps: 599    lr: 1.6e-05     reward: 6.62\n",
      "epis: 1558   score: 7.0   mem len: 350463   epsilon: 0.5041    steps: 425    lr: 1.6e-05     reward: 6.63\n",
      "epis: 1559   score: 8.0   mem len: 350909   epsilon: 0.5032    steps: 446    lr: 1.6e-05     reward: 6.69\n",
      "epis: 1560   score: 5.0   mem len: 351222   epsilon: 0.5026    steps: 313    lr: 1.6e-05     reward: 6.7\n",
      "epis: 1561   score: 4.0   mem len: 351482   epsilon: 0.5021    steps: 260    lr: 1.6e-05     reward: 6.68\n",
      "epis: 1562   score: 15.0   mem len: 352057   epsilon: 0.5009    steps: 575    lr: 1.6e-05     reward: 6.78\n",
      "epis: 1563   score: 8.0   mem len: 352462   epsilon: 0.5001    steps: 405    lr: 1.6e-05     reward: 6.78\n",
      "epis: 1564   score: 1.0   mem len: 352613   epsilon: 0.4998    steps: 151    lr: 1.6e-05     reward: 6.74\n",
      "epis: 1565   score: 6.0   mem len: 352920   epsilon: 0.4992    steps: 307    lr: 1.6e-05     reward: 6.77\n",
      "epis: 1566   score: 6.0   mem len: 353259   epsilon: 0.4985    steps: 339    lr: 1.6e-05     reward: 6.75\n",
      "epis: 1567   score: 10.0   mem len: 353722   epsilon: 0.4976    steps: 463    lr: 1.6e-05     reward: 6.79\n",
      "epis: 1568   score: 5.0   mem len: 354033   epsilon: 0.497    steps: 311    lr: 1.6e-05     reward: 6.8\n",
      "epis: 1569   score: 15.0   mem len: 354624   epsilon: 0.4958    steps: 591    lr: 1.6e-05     reward: 6.93\n",
      "epis: 1570   score: 8.0   mem len: 355061   epsilon: 0.495    steps: 437    lr: 1.6e-05     reward: 6.96\n",
      "epis: 1571   score: 7.0   mem len: 355462   epsilon: 0.4942    steps: 401    lr: 1.6e-05     reward: 6.96\n",
      "epis: 1572   score: 4.0   mem len: 355757   epsilon: 0.4936    steps: 295    lr: 1.6e-05     reward: 6.96\n",
      "epis: 1573   score: 11.0   mem len: 356167   epsilon: 0.4928    steps: 410    lr: 1.6e-05     reward: 7.02\n",
      "epis: 1574   score: 10.0   mem len: 356647   epsilon: 0.4918    steps: 480    lr: 1.6e-05     reward: 7.09\n",
      "epis: 1575   score: 6.0   mem len: 356999   epsilon: 0.4911    steps: 352    lr: 1.6e-05     reward: 7.07\n",
      "epis: 1576   score: 8.0   mem len: 357422   epsilon: 0.4903    steps: 423    lr: 1.6e-05     reward: 7.1\n",
      "epis: 1577   score: 11.0   mem len: 357971   epsilon: 0.4892    steps: 549    lr: 1.6e-05     reward: 7.13\n",
      "epis: 1578   score: 5.0   mem len: 358270   epsilon: 0.4886    steps: 299    lr: 1.6e-05     reward: 7.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1579   score: 8.0   mem len: 358697   epsilon: 0.4878    steps: 427    lr: 1.6e-05     reward: 7.15\n",
      "epis: 1580   score: 8.0   mem len: 359174   epsilon: 0.4868    steps: 477    lr: 1.6e-05     reward: 7.19\n",
      "epis: 1581   score: 4.0   mem len: 359434   epsilon: 0.4863    steps: 260    lr: 1.6e-05     reward: 7.14\n",
      "epis: 1582   score: 6.0   mem len: 359794   epsilon: 0.4856    steps: 360    lr: 1.6e-05     reward: 7.12\n",
      "epis: 1583   score: 3.0   mem len: 360006   epsilon: 0.4852    steps: 212    lr: 1.6e-05     reward: 7.08\n",
      "epis: 1584   score: 9.0   mem len: 360441   epsilon: 0.4843    steps: 435    lr: 1.6e-05     reward: 7.07\n",
      "epis: 1585   score: 9.0   mem len: 360908   epsilon: 0.4834    steps: 467    lr: 1.6e-05     reward: 7.08\n",
      "epis: 1586   score: 3.0   mem len: 361138   epsilon: 0.4829    steps: 230    lr: 1.6e-05     reward: 7.05\n",
      "epis: 1587   score: 5.0   mem len: 361481   epsilon: 0.4823    steps: 343    lr: 1.6e-05     reward: 7.05\n",
      "epis: 1588   score: 9.0   mem len: 361944   epsilon: 0.4813    steps: 463    lr: 1.6e-05     reward: 7.09\n",
      "epis: 1589   score: 4.0   mem len: 362206   epsilon: 0.4808    steps: 262    lr: 1.6e-05     reward: 7.05\n",
      "epis: 1590   score: 4.0   mem len: 362484   epsilon: 0.4803    steps: 278    lr: 1.6e-05     reward: 7.05\n",
      "epis: 1591   score: 5.0   mem len: 362795   epsilon: 0.4797    steps: 311    lr: 1.6e-05     reward: 7.06\n",
      "epis: 1592   score: 5.0   mem len: 363138   epsilon: 0.479    steps: 343    lr: 1.6e-05     reward: 7.03\n",
      "epis: 1593   score: 10.0   mem len: 363658   epsilon: 0.478    steps: 520    lr: 1.6e-05     reward: 7.04\n",
      "epis: 1594   score: 6.0   mem len: 364021   epsilon: 0.4772    steps: 363    lr: 1.6e-05     reward: 7.01\n",
      "epis: 1595   score: 4.0   mem len: 364295   epsilon: 0.4767    steps: 274    lr: 1.6e-05     reward: 6.96\n",
      "epis: 1596   score: 18.0   mem len: 364971   epsilon: 0.4754    steps: 676    lr: 1.6e-05     reward: 7.12\n",
      "epis: 1597   score: 8.0   mem len: 365412   epsilon: 0.4745    steps: 441    lr: 1.6e-05     reward: 7.13\n",
      "epis: 1598   score: 10.0   mem len: 365880   epsilon: 0.4736    steps: 468    lr: 1.6e-05     reward: 7.15\n",
      "epis: 1599   score: 4.0   mem len: 366155   epsilon: 0.473    steps: 275    lr: 1.6e-05     reward: 7.15\n",
      "epis: 1600   score: 9.0   mem len: 366654   epsilon: 0.472    steps: 499    lr: 1.6e-05     reward: 7.18\n",
      "epis: 1601   score: 8.0   mem len: 367123   epsilon: 0.4711    steps: 469    lr: 1.6e-05     reward: 7.21\n",
      "epis: 1602   score: 11.0   mem len: 367731   epsilon: 0.4699    steps: 608    lr: 1.6e-05     reward: 7.26\n",
      "epis: 1603   score: 7.0   mem len: 368099   epsilon: 0.4692    steps: 368    lr: 1.6e-05     reward: 7.3\n",
      "epis: 1604   score: 9.0   mem len: 368536   epsilon: 0.4683    steps: 437    lr: 1.6e-05     reward: 7.33\n",
      "epis: 1605   score: 4.0   mem len: 368777   epsilon: 0.4678    steps: 241    lr: 1.6e-05     reward: 7.31\n",
      "epis: 1606   score: 8.0   mem len: 369201   epsilon: 0.467    steps: 424    lr: 1.6e-05     reward: 7.34\n",
      "epis: 1607   score: 9.0   mem len: 369619   epsilon: 0.4662    steps: 418    lr: 1.6e-05     reward: 7.32\n",
      "epis: 1608   score: 5.0   mem len: 369943   epsilon: 0.4655    steps: 324    lr: 1.6e-05     reward: 7.33\n",
      "epis: 1609   score: 9.0   mem len: 370402   epsilon: 0.4646    steps: 459    lr: 1.6e-05     reward: 7.4\n",
      "epis: 1610   score: 5.0   mem len: 370711   epsilon: 0.464    steps: 309    lr: 1.6e-05     reward: 7.35\n",
      "epis: 1611   score: 5.0   mem len: 371058   epsilon: 0.4633    steps: 347    lr: 1.6e-05     reward: 7.34\n",
      "epis: 1612   score: 9.0   mem len: 371525   epsilon: 0.4624    steps: 467    lr: 1.6e-05     reward: 7.37\n",
      "epis: 1613   score: 12.0   mem len: 372104   epsilon: 0.4612    steps: 579    lr: 1.6e-05     reward: 7.36\n",
      "epis: 1614   score: 6.0   mem len: 372460   epsilon: 0.4605    steps: 356    lr: 1.6e-05     reward: 7.38\n",
      "epis: 1615   score: 7.0   mem len: 372862   epsilon: 0.4597    steps: 402    lr: 1.6e-05     reward: 7.34\n",
      "epis: 1616   score: 4.0   mem len: 373157   epsilon: 0.4591    steps: 295    lr: 1.6e-05     reward: 7.33\n",
      "epis: 1617   score: 9.0   mem len: 373584   epsilon: 0.4583    steps: 427    lr: 1.6e-05     reward: 7.38\n",
      "epis: 1618   score: 7.0   mem len: 373973   epsilon: 0.4575    steps: 389    lr: 1.6e-05     reward: 7.36\n",
      "epis: 1619   score: 11.0   mem len: 374531   epsilon: 0.4564    steps: 558    lr: 1.6e-05     reward: 7.43\n",
      "epis: 1620   score: 8.0   mem len: 374955   epsilon: 0.4556    steps: 424    lr: 1.6e-05     reward: 7.41\n",
      "epis: 1621   score: 8.0   mem len: 375398   epsilon: 0.4547    steps: 443    lr: 1.6e-05     reward: 7.4\n",
      "epis: 1622   score: 7.0   mem len: 375789   epsilon: 0.4539    steps: 391    lr: 1.6e-05     reward: 7.39\n",
      "epis: 1623   score: 12.0   mem len: 376428   epsilon: 0.4527    steps: 639    lr: 1.6e-05     reward: 7.45\n",
      "epis: 1624   score: 5.0   mem len: 376755   epsilon: 0.452    steps: 327    lr: 1.6e-05     reward: 7.39\n",
      "epis: 1625   score: 5.0   mem len: 377081   epsilon: 0.4514    steps: 326    lr: 1.6e-05     reward: 7.33\n",
      "epis: 1626   score: 8.0   mem len: 377461   epsilon: 0.4506    steps: 380    lr: 1.6e-05     reward: 7.36\n",
      "epis: 1627   score: 8.0   mem len: 377951   epsilon: 0.4497    steps: 490    lr: 1.6e-05     reward: 7.34\n",
      "epis: 1628   score: 10.0   mem len: 378519   epsilon: 0.4485    steps: 568    lr: 1.6e-05     reward: 7.39\n",
      "epis: 1629   score: 6.0   mem len: 378892   epsilon: 0.4478    steps: 373    lr: 1.6e-05     reward: 7.33\n",
      "epis: 1630   score: 12.0   mem len: 379382   epsilon: 0.4468    steps: 490    lr: 1.6e-05     reward: 7.4\n",
      "epis: 1631   score: 8.0   mem len: 379835   epsilon: 0.4459    steps: 453    lr: 1.6e-05     reward: 7.43\n",
      "epis: 1632   score: 7.0   mem len: 380223   epsilon: 0.4452    steps: 388    lr: 1.6e-05     reward: 7.42\n",
      "epis: 1633   score: 6.0   mem len: 380583   epsilon: 0.4444    steps: 360    lr: 1.6e-05     reward: 7.42\n",
      "epis: 1634   score: 9.0   mem len: 381031   epsilon: 0.4436    steps: 448    lr: 1.6e-05     reward: 7.46\n",
      "epis: 1635   score: 14.0   mem len: 381577   epsilon: 0.4425    steps: 546    lr: 1.6e-05     reward: 7.53\n",
      "epis: 1636   score: 3.0   mem len: 381790   epsilon: 0.4421    steps: 213    lr: 1.6e-05     reward: 7.46\n",
      "epis: 1637   score: 13.0   mem len: 382293   epsilon: 0.4411    steps: 503    lr: 1.6e-05     reward: 7.53\n",
      "epis: 1638   score: 17.0   mem len: 382833   epsilon: 0.44    steps: 540    lr: 1.6e-05     reward: 7.64\n",
      "epis: 1639   score: 7.0   mem len: 383205   epsilon: 0.4393    steps: 372    lr: 1.6e-05     reward: 7.67\n",
      "epis: 1640   score: 8.0   mem len: 383670   epsilon: 0.4383    steps: 465    lr: 1.6e-05     reward: 7.66\n",
      "epis: 1641   score: 8.0   mem len: 384122   epsilon: 0.4374    steps: 452    lr: 1.6e-05     reward: 7.63\n",
      "epis: 1642   score: 7.0   mem len: 384515   epsilon: 0.4367    steps: 393    lr: 1.6e-05     reward: 7.61\n",
      "epis: 1643   score: 6.0   mem len: 384855   epsilon: 0.436    steps: 340    lr: 1.6e-05     reward: 7.61\n",
      "epis: 1644   score: 10.0   mem len: 385265   epsilon: 0.4352    steps: 410    lr: 1.6e-05     reward: 7.64\n",
      "epis: 1645   score: 5.0   mem len: 385574   epsilon: 0.4346    steps: 309    lr: 1.6e-05     reward: 7.59\n",
      "epis: 1646   score: 11.0   mem len: 386053   epsilon: 0.4336    steps: 479    lr: 1.6e-05     reward: 7.64\n",
      "epis: 1647   score: 8.0   mem len: 386452   epsilon: 0.4328    steps: 399    lr: 1.6e-05     reward: 7.69\n",
      "epis: 1648   score: 6.0   mem len: 386831   epsilon: 0.4321    steps: 379    lr: 1.6e-05     reward: 7.68\n",
      "epis: 1649   score: 6.0   mem len: 387161   epsilon: 0.4314    steps: 330    lr: 1.6e-05     reward: 7.73\n",
      "epis: 1650   score: 15.0   mem len: 387851   epsilon: 0.4301    steps: 690    lr: 1.6e-05     reward: 7.8\n",
      "epis: 1651   score: 9.0   mem len: 388299   epsilon: 0.4292    steps: 448    lr: 1.6e-05     reward: 7.83\n",
      "epis: 1652   score: 5.0   mem len: 388644   epsilon: 0.4285    steps: 345    lr: 1.6e-05     reward: 7.76\n",
      "epis: 1653   score: 12.0   mem len: 389202   epsilon: 0.4274    steps: 558    lr: 1.6e-05     reward: 7.79\n",
      "epis: 1654   score: 6.0   mem len: 389541   epsilon: 0.4267    steps: 339    lr: 1.6e-05     reward: 7.77\n",
      "epis: 1655   score: 5.0   mem len: 389866   epsilon: 0.4261    steps: 325    lr: 1.6e-05     reward: 7.72\n",
      "epis: 1656   score: 8.0   mem len: 390285   epsilon: 0.4252    steps: 419    lr: 1.6e-05     reward: 7.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1657   score: 7.0   mem len: 390673   epsilon: 0.4245    steps: 388    lr: 1.6e-05     reward: 7.71\n",
      "epis: 1658   score: 8.0   mem len: 391102   epsilon: 0.4236    steps: 429    lr: 1.6e-05     reward: 7.72\n",
      "epis: 1659   score: 12.0   mem len: 391537   epsilon: 0.4228    steps: 435    lr: 1.6e-05     reward: 7.76\n",
      "epis: 1660   score: 8.0   mem len: 392014   epsilon: 0.4218    steps: 477    lr: 1.6e-05     reward: 7.79\n",
      "epis: 1661   score: 6.0   mem len: 392389   epsilon: 0.4211    steps: 375    lr: 1.6e-05     reward: 7.81\n",
      "epis: 1662   score: 12.0   mem len: 393023   epsilon: 0.4198    steps: 634    lr: 1.6e-05     reward: 7.78\n",
      "epis: 1663   score: 9.0   mem len: 393470   epsilon: 0.4189    steps: 447    lr: 1.6e-05     reward: 7.79\n",
      "epis: 1664   score: 9.0   mem len: 393944   epsilon: 0.418    steps: 474    lr: 1.6e-05     reward: 7.87\n",
      "epis: 1665   score: 7.0   mem len: 394367   epsilon: 0.4172    steps: 423    lr: 1.6e-05     reward: 7.88\n",
      "epis: 1666   score: 7.0   mem len: 394767   epsilon: 0.4164    steps: 400    lr: 1.6e-05     reward: 7.89\n",
      "epis: 1667   score: 6.0   mem len: 395138   epsilon: 0.4156    steps: 371    lr: 1.6e-05     reward: 7.85\n",
      "epis: 1668   score: 5.0   mem len: 395430   epsilon: 0.415    steps: 292    lr: 1.6e-05     reward: 7.85\n",
      "epis: 1669   score: 6.0   mem len: 395801   epsilon: 0.4143    steps: 371    lr: 1.6e-05     reward: 7.76\n",
      "epis: 1670   score: 8.0   mem len: 396221   epsilon: 0.4135    steps: 420    lr: 1.6e-05     reward: 7.76\n",
      "epis: 1671   score: 9.0   mem len: 396692   epsilon: 0.4125    steps: 471    lr: 1.6e-05     reward: 7.78\n",
      "epis: 1672   score: 7.0   mem len: 397098   epsilon: 0.4117    steps: 406    lr: 1.6e-05     reward: 7.81\n",
      "epis: 1673   score: 8.0   mem len: 397535   epsilon: 0.4109    steps: 437    lr: 1.6e-05     reward: 7.78\n",
      "epis: 1674   score: 8.0   mem len: 397973   epsilon: 0.41    steps: 438    lr: 1.6e-05     reward: 7.76\n",
      "epis: 1675   score: 7.0   mem len: 398380   epsilon: 0.4092    steps: 407    lr: 1.6e-05     reward: 7.77\n",
      "epis: 1676   score: 5.0   mem len: 398656   epsilon: 0.4087    steps: 276    lr: 1.6e-05     reward: 7.74\n",
      "epis: 1677   score: 12.0   mem len: 399230   epsilon: 0.4075    steps: 574    lr: 1.6e-05     reward: 7.75\n",
      "epis: 1678   score: 7.0   mem len: 399632   epsilon: 0.4067    steps: 402    lr: 1.6e-05     reward: 7.77\n",
      "epis: 1679   score: 7.0   mem len: 400030   epsilon: 0.4059    steps: 398    lr: 6.4e-06     reward: 7.76\n",
      "epis: 1680   score: 8.0   mem len: 400458   epsilon: 0.4051    steps: 428    lr: 6.4e-06     reward: 7.76\n",
      "epis: 1681   score: 12.0   mem len: 400878   epsilon: 0.4043    steps: 420    lr: 6.4e-06     reward: 7.84\n",
      "epis: 1682   score: 13.0   mem len: 401528   epsilon: 0.403    steps: 650    lr: 6.4e-06     reward: 7.91\n",
      "epis: 1683   score: 7.0   mem len: 401938   epsilon: 0.4022    steps: 410    lr: 6.4e-06     reward: 7.95\n",
      "epis: 1684   score: 6.0   mem len: 402281   epsilon: 0.4015    steps: 343    lr: 6.4e-06     reward: 7.92\n",
      "epis: 1685   score: 5.0   mem len: 402606   epsilon: 0.4008    steps: 325    lr: 6.4e-06     reward: 7.88\n",
      "epis: 1686   score: 14.0   mem len: 403245   epsilon: 0.3996    steps: 639    lr: 6.4e-06     reward: 7.99\n",
      "epis: 1687   score: 9.0   mem len: 403715   epsilon: 0.3986    steps: 470    lr: 6.4e-06     reward: 8.03\n",
      "epis: 1688   score: 7.0   mem len: 404118   epsilon: 0.3978    steps: 403    lr: 6.4e-06     reward: 8.01\n",
      "epis: 1689   score: 11.0   mem len: 404663   epsilon: 0.3968    steps: 545    lr: 6.4e-06     reward: 8.08\n",
      "epis: 1690   score: 6.0   mem len: 404981   epsilon: 0.3961    steps: 318    lr: 6.4e-06     reward: 8.1\n",
      "epis: 1691   score: 6.0   mem len: 405320   epsilon: 0.3955    steps: 339    lr: 6.4e-06     reward: 8.11\n",
      "epis: 1692   score: 7.0   mem len: 405685   epsilon: 0.3947    steps: 365    lr: 6.4e-06     reward: 8.13\n",
      "epis: 1693   score: 11.0   mem len: 406185   epsilon: 0.3938    steps: 500    lr: 6.4e-06     reward: 8.14\n",
      "epis: 1694   score: 5.0   mem len: 406498   epsilon: 0.3931    steps: 313    lr: 6.4e-06     reward: 8.13\n",
      "epis: 1695   score: 9.0   mem len: 406969   epsilon: 0.3922    steps: 471    lr: 6.4e-06     reward: 8.18\n",
      "epis: 1696   score: 4.0   mem len: 407229   epsilon: 0.3917    steps: 260    lr: 6.4e-06     reward: 8.04\n",
      "epis: 1697   score: 2.0   mem len: 407430   epsilon: 0.3913    steps: 201    lr: 6.4e-06     reward: 7.98\n",
      "epis: 1698   score: 8.0   mem len: 407876   epsilon: 0.3904    steps: 446    lr: 6.4e-06     reward: 7.96\n",
      "epis: 1699   score: 5.0   mem len: 408164   epsilon: 0.3898    steps: 288    lr: 6.4e-06     reward: 7.97\n",
      "epis: 1700   score: 11.0   mem len: 408569   epsilon: 0.389    steps: 405    lr: 6.4e-06     reward: 7.99\n",
      "epis: 1701   score: 13.0   mem len: 409196   epsilon: 0.3878    steps: 627    lr: 6.4e-06     reward: 8.04\n",
      "epis: 1702   score: 15.0   mem len: 409718   epsilon: 0.3868    steps: 522    lr: 6.4e-06     reward: 8.08\n",
      "epis: 1703   score: 4.0   mem len: 409979   epsilon: 0.3862    steps: 261    lr: 6.4e-06     reward: 8.05\n",
      "epis: 1704   score: 11.0   mem len: 410474   epsilon: 0.3853    steps: 495    lr: 6.4e-06     reward: 8.07\n",
      "epis: 1705   score: 8.0   mem len: 410947   epsilon: 0.3843    steps: 473    lr: 6.4e-06     reward: 8.11\n",
      "epis: 1706   score: 13.0   mem len: 411587   epsilon: 0.3831    steps: 640    lr: 6.4e-06     reward: 8.16\n",
      "epis: 1707   score: 8.0   mem len: 412022   epsilon: 0.3822    steps: 435    lr: 6.4e-06     reward: 8.15\n",
      "epis: 1708   score: 5.0   mem len: 412315   epsilon: 0.3816    steps: 293    lr: 6.4e-06     reward: 8.15\n",
      "epis: 1709   score: 14.0   mem len: 412993   epsilon: 0.3803    steps: 678    lr: 6.4e-06     reward: 8.2\n",
      "epis: 1710   score: 9.0   mem len: 413448   epsilon: 0.3794    steps: 455    lr: 6.4e-06     reward: 8.24\n",
      "epis: 1711   score: 11.0   mem len: 414021   epsilon: 0.3782    steps: 573    lr: 6.4e-06     reward: 8.3\n",
      "epis: 1712   score: 6.0   mem len: 414345   epsilon: 0.3776    steps: 324    lr: 6.4e-06     reward: 8.27\n",
      "epis: 1713   score: 16.0   mem len: 415019   epsilon: 0.3763    steps: 674    lr: 6.4e-06     reward: 8.31\n",
      "epis: 1714   score: 4.0   mem len: 415296   epsilon: 0.3757    steps: 277    lr: 6.4e-06     reward: 8.29\n",
      "epis: 1715   score: 15.0   mem len: 415869   epsilon: 0.3746    steps: 573    lr: 6.4e-06     reward: 8.37\n",
      "epis: 1716   score: 7.0   mem len: 416256   epsilon: 0.3738    steps: 387    lr: 6.4e-06     reward: 8.4\n",
      "epis: 1717   score: 14.0   mem len: 416882   epsilon: 0.3726    steps: 626    lr: 6.4e-06     reward: 8.45\n",
      "epis: 1718   score: 8.0   mem len: 417306   epsilon: 0.3717    steps: 424    lr: 6.4e-06     reward: 8.46\n",
      "epis: 1719   score: 9.0   mem len: 417778   epsilon: 0.3708    steps: 472    lr: 6.4e-06     reward: 8.44\n",
      "epis: 1720   score: 10.0   mem len: 418289   epsilon: 0.3698    steps: 511    lr: 6.4e-06     reward: 8.46\n",
      "epis: 1721   score: 6.0   mem len: 418647   epsilon: 0.3691    steps: 358    lr: 6.4e-06     reward: 8.44\n",
      "epis: 1722   score: 13.0   mem len: 419282   epsilon: 0.3678    steps: 635    lr: 6.4e-06     reward: 8.5\n",
      "epis: 1723   score: 9.0   mem len: 419750   epsilon: 0.3669    steps: 468    lr: 6.4e-06     reward: 8.47\n",
      "epis: 1724   score: 8.0   mem len: 420187   epsilon: 0.366    steps: 437    lr: 6.4e-06     reward: 8.5\n",
      "epis: 1725   score: 15.0   mem len: 420898   epsilon: 0.3646    steps: 711    lr: 6.4e-06     reward: 8.6\n",
      "epis: 1726   score: 11.0   mem len: 421358   epsilon: 0.3637    steps: 460    lr: 6.4e-06     reward: 8.63\n",
      "epis: 1727   score: 12.0   mem len: 421821   epsilon: 0.3628    steps: 463    lr: 6.4e-06     reward: 8.67\n",
      "epis: 1728   score: 10.0   mem len: 422313   epsilon: 0.3618    steps: 492    lr: 6.4e-06     reward: 8.67\n",
      "epis: 1729   score: 6.0   mem len: 422672   epsilon: 0.3611    steps: 359    lr: 6.4e-06     reward: 8.67\n",
      "epis: 1730   score: 8.0   mem len: 423115   epsilon: 0.3602    steps: 443    lr: 6.4e-06     reward: 8.63\n",
      "epis: 1731   score: 11.0   mem len: 423658   epsilon: 0.3592    steps: 543    lr: 6.4e-06     reward: 8.66\n",
      "epis: 1732   score: 6.0   mem len: 424003   epsilon: 0.3585    steps: 345    lr: 6.4e-06     reward: 8.65\n",
      "epis: 1733   score: 4.0   mem len: 424299   epsilon: 0.3579    steps: 296    lr: 6.4e-06     reward: 8.63\n",
      "epis: 1734   score: 8.0   mem len: 424725   epsilon: 0.357    steps: 426    lr: 6.4e-06     reward: 8.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1735   score: 11.0   mem len: 425260   epsilon: 0.356    steps: 535    lr: 6.4e-06     reward: 8.59\n",
      "epis: 1736   score: 14.0   mem len: 425918   epsilon: 0.3547    steps: 658    lr: 6.4e-06     reward: 8.7\n",
      "epis: 1737   score: 11.0   mem len: 426432   epsilon: 0.3537    steps: 514    lr: 6.4e-06     reward: 8.68\n",
      "epis: 1738   score: 9.0   mem len: 426902   epsilon: 0.3527    steps: 470    lr: 6.4e-06     reward: 8.6\n",
      "epis: 1739   score: 11.0   mem len: 427408   epsilon: 0.3517    steps: 506    lr: 6.4e-06     reward: 8.64\n",
      "epis: 1740   score: 7.0   mem len: 427783   epsilon: 0.351    steps: 375    lr: 6.4e-06     reward: 8.63\n",
      "epis: 1741   score: 12.0   mem len: 428341   epsilon: 0.3499    steps: 558    lr: 6.4e-06     reward: 8.67\n",
      "epis: 1742   score: 9.0   mem len: 428796   epsilon: 0.349    steps: 455    lr: 6.4e-06     reward: 8.69\n",
      "epis: 1743   score: 6.0   mem len: 429175   epsilon: 0.3482    steps: 379    lr: 6.4e-06     reward: 8.69\n",
      "epis: 1744   score: 7.0   mem len: 429583   epsilon: 0.3474    steps: 408    lr: 6.4e-06     reward: 8.66\n",
      "epis: 1745   score: 7.0   mem len: 429957   epsilon: 0.3467    steps: 374    lr: 6.4e-06     reward: 8.68\n",
      "epis: 1746   score: 10.0   mem len: 430436   epsilon: 0.3457    steps: 479    lr: 6.4e-06     reward: 8.67\n",
      "epis: 1747   score: 11.0   mem len: 430938   epsilon: 0.3447    steps: 502    lr: 6.4e-06     reward: 8.7\n",
      "epis: 1748   score: 9.0   mem len: 431418   epsilon: 0.3438    steps: 480    lr: 6.4e-06     reward: 8.73\n",
      "epis: 1749   score: 8.0   mem len: 431842   epsilon: 0.343    steps: 424    lr: 6.4e-06     reward: 8.75\n",
      "epis: 1750   score: 12.0   mem len: 432405   epsilon: 0.3418    steps: 563    lr: 6.4e-06     reward: 8.72\n",
      "epis: 1751   score: 8.0   mem len: 432842   epsilon: 0.341    steps: 437    lr: 6.4e-06     reward: 8.71\n",
      "epis: 1752   score: 4.0   mem len: 433103   epsilon: 0.3405    steps: 261    lr: 6.4e-06     reward: 8.7\n",
      "epis: 1753   score: 8.0   mem len: 433506   epsilon: 0.3397    steps: 403    lr: 6.4e-06     reward: 8.66\n",
      "epis: 1754   score: 13.0   mem len: 434033   epsilon: 0.3386    steps: 527    lr: 6.4e-06     reward: 8.73\n",
      "epis: 1755   score: 10.0   mem len: 434516   epsilon: 0.3377    steps: 483    lr: 6.4e-06     reward: 8.78\n",
      "epis: 1756   score: 6.0   mem len: 434853   epsilon: 0.337    steps: 337    lr: 6.4e-06     reward: 8.76\n",
      "epis: 1757   score: 7.0   mem len: 435194   epsilon: 0.3363    steps: 341    lr: 6.4e-06     reward: 8.76\n",
      "epis: 1758   score: 13.0   mem len: 435837   epsilon: 0.335    steps: 643    lr: 6.4e-06     reward: 8.81\n",
      "epis: 1759   score: 4.0   mem len: 436099   epsilon: 0.3345    steps: 262    lr: 6.4e-06     reward: 8.73\n",
      "epis: 1760   score: 6.0   mem len: 436439   epsilon: 0.3338    steps: 340    lr: 6.4e-06     reward: 8.71\n",
      "epis: 1761   score: 6.0   mem len: 436766   epsilon: 0.3332    steps: 327    lr: 6.4e-06     reward: 8.71\n",
      "epis: 1762   score: 10.0   mem len: 437296   epsilon: 0.3322    steps: 530    lr: 6.4e-06     reward: 8.69\n",
      "epis: 1763   score: 11.0   mem len: 437833   epsilon: 0.3311    steps: 537    lr: 6.4e-06     reward: 8.71\n",
      "epis: 1764   score: 11.0   mem len: 438458   epsilon: 0.3299    steps: 625    lr: 6.4e-06     reward: 8.73\n",
      "epis: 1765   score: 11.0   mem len: 439044   epsilon: 0.3287    steps: 586    lr: 6.4e-06     reward: 8.77\n",
      "epis: 1766   score: 5.0   mem len: 439354   epsilon: 0.3281    steps: 310    lr: 6.4e-06     reward: 8.75\n",
      "epis: 1767   score: 14.0   mem len: 439998   epsilon: 0.3268    steps: 644    lr: 6.4e-06     reward: 8.83\n",
      "epis: 1768   score: 4.0   mem len: 440244   epsilon: 0.3263    steps: 246    lr: 6.4e-06     reward: 8.82\n",
      "epis: 1769   score: 8.0   mem len: 440693   epsilon: 0.3254    steps: 449    lr: 6.4e-06     reward: 8.84\n",
      "epis: 1770   score: 4.0   mem len: 440933   epsilon: 0.325    steps: 240    lr: 6.4e-06     reward: 8.8\n",
      "epis: 1771   score: 6.0   mem len: 441271   epsilon: 0.3243    steps: 338    lr: 6.4e-06     reward: 8.77\n",
      "epis: 1772   score: 9.0   mem len: 441768   epsilon: 0.3233    steps: 497    lr: 6.4e-06     reward: 8.79\n",
      "epis: 1773   score: 10.0   mem len: 442316   epsilon: 0.3222    steps: 548    lr: 6.4e-06     reward: 8.81\n",
      "epis: 1774   score: 14.0   mem len: 442958   epsilon: 0.3209    steps: 642    lr: 6.4e-06     reward: 8.87\n",
      "epis: 1775   score: 7.0   mem len: 443362   epsilon: 0.3201    steps: 404    lr: 6.4e-06     reward: 8.87\n",
      "epis: 1776   score: 7.0   mem len: 443746   epsilon: 0.3194    steps: 384    lr: 6.4e-06     reward: 8.89\n",
      "epis: 1777   score: 10.0   mem len: 444210   epsilon: 0.3185    steps: 464    lr: 6.4e-06     reward: 8.87\n",
      "epis: 1778   score: 6.0   mem len: 444527   epsilon: 0.3178    steps: 317    lr: 6.4e-06     reward: 8.86\n",
      "epis: 1779   score: 13.0   mem len: 445131   epsilon: 0.3166    steps: 604    lr: 6.4e-06     reward: 8.92\n",
      "epis: 1780   score: 10.0   mem len: 445644   epsilon: 0.3156    steps: 513    lr: 6.4e-06     reward: 8.94\n",
      "epis: 1781   score: 10.0   mem len: 446164   epsilon: 0.3146    steps: 520    lr: 6.4e-06     reward: 8.92\n",
      "epis: 1782   score: 10.0   mem len: 446714   epsilon: 0.3135    steps: 550    lr: 6.4e-06     reward: 8.89\n",
      "epis: 1783   score: 9.0   mem len: 447162   epsilon: 0.3126    steps: 448    lr: 6.4e-06     reward: 8.91\n",
      "epis: 1784   score: 20.0   mem len: 447864   epsilon: 0.3112    steps: 702    lr: 6.4e-06     reward: 9.05\n",
      "epis: 1785   score: 11.0   mem len: 448400   epsilon: 0.3102    steps: 536    lr: 6.4e-06     reward: 9.11\n",
      "epis: 1786   score: 9.0   mem len: 448858   epsilon: 0.3093    steps: 458    lr: 6.4e-06     reward: 9.06\n",
      "epis: 1787   score: 7.0   mem len: 449227   epsilon: 0.3085    steps: 369    lr: 6.4e-06     reward: 9.04\n",
      "epis: 1788   score: 7.0   mem len: 449633   epsilon: 0.3077    steps: 406    lr: 6.4e-06     reward: 9.04\n",
      "epis: 1789   score: 6.0   mem len: 449987   epsilon: 0.307    steps: 354    lr: 6.4e-06     reward: 8.99\n",
      "epis: 1790   score: 12.0   mem len: 450506   epsilon: 0.306    steps: 519    lr: 6.4e-06     reward: 9.05\n",
      "epis: 1791   score: 13.0   mem len: 451100   epsilon: 0.3048    steps: 594    lr: 6.4e-06     reward: 9.12\n",
      "epis: 1792   score: 10.0   mem len: 451561   epsilon: 0.3039    steps: 461    lr: 6.4e-06     reward: 9.15\n",
      "epis: 1793   score: 10.0   mem len: 452085   epsilon: 0.3029    steps: 524    lr: 6.4e-06     reward: 9.14\n",
      "epis: 1794   score: 8.0   mem len: 452500   epsilon: 0.302    steps: 415    lr: 6.4e-06     reward: 9.17\n",
      "epis: 1795   score: 10.0   mem len: 452984   epsilon: 0.3011    steps: 484    lr: 6.4e-06     reward: 9.18\n",
      "epis: 1796   score: 17.0   mem len: 453622   epsilon: 0.2998    steps: 638    lr: 6.4e-06     reward: 9.31\n",
      "epis: 1797   score: 5.0   mem len: 453947   epsilon: 0.2992    steps: 325    lr: 6.4e-06     reward: 9.34\n",
      "epis: 1798   score: 9.0   mem len: 454451   epsilon: 0.2982    steps: 504    lr: 6.4e-06     reward: 9.35\n",
      "epis: 1799   score: 9.0   mem len: 454900   epsilon: 0.2973    steps: 449    lr: 6.4e-06     reward: 9.39\n",
      "epis: 1800   score: 17.0   mem len: 455537   epsilon: 0.296    steps: 637    lr: 6.4e-06     reward: 9.45\n",
      "epis: 1801   score: 12.0   mem len: 456079   epsilon: 0.295    steps: 542    lr: 6.4e-06     reward: 9.44\n",
      "epis: 1802   score: 5.0   mem len: 456370   epsilon: 0.2944    steps: 291    lr: 6.4e-06     reward: 9.34\n",
      "epis: 1803   score: 8.0   mem len: 456764   epsilon: 0.2936    steps: 394    lr: 6.4e-06     reward: 9.38\n",
      "epis: 1804   score: 10.0   mem len: 457305   epsilon: 0.2925    steps: 541    lr: 6.4e-06     reward: 9.37\n",
      "epis: 1805   score: 10.0   mem len: 457789   epsilon: 0.2916    steps: 484    lr: 6.4e-06     reward: 9.39\n",
      "epis: 1806   score: 9.0   mem len: 458285   epsilon: 0.2906    steps: 496    lr: 6.4e-06     reward: 9.35\n",
      "epis: 1807   score: 9.0   mem len: 458752   epsilon: 0.2897    steps: 467    lr: 6.4e-06     reward: 9.36\n",
      "epis: 1808   score: 8.0   mem len: 459195   epsilon: 0.2888    steps: 443    lr: 6.4e-06     reward: 9.39\n",
      "epis: 1809   score: 8.0   mem len: 459629   epsilon: 0.2879    steps: 434    lr: 6.4e-06     reward: 9.33\n",
      "epis: 1810   score: 10.0   mem len: 460147   epsilon: 0.2869    steps: 518    lr: 6.4e-06     reward: 9.34\n",
      "epis: 1811   score: 8.0   mem len: 460574   epsilon: 0.2861    steps: 427    lr: 6.4e-06     reward: 9.31\n",
      "epis: 1812   score: 11.0   mem len: 461105   epsilon: 0.285    steps: 531    lr: 6.4e-06     reward: 9.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1813   score: 17.0   mem len: 461807   epsilon: 0.2836    steps: 702    lr: 6.4e-06     reward: 9.37\n",
      "epis: 1814   score: 13.0   mem len: 462393   epsilon: 0.2825    steps: 586    lr: 6.4e-06     reward: 9.46\n",
      "epis: 1815   score: 11.0   mem len: 462880   epsilon: 0.2815    steps: 487    lr: 6.4e-06     reward: 9.42\n",
      "epis: 1816   score: 12.0   mem len: 463418   epsilon: 0.2804    steps: 538    lr: 6.4e-06     reward: 9.47\n",
      "epis: 1817   score: 17.0   mem len: 464056   epsilon: 0.2792    steps: 638    lr: 6.4e-06     reward: 9.5\n",
      "epis: 1818   score: 8.0   mem len: 464506   epsilon: 0.2783    steps: 450    lr: 6.4e-06     reward: 9.5\n",
      "epis: 1819   score: 7.0   mem len: 464879   epsilon: 0.2775    steps: 373    lr: 6.4e-06     reward: 9.48\n",
      "epis: 1820   score: 12.0   mem len: 465449   epsilon: 0.2764    steps: 570    lr: 6.4e-06     reward: 9.5\n",
      "epis: 1821   score: 18.0   mem len: 466116   epsilon: 0.2751    steps: 667    lr: 6.4e-06     reward: 9.62\n",
      "epis: 1822   score: 9.0   mem len: 466575   epsilon: 0.2742    steps: 459    lr: 6.4e-06     reward: 9.58\n",
      "epis: 1823   score: 9.0   mem len: 467001   epsilon: 0.2733    steps: 426    lr: 6.4e-06     reward: 9.58\n",
      "epis: 1824   score: 6.0   mem len: 467378   epsilon: 0.2726    steps: 377    lr: 6.4e-06     reward: 9.56\n",
      "epis: 1825   score: 8.0   mem len: 467811   epsilon: 0.2717    steps: 433    lr: 6.4e-06     reward: 9.49\n",
      "epis: 1826   score: 8.0   mem len: 468252   epsilon: 0.2709    steps: 441    lr: 6.4e-06     reward: 9.46\n",
      "epis: 1827   score: 10.0   mem len: 468782   epsilon: 0.2698    steps: 530    lr: 6.4e-06     reward: 9.44\n",
      "epis: 1828   score: 12.0   mem len: 469364   epsilon: 0.2687    steps: 582    lr: 6.4e-06     reward: 9.46\n",
      "epis: 1829   score: 8.0   mem len: 469793   epsilon: 0.2678    steps: 429    lr: 6.4e-06     reward: 9.48\n",
      "epis: 1830   score: 18.0   mem len: 470482   epsilon: 0.2664    steps: 689    lr: 6.4e-06     reward: 9.58\n",
      "epis: 1831   score: 8.0   mem len: 470936   epsilon: 0.2655    steps: 454    lr: 6.4e-06     reward: 9.55\n",
      "epis: 1832   score: 10.0   mem len: 471447   epsilon: 0.2645    steps: 511    lr: 6.4e-06     reward: 9.59\n",
      "epis: 1833   score: 16.0   mem len: 472035   epsilon: 0.2634    steps: 588    lr: 6.4e-06     reward: 9.71\n",
      "epis: 1834   score: 12.0   mem len: 472605   epsilon: 0.2622    steps: 570    lr: 6.4e-06     reward: 9.75\n",
      "epis: 1835   score: 12.0   mem len: 473232   epsilon: 0.261    steps: 627    lr: 6.4e-06     reward: 9.76\n",
      "epis: 1836   score: 15.0   mem len: 473662   epsilon: 0.2601    steps: 430    lr: 6.4e-06     reward: 9.77\n",
      "epis: 1837   score: 10.0   mem len: 474161   epsilon: 0.2592    steps: 499    lr: 6.4e-06     reward: 9.76\n",
      "epis: 1838   score: 7.0   mem len: 474567   epsilon: 0.2584    steps: 406    lr: 6.4e-06     reward: 9.74\n",
      "epis: 1839   score: 12.0   mem len: 475073   epsilon: 0.2574    steps: 506    lr: 6.4e-06     reward: 9.75\n",
      "epis: 1840   score: 12.0   mem len: 475615   epsilon: 0.2563    steps: 542    lr: 6.4e-06     reward: 9.8\n",
      "epis: 1841   score: 12.0   mem len: 476050   epsilon: 0.2554    steps: 435    lr: 6.4e-06     reward: 9.8\n",
      "epis: 1842   score: 10.0   mem len: 476537   epsilon: 0.2545    steps: 487    lr: 6.4e-06     reward: 9.81\n",
      "epis: 1843   score: 12.0   mem len: 476997   epsilon: 0.2535    steps: 460    lr: 6.4e-06     reward: 9.87\n",
      "epis: 1844   score: 10.0   mem len: 477520   epsilon: 0.2525    steps: 523    lr: 6.4e-06     reward: 9.9\n",
      "epis: 1845   score: 15.0   mem len: 478033   epsilon: 0.2515    steps: 513    lr: 6.4e-06     reward: 9.98\n",
      "epis: 1846   score: 7.0   mem len: 478421   epsilon: 0.2507    steps: 388    lr: 6.4e-06     reward: 9.95\n",
      "epis: 1847   score: 11.0   mem len: 478934   epsilon: 0.2497    steps: 513    lr: 6.4e-06     reward: 9.95\n",
      "epis: 1848   score: 15.0   mem len: 479606   epsilon: 0.2484    steps: 672    lr: 6.4e-06     reward: 10.01\n",
      "epis: 1849   score: 10.0   mem len: 480067   epsilon: 0.2475    steps: 461    lr: 6.4e-06     reward: 10.03\n",
      "epis: 1850   score: 17.0   mem len: 480842   epsilon: 0.2459    steps: 775    lr: 6.4e-06     reward: 10.08\n",
      "epis: 1851   score: 9.0   mem len: 481324   epsilon: 0.245    steps: 482    lr: 6.4e-06     reward: 10.09\n",
      "epis: 1852   score: 8.0   mem len: 481726   epsilon: 0.2442    steps: 402    lr: 6.4e-06     reward: 10.13\n",
      "epis: 1853   score: 12.0   mem len: 482329   epsilon: 0.243    steps: 603    lr: 6.4e-06     reward: 10.17\n",
      "epis: 1854   score: 13.0   mem len: 482932   epsilon: 0.2418    steps: 603    lr: 6.4e-06     reward: 10.17\n",
      "epis: 1855   score: 10.0   mem len: 483436   epsilon: 0.2408    steps: 504    lr: 6.4e-06     reward: 10.17\n",
      "epis: 1856   score: 9.0   mem len: 483896   epsilon: 0.2399    steps: 460    lr: 6.4e-06     reward: 10.2\n",
      "epis: 1857   score: 11.0   mem len: 484418   epsilon: 0.2389    steps: 522    lr: 6.4e-06     reward: 10.24\n",
      "epis: 1858   score: 5.0   mem len: 484746   epsilon: 0.2382    steps: 328    lr: 6.4e-06     reward: 10.16\n",
      "epis: 1859   score: 12.0   mem len: 485354   epsilon: 0.237    steps: 608    lr: 6.4e-06     reward: 10.24\n",
      "epis: 1860   score: 11.0   mem len: 485866   epsilon: 0.236    steps: 512    lr: 6.4e-06     reward: 10.29\n",
      "epis: 1861   score: 4.0   mem len: 486126   epsilon: 0.2355    steps: 260    lr: 6.4e-06     reward: 10.27\n",
      "epis: 1862   score: 14.0   mem len: 486713   epsilon: 0.2343    steps: 587    lr: 6.4e-06     reward: 10.31\n",
      "epis: 1863   score: 20.0   mem len: 487385   epsilon: 0.233    steps: 672    lr: 6.4e-06     reward: 10.4\n",
      "epis: 1864   score: 13.0   mem len: 487947   epsilon: 0.2319    steps: 562    lr: 6.4e-06     reward: 10.42\n",
      "epis: 1865   score: 12.0   mem len: 488513   epsilon: 0.2307    steps: 566    lr: 6.4e-06     reward: 10.43\n",
      "epis: 1866   score: 11.0   mem len: 488999   epsilon: 0.2298    steps: 486    lr: 6.4e-06     reward: 10.49\n",
      "epis: 1867   score: 7.0   mem len: 489406   epsilon: 0.229    steps: 407    lr: 6.4e-06     reward: 10.42\n",
      "epis: 1868   score: 8.0   mem len: 489854   epsilon: 0.2281    steps: 448    lr: 6.4e-06     reward: 10.46\n",
      "epis: 1869   score: 18.0   mem len: 490652   epsilon: 0.2265    steps: 798    lr: 6.4e-06     reward: 10.56\n",
      "epis: 1870   score: 12.0   mem len: 491191   epsilon: 0.2254    steps: 539    lr: 6.4e-06     reward: 10.64\n",
      "epis: 1871   score: 9.0   mem len: 491659   epsilon: 0.2245    steps: 468    lr: 6.4e-06     reward: 10.67\n",
      "epis: 1872   score: 16.0   mem len: 492255   epsilon: 0.2233    steps: 596    lr: 6.4e-06     reward: 10.74\n",
      "epis: 1873   score: 5.0   mem len: 492603   epsilon: 0.2226    steps: 348    lr: 6.4e-06     reward: 10.69\n",
      "epis: 1874   score: 11.0   mem len: 493146   epsilon: 0.2216    steps: 543    lr: 6.4e-06     reward: 10.66\n",
      "epis: 1875   score: 15.0   mem len: 493842   epsilon: 0.2202    steps: 696    lr: 6.4e-06     reward: 10.74\n",
      "epis: 1876   score: 10.0   mem len: 494315   epsilon: 0.2193    steps: 473    lr: 6.4e-06     reward: 10.77\n",
      "epis: 1877   score: 11.0   mem len: 494857   epsilon: 0.2182    steps: 542    lr: 6.4e-06     reward: 10.78\n",
      "epis: 1878   score: 11.0   mem len: 495297   epsilon: 0.2173    steps: 440    lr: 6.4e-06     reward: 10.83\n",
      "epis: 1879   score: 8.0   mem len: 495730   epsilon: 0.2165    steps: 433    lr: 6.4e-06     reward: 10.78\n",
      "epis: 1880   score: 14.0   mem len: 496265   epsilon: 0.2154    steps: 535    lr: 6.4e-06     reward: 10.82\n",
      "epis: 1881   score: 12.0   mem len: 496855   epsilon: 0.2142    steps: 590    lr: 6.4e-06     reward: 10.84\n",
      "epis: 1882   score: 14.0   mem len: 497419   epsilon: 0.2131    steps: 564    lr: 6.4e-06     reward: 10.88\n",
      "epis: 1883   score: 7.0   mem len: 497811   epsilon: 0.2123    steps: 392    lr: 6.4e-06     reward: 10.86\n",
      "epis: 1884   score: 9.0   mem len: 498298   epsilon: 0.2114    steps: 487    lr: 6.4e-06     reward: 10.75\n",
      "epis: 1885   score: 11.0   mem len: 498834   epsilon: 0.2103    steps: 536    lr: 6.4e-06     reward: 10.75\n",
      "epis: 1886   score: 14.0   mem len: 499481   epsilon: 0.209    steps: 647    lr: 6.4e-06     reward: 10.8\n",
      "epis: 1887   score: 7.0   mem len: 499868   epsilon: 0.2083    steps: 387    lr: 6.4e-06     reward: 10.8\n",
      "epis: 1888   score: 9.0   mem len: 500369   epsilon: 0.2073    steps: 501    lr: 2.6e-06     reward: 10.82\n",
      "epis: 1889   score: 13.0   mem len: 500863   epsilon: 0.2063    steps: 494    lr: 2.6e-06     reward: 10.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1890   score: 6.0   mem len: 501224   epsilon: 0.2056    steps: 361    lr: 2.6e-06     reward: 10.83\n",
      "epis: 1891   score: 17.0   mem len: 501859   epsilon: 0.2043    steps: 635    lr: 2.6e-06     reward: 10.87\n",
      "epis: 1892   score: 18.0   mem len: 502576   epsilon: 0.2029    steps: 717    lr: 2.6e-06     reward: 10.95\n",
      "epis: 1893   score: 8.0   mem len: 503009   epsilon: 0.202    steps: 433    lr: 2.6e-06     reward: 10.93\n",
      "epis: 1894   score: 13.0   mem len: 503516   epsilon: 0.201    steps: 507    lr: 2.6e-06     reward: 10.98\n",
      "epis: 1895   score: 7.0   mem len: 503927   epsilon: 0.2002    steps: 411    lr: 2.6e-06     reward: 10.95\n",
      "epis: 1896   score: 11.0   mem len: 504516   epsilon: 0.1991    steps: 589    lr: 2.6e-06     reward: 10.89\n",
      "epis: 1897   score: 15.0   mem len: 505091   epsilon: 0.1979    steps: 575    lr: 2.6e-06     reward: 10.99\n",
      "epis: 1898   score: 16.0   mem len: 505637   epsilon: 0.1968    steps: 546    lr: 2.6e-06     reward: 11.06\n",
      "epis: 1899   score: 13.0   mem len: 506209   epsilon: 0.1957    steps: 572    lr: 2.6e-06     reward: 11.1\n",
      "epis: 1900   score: 9.0   mem len: 506640   epsilon: 0.1949    steps: 431    lr: 2.6e-06     reward: 11.02\n",
      "epis: 1901   score: 7.0   mem len: 507048   epsilon: 0.194    steps: 408    lr: 2.6e-06     reward: 10.97\n",
      "epis: 1902   score: 9.0   mem len: 507534   epsilon: 0.1931    steps: 486    lr: 2.6e-06     reward: 11.01\n",
      "epis: 1903   score: 14.0   mem len: 508088   epsilon: 0.192    steps: 554    lr: 2.6e-06     reward: 11.07\n",
      "epis: 1904   score: 10.0   mem len: 508597   epsilon: 0.191    steps: 509    lr: 2.6e-06     reward: 11.07\n",
      "epis: 1905   score: 10.0   mem len: 509128   epsilon: 0.1899    steps: 531    lr: 2.6e-06     reward: 11.07\n",
      "epis: 1906   score: 7.0   mem len: 509541   epsilon: 0.1891    steps: 413    lr: 2.6e-06     reward: 11.05\n",
      "epis: 1907   score: 9.0   mem len: 510000   epsilon: 0.1882    steps: 459    lr: 2.6e-06     reward: 11.05\n",
      "epis: 1908   score: 10.0   mem len: 510500   epsilon: 0.1872    steps: 500    lr: 2.6e-06     reward: 11.07\n",
      "epis: 1909   score: 13.0   mem len: 511116   epsilon: 0.186    steps: 616    lr: 2.6e-06     reward: 11.12\n",
      "epis: 1910   score: 20.0   mem len: 511732   epsilon: 0.1848    steps: 616    lr: 2.6e-06     reward: 11.22\n",
      "epis: 1911   score: 17.0   mem len: 512373   epsilon: 0.1835    steps: 641    lr: 2.6e-06     reward: 11.31\n",
      "epis: 1912   score: 11.0   mem len: 512904   epsilon: 0.1824    steps: 531    lr: 2.6e-06     reward: 11.31\n",
      "epis: 1913   score: 21.0   mem len: 513578   epsilon: 0.1811    steps: 674    lr: 2.6e-06     reward: 11.35\n",
      "epis: 1914   score: 11.0   mem len: 514152   epsilon: 0.18    steps: 574    lr: 2.6e-06     reward: 11.33\n",
      "epis: 1915   score: 13.0   mem len: 514738   epsilon: 0.1788    steps: 586    lr: 2.6e-06     reward: 11.35\n",
      "epis: 1916   score: 11.0   mem len: 515308   epsilon: 0.1777    steps: 570    lr: 2.6e-06     reward: 11.34\n",
      "epis: 1917   score: 10.0   mem len: 515787   epsilon: 0.1767    steps: 479    lr: 2.6e-06     reward: 11.27\n",
      "epis: 1918   score: 9.0   mem len: 516094   epsilon: 0.1761    steps: 307    lr: 2.6e-06     reward: 11.28\n",
      "epis: 1919   score: 12.0   mem len: 516685   epsilon: 0.175    steps: 591    lr: 2.6e-06     reward: 11.33\n",
      "epis: 1920   score: 14.0   mem len: 517235   epsilon: 0.1739    steps: 550    lr: 2.6e-06     reward: 11.35\n",
      "epis: 1921   score: 16.0   mem len: 517900   epsilon: 0.1726    steps: 665    lr: 2.6e-06     reward: 11.33\n",
      "epis: 1922   score: 12.0   mem len: 518494   epsilon: 0.1714    steps: 594    lr: 2.6e-06     reward: 11.36\n",
      "epis: 1923   score: 12.0   mem len: 519115   epsilon: 0.1702    steps: 621    lr: 2.6e-06     reward: 11.39\n",
      "epis: 1924   score: 9.0   mem len: 519586   epsilon: 0.1692    steps: 471    lr: 2.6e-06     reward: 11.42\n",
      "epis: 1925   score: 10.0   mem len: 520099   epsilon: 0.1682    steps: 513    lr: 2.6e-06     reward: 11.44\n",
      "epis: 1926   score: 14.0   mem len: 520640   epsilon: 0.1671    steps: 541    lr: 2.6e-06     reward: 11.5\n",
      "epis: 1927   score: 26.0   mem len: 521427   epsilon: 0.1656    steps: 787    lr: 2.6e-06     reward: 11.66\n",
      "epis: 1928   score: 8.0   mem len: 521904   epsilon: 0.1646    steps: 477    lr: 2.6e-06     reward: 11.62\n",
      "epis: 1929   score: 7.0   mem len: 522326   epsilon: 0.1638    steps: 422    lr: 2.6e-06     reward: 11.61\n",
      "epis: 1930   score: 6.0   mem len: 522684   epsilon: 0.1631    steps: 358    lr: 2.6e-06     reward: 11.49\n",
      "epis: 1931   score: 13.0   mem len: 523222   epsilon: 0.162    steps: 538    lr: 2.6e-06     reward: 11.54\n",
      "epis: 1932   score: 6.0   mem len: 523521   epsilon: 0.1614    steps: 299    lr: 2.6e-06     reward: 11.5\n",
      "epis: 1933   score: 14.0   mem len: 524119   epsilon: 0.1602    steps: 598    lr: 2.6e-06     reward: 11.48\n",
      "epis: 1934   score: 12.0   mem len: 524657   epsilon: 0.1592    steps: 538    lr: 2.6e-06     reward: 11.48\n",
      "epis: 1935   score: 14.0   mem len: 525211   epsilon: 0.1581    steps: 554    lr: 2.6e-06     reward: 11.5\n",
      "epis: 1936   score: 7.0   mem len: 525575   epsilon: 0.1574    steps: 364    lr: 2.6e-06     reward: 11.42\n",
      "epis: 1937   score: 15.0   mem len: 526205   epsilon: 0.1561    steps: 630    lr: 2.6e-06     reward: 11.47\n",
      "epis: 1938   score: 10.0   mem len: 526691   epsilon: 0.1551    steps: 486    lr: 2.6e-06     reward: 11.5\n",
      "epis: 1939   score: 14.0   mem len: 527329   epsilon: 0.1539    steps: 638    lr: 2.6e-06     reward: 11.52\n",
      "epis: 1940   score: 13.0   mem len: 527886   epsilon: 0.1528    steps: 557    lr: 2.6e-06     reward: 11.53\n",
      "epis: 1941   score: 13.0   mem len: 528516   epsilon: 0.1515    steps: 630    lr: 2.6e-06     reward: 11.54\n",
      "epis: 1942   score: 10.0   mem len: 529019   epsilon: 0.1505    steps: 503    lr: 2.6e-06     reward: 11.54\n",
      "epis: 1943   score: 19.0   mem len: 529727   epsilon: 0.1491    steps: 708    lr: 2.6e-06     reward: 11.61\n",
      "epis: 1944   score: 6.0   mem len: 530051   epsilon: 0.1485    steps: 324    lr: 2.6e-06     reward: 11.57\n",
      "epis: 1945   score: 10.0   mem len: 530645   epsilon: 0.1473    steps: 594    lr: 2.6e-06     reward: 11.52\n",
      "epis: 1946   score: 17.0   mem len: 531334   epsilon: 0.146    steps: 689    lr: 2.6e-06     reward: 11.62\n",
      "epis: 1947   score: 8.0   mem len: 531777   epsilon: 0.1451    steps: 443    lr: 2.6e-06     reward: 11.59\n",
      "epis: 1948   score: 6.0   mem len: 532083   epsilon: 0.1445    steps: 306    lr: 2.6e-06     reward: 11.5\n",
      "epis: 1949   score: 14.0   mem len: 532739   epsilon: 0.1432    steps: 656    lr: 2.6e-06     reward: 11.54\n",
      "epis: 1950   score: 12.0   mem len: 533277   epsilon: 0.1421    steps: 538    lr: 2.6e-06     reward: 11.49\n",
      "epis: 1951   score: 10.0   mem len: 533795   epsilon: 0.1411    steps: 518    lr: 2.6e-06     reward: 11.5\n",
      "epis: 1952   score: 8.0   mem len: 534225   epsilon: 0.1402    steps: 430    lr: 2.6e-06     reward: 11.5\n",
      "epis: 1953   score: 9.0   mem len: 534720   epsilon: 0.1393    steps: 495    lr: 2.6e-06     reward: 11.47\n",
      "epis: 1954   score: 21.0   mem len: 535459   epsilon: 0.1378    steps: 739    lr: 2.6e-06     reward: 11.55\n",
      "epis: 1955   score: 13.0   mem len: 536029   epsilon: 0.1367    steps: 570    lr: 2.6e-06     reward: 11.58\n",
      "epis: 1956   score: 8.0   mem len: 536499   epsilon: 0.1357    steps: 470    lr: 2.6e-06     reward: 11.57\n",
      "epis: 1957   score: 7.0   mem len: 536894   epsilon: 0.1349    steps: 395    lr: 2.6e-06     reward: 11.53\n",
      "epis: 1958   score: 10.0   mem len: 537442   epsilon: 0.1339    steps: 548    lr: 2.6e-06     reward: 11.58\n",
      "epis: 1959   score: 12.0   mem len: 538028   epsilon: 0.1327    steps: 586    lr: 2.6e-06     reward: 11.58\n",
      "epis: 1960   score: 11.0   mem len: 538564   epsilon: 0.1316    steps: 536    lr: 2.6e-06     reward: 11.58\n",
      "epis: 1961   score: 7.0   mem len: 538950   epsilon: 0.1309    steps: 386    lr: 2.6e-06     reward: 11.61\n",
      "epis: 1962   score: 8.0   mem len: 539391   epsilon: 0.13    steps: 441    lr: 2.6e-06     reward: 11.55\n",
      "epis: 1963   score: 8.0   mem len: 539842   epsilon: 0.1291    steps: 451    lr: 2.6e-06     reward: 11.43\n",
      "epis: 1964   score: 13.0   mem len: 540450   epsilon: 0.1279    steps: 608    lr: 2.6e-06     reward: 11.43\n",
      "epis: 1965   score: 7.0   mem len: 540840   epsilon: 0.1271    steps: 390    lr: 2.6e-06     reward: 11.38\n",
      "epis: 1966   score: 11.0   mem len: 541398   epsilon: 0.126    steps: 558    lr: 2.6e-06     reward: 11.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 1967   score: 11.0   mem len: 542000   epsilon: 0.1248    steps: 602    lr: 2.6e-06     reward: 11.42\n",
      "epis: 1968   score: 13.0   mem len: 542651   epsilon: 0.1235    steps: 651    lr: 2.6e-06     reward: 11.47\n",
      "epis: 1969   score: 11.0   mem len: 543199   epsilon: 0.1225    steps: 548    lr: 2.6e-06     reward: 11.4\n",
      "epis: 1970   score: 16.0   mem len: 543806   epsilon: 0.1213    steps: 607    lr: 2.6e-06     reward: 11.44\n",
      "epis: 1971   score: 13.0   mem len: 544433   epsilon: 0.12    steps: 627    lr: 2.6e-06     reward: 11.48\n",
      "epis: 1972   score: 7.0   mem len: 544815   epsilon: 0.1193    steps: 382    lr: 2.6e-06     reward: 11.39\n",
      "epis: 1973   score: 14.0   mem len: 545326   epsilon: 0.1183    steps: 511    lr: 2.6e-06     reward: 11.48\n",
      "epis: 1974   score: 9.0   mem len: 545834   epsilon: 0.1172    steps: 508    lr: 2.6e-06     reward: 11.46\n",
      "epis: 1975   score: 5.0   mem len: 546182   epsilon: 0.1166    steps: 348    lr: 2.6e-06     reward: 11.36\n",
      "epis: 1976   score: 11.0   mem len: 546738   epsilon: 0.1155    steps: 556    lr: 2.6e-06     reward: 11.37\n",
      "epis: 1977   score: 14.0   mem len: 547328   epsilon: 0.1143    steps: 590    lr: 2.6e-06     reward: 11.4\n",
      "epis: 1978   score: 10.0   mem len: 547832   epsilon: 0.1133    steps: 504    lr: 2.6e-06     reward: 11.39\n",
      "epis: 1979   score: 8.0   mem len: 548218   epsilon: 0.1125    steps: 386    lr: 2.6e-06     reward: 11.39\n",
      "epis: 1980   score: 6.0   mem len: 548594   epsilon: 0.1118    steps: 376    lr: 2.6e-06     reward: 11.31\n",
      "epis: 1981   score: 5.0   mem len: 548887   epsilon: 0.1112    steps: 293    lr: 2.6e-06     reward: 11.24\n",
      "epis: 1982   score: 17.0   mem len: 549502   epsilon: 0.11    steps: 615    lr: 2.6e-06     reward: 11.27\n",
      "epis: 1983   score: 17.0   mem len: 550109   epsilon: 0.1088    steps: 607    lr: 2.6e-06     reward: 11.37\n",
      "epis: 1984   score: 7.0   mem len: 550515   epsilon: 0.108    steps: 406    lr: 2.6e-06     reward: 11.35\n",
      "epis: 1985   score: 17.0   mem len: 551147   epsilon: 0.1067    steps: 632    lr: 2.6e-06     reward: 11.41\n",
      "epis: 1986   score: 13.0   mem len: 551817   epsilon: 0.1054    steps: 670    lr: 2.6e-06     reward: 11.4\n",
      "epis: 1987   score: 9.0   mem len: 552305   epsilon: 0.1044    steps: 488    lr: 2.6e-06     reward: 11.42\n",
      "epis: 1988   score: 8.0   mem len: 552728   epsilon: 0.1036    steps: 423    lr: 2.6e-06     reward: 11.41\n",
      "epis: 1989   score: 13.0   mem len: 553307   epsilon: 0.1025    steps: 579    lr: 2.6e-06     reward: 11.41\n",
      "epis: 1990   score: 13.0   mem len: 553927   epsilon: 0.1012    steps: 620    lr: 2.6e-06     reward: 11.48\n",
      "epis: 1991   score: 19.0   mem len: 554410   epsilon: 0.1003    steps: 483    lr: 2.6e-06     reward: 11.5\n",
      "epis: 1992   score: 15.0   mem len: 554971   epsilon: 0.0992    steps: 561    lr: 2.6e-06     reward: 11.47\n",
      "epis: 1993   score: 13.0   mem len: 555602   epsilon: 0.0979    steps: 631    lr: 2.6e-06     reward: 11.52\n",
      "epis: 1994   score: 18.0   mem len: 556318   epsilon: 0.0965    steps: 716    lr: 2.6e-06     reward: 11.57\n",
      "epis: 1995   score: 9.0   mem len: 556805   epsilon: 0.0955    steps: 487    lr: 2.6e-06     reward: 11.59\n",
      "epis: 1996   score: 8.0   mem len: 557258   epsilon: 0.0946    steps: 453    lr: 2.6e-06     reward: 11.56\n",
      "epis: 1997   score: 8.0   mem len: 557712   epsilon: 0.0937    steps: 454    lr: 2.6e-06     reward: 11.49\n",
      "epis: 1998   score: 14.0   mem len: 558203   epsilon: 0.0928    steps: 491    lr: 2.6e-06     reward: 11.47\n",
      "epis: 1999   score: 13.0   mem len: 558756   epsilon: 0.0917    steps: 553    lr: 2.6e-06     reward: 11.47\n",
      "epis: 2000   score: 19.0   mem len: 559436   epsilon: 0.0903    steps: 680    lr: 2.6e-06     reward: 11.57\n",
      "epis: 2001   score: 12.0   mem len: 560016   epsilon: 0.0892    steps: 580    lr: 2.6e-06     reward: 11.62\n",
      "epis: 2002   score: 5.0   mem len: 560364   epsilon: 0.0885    steps: 348    lr: 2.6e-06     reward: 11.58\n",
      "epis: 2003   score: 12.0   mem len: 560935   epsilon: 0.0873    steps: 571    lr: 2.6e-06     reward: 11.56\n",
      "epis: 2004   score: 7.0   mem len: 561324   epsilon: 0.0866    steps: 389    lr: 2.6e-06     reward: 11.53\n",
      "epis: 2005   score: 11.0   mem len: 561847   epsilon: 0.0855    steps: 523    lr: 2.6e-06     reward: 11.54\n",
      "epis: 2006   score: 10.0   mem len: 562363   epsilon: 0.0845    steps: 516    lr: 2.6e-06     reward: 11.57\n",
      "epis: 2007   score: 12.0   mem len: 562965   epsilon: 0.0833    steps: 602    lr: 2.6e-06     reward: 11.6\n",
      "epis: 2008   score: 10.0   mem len: 563416   epsilon: 0.0824    steps: 451    lr: 2.6e-06     reward: 11.6\n",
      "epis: 2009   score: 10.0   mem len: 563897   epsilon: 0.0815    steps: 481    lr: 2.6e-06     reward: 11.57\n",
      "epis: 2010   score: 13.0   mem len: 564360   epsilon: 0.0806    steps: 463    lr: 2.6e-06     reward: 11.5\n",
      "epis: 2011   score: 9.0   mem len: 564811   epsilon: 0.0797    steps: 451    lr: 2.6e-06     reward: 11.42\n",
      "epis: 2012   score: 20.0   mem len: 565393   epsilon: 0.0785    steps: 582    lr: 2.6e-06     reward: 11.51\n",
      "epis: 2013   score: 10.0   mem len: 565914   epsilon: 0.0775    steps: 521    lr: 2.6e-06     reward: 11.4\n",
      "epis: 2014   score: 6.0   mem len: 566255   epsilon: 0.0768    steps: 341    lr: 2.6e-06     reward: 11.35\n",
      "epis: 2015   score: 9.0   mem len: 566694   epsilon: 0.0759    steps: 439    lr: 2.6e-06     reward: 11.31\n",
      "epis: 2016   score: 18.0   mem len: 567259   epsilon: 0.0748    steps: 565    lr: 2.6e-06     reward: 11.38\n",
      "epis: 2017   score: 9.0   mem len: 567726   epsilon: 0.0739    steps: 467    lr: 2.6e-06     reward: 11.37\n",
      "epis: 2018   score: 11.0   mem len: 568243   epsilon: 0.0729    steps: 517    lr: 2.6e-06     reward: 11.39\n",
      "epis: 2019   score: 10.0   mem len: 568796   epsilon: 0.0718    steps: 553    lr: 2.6e-06     reward: 11.37\n",
      "epis: 2020   score: 9.0   mem len: 569278   epsilon: 0.0708    steps: 482    lr: 2.6e-06     reward: 11.32\n",
      "epis: 2021   score: 11.0   mem len: 569862   epsilon: 0.0697    steps: 584    lr: 2.6e-06     reward: 11.27\n",
      "epis: 2022   score: 11.0   mem len: 570435   epsilon: 0.0685    steps: 573    lr: 2.6e-06     reward: 11.26\n",
      "epis: 2023   score: 14.0   mem len: 571080   epsilon: 0.0673    steps: 645    lr: 2.6e-06     reward: 11.28\n",
      "epis: 2024   score: 9.0   mem len: 571555   epsilon: 0.0663    steps: 475    lr: 2.6e-06     reward: 11.28\n",
      "epis: 2025   score: 9.0   mem len: 571993   epsilon: 0.0655    steps: 438    lr: 2.6e-06     reward: 11.27\n",
      "epis: 2026   score: 22.0   mem len: 572612   epsilon: 0.0642    steps: 619    lr: 2.6e-06     reward: 11.35\n",
      "epis: 2027   score: 11.0   mem len: 573164   epsilon: 0.0631    steps: 552    lr: 2.6e-06     reward: 11.2\n",
      "epis: 2028   score: 8.0   mem len: 573605   epsilon: 0.0623    steps: 441    lr: 2.6e-06     reward: 11.2\n",
      "epis: 2029   score: 7.0   mem len: 574012   epsilon: 0.0615    steps: 407    lr: 2.6e-06     reward: 11.2\n",
      "epis: 2030   score: 17.0   mem len: 574726   epsilon: 0.06    steps: 714    lr: 2.6e-06     reward: 11.31\n",
      "epis: 2031   score: 25.0   mem len: 575208   epsilon: 0.0591    steps: 482    lr: 2.6e-06     reward: 11.43\n",
      "epis: 2032   score: 12.0   mem len: 575801   epsilon: 0.0579    steps: 593    lr: 2.6e-06     reward: 11.49\n",
      "epis: 2033   score: 17.0   mem len: 576520   epsilon: 0.0565    steps: 719    lr: 2.6e-06     reward: 11.52\n",
      "epis: 2034   score: 12.0   mem len: 577083   epsilon: 0.0554    steps: 563    lr: 2.6e-06     reward: 11.52\n",
      "epis: 2035   score: 11.0   mem len: 577610   epsilon: 0.0543    steps: 527    lr: 2.6e-06     reward: 11.49\n",
      "epis: 2036   score: 15.0   mem len: 578091   epsilon: 0.0534    steps: 481    lr: 2.6e-06     reward: 11.57\n",
      "epis: 2037   score: 12.0   mem len: 578643   epsilon: 0.0523    steps: 552    lr: 2.6e-06     reward: 11.54\n",
      "epis: 2038   score: 14.0   mem len: 579148   epsilon: 0.0513    steps: 505    lr: 2.6e-06     reward: 11.58\n",
      "epis: 2039   score: 9.0   mem len: 579651   epsilon: 0.0503    steps: 503    lr: 2.6e-06     reward: 11.53\n",
      "epis: 2040   score: 13.0   mem len: 580138   epsilon: 0.0493    steps: 487    lr: 2.6e-06     reward: 11.53\n",
      "epis: 2041   score: 12.0   mem len: 580720   epsilon: 0.0482    steps: 582    lr: 2.6e-06     reward: 11.52\n",
      "epis: 2042   score: 13.0   mem len: 581279   epsilon: 0.0471    steps: 559    lr: 2.6e-06     reward: 11.55\n",
      "epis: 2043   score: 8.0   mem len: 581664   epsilon: 0.0463    steps: 385    lr: 2.6e-06     reward: 11.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2044   score: 12.0   mem len: 582190   epsilon: 0.0453    steps: 526    lr: 2.6e-06     reward: 11.5\n",
      "epis: 2045   score: 12.0   mem len: 582771   epsilon: 0.0441    steps: 581    lr: 2.6e-06     reward: 11.52\n",
      "epis: 2046   score: 13.0   mem len: 583269   epsilon: 0.0431    steps: 498    lr: 2.6e-06     reward: 11.48\n",
      "epis: 2047   score: 14.0   mem len: 583895   epsilon: 0.0419    steps: 626    lr: 2.6e-06     reward: 11.54\n",
      "epis: 2048   score: 14.0   mem len: 584559   epsilon: 0.0406    steps: 664    lr: 2.6e-06     reward: 11.62\n",
      "epis: 2049   score: 15.0   mem len: 585129   epsilon: 0.0394    steps: 570    lr: 2.6e-06     reward: 11.63\n",
      "epis: 2050   score: 11.0   mem len: 585668   epsilon: 0.0384    steps: 539    lr: 2.6e-06     reward: 11.62\n",
      "epis: 2051   score: 10.0   mem len: 586189   epsilon: 0.0373    steps: 521    lr: 2.6e-06     reward: 11.62\n",
      "epis: 2052   score: 9.0   mem len: 586681   epsilon: 0.0364    steps: 492    lr: 2.6e-06     reward: 11.63\n",
      "epis: 2053   score: 12.0   mem len: 587256   epsilon: 0.0352    steps: 575    lr: 2.6e-06     reward: 11.66\n",
      "epis: 2054   score: 15.0   mem len: 587894   epsilon: 0.034    steps: 638    lr: 2.6e-06     reward: 11.6\n",
      "epis: 2055   score: 11.0   mem len: 588449   epsilon: 0.0329    steps: 555    lr: 2.6e-06     reward: 11.58\n",
      "epis: 2056   score: 7.0   mem len: 588840   epsilon: 0.0321    steps: 391    lr: 2.6e-06     reward: 11.57\n",
      "epis: 2057   score: 16.0   mem len: 589506   epsilon: 0.0308    steps: 666    lr: 2.6e-06     reward: 11.66\n",
      "epis: 2058   score: 14.0   mem len: 590073   epsilon: 0.0297    steps: 567    lr: 2.6e-06     reward: 11.7\n",
      "epis: 2059   score: 12.0   mem len: 590642   epsilon: 0.0285    steps: 569    lr: 2.6e-06     reward: 11.7\n",
      "epis: 2060   score: 12.0   mem len: 591218   epsilon: 0.0274    steps: 576    lr: 2.6e-06     reward: 11.71\n",
      "epis: 2061   score: 11.0   mem len: 591768   epsilon: 0.0263    steps: 550    lr: 2.6e-06     reward: 11.75\n",
      "epis: 2062   score: 6.0   mem len: 592075   epsilon: 0.0257    steps: 307    lr: 2.6e-06     reward: 11.73\n",
      "epis: 2063   score: 16.0   mem len: 592787   epsilon: 0.0243    steps: 712    lr: 2.6e-06     reward: 11.81\n",
      "epis: 2064   score: 13.0   mem len: 593402   epsilon: 0.0231    steps: 615    lr: 2.6e-06     reward: 11.81\n",
      "epis: 2065   score: 9.0   mem len: 593875   epsilon: 0.0221    steps: 473    lr: 2.6e-06     reward: 11.83\n",
      "epis: 2066   score: 6.0   mem len: 594229   epsilon: 0.0214    steps: 354    lr: 2.6e-06     reward: 11.78\n",
      "epis: 2067   score: 12.0   mem len: 594804   epsilon: 0.0203    steps: 575    lr: 2.6e-06     reward: 11.79\n",
      "epis: 2068   score: 17.0   mem len: 595452   epsilon: 0.019    steps: 648    lr: 2.6e-06     reward: 11.83\n",
      "epis: 2069   score: 9.0   mem len: 595974   epsilon: 0.018    steps: 522    lr: 2.6e-06     reward: 11.81\n",
      "epis: 2070   score: 21.0   mem len: 596591   epsilon: 0.0167    steps: 617    lr: 2.6e-06     reward: 11.86\n",
      "epis: 2071   score: 10.0   mem len: 597118   epsilon: 0.0157    steps: 527    lr: 2.6e-06     reward: 11.83\n",
      "epis: 2072   score: 28.0   mem len: 597937   epsilon: 0.0141    steps: 819    lr: 2.6e-06     reward: 12.04\n",
      "epis: 2073   score: 18.0   mem len: 598778   epsilon: 0.0124    steps: 841    lr: 2.6e-06     reward: 12.08\n",
      "epis: 2074   score: 6.0   mem len: 599167   epsilon: 0.0116    steps: 389    lr: 2.6e-06     reward: 12.05\n",
      "epis: 2075   score: 8.0   mem len: 599592   epsilon: 0.0108    steps: 425    lr: 2.6e-06     reward: 12.08\n",
      "epis: 2076   score: 4.0   mem len: 599838   epsilon: 0.0103    steps: 246    lr: 2.6e-06     reward: 12.01\n",
      "epis: 2077   score: 15.0   mem len: 600372   epsilon: 0.01    steps: 534    lr: 1e-06     reward: 12.02\n",
      "epis: 2078   score: 9.0   mem len: 600794   epsilon: 0.01    steps: 422    lr: 1e-06     reward: 12.01\n",
      "epis: 2079   score: 25.0   mem len: 601615   epsilon: 0.01    steps: 821    lr: 1e-06     reward: 12.18\n",
      "epis: 2080   score: 24.0   mem len: 602321   epsilon: 0.01    steps: 706    lr: 1e-06     reward: 12.36\n",
      "epis: 2081   score: 9.0   mem len: 602803   epsilon: 0.01    steps: 482    lr: 1e-06     reward: 12.4\n",
      "epis: 2082   score: 12.0   mem len: 603380   epsilon: 0.01    steps: 577    lr: 1e-06     reward: 12.35\n",
      "epis: 2083   score: 6.0   mem len: 603722   epsilon: 0.01    steps: 342    lr: 1e-06     reward: 12.24\n",
      "epis: 2084   score: 25.0   mem len: 604507   epsilon: 0.01    steps: 785    lr: 1e-06     reward: 12.42\n",
      "epis: 2085   score: 15.0   mem len: 605076   epsilon: 0.01    steps: 569    lr: 1e-06     reward: 12.4\n",
      "epis: 2086   score: 11.0   mem len: 605575   epsilon: 0.01    steps: 499    lr: 1e-06     reward: 12.38\n",
      "epis: 2087   score: 13.0   mem len: 606165   epsilon: 0.01    steps: 590    lr: 1e-06     reward: 12.42\n",
      "epis: 2088   score: 13.0   mem len: 606775   epsilon: 0.01    steps: 610    lr: 1e-06     reward: 12.47\n",
      "epis: 2089   score: 12.0   mem len: 607373   epsilon: 0.01    steps: 598    lr: 1e-06     reward: 12.46\n",
      "epis: 2090   score: 6.0   mem len: 607718   epsilon: 0.01    steps: 345    lr: 1e-06     reward: 12.39\n",
      "epis: 2091   score: 15.0   mem len: 608434   epsilon: 0.01    steps: 716    lr: 1e-06     reward: 12.35\n",
      "epis: 2092   score: 18.0   mem len: 609142   epsilon: 0.01    steps: 708    lr: 1e-06     reward: 12.38\n",
      "epis: 2093   score: 16.0   mem len: 609823   epsilon: 0.01    steps: 681    lr: 1e-06     reward: 12.41\n",
      "epis: 2094   score: 12.0   mem len: 610415   epsilon: 0.01    steps: 592    lr: 1e-06     reward: 12.35\n",
      "epis: 2095   score: 13.0   mem len: 611043   epsilon: 0.01    steps: 628    lr: 1e-06     reward: 12.39\n",
      "epis: 2096   score: 6.0   mem len: 611386   epsilon: 0.01    steps: 343    lr: 1e-06     reward: 12.37\n",
      "epis: 2097   score: 14.0   mem len: 612017   epsilon: 0.01    steps: 631    lr: 1e-06     reward: 12.43\n",
      "epis: 2098   score: 16.0   mem len: 612648   epsilon: 0.01    steps: 631    lr: 1e-06     reward: 12.45\n",
      "epis: 2099   score: 16.0   mem len: 613376   epsilon: 0.01    steps: 728    lr: 1e-06     reward: 12.48\n",
      "epis: 2100   score: 12.0   mem len: 613984   epsilon: 0.01    steps: 608    lr: 1e-06     reward: 12.41\n",
      "epis: 2101   score: 12.0   mem len: 614480   epsilon: 0.01    steps: 496    lr: 1e-06     reward: 12.41\n",
      "epis: 2102   score: 17.0   mem len: 615133   epsilon: 0.01    steps: 653    lr: 1e-06     reward: 12.53\n",
      "epis: 2103   score: 14.0   mem len: 615768   epsilon: 0.01    steps: 635    lr: 1e-06     reward: 12.55\n",
      "epis: 2104   score: 18.0   mem len: 616620   epsilon: 0.01    steps: 852    lr: 1e-06     reward: 12.66\n",
      "epis: 2105   score: 8.0   mem len: 617074   epsilon: 0.01    steps: 454    lr: 1e-06     reward: 12.63\n",
      "epis: 2106   score: 23.0   mem len: 617640   epsilon: 0.01    steps: 566    lr: 1e-06     reward: 12.76\n",
      "epis: 2107   score: 10.0   mem len: 618118   epsilon: 0.01    steps: 478    lr: 1e-06     reward: 12.74\n",
      "epis: 2108   score: 17.0   mem len: 618894   epsilon: 0.01    steps: 776    lr: 1e-06     reward: 12.81\n",
      "epis: 2109   score: 5.0   mem len: 619168   epsilon: 0.01    steps: 274    lr: 1e-06     reward: 12.76\n",
      "epis: 2110   score: 10.0   mem len: 619675   epsilon: 0.01    steps: 507    lr: 1e-06     reward: 12.73\n",
      "epis: 2111   score: 29.0   mem len: 620423   epsilon: 0.01    steps: 748    lr: 1e-06     reward: 12.93\n",
      "epis: 2112   score: 11.0   mem len: 621021   epsilon: 0.01    steps: 598    lr: 1e-06     reward: 12.84\n",
      "epis: 2113   score: 12.0   mem len: 621551   epsilon: 0.01    steps: 530    lr: 1e-06     reward: 12.86\n",
      "epis: 2114   score: 11.0   mem len: 622086   epsilon: 0.01    steps: 535    lr: 1e-06     reward: 12.91\n",
      "epis: 2115   score: 12.0   mem len: 622648   epsilon: 0.01    steps: 562    lr: 1e-06     reward: 12.94\n",
      "epis: 2116   score: 13.0   mem len: 623259   epsilon: 0.01    steps: 611    lr: 1e-06     reward: 12.89\n",
      "epis: 2117   score: 9.0   mem len: 623723   epsilon: 0.01    steps: 464    lr: 1e-06     reward: 12.89\n",
      "epis: 2118   score: 12.0   mem len: 624286   epsilon: 0.01    steps: 563    lr: 1e-06     reward: 12.9\n",
      "epis: 2119   score: 21.0   mem len: 624941   epsilon: 0.01    steps: 655    lr: 1e-06     reward: 13.01\n",
      "epis: 2120   score: 12.0   mem len: 625546   epsilon: 0.01    steps: 605    lr: 1e-06     reward: 13.04\n",
      "epis: 2121   score: 16.0   mem len: 626296   epsilon: 0.01    steps: 750    lr: 1e-06     reward: 13.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2122   score: 16.0   mem len: 626901   epsilon: 0.01    steps: 605    lr: 1e-06     reward: 13.14\n",
      "epis: 2123   score: 13.0   mem len: 627478   epsilon: 0.01    steps: 577    lr: 1e-06     reward: 13.13\n",
      "epis: 2124   score: 9.0   mem len: 627949   epsilon: 0.01    steps: 471    lr: 1e-06     reward: 13.13\n",
      "epis: 2125   score: 7.0   mem len: 628351   epsilon: 0.01    steps: 402    lr: 1e-06     reward: 13.11\n",
      "epis: 2126   score: 15.0   mem len: 629015   epsilon: 0.01    steps: 664    lr: 1e-06     reward: 13.04\n",
      "epis: 2127   score: 11.0   mem len: 629523   epsilon: 0.01    steps: 508    lr: 1e-06     reward: 13.04\n",
      "epis: 2128   score: 15.0   mem len: 630132   epsilon: 0.01    steps: 609    lr: 1e-06     reward: 13.11\n",
      "epis: 2129   score: 13.0   mem len: 630707   epsilon: 0.01    steps: 575    lr: 1e-06     reward: 13.17\n",
      "epis: 2130   score: 8.0   mem len: 631181   epsilon: 0.01    steps: 474    lr: 1e-06     reward: 13.08\n",
      "epis: 2131   score: 13.0   mem len: 631774   epsilon: 0.01    steps: 593    lr: 1e-06     reward: 12.96\n",
      "epis: 2132   score: 8.0   mem len: 632186   epsilon: 0.01    steps: 412    lr: 1e-06     reward: 12.92\n",
      "epis: 2133   score: 8.0   mem len: 632642   epsilon: 0.01    steps: 456    lr: 1e-06     reward: 12.83\n",
      "epis: 2134   score: 10.0   mem len: 633184   epsilon: 0.01    steps: 542    lr: 1e-06     reward: 12.81\n",
      "epis: 2135   score: 10.0   mem len: 633677   epsilon: 0.01    steps: 493    lr: 1e-06     reward: 12.8\n",
      "epis: 2136   score: 12.0   mem len: 634270   epsilon: 0.01    steps: 593    lr: 1e-06     reward: 12.77\n",
      "epis: 2137   score: 11.0   mem len: 634837   epsilon: 0.01    steps: 567    lr: 1e-06     reward: 12.76\n",
      "epis: 2138   score: 12.0   mem len: 635446   epsilon: 0.01    steps: 609    lr: 1e-06     reward: 12.74\n",
      "epis: 2139   score: 10.0   mem len: 635977   epsilon: 0.01    steps: 531    lr: 1e-06     reward: 12.75\n",
      "epis: 2140   score: 12.0   mem len: 636520   epsilon: 0.01    steps: 543    lr: 1e-06     reward: 12.74\n",
      "epis: 2141   score: 13.0   mem len: 637034   epsilon: 0.01    steps: 514    lr: 1e-06     reward: 12.75\n",
      "epis: 2142   score: 12.0   mem len: 637497   epsilon: 0.01    steps: 463    lr: 1e-06     reward: 12.74\n",
      "epis: 2143   score: 21.0   mem len: 638141   epsilon: 0.01    steps: 644    lr: 1e-06     reward: 12.87\n",
      "epis: 2144   score: 14.0   mem len: 638684   epsilon: 0.01    steps: 543    lr: 1e-06     reward: 12.89\n",
      "epis: 2145   score: 10.0   mem len: 639209   epsilon: 0.01    steps: 525    lr: 1e-06     reward: 12.87\n",
      "epis: 2146   score: 10.0   mem len: 639682   epsilon: 0.01    steps: 473    lr: 1e-06     reward: 12.84\n",
      "epis: 2147   score: 14.0   mem len: 640179   epsilon: 0.01    steps: 497    lr: 1e-06     reward: 12.84\n",
      "epis: 2148   score: 10.0   mem len: 640697   epsilon: 0.01    steps: 518    lr: 1e-06     reward: 12.8\n",
      "epis: 2149   score: 6.0   mem len: 641052   epsilon: 0.01    steps: 355    lr: 1e-06     reward: 12.71\n",
      "epis: 2150   score: 16.0   mem len: 641617   epsilon: 0.01    steps: 565    lr: 1e-06     reward: 12.76\n",
      "epis: 2151   score: 14.0   mem len: 642327   epsilon: 0.01    steps: 710    lr: 1e-06     reward: 12.8\n",
      "epis: 2152   score: 11.0   mem len: 642859   epsilon: 0.01    steps: 532    lr: 1e-06     reward: 12.82\n",
      "epis: 2153   score: 12.0   mem len: 643470   epsilon: 0.01    steps: 611    lr: 1e-06     reward: 12.82\n",
      "epis: 2154   score: 9.0   mem len: 643934   epsilon: 0.01    steps: 464    lr: 1e-06     reward: 12.76\n",
      "epis: 2155   score: 18.0   mem len: 644597   epsilon: 0.01    steps: 663    lr: 1e-06     reward: 12.83\n",
      "epis: 2156   score: 15.0   mem len: 645264   epsilon: 0.01    steps: 667    lr: 1e-06     reward: 12.91\n",
      "epis: 2157   score: 9.0   mem len: 645768   epsilon: 0.01    steps: 504    lr: 1e-06     reward: 12.84\n",
      "epis: 2158   score: 14.0   mem len: 646442   epsilon: 0.01    steps: 674    lr: 1e-06     reward: 12.84\n",
      "epis: 2159   score: 17.0   mem len: 647069   epsilon: 0.01    steps: 627    lr: 1e-06     reward: 12.89\n",
      "epis: 2160   score: 13.0   mem len: 647720   epsilon: 0.01    steps: 651    lr: 1e-06     reward: 12.9\n",
      "epis: 2161   score: 20.0   mem len: 648365   epsilon: 0.01    steps: 645    lr: 1e-06     reward: 12.99\n",
      "epis: 2162   score: 20.0   mem len: 649054   epsilon: 0.01    steps: 689    lr: 1e-06     reward: 13.13\n",
      "epis: 2163   score: 9.0   mem len: 649563   epsilon: 0.01    steps: 509    lr: 1e-06     reward: 13.06\n",
      "epis: 2164   score: 18.0   mem len: 650226   epsilon: 0.01    steps: 663    lr: 1e-06     reward: 13.11\n",
      "epis: 2165   score: 12.0   mem len: 650811   epsilon: 0.01    steps: 585    lr: 1e-06     reward: 13.14\n",
      "epis: 2166   score: 13.0   mem len: 651439   epsilon: 0.01    steps: 628    lr: 1e-06     reward: 13.21\n",
      "epis: 2167   score: 13.0   mem len: 652120   epsilon: 0.01    steps: 681    lr: 1e-06     reward: 13.22\n",
      "epis: 2168   score: 12.0   mem len: 652770   epsilon: 0.01    steps: 650    lr: 1e-06     reward: 13.17\n",
      "epis: 2169   score: 19.0   mem len: 653313   epsilon: 0.01    steps: 543    lr: 1e-06     reward: 13.27\n",
      "epis: 2170   score: 18.0   mem len: 653995   epsilon: 0.01    steps: 682    lr: 1e-06     reward: 13.24\n",
      "epis: 2171   score: 14.0   mem len: 654635   epsilon: 0.01    steps: 640    lr: 1e-06     reward: 13.28\n",
      "epis: 2172   score: 10.0   mem len: 655178   epsilon: 0.01    steps: 543    lr: 1e-06     reward: 13.1\n",
      "epis: 2173   score: 12.0   mem len: 655759   epsilon: 0.01    steps: 581    lr: 1e-06     reward: 13.04\n",
      "epis: 2174   score: 15.0   mem len: 656381   epsilon: 0.01    steps: 622    lr: 1e-06     reward: 13.13\n",
      "epis: 2175   score: 18.0   mem len: 657089   epsilon: 0.01    steps: 708    lr: 1e-06     reward: 13.23\n",
      "epis: 2176   score: 10.0   mem len: 657620   epsilon: 0.01    steps: 531    lr: 1e-06     reward: 13.29\n",
      "epis: 2177   score: 12.0   mem len: 658227   epsilon: 0.01    steps: 607    lr: 1e-06     reward: 13.26\n",
      "epis: 2178   score: 18.0   mem len: 658822   epsilon: 0.01    steps: 595    lr: 1e-06     reward: 13.35\n",
      "epis: 2179   score: 12.0   mem len: 659398   epsilon: 0.01    steps: 576    lr: 1e-06     reward: 13.22\n",
      "epis: 2180   score: 12.0   mem len: 659962   epsilon: 0.01    steps: 564    lr: 1e-06     reward: 13.1\n",
      "epis: 2181   score: 10.0   mem len: 660452   epsilon: 0.01    steps: 490    lr: 1e-06     reward: 13.11\n",
      "epis: 2182   score: 17.0   mem len: 661089   epsilon: 0.01    steps: 637    lr: 1e-06     reward: 13.16\n",
      "epis: 2183   score: 8.0   mem len: 661547   epsilon: 0.01    steps: 458    lr: 1e-06     reward: 13.18\n",
      "epis: 2184   score: 8.0   mem len: 662006   epsilon: 0.01    steps: 459    lr: 1e-06     reward: 13.01\n",
      "epis: 2185   score: 14.0   mem len: 662703   epsilon: 0.01    steps: 697    lr: 1e-06     reward: 13.0\n",
      "epis: 2186   score: 20.0   mem len: 663373   epsilon: 0.01    steps: 670    lr: 1e-06     reward: 13.09\n",
      "epis: 2187   score: 8.0   mem len: 663781   epsilon: 0.01    steps: 408    lr: 1e-06     reward: 13.04\n",
      "epis: 2188   score: 11.0   mem len: 664317   epsilon: 0.01    steps: 536    lr: 1e-06     reward: 13.02\n",
      "epis: 2189   score: 14.0   mem len: 664900   epsilon: 0.01    steps: 583    lr: 1e-06     reward: 13.04\n",
      "epis: 2190   score: 16.0   mem len: 665508   epsilon: 0.01    steps: 608    lr: 1e-06     reward: 13.14\n",
      "epis: 2191   score: 18.0   mem len: 666171   epsilon: 0.01    steps: 663    lr: 1e-06     reward: 13.17\n",
      "epis: 2192   score: 9.0   mem len: 666677   epsilon: 0.01    steps: 506    lr: 1e-06     reward: 13.08\n",
      "epis: 2193   score: 30.0   mem len: 667454   epsilon: 0.01    steps: 777    lr: 1e-06     reward: 13.22\n",
      "epis: 2194   score: 12.0   mem len: 668014   epsilon: 0.01    steps: 560    lr: 1e-06     reward: 13.22\n",
      "epis: 2195   score: 11.0   mem len: 668529   epsilon: 0.01    steps: 515    lr: 1e-06     reward: 13.2\n",
      "epis: 2196   score: 10.0   mem len: 669029   epsilon: 0.01    steps: 500    lr: 1e-06     reward: 13.24\n",
      "epis: 2197   score: 11.0   mem len: 669632   epsilon: 0.01    steps: 603    lr: 1e-06     reward: 13.21\n",
      "epis: 2198   score: 13.0   mem len: 670181   epsilon: 0.01    steps: 549    lr: 1e-06     reward: 13.18\n",
      "epis: 2199   score: 8.0   mem len: 670639   epsilon: 0.01    steps: 458    lr: 1e-06     reward: 13.1\n",
      "epis: 2200   score: 10.0   mem len: 671145   epsilon: 0.01    steps: 506    lr: 1e-06     reward: 13.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2201   score: 12.0   mem len: 671690   epsilon: 0.01    steps: 545    lr: 1e-06     reward: 13.08\n",
      "epis: 2202   score: 20.0   mem len: 672430   epsilon: 0.01    steps: 740    lr: 1e-06     reward: 13.11\n",
      "epis: 2203   score: 10.0   mem len: 672985   epsilon: 0.01    steps: 555    lr: 1e-06     reward: 13.07\n",
      "epis: 2204   score: 10.0   mem len: 673471   epsilon: 0.01    steps: 486    lr: 1e-06     reward: 12.99\n",
      "epis: 2205   score: 13.0   mem len: 674078   epsilon: 0.01    steps: 607    lr: 1e-06     reward: 13.04\n",
      "epis: 2206   score: 10.0   mem len: 674592   epsilon: 0.01    steps: 514    lr: 1e-06     reward: 12.91\n",
      "epis: 2207   score: 18.0   mem len: 675139   epsilon: 0.01    steps: 547    lr: 1e-06     reward: 12.99\n",
      "epis: 2208   score: 11.0   mem len: 675710   epsilon: 0.01    steps: 571    lr: 1e-06     reward: 12.93\n",
      "epis: 2209   score: 8.0   mem len: 676142   epsilon: 0.01    steps: 432    lr: 1e-06     reward: 12.96\n",
      "epis: 2210   score: 9.0   mem len: 676643   epsilon: 0.01    steps: 501    lr: 1e-06     reward: 12.95\n",
      "epis: 2211   score: 8.0   mem len: 677091   epsilon: 0.01    steps: 448    lr: 1e-06     reward: 12.74\n",
      "epis: 2212   score: 14.0   mem len: 677793   epsilon: 0.01    steps: 702    lr: 1e-06     reward: 12.77\n",
      "epis: 2213   score: 13.0   mem len: 678308   epsilon: 0.01    steps: 515    lr: 1e-06     reward: 12.78\n",
      "epis: 2214   score: 7.0   mem len: 678738   epsilon: 0.01    steps: 430    lr: 1e-06     reward: 12.74\n",
      "epis: 2215   score: 10.0   mem len: 679239   epsilon: 0.01    steps: 501    lr: 1e-06     reward: 12.72\n",
      "epis: 2216   score: 11.0   mem len: 679783   epsilon: 0.01    steps: 544    lr: 1e-06     reward: 12.7\n",
      "epis: 2217   score: 14.0   mem len: 680458   epsilon: 0.01    steps: 675    lr: 1e-06     reward: 12.75\n",
      "epis: 2218   score: 14.0   mem len: 681141   epsilon: 0.01    steps: 683    lr: 1e-06     reward: 12.77\n",
      "epis: 2219   score: 17.0   mem len: 681846   epsilon: 0.01    steps: 705    lr: 1e-06     reward: 12.73\n",
      "epis: 2220   score: 13.0   mem len: 682457   epsilon: 0.01    steps: 611    lr: 1e-06     reward: 12.74\n",
      "epis: 2221   score: 12.0   mem len: 683001   epsilon: 0.01    steps: 544    lr: 1e-06     reward: 12.7\n",
      "epis: 2222   score: 9.0   mem len: 683526   epsilon: 0.01    steps: 525    lr: 1e-06     reward: 12.63\n",
      "epis: 2223   score: 20.0   mem len: 684291   epsilon: 0.01    steps: 765    lr: 1e-06     reward: 12.7\n",
      "epis: 2224   score: 10.0   mem len: 684779   epsilon: 0.01    steps: 488    lr: 1e-06     reward: 12.71\n",
      "epis: 2225   score: 12.0   mem len: 685344   epsilon: 0.01    steps: 565    lr: 1e-06     reward: 12.76\n",
      "epis: 2226   score: 16.0   mem len: 685954   epsilon: 0.01    steps: 610    lr: 1e-06     reward: 12.77\n",
      "epis: 2227   score: 31.0   mem len: 686604   epsilon: 0.01    steps: 650    lr: 1e-06     reward: 12.97\n",
      "epis: 2228   score: 9.0   mem len: 687130   epsilon: 0.01    steps: 526    lr: 1e-06     reward: 12.91\n",
      "epis: 2229   score: 12.0   mem len: 687754   epsilon: 0.01    steps: 624    lr: 1e-06     reward: 12.9\n",
      "epis: 2230   score: 8.0   mem len: 688177   epsilon: 0.01    steps: 423    lr: 1e-06     reward: 12.9\n",
      "epis: 2231   score: 20.0   mem len: 688862   epsilon: 0.01    steps: 685    lr: 1e-06     reward: 12.97\n",
      "epis: 2232   score: 8.0   mem len: 689318   epsilon: 0.01    steps: 456    lr: 1e-06     reward: 12.97\n",
      "epis: 2233   score: 10.0   mem len: 689862   epsilon: 0.01    steps: 544    lr: 1e-06     reward: 12.99\n",
      "epis: 2234   score: 11.0   mem len: 690388   epsilon: 0.01    steps: 526    lr: 1e-06     reward: 13.0\n",
      "epis: 2235   score: 11.0   mem len: 690952   epsilon: 0.01    steps: 564    lr: 1e-06     reward: 13.01\n",
      "epis: 2236   score: 8.0   mem len: 691375   epsilon: 0.01    steps: 423    lr: 1e-06     reward: 12.97\n",
      "epis: 2237   score: 11.0   mem len: 691909   epsilon: 0.01    steps: 534    lr: 1e-06     reward: 12.97\n",
      "epis: 2238   score: 10.0   mem len: 692436   epsilon: 0.01    steps: 527    lr: 1e-06     reward: 12.95\n",
      "epis: 2239   score: 18.0   mem len: 693020   epsilon: 0.01    steps: 584    lr: 1e-06     reward: 13.03\n",
      "epis: 2240   score: 13.0   mem len: 693626   epsilon: 0.01    steps: 606    lr: 1e-06     reward: 13.04\n",
      "epis: 2241   score: 11.0   mem len: 694145   epsilon: 0.01    steps: 519    lr: 1e-06     reward: 13.02\n",
      "epis: 2242   score: 13.0   mem len: 694687   epsilon: 0.01    steps: 542    lr: 1e-06     reward: 13.03\n",
      "epis: 2243   score: 11.0   mem len: 695250   epsilon: 0.01    steps: 563    lr: 1e-06     reward: 12.93\n",
      "epis: 2244   score: 13.0   mem len: 695890   epsilon: 0.01    steps: 640    lr: 1e-06     reward: 12.92\n",
      "epis: 2245   score: 15.0   mem len: 696576   epsilon: 0.01    steps: 686    lr: 1e-06     reward: 12.97\n",
      "epis: 2246   score: 17.0   mem len: 697352   epsilon: 0.01    steps: 776    lr: 1e-06     reward: 13.04\n",
      "epis: 2247   score: 11.0   mem len: 697901   epsilon: 0.01    steps: 549    lr: 1e-06     reward: 13.01\n",
      "epis: 2248   score: 13.0   mem len: 698389   epsilon: 0.01    steps: 488    lr: 1e-06     reward: 13.04\n",
      "epis: 2249   score: 18.0   mem len: 699037   epsilon: 0.01    steps: 648    lr: 1e-06     reward: 13.16\n",
      "epis: 2250   score: 14.0   mem len: 699628   epsilon: 0.01    steps: 591    lr: 1e-06     reward: 13.14\n",
      "epis: 2251   score: 8.0   mem len: 700050   epsilon: 0.01    steps: 422    lr: 4e-07     reward: 13.08\n",
      "epis: 2252   score: 15.0   mem len: 700705   epsilon: 0.01    steps: 655    lr: 4e-07     reward: 13.12\n",
      "epis: 2253   score: 20.0   mem len: 701360   epsilon: 0.01    steps: 655    lr: 4e-07     reward: 13.2\n",
      "epis: 2254   score: 11.0   mem len: 701920   epsilon: 0.01    steps: 560    lr: 4e-07     reward: 13.22\n",
      "epis: 2255   score: 14.0   mem len: 702445   epsilon: 0.01    steps: 525    lr: 4e-07     reward: 13.18\n",
      "epis: 2256   score: 13.0   mem len: 702944   epsilon: 0.01    steps: 499    lr: 4e-07     reward: 13.16\n",
      "epis: 2257   score: 11.0   mem len: 703550   epsilon: 0.01    steps: 606    lr: 4e-07     reward: 13.18\n",
      "epis: 2258   score: 14.0   mem len: 704128   epsilon: 0.01    steps: 578    lr: 4e-07     reward: 13.18\n",
      "epis: 2259   score: 10.0   mem len: 704640   epsilon: 0.01    steps: 512    lr: 4e-07     reward: 13.11\n",
      "epis: 2260   score: 12.0   mem len: 705205   epsilon: 0.01    steps: 565    lr: 4e-07     reward: 13.1\n",
      "epis: 2261   score: 9.0   mem len: 705677   epsilon: 0.01    steps: 472    lr: 4e-07     reward: 12.99\n",
      "epis: 2262   score: 15.0   mem len: 706381   epsilon: 0.01    steps: 704    lr: 4e-07     reward: 12.94\n",
      "epis: 2263   score: 12.0   mem len: 706957   epsilon: 0.01    steps: 576    lr: 4e-07     reward: 12.97\n",
      "epis: 2264   score: 14.0   mem len: 707648   epsilon: 0.01    steps: 691    lr: 4e-07     reward: 12.93\n",
      "epis: 2265   score: 6.0   mem len: 708009   epsilon: 0.01    steps: 361    lr: 4e-07     reward: 12.87\n",
      "epis: 2266   score: 12.0   mem len: 708665   epsilon: 0.01    steps: 656    lr: 4e-07     reward: 12.86\n",
      "epis: 2267   score: 10.0   mem len: 709154   epsilon: 0.01    steps: 489    lr: 4e-07     reward: 12.83\n",
      "epis: 2268   score: 10.0   mem len: 709662   epsilon: 0.01    steps: 508    lr: 4e-07     reward: 12.81\n",
      "epis: 2269   score: 9.0   mem len: 710151   epsilon: 0.01    steps: 489    lr: 4e-07     reward: 12.71\n",
      "epis: 2270   score: 30.0   mem len: 710778   epsilon: 0.01    steps: 627    lr: 4e-07     reward: 12.83\n",
      "epis: 2271   score: 10.0   mem len: 711286   epsilon: 0.01    steps: 508    lr: 4e-07     reward: 12.79\n",
      "epis: 2272   score: 18.0   mem len: 711981   epsilon: 0.01    steps: 695    lr: 4e-07     reward: 12.87\n",
      "epis: 2273   score: 16.0   mem len: 712627   epsilon: 0.01    steps: 646    lr: 4e-07     reward: 12.91\n",
      "epis: 2274   score: 14.0   mem len: 713241   epsilon: 0.01    steps: 614    lr: 4e-07     reward: 12.9\n",
      "epis: 2275   score: 14.0   mem len: 713803   epsilon: 0.01    steps: 562    lr: 4e-07     reward: 12.86\n",
      "epis: 2276   score: 19.0   mem len: 714553   epsilon: 0.01    steps: 750    lr: 4e-07     reward: 12.95\n",
      "epis: 2277   score: 14.0   mem len: 715220   epsilon: 0.01    steps: 667    lr: 4e-07     reward: 12.97\n",
      "epis: 2278   score: 13.0   mem len: 715749   epsilon: 0.01    steps: 529    lr: 4e-07     reward: 12.92\n",
      "epis: 2279   score: 13.0   mem len: 716249   epsilon: 0.01    steps: 500    lr: 4e-07     reward: 12.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2280   score: 11.0   mem len: 716785   epsilon: 0.01    steps: 536    lr: 4e-07     reward: 12.92\n",
      "epis: 2281   score: 7.0   mem len: 717196   epsilon: 0.01    steps: 411    lr: 4e-07     reward: 12.89\n",
      "epis: 2282   score: 11.0   mem len: 717753   epsilon: 0.01    steps: 557    lr: 4e-07     reward: 12.83\n",
      "epis: 2283   score: 16.0   mem len: 718309   epsilon: 0.01    steps: 556    lr: 4e-07     reward: 12.91\n",
      "epis: 2284   score: 15.0   mem len: 718952   epsilon: 0.01    steps: 643    lr: 4e-07     reward: 12.98\n",
      "epis: 2285   score: 12.0   mem len: 719558   epsilon: 0.01    steps: 606    lr: 4e-07     reward: 12.96\n",
      "epis: 2286   score: 14.0   mem len: 720224   epsilon: 0.01    steps: 666    lr: 4e-07     reward: 12.9\n",
      "epis: 2287   score: 12.0   mem len: 720839   epsilon: 0.01    steps: 615    lr: 4e-07     reward: 12.94\n",
      "epis: 2288   score: 11.0   mem len: 721430   epsilon: 0.01    steps: 591    lr: 4e-07     reward: 12.94\n",
      "epis: 2289   score: 13.0   mem len: 722076   epsilon: 0.01    steps: 646    lr: 4e-07     reward: 12.93\n",
      "epis: 2290   score: 17.0   mem len: 722804   epsilon: 0.01    steps: 728    lr: 4e-07     reward: 12.94\n",
      "epis: 2291   score: 11.0   mem len: 723230   epsilon: 0.01    steps: 426    lr: 4e-07     reward: 12.87\n",
      "epis: 2292   score: 20.0   mem len: 724013   epsilon: 0.01    steps: 783    lr: 4e-07     reward: 12.98\n",
      "epis: 2293   score: 8.0   mem len: 724451   epsilon: 0.01    steps: 438    lr: 4e-07     reward: 12.76\n",
      "epis: 2294   score: 19.0   mem len: 725151   epsilon: 0.01    steps: 700    lr: 4e-07     reward: 12.83\n",
      "epis: 2295   score: 14.0   mem len: 725746   epsilon: 0.01    steps: 595    lr: 4e-07     reward: 12.86\n",
      "epis: 2296   score: 12.0   mem len: 726215   epsilon: 0.01    steps: 469    lr: 4e-07     reward: 12.88\n",
      "epis: 2297   score: 15.0   mem len: 726800   epsilon: 0.01    steps: 585    lr: 4e-07     reward: 12.92\n",
      "epis: 2298   score: 14.0   mem len: 727386   epsilon: 0.01    steps: 586    lr: 4e-07     reward: 12.93\n",
      "epis: 2299   score: 10.0   mem len: 727889   epsilon: 0.01    steps: 503    lr: 4e-07     reward: 12.95\n",
      "epis: 2300   score: 14.0   mem len: 728579   epsilon: 0.01    steps: 690    lr: 4e-07     reward: 12.99\n",
      "epis: 2301   score: 14.0   mem len: 729104   epsilon: 0.01    steps: 525    lr: 4e-07     reward: 13.01\n",
      "epis: 2302   score: 10.0   mem len: 729657   epsilon: 0.01    steps: 553    lr: 4e-07     reward: 12.91\n",
      "epis: 2303   score: 6.0   mem len: 729999   epsilon: 0.01    steps: 342    lr: 4e-07     reward: 12.87\n",
      "epis: 2304   score: 22.0   mem len: 730717   epsilon: 0.01    steps: 718    lr: 4e-07     reward: 12.99\n",
      "epis: 2305   score: 14.0   mem len: 731429   epsilon: 0.01    steps: 712    lr: 4e-07     reward: 13.0\n",
      "epis: 2306   score: 15.0   mem len: 732019   epsilon: 0.01    steps: 590    lr: 4e-07     reward: 13.05\n",
      "epis: 2307   score: 18.0   mem len: 732674   epsilon: 0.01    steps: 655    lr: 4e-07     reward: 13.05\n",
      "epis: 2308   score: 11.0   mem len: 733219   epsilon: 0.01    steps: 545    lr: 4e-07     reward: 13.05\n",
      "epis: 2309   score: 15.0   mem len: 733839   epsilon: 0.01    steps: 620    lr: 4e-07     reward: 13.12\n",
      "epis: 2310   score: 14.0   mem len: 734480   epsilon: 0.01    steps: 641    lr: 4e-07     reward: 13.17\n",
      "epis: 2311   score: 14.0   mem len: 735040   epsilon: 0.01    steps: 560    lr: 4e-07     reward: 13.23\n",
      "epis: 2312   score: 12.0   mem len: 735660   epsilon: 0.01    steps: 620    lr: 4e-07     reward: 13.21\n",
      "epis: 2313   score: 10.0   mem len: 736211   epsilon: 0.01    steps: 551    lr: 4e-07     reward: 13.18\n",
      "epis: 2314   score: 7.0   mem len: 736602   epsilon: 0.01    steps: 391    lr: 4e-07     reward: 13.18\n",
      "epis: 2315   score: 9.0   mem len: 737041   epsilon: 0.01    steps: 439    lr: 4e-07     reward: 13.17\n",
      "epis: 2316   score: 13.0   mem len: 737679   epsilon: 0.01    steps: 638    lr: 4e-07     reward: 13.19\n",
      "epis: 2317   score: 13.0   mem len: 738286   epsilon: 0.01    steps: 607    lr: 4e-07     reward: 13.18\n",
      "epis: 2318   score: 14.0   mem len: 739009   epsilon: 0.01    steps: 723    lr: 4e-07     reward: 13.18\n",
      "epis: 2319   score: 9.0   mem len: 739513   epsilon: 0.01    steps: 504    lr: 4e-07     reward: 13.1\n",
      "epis: 2320   score: 19.0   mem len: 740194   epsilon: 0.01    steps: 681    lr: 4e-07     reward: 13.16\n",
      "epis: 2321   score: 33.0   mem len: 741163   epsilon: 0.01    steps: 969    lr: 4e-07     reward: 13.37\n",
      "epis: 2322   score: 10.0   mem len: 741699   epsilon: 0.01    steps: 536    lr: 4e-07     reward: 13.38\n",
      "epis: 2323   score: 14.0   mem len: 742338   epsilon: 0.01    steps: 639    lr: 4e-07     reward: 13.32\n",
      "epis: 2324   score: 13.0   mem len: 742838   epsilon: 0.01    steps: 500    lr: 4e-07     reward: 13.35\n",
      "epis: 2325   score: 10.0   mem len: 743348   epsilon: 0.01    steps: 510    lr: 4e-07     reward: 13.33\n",
      "epis: 2326   score: 10.0   mem len: 743858   epsilon: 0.01    steps: 510    lr: 4e-07     reward: 13.27\n",
      "epis: 2327   score: 19.0   mem len: 744534   epsilon: 0.01    steps: 676    lr: 4e-07     reward: 13.15\n",
      "epis: 2328   score: 19.0   mem len: 745238   epsilon: 0.01    steps: 704    lr: 4e-07     reward: 13.25\n",
      "epis: 2329   score: 15.0   mem len: 745950   epsilon: 0.01    steps: 712    lr: 4e-07     reward: 13.28\n",
      "epis: 2330   score: 10.0   mem len: 746448   epsilon: 0.01    steps: 498    lr: 4e-07     reward: 13.3\n",
      "epis: 2331   score: 19.0   mem len: 747143   epsilon: 0.01    steps: 695    lr: 4e-07     reward: 13.29\n",
      "epis: 2332   score: 11.0   mem len: 747723   epsilon: 0.01    steps: 580    lr: 4e-07     reward: 13.32\n",
      "epis: 2333   score: 17.0   mem len: 748387   epsilon: 0.01    steps: 664    lr: 4e-07     reward: 13.39\n",
      "epis: 2334   score: 14.0   mem len: 749027   epsilon: 0.01    steps: 640    lr: 4e-07     reward: 13.42\n",
      "epis: 2335   score: 18.0   mem len: 749708   epsilon: 0.01    steps: 681    lr: 4e-07     reward: 13.49\n",
      "epis: 2336   score: 13.0   mem len: 750300   epsilon: 0.01    steps: 592    lr: 4e-07     reward: 13.54\n",
      "epis: 2337   score: 25.0   mem len: 750950   epsilon: 0.01    steps: 650    lr: 4e-07     reward: 13.68\n",
      "epis: 2338   score: 23.0   mem len: 751591   epsilon: 0.01    steps: 641    lr: 4e-07     reward: 13.81\n",
      "epis: 2339   score: 15.0   mem len: 752296   epsilon: 0.01    steps: 705    lr: 4e-07     reward: 13.78\n",
      "epis: 2340   score: 11.0   mem len: 752917   epsilon: 0.01    steps: 621    lr: 4e-07     reward: 13.76\n",
      "epis: 2341   score: 7.0   mem len: 753308   epsilon: 0.01    steps: 391    lr: 4e-07     reward: 13.72\n",
      "epis: 2342   score: 20.0   mem len: 754062   epsilon: 0.01    steps: 754    lr: 4e-07     reward: 13.79\n",
      "epis: 2343   score: 14.0   mem len: 754624   epsilon: 0.01    steps: 562    lr: 4e-07     reward: 13.82\n",
      "epis: 2344   score: 6.0   mem len: 754985   epsilon: 0.01    steps: 361    lr: 4e-07     reward: 13.75\n",
      "epis: 2345   score: 6.0   mem len: 755346   epsilon: 0.01    steps: 361    lr: 4e-07     reward: 13.66\n",
      "epis: 2346   score: 22.0   mem len: 756154   epsilon: 0.01    steps: 808    lr: 4e-07     reward: 13.71\n",
      "epis: 2347   score: 16.0   mem len: 756790   epsilon: 0.01    steps: 636    lr: 4e-07     reward: 13.76\n",
      "epis: 2348   score: 16.0   mem len: 757385   epsilon: 0.01    steps: 595    lr: 4e-07     reward: 13.79\n",
      "epis: 2349   score: 13.0   mem len: 758000   epsilon: 0.01    steps: 615    lr: 4e-07     reward: 13.74\n",
      "epis: 2350   score: 16.0   mem len: 758600   epsilon: 0.01    steps: 600    lr: 4e-07     reward: 13.76\n",
      "epis: 2351   score: 12.0   mem len: 759181   epsilon: 0.01    steps: 581    lr: 4e-07     reward: 13.8\n",
      "epis: 2352   score: 12.0   mem len: 759618   epsilon: 0.01    steps: 437    lr: 4e-07     reward: 13.77\n",
      "epis: 2353   score: 15.0   mem len: 760204   epsilon: 0.01    steps: 586    lr: 4e-07     reward: 13.72\n",
      "epis: 2354   score: 12.0   mem len: 760777   epsilon: 0.01    steps: 573    lr: 4e-07     reward: 13.73\n",
      "epis: 2355   score: 24.0   mem len: 761483   epsilon: 0.01    steps: 706    lr: 4e-07     reward: 13.83\n",
      "epis: 2356   score: 16.0   mem len: 762108   epsilon: 0.01    steps: 625    lr: 4e-07     reward: 13.86\n",
      "epis: 2357   score: 18.0   mem len: 762790   epsilon: 0.01    steps: 682    lr: 4e-07     reward: 13.93\n",
      "epis: 2358   score: 19.0   mem len: 763492   epsilon: 0.01    steps: 702    lr: 4e-07     reward: 13.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2359   score: 12.0   mem len: 764069   epsilon: 0.01    steps: 577    lr: 4e-07     reward: 14.0\n",
      "epis: 2360   score: 15.0   mem len: 764656   epsilon: 0.01    steps: 587    lr: 4e-07     reward: 14.03\n",
      "epis: 2361   score: 15.0   mem len: 765237   epsilon: 0.01    steps: 581    lr: 4e-07     reward: 14.09\n",
      "epis: 2362   score: 8.0   mem len: 765711   epsilon: 0.01    steps: 474    lr: 4e-07     reward: 14.02\n",
      "epis: 2363   score: 15.0   mem len: 766315   epsilon: 0.01    steps: 604    lr: 4e-07     reward: 14.05\n",
      "epis: 2364   score: 18.0   mem len: 767039   epsilon: 0.01    steps: 724    lr: 4e-07     reward: 14.09\n",
      "epis: 2365   score: 22.0   mem len: 767773   epsilon: 0.01    steps: 734    lr: 4e-07     reward: 14.25\n",
      "epis: 2366   score: 11.0   mem len: 768350   epsilon: 0.01    steps: 577    lr: 4e-07     reward: 14.24\n",
      "epis: 2367   score: 13.0   mem len: 768883   epsilon: 0.01    steps: 533    lr: 4e-07     reward: 14.27\n",
      "epis: 2368   score: 12.0   mem len: 769420   epsilon: 0.01    steps: 537    lr: 4e-07     reward: 14.29\n",
      "epis: 2369   score: 13.0   mem len: 769912   epsilon: 0.01    steps: 492    lr: 4e-07     reward: 14.33\n",
      "epis: 2370   score: 14.0   mem len: 770495   epsilon: 0.01    steps: 583    lr: 4e-07     reward: 14.17\n",
      "epis: 2371   score: 13.0   mem len: 771095   epsilon: 0.01    steps: 600    lr: 4e-07     reward: 14.2\n",
      "epis: 2372   score: 14.0   mem len: 771758   epsilon: 0.01    steps: 663    lr: 4e-07     reward: 14.16\n",
      "epis: 2373   score: 12.0   mem len: 772342   epsilon: 0.01    steps: 584    lr: 4e-07     reward: 14.12\n",
      "epis: 2374   score: 20.0   mem len: 773125   epsilon: 0.01    steps: 783    lr: 4e-07     reward: 14.18\n",
      "epis: 2375   score: 11.0   mem len: 773638   epsilon: 0.01    steps: 513    lr: 4e-07     reward: 14.15\n",
      "epis: 2376   score: 9.0   mem len: 774138   epsilon: 0.01    steps: 500    lr: 4e-07     reward: 14.05\n",
      "epis: 2377   score: 18.0   mem len: 774936   epsilon: 0.01    steps: 798    lr: 4e-07     reward: 14.09\n",
      "epis: 2378   score: 17.0   mem len: 775546   epsilon: 0.01    steps: 610    lr: 4e-07     reward: 14.13\n",
      "epis: 2379   score: 17.0   mem len: 776205   epsilon: 0.01    steps: 659    lr: 4e-07     reward: 14.17\n",
      "epis: 2380   score: 14.0   mem len: 776765   epsilon: 0.01    steps: 560    lr: 4e-07     reward: 14.2\n",
      "epis: 2381   score: 12.0   mem len: 777321   epsilon: 0.01    steps: 556    lr: 4e-07     reward: 14.25\n",
      "epis: 2382   score: 12.0   mem len: 777926   epsilon: 0.01    steps: 605    lr: 4e-07     reward: 14.26\n",
      "epis: 2383   score: 18.0   mem len: 778611   epsilon: 0.01    steps: 685    lr: 4e-07     reward: 14.28\n",
      "epis: 2384   score: 18.0   mem len: 779275   epsilon: 0.01    steps: 664    lr: 4e-07     reward: 14.31\n",
      "epis: 2385   score: 13.0   mem len: 779906   epsilon: 0.01    steps: 631    lr: 4e-07     reward: 14.32\n",
      "epis: 2386   score: 13.0   mem len: 780582   epsilon: 0.01    steps: 676    lr: 4e-07     reward: 14.31\n",
      "epis: 2387   score: 14.0   mem len: 781283   epsilon: 0.01    steps: 701    lr: 4e-07     reward: 14.33\n",
      "epis: 2388   score: 14.0   mem len: 781941   epsilon: 0.01    steps: 658    lr: 4e-07     reward: 14.36\n",
      "epis: 2389   score: 17.0   mem len: 782526   epsilon: 0.01    steps: 585    lr: 4e-07     reward: 14.4\n",
      "epis: 2390   score: 20.0   mem len: 783289   epsilon: 0.01    steps: 763    lr: 4e-07     reward: 14.43\n",
      "epis: 2391   score: 10.0   mem len: 783777   epsilon: 0.01    steps: 488    lr: 4e-07     reward: 14.42\n",
      "epis: 2392   score: 9.0   mem len: 784237   epsilon: 0.01    steps: 460    lr: 4e-07     reward: 14.31\n",
      "epis: 2393   score: 19.0   mem len: 784818   epsilon: 0.01    steps: 581    lr: 4e-07     reward: 14.42\n",
      "epis: 2394   score: 10.0   mem len: 785317   epsilon: 0.01    steps: 499    lr: 4e-07     reward: 14.33\n",
      "epis: 2395   score: 14.0   mem len: 785831   epsilon: 0.01    steps: 514    lr: 4e-07     reward: 14.33\n",
      "epis: 2396   score: 15.0   mem len: 786466   epsilon: 0.01    steps: 635    lr: 4e-07     reward: 14.36\n",
      "epis: 2397   score: 10.0   mem len: 786988   epsilon: 0.01    steps: 522    lr: 4e-07     reward: 14.31\n",
      "epis: 2398   score: 18.0   mem len: 787590   epsilon: 0.01    steps: 602    lr: 4e-07     reward: 14.35\n",
      "epis: 2399   score: 11.0   mem len: 788142   epsilon: 0.01    steps: 552    lr: 4e-07     reward: 14.36\n",
      "epis: 2400   score: 15.0   mem len: 788743   epsilon: 0.01    steps: 601    lr: 4e-07     reward: 14.37\n",
      "epis: 2401   score: 9.0   mem len: 789264   epsilon: 0.01    steps: 521    lr: 4e-07     reward: 14.32\n",
      "epis: 2402   score: 19.0   mem len: 789881   epsilon: 0.01    steps: 617    lr: 4e-07     reward: 14.41\n",
      "epis: 2403   score: 16.0   mem len: 790610   epsilon: 0.01    steps: 729    lr: 4e-07     reward: 14.51\n",
      "epis: 2404   score: 20.0   mem len: 791370   epsilon: 0.01    steps: 760    lr: 4e-07     reward: 14.49\n",
      "epis: 2405   score: 9.0   mem len: 791827   epsilon: 0.01    steps: 457    lr: 4e-07     reward: 14.44\n",
      "epis: 2406   score: 20.0   mem len: 792495   epsilon: 0.01    steps: 668    lr: 4e-07     reward: 14.49\n",
      "epis: 2407   score: 14.0   mem len: 793118   epsilon: 0.01    steps: 623    lr: 4e-07     reward: 14.45\n",
      "epis: 2408   score: 9.0   mem len: 793603   epsilon: 0.01    steps: 485    lr: 4e-07     reward: 14.43\n",
      "epis: 2409   score: 13.0   mem len: 794211   epsilon: 0.01    steps: 608    lr: 4e-07     reward: 14.41\n",
      "epis: 2410   score: 7.0   mem len: 794599   epsilon: 0.01    steps: 388    lr: 4e-07     reward: 14.34\n",
      "epis: 2411   score: 10.0   mem len: 795106   epsilon: 0.01    steps: 507    lr: 4e-07     reward: 14.3\n",
      "epis: 2412   score: 11.0   mem len: 795681   epsilon: 0.01    steps: 575    lr: 4e-07     reward: 14.29\n",
      "epis: 2413   score: 11.0   mem len: 796207   epsilon: 0.01    steps: 526    lr: 4e-07     reward: 14.3\n",
      "epis: 2414   score: 11.0   mem len: 796724   epsilon: 0.01    steps: 517    lr: 4e-07     reward: 14.34\n",
      "epis: 2415   score: 15.0   mem len: 797367   epsilon: 0.01    steps: 643    lr: 4e-07     reward: 14.4\n",
      "epis: 2416   score: 9.0   mem len: 797838   epsilon: 0.01    steps: 471    lr: 4e-07     reward: 14.36\n",
      "epis: 2417   score: 19.0   mem len: 798543   epsilon: 0.01    steps: 705    lr: 4e-07     reward: 14.42\n",
      "epis: 2418   score: 11.0   mem len: 799081   epsilon: 0.01    steps: 538    lr: 4e-07     reward: 14.39\n",
      "epis: 2419   score: 16.0   mem len: 799691   epsilon: 0.01    steps: 610    lr: 4e-07     reward: 14.46\n",
      "epis: 2420   score: 12.0   mem len: 800276   epsilon: 0.01    steps: 585    lr: 2e-07     reward: 14.39\n",
      "epis: 2421   score: 11.0   mem len: 800818   epsilon: 0.01    steps: 542    lr: 2e-07     reward: 14.17\n",
      "epis: 2422   score: 14.0   mem len: 801468   epsilon: 0.01    steps: 650    lr: 2e-07     reward: 14.21\n",
      "epis: 2423   score: 15.0   mem len: 802163   epsilon: 0.01    steps: 695    lr: 2e-07     reward: 14.22\n",
      "epis: 2424   score: 11.0   mem len: 802781   epsilon: 0.01    steps: 618    lr: 2e-07     reward: 14.2\n",
      "epis: 2425   score: 14.0   mem len: 803333   epsilon: 0.01    steps: 552    lr: 2e-07     reward: 14.24\n",
      "epis: 2426   score: 15.0   mem len: 803929   epsilon: 0.01    steps: 596    lr: 2e-07     reward: 14.29\n",
      "epis: 2427   score: 11.0   mem len: 804433   epsilon: 0.01    steps: 504    lr: 2e-07     reward: 14.21\n",
      "epis: 2428   score: 13.0   mem len: 805010   epsilon: 0.01    steps: 577    lr: 2e-07     reward: 14.15\n",
      "epis: 2429   score: 16.0   mem len: 805687   epsilon: 0.01    steps: 677    lr: 2e-07     reward: 14.16\n",
      "epis: 2430   score: 13.0   mem len: 806226   epsilon: 0.01    steps: 539    lr: 2e-07     reward: 14.19\n",
      "epis: 2431   score: 10.0   mem len: 806750   epsilon: 0.01    steps: 524    lr: 2e-07     reward: 14.1\n",
      "epis: 2432   score: 10.0   mem len: 807244   epsilon: 0.01    steps: 494    lr: 2e-07     reward: 14.09\n",
      "epis: 2433   score: 16.0   mem len: 807837   epsilon: 0.01    steps: 593    lr: 2e-07     reward: 14.08\n",
      "epis: 2434   score: 19.0   mem len: 808541   epsilon: 0.01    steps: 704    lr: 2e-07     reward: 14.13\n",
      "epis: 2435   score: 9.0   mem len: 809019   epsilon: 0.01    steps: 478    lr: 2e-07     reward: 14.04\n",
      "epis: 2436   score: 9.0   mem len: 809476   epsilon: 0.01    steps: 457    lr: 2e-07     reward: 14.0\n",
      "epis: 2437   score: 16.0   mem len: 810205   epsilon: 0.01    steps: 729    lr: 2e-07     reward: 13.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2438   score: 24.0   mem len: 810901   epsilon: 0.01    steps: 696    lr: 2e-07     reward: 13.92\n",
      "epis: 2439   score: 15.0   mem len: 811482   epsilon: 0.01    steps: 581    lr: 2e-07     reward: 13.92\n",
      "epis: 2440   score: 18.0   mem len: 812281   epsilon: 0.01    steps: 799    lr: 2e-07     reward: 13.99\n",
      "epis: 2441   score: 13.0   mem len: 812810   epsilon: 0.01    steps: 529    lr: 2e-07     reward: 14.05\n",
      "epis: 2442   score: 15.0   mem len: 813513   epsilon: 0.01    steps: 703    lr: 2e-07     reward: 14.0\n",
      "epis: 2443   score: 20.0   mem len: 814248   epsilon: 0.01    steps: 735    lr: 2e-07     reward: 14.06\n",
      "epis: 2444   score: 12.0   mem len: 814835   epsilon: 0.01    steps: 587    lr: 2e-07     reward: 14.12\n",
      "epis: 2445   score: 19.0   mem len: 815578   epsilon: 0.01    steps: 743    lr: 2e-07     reward: 14.25\n",
      "epis: 2446   score: 14.0   mem len: 816221   epsilon: 0.01    steps: 643    lr: 2e-07     reward: 14.17\n",
      "epis: 2447   score: 13.0   mem len: 816816   epsilon: 0.01    steps: 595    lr: 2e-07     reward: 14.14\n",
      "epis: 2448   score: 13.0   mem len: 817385   epsilon: 0.01    steps: 569    lr: 2e-07     reward: 14.11\n",
      "epis: 2449   score: 12.0   mem len: 817909   epsilon: 0.01    steps: 524    lr: 2e-07     reward: 14.1\n",
      "epis: 2450   score: 18.0   mem len: 818606   epsilon: 0.01    steps: 697    lr: 2e-07     reward: 14.12\n",
      "epis: 2451   score: 19.0   mem len: 819235   epsilon: 0.01    steps: 629    lr: 2e-07     reward: 14.19\n",
      "epis: 2452   score: 16.0   mem len: 819850   epsilon: 0.01    steps: 615    lr: 2e-07     reward: 14.23\n",
      "epis: 2453   score: 13.0   mem len: 820457   epsilon: 0.01    steps: 607    lr: 2e-07     reward: 14.21\n",
      "epis: 2454   score: 14.0   mem len: 821095   epsilon: 0.01    steps: 638    lr: 2e-07     reward: 14.23\n",
      "epis: 2455   score: 15.0   mem len: 821642   epsilon: 0.01    steps: 547    lr: 2e-07     reward: 14.14\n",
      "epis: 2456   score: 15.0   mem len: 822281   epsilon: 0.01    steps: 639    lr: 2e-07     reward: 14.13\n",
      "epis: 2457   score: 11.0   mem len: 822859   epsilon: 0.01    steps: 578    lr: 2e-07     reward: 14.06\n",
      "epis: 2458   score: 10.0   mem len: 823397   epsilon: 0.01    steps: 538    lr: 2e-07     reward: 13.97\n",
      "epis: 2459   score: 12.0   mem len: 823966   epsilon: 0.01    steps: 569    lr: 2e-07     reward: 13.97\n",
      "epis: 2460   score: 16.0   mem len: 824519   epsilon: 0.01    steps: 553    lr: 2e-07     reward: 13.98\n",
      "epis: 2461   score: 14.0   mem len: 825142   epsilon: 0.01    steps: 623    lr: 2e-07     reward: 13.97\n",
      "epis: 2462   score: 8.0   mem len: 825615   epsilon: 0.01    steps: 473    lr: 2e-07     reward: 13.97\n",
      "epis: 2463   score: 11.0   mem len: 826186   epsilon: 0.01    steps: 571    lr: 2e-07     reward: 13.93\n",
      "epis: 2464   score: 13.0   mem len: 826824   epsilon: 0.01    steps: 638    lr: 2e-07     reward: 13.88\n",
      "epis: 2465   score: 12.0   mem len: 827386   epsilon: 0.01    steps: 562    lr: 2e-07     reward: 13.78\n",
      "epis: 2466   score: 14.0   mem len: 828041   epsilon: 0.01    steps: 655    lr: 2e-07     reward: 13.81\n",
      "epis: 2467   score: 11.0   mem len: 828586   epsilon: 0.01    steps: 545    lr: 2e-07     reward: 13.79\n",
      "epis: 2468   score: 13.0   mem len: 829177   epsilon: 0.01    steps: 591    lr: 2e-07     reward: 13.8\n",
      "epis: 2469   score: 17.0   mem len: 829775   epsilon: 0.01    steps: 598    lr: 2e-07     reward: 13.84\n",
      "epis: 2470   score: 10.0   mem len: 830327   epsilon: 0.01    steps: 552    lr: 2e-07     reward: 13.8\n",
      "epis: 2471   score: 10.0   mem len: 830739   epsilon: 0.01    steps: 412    lr: 2e-07     reward: 13.77\n",
      "epis: 2472   score: 11.0   mem len: 831263   epsilon: 0.01    steps: 524    lr: 2e-07     reward: 13.74\n",
      "epis: 2473   score: 18.0   mem len: 831863   epsilon: 0.01    steps: 600    lr: 2e-07     reward: 13.8\n",
      "epis: 2474   score: 13.0   mem len: 832482   epsilon: 0.01    steps: 619    lr: 2e-07     reward: 13.73\n",
      "epis: 2475   score: 11.0   mem len: 832992   epsilon: 0.01    steps: 510    lr: 2e-07     reward: 13.73\n",
      "epis: 2476   score: 22.0   mem len: 833717   epsilon: 0.01    steps: 725    lr: 2e-07     reward: 13.86\n",
      "epis: 2477   score: 14.0   mem len: 834304   epsilon: 0.01    steps: 587    lr: 2e-07     reward: 13.82\n",
      "epis: 2478   score: 9.0   mem len: 834761   epsilon: 0.01    steps: 457    lr: 2e-07     reward: 13.74\n",
      "epis: 2479   score: 9.0   mem len: 835240   epsilon: 0.01    steps: 479    lr: 2e-07     reward: 13.66\n",
      "epis: 2480   score: 10.0   mem len: 835782   epsilon: 0.01    steps: 542    lr: 2e-07     reward: 13.62\n",
      "epis: 2481   score: 10.0   mem len: 836307   epsilon: 0.01    steps: 525    lr: 2e-07     reward: 13.6\n",
      "epis: 2482   score: 19.0   mem len: 837064   epsilon: 0.01    steps: 757    lr: 2e-07     reward: 13.67\n",
      "epis: 2483   score: 15.0   mem len: 837676   epsilon: 0.01    steps: 612    lr: 2e-07     reward: 13.64\n",
      "epis: 2484   score: 12.0   mem len: 838288   epsilon: 0.01    steps: 612    lr: 2e-07     reward: 13.58\n",
      "epis: 2485   score: 12.0   mem len: 838894   epsilon: 0.01    steps: 606    lr: 2e-07     reward: 13.57\n",
      "epis: 2486   score: 5.0   mem len: 839187   epsilon: 0.01    steps: 293    lr: 2e-07     reward: 13.49\n",
      "epis: 2487   score: 20.0   mem len: 839906   epsilon: 0.01    steps: 719    lr: 2e-07     reward: 13.55\n",
      "epis: 2488   score: 15.0   mem len: 840457   epsilon: 0.01    steps: 551    lr: 2e-07     reward: 13.56\n",
      "epis: 2489   score: 10.0   mem len: 840922   epsilon: 0.01    steps: 465    lr: 2e-07     reward: 13.49\n",
      "epis: 2490   score: 14.0   mem len: 841406   epsilon: 0.01    steps: 484    lr: 2e-07     reward: 13.43\n",
      "epis: 2491   score: 11.0   mem len: 841976   epsilon: 0.01    steps: 570    lr: 2e-07     reward: 13.44\n",
      "epis: 2492   score: 11.0   mem len: 842475   epsilon: 0.01    steps: 499    lr: 2e-07     reward: 13.46\n",
      "epis: 2493   score: 19.0   mem len: 843169   epsilon: 0.01    steps: 694    lr: 2e-07     reward: 13.46\n",
      "epis: 2494   score: 16.0   mem len: 843890   epsilon: 0.01    steps: 721    lr: 2e-07     reward: 13.52\n",
      "epis: 2495   score: 19.0   mem len: 844638   epsilon: 0.01    steps: 748    lr: 2e-07     reward: 13.57\n",
      "epis: 2496   score: 20.0   mem len: 845386   epsilon: 0.01    steps: 748    lr: 2e-07     reward: 13.62\n",
      "epis: 2497   score: 12.0   mem len: 845956   epsilon: 0.01    steps: 570    lr: 2e-07     reward: 13.64\n",
      "epis: 2498   score: 13.0   mem len: 846567   epsilon: 0.01    steps: 611    lr: 2e-07     reward: 13.59\n",
      "epis: 2499   score: 9.0   mem len: 847069   epsilon: 0.01    steps: 502    lr: 2e-07     reward: 13.57\n",
      "epis: 2500   score: 15.0   mem len: 847659   epsilon: 0.01    steps: 590    lr: 2e-07     reward: 13.57\n",
      "epis: 2501   score: 19.0   mem len: 848166   epsilon: 0.01    steps: 507    lr: 2e-07     reward: 13.67\n",
      "epis: 2502   score: 16.0   mem len: 848805   epsilon: 0.01    steps: 639    lr: 2e-07     reward: 13.64\n",
      "epis: 2503   score: 18.0   mem len: 849498   epsilon: 0.01    steps: 693    lr: 2e-07     reward: 13.66\n",
      "epis: 2504   score: 11.0   mem len: 850054   epsilon: 0.01    steps: 556    lr: 2e-07     reward: 13.57\n",
      "epis: 2505   score: 11.0   mem len: 850643   epsilon: 0.01    steps: 589    lr: 2e-07     reward: 13.59\n",
      "epis: 2506   score: 13.0   mem len: 851234   epsilon: 0.01    steps: 591    lr: 2e-07     reward: 13.52\n",
      "epis: 2507   score: 11.0   mem len: 851734   epsilon: 0.01    steps: 500    lr: 2e-07     reward: 13.49\n",
      "epis: 2508   score: 17.0   mem len: 852431   epsilon: 0.01    steps: 697    lr: 2e-07     reward: 13.57\n",
      "epis: 2509   score: 8.0   mem len: 852900   epsilon: 0.01    steps: 469    lr: 2e-07     reward: 13.52\n",
      "epis: 2510   score: 14.0   mem len: 853504   epsilon: 0.01    steps: 604    lr: 2e-07     reward: 13.59\n",
      "epis: 2511   score: 12.0   mem len: 854050   epsilon: 0.01    steps: 546    lr: 2e-07     reward: 13.61\n",
      "epis: 2512   score: 29.0   mem len: 854766   epsilon: 0.01    steps: 716    lr: 2e-07     reward: 13.79\n",
      "epis: 2513   score: 15.0   mem len: 855464   epsilon: 0.01    steps: 698    lr: 2e-07     reward: 13.83\n",
      "epis: 2514   score: 13.0   mem len: 856074   epsilon: 0.01    steps: 610    lr: 2e-07     reward: 13.85\n",
      "epis: 2515   score: 12.0   mem len: 856666   epsilon: 0.01    steps: 592    lr: 2e-07     reward: 13.82\n",
      "epis: 2516   score: 15.0   mem len: 857348   epsilon: 0.01    steps: 682    lr: 2e-07     reward: 13.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2517   score: 13.0   mem len: 857903   epsilon: 0.01    steps: 555    lr: 2e-07     reward: 13.82\n",
      "epis: 2518   score: 19.0   mem len: 858591   epsilon: 0.01    steps: 688    lr: 2e-07     reward: 13.9\n",
      "epis: 2519   score: 17.0   mem len: 859189   epsilon: 0.01    steps: 598    lr: 2e-07     reward: 13.91\n",
      "epis: 2520   score: 11.0   mem len: 859752   epsilon: 0.01    steps: 563    lr: 2e-07     reward: 13.9\n",
      "epis: 2521   score: 13.0   mem len: 860331   epsilon: 0.01    steps: 579    lr: 2e-07     reward: 13.92\n",
      "epis: 2522   score: 10.0   mem len: 860828   epsilon: 0.01    steps: 497    lr: 2e-07     reward: 13.88\n",
      "epis: 2523   score: 11.0   mem len: 861352   epsilon: 0.01    steps: 524    lr: 2e-07     reward: 13.84\n",
      "epis: 2524   score: 10.0   mem len: 861891   epsilon: 0.01    steps: 539    lr: 2e-07     reward: 13.83\n",
      "epis: 2525   score: 11.0   mem len: 862415   epsilon: 0.01    steps: 524    lr: 2e-07     reward: 13.8\n",
      "epis: 2526   score: 12.0   mem len: 862984   epsilon: 0.01    steps: 569    lr: 2e-07     reward: 13.77\n",
      "epis: 2527   score: 11.0   mem len: 863513   epsilon: 0.01    steps: 529    lr: 2e-07     reward: 13.77\n",
      "epis: 2528   score: 13.0   mem len: 864124   epsilon: 0.01    steps: 611    lr: 2e-07     reward: 13.77\n",
      "epis: 2529   score: 15.0   mem len: 864769   epsilon: 0.01    steps: 645    lr: 2e-07     reward: 13.76\n",
      "epis: 2530   score: 13.0   mem len: 865268   epsilon: 0.01    steps: 499    lr: 2e-07     reward: 13.76\n",
      "epis: 2531   score: 10.0   mem len: 865826   epsilon: 0.01    steps: 558    lr: 2e-07     reward: 13.76\n",
      "epis: 2532   score: 12.0   mem len: 866284   epsilon: 0.01    steps: 458    lr: 2e-07     reward: 13.78\n",
      "epis: 2533   score: 22.0   mem len: 867019   epsilon: 0.01    steps: 735    lr: 2e-07     reward: 13.84\n",
      "epis: 2534   score: 12.0   mem len: 867576   epsilon: 0.01    steps: 557    lr: 2e-07     reward: 13.77\n",
      "epis: 2535   score: 9.0   mem len: 868042   epsilon: 0.01    steps: 466    lr: 2e-07     reward: 13.77\n",
      "epis: 2536   score: 21.0   mem len: 868623   epsilon: 0.01    steps: 581    lr: 2e-07     reward: 13.89\n",
      "epis: 2537   score: 19.0   mem len: 869264   epsilon: 0.01    steps: 641    lr: 2e-07     reward: 13.92\n",
      "epis: 2538   score: 16.0   mem len: 869908   epsilon: 0.01    steps: 644    lr: 2e-07     reward: 13.84\n",
      "epis: 2539   score: 14.0   mem len: 870551   epsilon: 0.01    steps: 643    lr: 2e-07     reward: 13.83\n",
      "epis: 2540   score: 5.0   mem len: 870841   epsilon: 0.01    steps: 290    lr: 2e-07     reward: 13.7\n",
      "epis: 2541   score: 18.0   mem len: 871445   epsilon: 0.01    steps: 604    lr: 2e-07     reward: 13.75\n",
      "epis: 2542   score: 10.0   mem len: 871965   epsilon: 0.01    steps: 520    lr: 2e-07     reward: 13.7\n",
      "epis: 2543   score: 16.0   mem len: 872683   epsilon: 0.01    steps: 718    lr: 2e-07     reward: 13.66\n",
      "epis: 2544   score: 8.0   mem len: 873102   epsilon: 0.01    steps: 419    lr: 2e-07     reward: 13.62\n",
      "epis: 2545   score: 10.0   mem len: 873600   epsilon: 0.01    steps: 498    lr: 2e-07     reward: 13.53\n",
      "epis: 2546   score: 9.0   mem len: 874048   epsilon: 0.01    steps: 448    lr: 2e-07     reward: 13.48\n",
      "epis: 2547   score: 16.0   mem len: 874651   epsilon: 0.01    steps: 603    lr: 2e-07     reward: 13.51\n",
      "epis: 2548   score: 14.0   mem len: 875304   epsilon: 0.01    steps: 653    lr: 2e-07     reward: 13.52\n",
      "epis: 2549   score: 17.0   mem len: 875972   epsilon: 0.01    steps: 668    lr: 2e-07     reward: 13.57\n",
      "epis: 2550   score: 12.0   mem len: 876558   epsilon: 0.01    steps: 586    lr: 2e-07     reward: 13.51\n",
      "epis: 2551   score: 13.0   mem len: 877163   epsilon: 0.01    steps: 605    lr: 2e-07     reward: 13.45\n",
      "epis: 2552   score: 9.0   mem len: 877688   epsilon: 0.01    steps: 525    lr: 2e-07     reward: 13.38\n",
      "epis: 2553   score: 8.0   mem len: 878137   epsilon: 0.01    steps: 449    lr: 2e-07     reward: 13.33\n",
      "epis: 2554   score: 15.0   mem len: 878882   epsilon: 0.01    steps: 745    lr: 2e-07     reward: 13.34\n",
      "epis: 2555   score: 19.0   mem len: 879576   epsilon: 0.01    steps: 694    lr: 2e-07     reward: 13.38\n",
      "epis: 2556   score: 16.0   mem len: 880204   epsilon: 0.01    steps: 628    lr: 2e-07     reward: 13.39\n",
      "epis: 2557   score: 25.0   mem len: 880983   epsilon: 0.01    steps: 779    lr: 2e-07     reward: 13.53\n",
      "epis: 2558   score: 16.0   mem len: 881706   epsilon: 0.01    steps: 723    lr: 2e-07     reward: 13.59\n",
      "epis: 2559   score: 12.0   mem len: 882281   epsilon: 0.01    steps: 575    lr: 2e-07     reward: 13.59\n",
      "epis: 2560   score: 11.0   mem len: 882843   epsilon: 0.01    steps: 562    lr: 2e-07     reward: 13.54\n",
      "epis: 2561   score: 15.0   mem len: 883427   epsilon: 0.01    steps: 584    lr: 2e-07     reward: 13.55\n",
      "epis: 2562   score: 12.0   mem len: 883985   epsilon: 0.01    steps: 558    lr: 2e-07     reward: 13.59\n",
      "epis: 2563   score: 13.0   mem len: 884664   epsilon: 0.01    steps: 679    lr: 2e-07     reward: 13.61\n",
      "epis: 2564   score: 11.0   mem len: 885200   epsilon: 0.01    steps: 536    lr: 2e-07     reward: 13.59\n",
      "epis: 2565   score: 18.0   mem len: 885917   epsilon: 0.01    steps: 717    lr: 2e-07     reward: 13.65\n",
      "epis: 2566   score: 17.0   mem len: 886603   epsilon: 0.01    steps: 686    lr: 2e-07     reward: 13.68\n",
      "epis: 2567   score: 12.0   mem len: 887205   epsilon: 0.01    steps: 602    lr: 2e-07     reward: 13.69\n",
      "epis: 2568   score: 12.0   mem len: 887816   epsilon: 0.01    steps: 611    lr: 2e-07     reward: 13.68\n",
      "epis: 2569   score: 12.0   mem len: 888396   epsilon: 0.01    steps: 580    lr: 2e-07     reward: 13.63\n",
      "epis: 2570   score: 12.0   mem len: 889007   epsilon: 0.01    steps: 611    lr: 2e-07     reward: 13.65\n",
      "epis: 2571   score: 14.0   mem len: 889622   epsilon: 0.01    steps: 615    lr: 2e-07     reward: 13.69\n",
      "epis: 2572   score: 13.0   mem len: 890238   epsilon: 0.01    steps: 616    lr: 2e-07     reward: 13.71\n",
      "epis: 2573   score: 12.0   mem len: 890765   epsilon: 0.01    steps: 527    lr: 2e-07     reward: 13.65\n",
      "epis: 2574   score: 10.0   mem len: 891276   epsilon: 0.01    steps: 511    lr: 2e-07     reward: 13.62\n",
      "epis: 2575   score: 19.0   mem len: 892000   epsilon: 0.01    steps: 724    lr: 2e-07     reward: 13.7\n",
      "epis: 2576   score: 14.0   mem len: 892651   epsilon: 0.01    steps: 651    lr: 2e-07     reward: 13.62\n",
      "epis: 2577   score: 11.0   mem len: 893202   epsilon: 0.01    steps: 551    lr: 2e-07     reward: 13.59\n",
      "epis: 2578   score: 16.0   mem len: 893819   epsilon: 0.01    steps: 617    lr: 2e-07     reward: 13.66\n",
      "epis: 2579   score: 11.0   mem len: 894355   epsilon: 0.01    steps: 536    lr: 2e-07     reward: 13.68\n",
      "epis: 2580   score: 21.0   mem len: 895135   epsilon: 0.01    steps: 780    lr: 2e-07     reward: 13.79\n",
      "epis: 2581   score: 14.0   mem len: 895760   epsilon: 0.01    steps: 625    lr: 2e-07     reward: 13.83\n",
      "epis: 2582   score: 11.0   mem len: 896273   epsilon: 0.01    steps: 513    lr: 2e-07     reward: 13.75\n",
      "epis: 2583   score: 15.0   mem len: 896907   epsilon: 0.01    steps: 634    lr: 2e-07     reward: 13.75\n",
      "epis: 2584   score: 8.0   mem len: 897325   epsilon: 0.01    steps: 418    lr: 2e-07     reward: 13.71\n",
      "epis: 2585   score: 16.0   mem len: 897958   epsilon: 0.01    steps: 633    lr: 2e-07     reward: 13.75\n",
      "epis: 2586   score: 15.0   mem len: 898531   epsilon: 0.01    steps: 573    lr: 2e-07     reward: 13.85\n",
      "epis: 2587   score: 12.0   mem len: 899088   epsilon: 0.01    steps: 557    lr: 2e-07     reward: 13.77\n",
      "epis: 2588   score: 15.0   mem len: 899763   epsilon: 0.01    steps: 675    lr: 2e-07     reward: 13.77\n",
      "epis: 2589   score: 17.0   mem len: 900390   epsilon: 0.01    steps: 627    lr: 1e-07     reward: 13.84\n",
      "epis: 2590   score: 13.0   mem len: 900959   epsilon: 0.01    steps: 569    lr: 1e-07     reward: 13.83\n",
      "epis: 2591   score: 12.0   mem len: 901606   epsilon: 0.01    steps: 647    lr: 1e-07     reward: 13.84\n",
      "epis: 2592   score: 10.0   mem len: 902113   epsilon: 0.01    steps: 507    lr: 1e-07     reward: 13.83\n",
      "epis: 2593   score: 10.0   mem len: 902583   epsilon: 0.01    steps: 470    lr: 1e-07     reward: 13.74\n",
      "epis: 2594   score: 21.0   mem len: 903394   epsilon: 0.01    steps: 811    lr: 1e-07     reward: 13.79\n",
      "epis: 2595   score: 8.0   mem len: 903847   epsilon: 0.01    steps: 453    lr: 1e-07     reward: 13.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2596   score: 7.0   mem len: 904270   epsilon: 0.01    steps: 423    lr: 1e-07     reward: 13.55\n",
      "epis: 2597   score: 7.0   mem len: 904693   epsilon: 0.01    steps: 423    lr: 1e-07     reward: 13.5\n",
      "epis: 2598   score: 12.0   mem len: 905304   epsilon: 0.01    steps: 611    lr: 1e-07     reward: 13.49\n",
      "epis: 2599   score: 15.0   mem len: 905986   epsilon: 0.01    steps: 682    lr: 1e-07     reward: 13.55\n",
      "epis: 2600   score: 18.0   mem len: 906700   epsilon: 0.01    steps: 714    lr: 1e-07     reward: 13.58\n",
      "epis: 2601   score: 8.0   mem len: 907151   epsilon: 0.01    steps: 451    lr: 1e-07     reward: 13.47\n",
      "epis: 2602   score: 6.0   mem len: 907547   epsilon: 0.01    steps: 396    lr: 1e-07     reward: 13.37\n",
      "epis: 2603   score: 8.0   mem len: 908022   epsilon: 0.01    steps: 475    lr: 1e-07     reward: 13.27\n",
      "epis: 2604   score: 12.0   mem len: 908633   epsilon: 0.01    steps: 611    lr: 1e-07     reward: 13.28\n",
      "epis: 2605   score: 12.0   mem len: 909142   epsilon: 0.01    steps: 509    lr: 1e-07     reward: 13.29\n",
      "epis: 2606   score: 13.0   mem len: 909737   epsilon: 0.01    steps: 595    lr: 1e-07     reward: 13.29\n",
      "epis: 2607   score: 9.0   mem len: 910201   epsilon: 0.01    steps: 464    lr: 1e-07     reward: 13.27\n",
      "epis: 2608   score: 12.0   mem len: 910812   epsilon: 0.01    steps: 611    lr: 1e-07     reward: 13.22\n",
      "epis: 2609   score: 20.0   mem len: 911397   epsilon: 0.01    steps: 585    lr: 1e-07     reward: 13.34\n",
      "epis: 2610   score: 9.0   mem len: 911885   epsilon: 0.01    steps: 488    lr: 1e-07     reward: 13.29\n",
      "epis: 2611   score: 17.0   mem len: 912536   epsilon: 0.01    steps: 651    lr: 1e-07     reward: 13.34\n",
      "epis: 2612   score: 9.0   mem len: 913017   epsilon: 0.01    steps: 481    lr: 1e-07     reward: 13.14\n",
      "epis: 2613   score: 14.0   mem len: 913601   epsilon: 0.01    steps: 584    lr: 1e-07     reward: 13.13\n",
      "epis: 2614   score: 17.0   mem len: 914349   epsilon: 0.01    steps: 748    lr: 1e-07     reward: 13.17\n",
      "epis: 2615   score: 7.0   mem len: 914775   epsilon: 0.01    steps: 426    lr: 1e-07     reward: 13.12\n",
      "epis: 2616   score: 11.0   mem len: 915282   epsilon: 0.01    steps: 507    lr: 1e-07     reward: 13.08\n",
      "epis: 2617   score: 18.0   mem len: 915992   epsilon: 0.01    steps: 710    lr: 1e-07     reward: 13.13\n",
      "epis: 2618   score: 12.0   mem len: 916542   epsilon: 0.01    steps: 550    lr: 1e-07     reward: 13.06\n",
      "epis: 2619   score: 12.0   mem len: 917096   epsilon: 0.01    steps: 554    lr: 1e-07     reward: 13.01\n",
      "epis: 2620   score: 21.0   mem len: 917839   epsilon: 0.01    steps: 743    lr: 1e-07     reward: 13.11\n",
      "epis: 2621   score: 15.0   mem len: 918548   epsilon: 0.01    steps: 709    lr: 1e-07     reward: 13.13\n",
      "epis: 2622   score: 10.0   mem len: 919096   epsilon: 0.01    steps: 548    lr: 1e-07     reward: 13.13\n",
      "epis: 2623   score: 17.0   mem len: 919739   epsilon: 0.01    steps: 643    lr: 1e-07     reward: 13.19\n",
      "epis: 2624   score: 11.0   mem len: 920312   epsilon: 0.01    steps: 573    lr: 1e-07     reward: 13.2\n",
      "epis: 2625   score: 15.0   mem len: 920896   epsilon: 0.01    steps: 584    lr: 1e-07     reward: 13.24\n",
      "epis: 2626   score: 16.0   mem len: 921599   epsilon: 0.01    steps: 703    lr: 1e-07     reward: 13.28\n",
      "epis: 2627   score: 18.0   mem len: 922248   epsilon: 0.01    steps: 649    lr: 1e-07     reward: 13.35\n",
      "epis: 2628   score: 10.0   mem len: 922762   epsilon: 0.01    steps: 514    lr: 1e-07     reward: 13.32\n",
      "epis: 2629   score: 10.0   mem len: 923310   epsilon: 0.01    steps: 548    lr: 1e-07     reward: 13.27\n",
      "epis: 2630   score: 21.0   mem len: 923986   epsilon: 0.01    steps: 676    lr: 1e-07     reward: 13.35\n",
      "epis: 2631   score: 10.0   mem len: 924479   epsilon: 0.01    steps: 493    lr: 1e-07     reward: 13.35\n",
      "epis: 2632   score: 9.0   mem len: 924923   epsilon: 0.01    steps: 444    lr: 1e-07     reward: 13.32\n",
      "epis: 2633   score: 7.0   mem len: 925316   epsilon: 0.01    steps: 393    lr: 1e-07     reward: 13.17\n",
      "epis: 2634   score: 11.0   mem len: 925886   epsilon: 0.01    steps: 570    lr: 1e-07     reward: 13.16\n",
      "epis: 2635   score: 10.0   mem len: 926434   epsilon: 0.01    steps: 548    lr: 1e-07     reward: 13.17\n",
      "epis: 2636   score: 11.0   mem len: 926856   epsilon: 0.01    steps: 422    lr: 1e-07     reward: 13.07\n",
      "epis: 2637   score: 9.0   mem len: 927286   epsilon: 0.01    steps: 430    lr: 1e-07     reward: 12.97\n",
      "epis: 2638   score: 8.0   mem len: 927738   epsilon: 0.01    steps: 452    lr: 1e-07     reward: 12.89\n",
      "epis: 2639   score: 7.0   mem len: 928125   epsilon: 0.01    steps: 387    lr: 1e-07     reward: 12.82\n",
      "epis: 2640   score: 11.0   mem len: 928692   epsilon: 0.01    steps: 567    lr: 1e-07     reward: 12.88\n",
      "epis: 2641   score: 10.0   mem len: 929240   epsilon: 0.01    steps: 548    lr: 1e-07     reward: 12.8\n",
      "epis: 2642   score: 13.0   mem len: 929856   epsilon: 0.01    steps: 616    lr: 1e-07     reward: 12.83\n",
      "epis: 2643   score: 7.0   mem len: 930258   epsilon: 0.01    steps: 402    lr: 1e-07     reward: 12.74\n",
      "epis: 2644   score: 10.0   mem len: 930715   epsilon: 0.01    steps: 457    lr: 1e-07     reward: 12.76\n",
      "epis: 2645   score: 11.0   mem len: 931283   epsilon: 0.01    steps: 568    lr: 1e-07     reward: 12.77\n",
      "epis: 2646   score: 11.0   mem len: 931850   epsilon: 0.01    steps: 567    lr: 1e-07     reward: 12.79\n",
      "epis: 2647   score: 13.0   mem len: 932466   epsilon: 0.01    steps: 616    lr: 1e-07     reward: 12.76\n",
      "epis: 2648   score: 13.0   mem len: 933065   epsilon: 0.01    steps: 599    lr: 1e-07     reward: 12.75\n",
      "epis: 2649   score: 13.0   mem len: 933594   epsilon: 0.01    steps: 529    lr: 1e-07     reward: 12.71\n",
      "epis: 2650   score: 18.0   mem len: 934263   epsilon: 0.01    steps: 669    lr: 1e-07     reward: 12.77\n",
      "epis: 2651   score: 10.0   mem len: 934756   epsilon: 0.01    steps: 493    lr: 1e-07     reward: 12.74\n",
      "epis: 2652   score: 12.0   mem len: 935336   epsilon: 0.01    steps: 580    lr: 1e-07     reward: 12.77\n",
      "epis: 2653   score: 21.0   mem len: 936041   epsilon: 0.01    steps: 705    lr: 1e-07     reward: 12.9\n",
      "epis: 2654   score: 9.0   mem len: 936494   epsilon: 0.01    steps: 453    lr: 1e-07     reward: 12.84\n",
      "epis: 2655   score: 11.0   mem len: 936896   epsilon: 0.01    steps: 402    lr: 1e-07     reward: 12.76\n",
      "epis: 2656   score: 9.0   mem len: 937394   epsilon: 0.01    steps: 498    lr: 1e-07     reward: 12.69\n",
      "epis: 2657   score: 13.0   mem len: 938010   epsilon: 0.01    steps: 616    lr: 1e-07     reward: 12.57\n",
      "epis: 2658   score: 15.0   mem len: 938566   epsilon: 0.01    steps: 556    lr: 1e-07     reward: 12.56\n",
      "epis: 2659   score: 25.0   mem len: 939286   epsilon: 0.01    steps: 720    lr: 1e-07     reward: 12.69\n",
      "epis: 2660   score: 13.0   mem len: 939897   epsilon: 0.01    steps: 611    lr: 1e-07     reward: 12.71\n",
      "epis: 2661   score: 9.0   mem len: 940393   epsilon: 0.01    steps: 496    lr: 1e-07     reward: 12.65\n",
      "epis: 2662   score: 12.0   mem len: 940950   epsilon: 0.01    steps: 557    lr: 1e-07     reward: 12.65\n",
      "epis: 2663   score: 11.0   mem len: 941496   epsilon: 0.01    steps: 546    lr: 1e-07     reward: 12.63\n",
      "epis: 2664   score: 10.0   mem len: 942005   epsilon: 0.01    steps: 509    lr: 1e-07     reward: 12.62\n",
      "epis: 2665   score: 15.0   mem len: 942675   epsilon: 0.01    steps: 670    lr: 1e-07     reward: 12.59\n",
      "epis: 2666   score: 19.0   mem len: 943304   epsilon: 0.01    steps: 629    lr: 1e-07     reward: 12.61\n",
      "epis: 2667   score: 16.0   mem len: 943908   epsilon: 0.01    steps: 604    lr: 1e-07     reward: 12.65\n",
      "epis: 2668   score: 11.0   mem len: 944429   epsilon: 0.01    steps: 521    lr: 1e-07     reward: 12.64\n",
      "epis: 2669   score: 17.0   mem len: 945094   epsilon: 0.01    steps: 665    lr: 1e-07     reward: 12.69\n",
      "epis: 2670   score: 9.0   mem len: 945598   epsilon: 0.01    steps: 504    lr: 1e-07     reward: 12.66\n",
      "epis: 2671   score: 13.0   mem len: 946213   epsilon: 0.01    steps: 615    lr: 1e-07     reward: 12.65\n",
      "epis: 2672   score: 22.0   mem len: 946963   epsilon: 0.01    steps: 750    lr: 1e-07     reward: 12.74\n",
      "epis: 2673   score: 11.0   mem len: 947538   epsilon: 0.01    steps: 575    lr: 1e-07     reward: 12.73\n",
      "epis: 2674   score: 12.0   mem len: 948120   epsilon: 0.01    steps: 582    lr: 1e-07     reward: 12.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2675   score: 17.0   mem len: 948706   epsilon: 0.01    steps: 586    lr: 1e-07     reward: 12.73\n",
      "epis: 2676   score: 8.0   mem len: 949157   epsilon: 0.01    steps: 451    lr: 1e-07     reward: 12.67\n",
      "epis: 2677   score: 13.0   mem len: 949693   epsilon: 0.01    steps: 536    lr: 1e-07     reward: 12.69\n",
      "epis: 2678   score: 10.0   mem len: 950237   epsilon: 0.01    steps: 544    lr: 1e-07     reward: 12.63\n",
      "epis: 2679   score: 9.0   mem len: 950693   epsilon: 0.01    steps: 456    lr: 1e-07     reward: 12.61\n",
      "epis: 2680   score: 15.0   mem len: 951301   epsilon: 0.01    steps: 608    lr: 1e-07     reward: 12.55\n",
      "epis: 2681   score: 13.0   mem len: 951917   epsilon: 0.01    steps: 616    lr: 1e-07     reward: 12.54\n",
      "epis: 2682   score: 13.0   mem len: 952502   epsilon: 0.01    steps: 585    lr: 1e-07     reward: 12.56\n",
      "epis: 2683   score: 9.0   mem len: 952989   epsilon: 0.01    steps: 487    lr: 1e-07     reward: 12.5\n",
      "epis: 2684   score: 17.0   mem len: 953668   epsilon: 0.01    steps: 679    lr: 1e-07     reward: 12.59\n",
      "epis: 2685   score: 11.0   mem len: 954217   epsilon: 0.01    steps: 549    lr: 1e-07     reward: 12.54\n",
      "epis: 2686   score: 10.0   mem len: 954706   epsilon: 0.01    steps: 489    lr: 1e-07     reward: 12.49\n",
      "epis: 2687   score: 16.0   mem len: 955324   epsilon: 0.01    steps: 618    lr: 1e-07     reward: 12.53\n",
      "epis: 2688   score: 12.0   mem len: 955912   epsilon: 0.01    steps: 588    lr: 1e-07     reward: 12.5\n",
      "epis: 2689   score: 29.0   mem len: 956766   epsilon: 0.01    steps: 854    lr: 1e-07     reward: 12.62\n",
      "epis: 2690   score: 12.0   mem len: 957310   epsilon: 0.01    steps: 544    lr: 1e-07     reward: 12.61\n",
      "epis: 2691   score: 8.0   mem len: 957726   epsilon: 0.01    steps: 416    lr: 1e-07     reward: 12.57\n",
      "epis: 2692   score: 9.0   mem len: 958233   epsilon: 0.01    steps: 507    lr: 1e-07     reward: 12.56\n",
      "epis: 2693   score: 11.0   mem len: 958755   epsilon: 0.01    steps: 522    lr: 1e-07     reward: 12.57\n",
      "epis: 2694   score: 15.0   mem len: 959397   epsilon: 0.01    steps: 642    lr: 1e-07     reward: 12.51\n",
      "epis: 2695   score: 10.0   mem len: 959936   epsilon: 0.01    steps: 539    lr: 1e-07     reward: 12.53\n",
      "epis: 2696   score: 14.0   mem len: 960637   epsilon: 0.01    steps: 701    lr: 1e-07     reward: 12.6\n",
      "epis: 2697   score: 7.0   mem len: 961059   epsilon: 0.01    steps: 422    lr: 1e-07     reward: 12.6\n",
      "epis: 2698   score: 13.0   mem len: 961665   epsilon: 0.01    steps: 606    lr: 1e-07     reward: 12.61\n",
      "epis: 2699   score: 11.0   mem len: 962188   epsilon: 0.01    steps: 523    lr: 1e-07     reward: 12.57\n",
      "epis: 2700   score: 11.0   mem len: 962756   epsilon: 0.01    steps: 568    lr: 1e-07     reward: 12.5\n",
      "epis: 2701   score: 21.0   mem len: 963396   epsilon: 0.01    steps: 640    lr: 1e-07     reward: 12.63\n",
      "epis: 2702   score: 15.0   mem len: 963982   epsilon: 0.01    steps: 586    lr: 1e-07     reward: 12.72\n",
      "epis: 2703   score: 11.0   mem len: 964504   epsilon: 0.01    steps: 522    lr: 1e-07     reward: 12.75\n",
      "epis: 2704   score: 19.0   mem len: 965213   epsilon: 0.01    steps: 709    lr: 1e-07     reward: 12.82\n",
      "epis: 2705   score: 15.0   mem len: 965836   epsilon: 0.01    steps: 623    lr: 1e-07     reward: 12.85\n",
      "epis: 2706   score: 14.0   mem len: 966491   epsilon: 0.01    steps: 655    lr: 1e-07     reward: 12.86\n",
      "epis: 2707   score: 10.0   mem len: 967021   epsilon: 0.01    steps: 530    lr: 1e-07     reward: 12.87\n",
      "epis: 2708   score: 10.0   mem len: 967511   epsilon: 0.01    steps: 490    lr: 1e-07     reward: 12.85\n",
      "epis: 2709   score: 14.0   mem len: 968045   epsilon: 0.01    steps: 534    lr: 1e-07     reward: 12.79\n",
      "epis: 2710   score: 17.0   mem len: 968750   epsilon: 0.01    steps: 705    lr: 1e-07     reward: 12.87\n",
      "epis: 2711   score: 14.0   mem len: 969366   epsilon: 0.01    steps: 616    lr: 1e-07     reward: 12.84\n",
      "epis: 2712   score: 8.0   mem len: 969801   epsilon: 0.01    steps: 435    lr: 1e-07     reward: 12.83\n",
      "epis: 2713   score: 8.0   mem len: 970293   epsilon: 0.01    steps: 492    lr: 1e-07     reward: 12.77\n",
      "epis: 2714   score: 9.0   mem len: 970815   epsilon: 0.01    steps: 522    lr: 1e-07     reward: 12.69\n",
      "epis: 2715   score: 10.0   mem len: 971362   epsilon: 0.01    steps: 547    lr: 1e-07     reward: 12.72\n",
      "epis: 2716   score: 11.0   mem len: 971885   epsilon: 0.01    steps: 523    lr: 1e-07     reward: 12.72\n",
      "epis: 2717   score: 10.0   mem len: 972400   epsilon: 0.01    steps: 515    lr: 1e-07     reward: 12.64\n",
      "epis: 2718   score: 12.0   mem len: 972988   epsilon: 0.01    steps: 588    lr: 1e-07     reward: 12.64\n",
      "epis: 2719   score: 10.0   mem len: 973506   epsilon: 0.01    steps: 518    lr: 1e-07     reward: 12.62\n",
      "epis: 2720   score: 12.0   mem len: 974064   epsilon: 0.01    steps: 558    lr: 1e-07     reward: 12.53\n",
      "epis: 2721   score: 12.0   mem len: 974621   epsilon: 0.01    steps: 557    lr: 1e-07     reward: 12.5\n",
      "epis: 2722   score: 10.0   mem len: 975138   epsilon: 0.01    steps: 517    lr: 1e-07     reward: 12.5\n",
      "epis: 2723   score: 30.0   mem len: 975856   epsilon: 0.01    steps: 718    lr: 1e-07     reward: 12.63\n",
      "epis: 2724   score: 15.0   mem len: 976442   epsilon: 0.01    steps: 586    lr: 1e-07     reward: 12.67\n",
      "epis: 2725   score: 9.0   mem len: 976910   epsilon: 0.01    steps: 468    lr: 1e-07     reward: 12.61\n",
      "epis: 2726   score: 10.0   mem len: 977449   epsilon: 0.01    steps: 539    lr: 1e-07     reward: 12.55\n",
      "epis: 2727   score: 18.0   mem len: 978110   epsilon: 0.01    steps: 661    lr: 1e-07     reward: 12.55\n",
      "epis: 2728   score: 11.0   mem len: 978634   epsilon: 0.01    steps: 524    lr: 1e-07     reward: 12.56\n",
      "epis: 2729   score: 8.0   mem len: 979111   epsilon: 0.01    steps: 477    lr: 1e-07     reward: 12.54\n",
      "epis: 2730   score: 9.0   mem len: 979586   epsilon: 0.01    steps: 475    lr: 1e-07     reward: 12.42\n",
      "epis: 2731   score: 12.0   mem len: 980181   epsilon: 0.01    steps: 595    lr: 1e-07     reward: 12.44\n",
      "epis: 2732   score: 7.0   mem len: 980569   epsilon: 0.01    steps: 388    lr: 1e-07     reward: 12.42\n",
      "epis: 2733   score: 8.0   mem len: 981001   epsilon: 0.01    steps: 432    lr: 1e-07     reward: 12.43\n",
      "epis: 2734   score: 12.0   mem len: 981546   epsilon: 0.01    steps: 545    lr: 1e-07     reward: 12.44\n",
      "epis: 2735   score: 12.0   mem len: 982138   epsilon: 0.01    steps: 592    lr: 1e-07     reward: 12.46\n",
      "epis: 2736   score: 13.0   mem len: 982666   epsilon: 0.01    steps: 528    lr: 1e-07     reward: 12.48\n",
      "epis: 2737   score: 14.0   mem len: 983279   epsilon: 0.01    steps: 613    lr: 1e-07     reward: 12.53\n",
      "epis: 2738   score: 13.0   mem len: 983889   epsilon: 0.01    steps: 610    lr: 1e-07     reward: 12.58\n",
      "epis: 2739   score: 13.0   mem len: 984451   epsilon: 0.01    steps: 562    lr: 1e-07     reward: 12.64\n",
      "epis: 2740   score: 14.0   mem len: 985122   epsilon: 0.01    steps: 671    lr: 1e-07     reward: 12.67\n",
      "epis: 2741   score: 15.0   mem len: 985671   epsilon: 0.01    steps: 549    lr: 1e-07     reward: 12.72\n",
      "epis: 2742   score: 9.0   mem len: 986146   epsilon: 0.01    steps: 475    lr: 1e-07     reward: 12.68\n",
      "epis: 2743   score: 15.0   mem len: 986727   epsilon: 0.01    steps: 581    lr: 1e-07     reward: 12.76\n",
      "epis: 2744   score: 9.0   mem len: 987201   epsilon: 0.01    steps: 474    lr: 1e-07     reward: 12.75\n",
      "epis: 2745   score: 12.0   mem len: 987745   epsilon: 0.01    steps: 544    lr: 1e-07     reward: 12.76\n",
      "epis: 2746   score: 15.0   mem len: 988385   epsilon: 0.01    steps: 640    lr: 1e-07     reward: 12.8\n",
      "epis: 2747   score: 10.0   mem len: 988902   epsilon: 0.01    steps: 517    lr: 1e-07     reward: 12.77\n",
      "epis: 2748   score: 9.0   mem len: 989359   epsilon: 0.01    steps: 457    lr: 1e-07     reward: 12.73\n",
      "epis: 2749   score: 15.0   mem len: 990029   epsilon: 0.01    steps: 670    lr: 1e-07     reward: 12.75\n",
      "epis: 2750   score: 13.0   mem len: 990568   epsilon: 0.01    steps: 539    lr: 1e-07     reward: 12.7\n",
      "epis: 2751   score: 15.0   mem len: 991210   epsilon: 0.01    steps: 642    lr: 1e-07     reward: 12.75\n",
      "epis: 2752   score: 11.0   mem len: 991730   epsilon: 0.01    steps: 520    lr: 1e-07     reward: 12.74\n",
      "epis: 2753   score: 15.0   mem len: 992286   epsilon: 0.01    steps: 556    lr: 1e-07     reward: 12.68\n",
      "epis: 2754   score: 7.0   mem len: 992674   epsilon: 0.01    steps: 388    lr: 1e-07     reward: 12.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2755   score: 12.0   mem len: 993220   epsilon: 0.01    steps: 546    lr: 1e-07     reward: 12.67\n",
      "epis: 2756   score: 12.0   mem len: 993766   epsilon: 0.01    steps: 546    lr: 1e-07     reward: 12.7\n",
      "epis: 2757   score: 9.0   mem len: 994306   epsilon: 0.01    steps: 540    lr: 1e-07     reward: 12.66\n",
      "epis: 2758   score: 18.0   mem len: 995086   epsilon: 0.01    steps: 780    lr: 1e-07     reward: 12.69\n",
      "epis: 2759   score: 9.0   mem len: 995544   epsilon: 0.01    steps: 458    lr: 1e-07     reward: 12.53\n",
      "epis: 2760   score: 12.0   mem len: 996101   epsilon: 0.01    steps: 557    lr: 1e-07     reward: 12.52\n",
      "epis: 2761   score: 7.0   mem len: 996491   epsilon: 0.01    steps: 390    lr: 1e-07     reward: 12.5\n",
      "epis: 2762   score: 15.0   mem len: 997060   epsilon: 0.01    steps: 569    lr: 1e-07     reward: 12.53\n",
      "epis: 2763   score: 15.0   mem len: 997609   epsilon: 0.01    steps: 549    lr: 1e-07     reward: 12.57\n",
      "epis: 2764   score: 8.0   mem len: 998061   epsilon: 0.01    steps: 452    lr: 1e-07     reward: 12.55\n",
      "epis: 2765   score: 13.0   mem len: 998663   epsilon: 0.01    steps: 602    lr: 1e-07     reward: 12.53\n",
      "epis: 2766   score: 11.0   mem len: 999212   epsilon: 0.01    steps: 549    lr: 1e-07     reward: 12.45\n",
      "epis: 2767   score: 13.0   mem len: 999865   epsilon: 0.01    steps: 653    lr: 1e-07     reward: 12.42\n",
      "epis: 2768   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 664    lr: 0.0     reward: 12.45\n",
      "epis: 2769   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 12.36\n",
      "epis: 2770   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 651    lr: 0.0     reward: 12.4\n",
      "epis: 2771   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 415    lr: 0.0     reward: 12.35\n",
      "epis: 2772   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 473    lr: 0.0     reward: 12.22\n",
      "epis: 2773   score: 22.0   mem len: 1000000   epsilon: 0.01    steps: 612    lr: 0.0     reward: 12.33\n",
      "epis: 2774   score: 21.0   mem len: 1000000   epsilon: 0.01    steps: 717    lr: 0.0     reward: 12.42\n",
      "epis: 2775   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 490    lr: 0.0     reward: 12.37\n",
      "epis: 2776   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 553    lr: 0.0     reward: 12.41\n",
      "epis: 2777   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 415    lr: 0.0     reward: 12.36\n",
      "epis: 2778   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 502    lr: 0.0     reward: 12.36\n",
      "epis: 2779   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 415    lr: 0.0     reward: 12.35\n",
      "epis: 2780   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 438    lr: 0.0     reward: 12.28\n",
      "epis: 2781   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 569    lr: 0.0     reward: 12.3\n",
      "epis: 2782   score: 21.0   mem len: 1000000   epsilon: 0.01    steps: 798    lr: 0.0     reward: 12.38\n",
      "epis: 2783   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 611    lr: 0.0     reward: 12.42\n",
      "epis: 2784   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 599    lr: 0.0     reward: 12.4\n",
      "epis: 2785   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 571    lr: 0.0     reward: 12.4\n",
      "epis: 2786   score: 24.0   mem len: 1000000   epsilon: 0.01    steps: 722    lr: 0.0     reward: 12.54\n",
      "epis: 2787   score: 17.0   mem len: 1000000   epsilon: 0.01    steps: 679    lr: 0.0     reward: 12.55\n",
      "epis: 2788   score: 21.0   mem len: 1000000   epsilon: 0.01    steps: 604    lr: 0.0     reward: 12.64\n",
      "epis: 2789   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 582    lr: 0.0     reward: 12.5\n",
      "epis: 2790   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 444    lr: 0.0     reward: 12.47\n",
      "epis: 2791   score: 23.0   mem len: 1000000   epsilon: 0.01    steps: 868    lr: 0.0     reward: 12.62\n",
      "epis: 2792   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 569    lr: 0.0     reward: 12.68\n",
      "epis: 2793   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 388    lr: 0.0     reward: 12.64\n",
      "epis: 2794   score: 19.0   mem len: 1000000   epsilon: 0.01    steps: 629    lr: 0.0     reward: 12.68\n",
      "epis: 2795   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 636    lr: 0.0     reward: 12.72\n",
      "epis: 2796   score: 17.0   mem len: 1000000   epsilon: 0.01    steps: 746    lr: 0.0     reward: 12.75\n",
      "epis: 2797   score: 19.0   mem len: 1000000   epsilon: 0.01    steps: 607    lr: 0.0     reward: 12.87\n",
      "epis: 2798   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 609    lr: 0.0     reward: 12.87\n",
      "epis: 2799   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 571    lr: 0.0     reward: 12.88\n",
      "epis: 2800   score: 17.0   mem len: 1000000   epsilon: 0.01    steps: 746    lr: 0.0     reward: 12.94\n",
      "epis: 2801   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 604    lr: 0.0     reward: 12.85\n",
      "epis: 2802   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 457    lr: 0.0     reward: 12.79\n",
      "epis: 2803   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 654    lr: 0.0     reward: 12.81\n",
      "epis: 2804   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 619    lr: 0.0     reward: 12.75\n",
      "epis: 2805   score: 19.0   mem len: 1000000   epsilon: 0.01    steps: 634    lr: 0.0     reward: 12.79\n",
      "epis: 2806   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 654    lr: 0.0     reward: 12.79\n",
      "epis: 2807   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 714    lr: 0.0     reward: 12.84\n",
      "epis: 2808   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 588    lr: 0.0     reward: 12.86\n",
      "epis: 2809   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 637    lr: 0.0     reward: 12.85\n",
      "epis: 2810   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 637    lr: 0.0     reward: 12.81\n",
      "epis: 2811   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 532    lr: 0.0     reward: 12.78\n",
      "epis: 2812   score: 22.0   mem len: 1000000   epsilon: 0.01    steps: 637    lr: 0.0     reward: 12.92\n",
      "epis: 2813   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 637    lr: 0.0     reward: 12.97\n",
      "epis: 2814   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 457    lr: 0.0     reward: 12.97\n",
      "epis: 2815   score: 21.0   mem len: 1000000   epsilon: 0.01    steps: 604    lr: 0.0     reward: 13.08\n",
      "epis: 2816   score: 17.0   mem len: 1000000   epsilon: 0.01    steps: 534    lr: 0.0     reward: 13.14\n",
      "epis: 2817   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 571    lr: 0.0     reward: 13.15\n",
      "epis: 2818   score: 21.0   mem len: 1000000   epsilon: 0.01    steps: 604    lr: 0.0     reward: 13.24\n",
      "epis: 2819   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 451    lr: 0.0     reward: 13.23\n",
      "epis: 2820   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 517    lr: 0.0     reward: 13.21\n",
      "epis: 2821   score: 21.0   mem len: 1000000   epsilon: 0.01    steps: 604    lr: 0.0     reward: 13.3\n",
      "epis: 2822   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 557    lr: 0.0     reward: 13.31\n",
      "epis: 2823   score: 17.0   mem len: 1000000   epsilon: 0.01    steps: 651    lr: 0.0     reward: 13.18\n",
      "epis: 2824   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 571    lr: 0.0     reward: 13.14\n",
      "epis: 2825   score: 23.0   mem len: 1000000   epsilon: 0.01    steps: 797    lr: 0.0     reward: 13.28\n",
      "epis: 2826   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 621    lr: 0.0     reward: 13.31\n",
      "epis: 2827   score: 22.0   mem len: 1000000   epsilon: 0.01    steps: 570    lr: 0.0     reward: 13.35\n",
      "epis: 2828   score: 21.0   mem len: 1000000   epsilon: 0.01    steps: 666    lr: 0.0     reward: 13.45\n",
      "epis: 2829   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 457    lr: 0.0     reward: 13.46\n",
      "epis: 2830   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 457    lr: 0.0     reward: 13.46\n",
      "epis: 2831   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 607    lr: 0.0     reward: 13.47\n",
      "epis: 2832   score: 6.0   mem len: 1000000   epsilon: 0.01    steps: 336    lr: 0.0     reward: 13.46\n",
      "epis: 2833   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 721    lr: 0.0     reward: 13.52\n",
      "epis: 2834   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 617    lr: 0.0     reward: 13.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2835   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 477    lr: 0.0     reward: 13.55\n",
      "epis: 2836   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 464    lr: 0.0     reward: 13.51\n",
      "epis: 2837   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 13.45\n",
      "epis: 2838   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 569    lr: 0.0     reward: 13.47\n",
      "epis: 2839   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 589    lr: 0.0     reward: 13.45\n",
      "epis: 2840   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 637    lr: 0.0     reward: 13.44\n",
      "epis: 2841   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 637    lr: 0.0     reward: 13.42\n",
      "epis: 2842   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 489    lr: 0.0     reward: 13.43\n",
      "epis: 2843   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 713    lr: 0.0     reward: 13.43\n",
      "epis: 2844   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 457    lr: 0.0     reward: 13.43\n",
      "epis: 2845   score: 17.0   mem len: 1000000   epsilon: 0.01    steps: 657    lr: 0.0     reward: 13.48\n",
      "epis: 2846   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 528    lr: 0.0     reward: 13.45\n",
      "epis: 2847   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 637    lr: 0.0     reward: 13.48\n",
      "epis: 2848   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 464    lr: 0.0     reward: 13.48\n",
      "epis: 2849   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 555    lr: 0.0     reward: 13.44\n",
      "epis: 2850   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 475    lr: 0.0     reward: 13.4\n",
      "epis: 2851   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 415    lr: 0.0     reward: 13.33\n",
      "epis: 2852   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 415    lr: 0.0     reward: 13.3\n",
      "epis: 2853   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 415    lr: 0.0     reward: 13.23\n",
      "epis: 2854   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 511    lr: 0.0     reward: 13.26\n",
      "epis: 2855   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 490    lr: 0.0     reward: 13.26\n",
      "epis: 2856   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 620    lr: 0.0     reward: 13.26\n",
      "epis: 2857   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 421    lr: 0.0     reward: 13.25\n",
      "epis: 2858   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 557    lr: 0.0     reward: 13.18\n",
      "epis: 2859   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 693    lr: 0.0     reward: 13.24\n",
      "epis: 2860   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 372    lr: 0.0     reward: 13.19\n",
      "epis: 2861   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 490    lr: 0.0     reward: 13.24\n",
      "epis: 2862   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 557    lr: 0.0     reward: 13.2\n",
      "epis: 2863   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 557    lr: 0.0     reward: 13.16\n",
      "epis: 2864   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 579    lr: 0.0     reward: 13.2\n",
      "epis: 2865   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 538    lr: 0.0     reward: 13.18\n",
      "epis: 2866   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 557    lr: 0.0     reward: 13.18\n",
      "epis: 2867   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 589    lr: 0.0     reward: 13.17\n",
      "epis: 2868   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 557    lr: 0.0     reward: 13.14\n",
      "epis: 2869   score: 17.0   mem len: 1000000   epsilon: 0.01    steps: 651    lr: 0.0     reward: 13.23\n",
      "epis: 2870   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 623    lr: 0.0     reward: 13.25\n",
      "epis: 2871   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 515    lr: 0.0     reward: 13.27\n",
      "epis: 2872   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 609    lr: 0.0     reward: 13.3\n",
      "epis: 2873   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 653    lr: 0.0     reward: 13.21\n",
      "epis: 2874   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 569    lr: 0.0     reward: 13.13\n",
      "epis: 2875   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 557    lr: 0.0     reward: 13.12\n",
      "epis: 2876   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 659    lr: 0.0     reward: 13.14\n",
      "epis: 2877   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 637    lr: 0.0     reward: 13.19\n",
      "epis: 2878   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 563    lr: 0.0     reward: 13.21\n",
      "epis: 2879   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 416    lr: 0.0     reward: 13.21\n",
      "epis: 2880   score: 20.0   mem len: 1000000   epsilon: 0.01    steps: 675    lr: 0.0     reward: 13.33\n",
      "epis: 2881   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 554    lr: 0.0     reward: 13.28\n",
      "epis: 2882   score: 22.0   mem len: 1000000   epsilon: 0.01    steps: 705    lr: 0.0     reward: 13.29\n",
      "epis: 2883   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 650    lr: 0.0     reward: 13.29\n",
      "epis: 2884   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 457    lr: 0.0     reward: 13.23\n",
      "epis: 2885   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 617    lr: 0.0     reward: 13.24\n",
      "epis: 2886   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 605    lr: 0.0     reward: 13.12\n",
      "epis: 2887   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 490    lr: 0.0     reward: 13.07\n",
      "epis: 2888   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 415    lr: 0.0     reward: 12.94\n",
      "epis: 2889   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 415    lr: 0.0     reward: 12.87\n",
      "epis: 2890   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 433    lr: 0.0     reward: 12.86\n",
      "epis: 2891   score: 7.0   mem len: 1000000   epsilon: 0.01    steps: 372    lr: 0.0     reward: 12.7\n",
      "epis: 2892   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 490    lr: 0.0     reward: 12.64\n",
      "epis: 2893   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 664    lr: 0.0     reward: 12.71\n",
      "epis: 2894   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 678    lr: 0.0     reward: 12.66\n",
      "epis: 2895   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 549    lr: 0.0     reward: 12.64\n",
      "epis: 2896   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 416    lr: 0.0     reward: 12.55\n",
      "epis: 2897   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 571    lr: 0.0     reward: 12.48\n",
      "epis: 2898   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 505    lr: 0.0     reward: 12.45\n",
      "epis: 2899   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 457    lr: 0.0     reward: 12.42\n",
      "epis: 2900   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 538    lr: 0.0     reward: 12.36\n",
      "epis: 2901   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 637    lr: 0.0     reward: 12.37\n",
      "epis: 2902   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 538    lr: 0.0     reward: 12.39\n",
      "epis: 2903   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 416    lr: 0.0     reward: 12.34\n",
      "epis: 2904   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 697    lr: 0.0     reward: 12.36\n",
      "epis: 2905   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 560    lr: 0.0     reward: 12.29\n",
      "epis: 2906   score: 22.0   mem len: 1000000   epsilon: 0.01    steps: 664    lr: 0.0     reward: 12.37\n",
      "epis: 2907   score: 17.0   mem len: 1000000   epsilon: 0.01    steps: 746    lr: 0.0     reward: 12.39\n",
      "epis: 2908   score: 16.0   mem len: 1000000   epsilon: 0.01    steps: 667    lr: 0.0     reward: 12.43\n",
      "epis: 2909   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 557    lr: 0.0     reward: 12.42\n",
      "epis: 2910   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 486    lr: 0.0     reward: 12.38\n",
      "epis: 2911   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 477    lr: 0.0     reward: 12.35\n",
      "epis: 2912   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 578    lr: 0.0     reward: 12.26\n",
      "epis: 2913   score: 18.0   mem len: 1000000   epsilon: 0.01    steps: 656    lr: 0.0     reward: 12.31\n",
      "epis: 2914   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 557    lr: 0.0     reward: 12.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2915   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 457    lr: 0.0     reward: 12.21\n",
      "epis: 2916   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 538    lr: 0.0     reward: 12.15\n",
      "epis: 2917   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 538    lr: 0.0     reward: 12.15\n",
      "epis: 2918   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 507    lr: 0.0     reward: 12.06\n",
      "epis: 2919   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 538    lr: 0.0     reward: 12.08\n",
      "epis: 2920   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 416    lr: 0.0     reward: 12.06\n",
      "epis: 2921   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 557    lr: 0.0     reward: 11.96\n",
      "epis: 2922   score: 21.0   mem len: 1000000   epsilon: 0.01    steps: 725    lr: 0.0     reward: 12.06\n",
      "epis: 2923   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 455    lr: 0.0     reward: 11.98\n",
      "epis: 2924   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 449    lr: 0.0     reward: 11.97\n",
      "epis: 2925   score: 6.0   mem len: 1000000   epsilon: 0.01    steps: 361    lr: 0.0     reward: 11.8\n",
      "epis: 2926   score: 20.0   mem len: 1000000   epsilon: 0.01    steps: 655    lr: 0.0     reward: 11.87\n",
      "epis: 2927   score: 16.0   mem len: 1000000   epsilon: 0.01    steps: 644    lr: 0.0     reward: 11.81\n",
      "epis: 2928   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 459    lr: 0.0     reward: 11.69\n",
      "epis: 2929   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 615    lr: 0.0     reward: 11.74\n",
      "epis: 2930   score: 6.0   mem len: 1000000   epsilon: 0.01    steps: 357    lr: 0.0     reward: 11.71\n",
      "epis: 2931   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 511    lr: 0.0     reward: 11.68\n",
      "epis: 2932   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 513    lr: 0.0     reward: 11.73\n",
      "epis: 2933   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 510    lr: 0.0     reward: 11.69\n",
      "epis: 2934   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 529    lr: 0.0     reward: 11.64\n",
      "epis: 2935   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 11.6\n",
      "epis: 2936   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 444    lr: 0.0     reward: 11.59\n",
      "epis: 2937   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 438    lr: 0.0     reward: 11.59\n",
      "epis: 2938   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 438    lr: 0.0     reward: 11.52\n",
      "epis: 2939   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 551    lr: 0.0     reward: 11.51\n",
      "epis: 2940   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 609    lr: 0.0     reward: 11.51\n",
      "epis: 2941   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 460    lr: 0.0     reward: 11.46\n",
      "epis: 2942   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 498    lr: 0.0     reward: 11.45\n",
      "epis: 2943   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 11.38\n",
      "epis: 2944   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 383    lr: 0.0     reward: 11.37\n",
      "epis: 2945   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 438    lr: 0.0     reward: 11.28\n",
      "epis: 2946   score: 18.0   mem len: 1000000   epsilon: 0.01    steps: 499    lr: 0.0     reward: 11.34\n",
      "epis: 2947   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 415    lr: 0.0     reward: 11.29\n",
      "epis: 2948   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 555    lr: 0.0     reward: 11.31\n",
      "epis: 2949   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 454    lr: 0.0     reward: 11.28\n",
      "epis: 2950   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 502    lr: 0.0     reward: 11.29\n",
      "epis: 2951   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 415    lr: 0.0     reward: 11.29\n",
      "epis: 2952   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 490    lr: 0.0     reward: 11.33\n",
      "epis: 2953   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 438    lr: 0.0     reward: 11.33\n",
      "epis: 2954   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 679    lr: 0.0     reward: 11.37\n",
      "epis: 2955   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 485    lr: 0.0     reward: 11.34\n",
      "epis: 2956   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 589    lr: 0.0     reward: 11.35\n",
      "epis: 2957   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 611    lr: 0.0     reward: 11.41\n",
      "epis: 2958   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 433    lr: 0.0     reward: 11.38\n",
      "epis: 2959   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 578    lr: 0.0     reward: 11.34\n",
      "epis: 2960   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 619    lr: 0.0     reward: 11.4\n",
      "epis: 2961   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 538    lr: 0.0     reward: 11.39\n",
      "epis: 2962   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 657    lr: 0.0     reward: 11.42\n",
      "epis: 2963   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 459    lr: 0.0     reward: 11.4\n",
      "epis: 2964   score: 27.0   mem len: 1000000   epsilon: 0.01    steps: 596    lr: 0.0     reward: 11.55\n",
      "epis: 2965   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 589    lr: 0.0     reward: 11.57\n",
      "epis: 2966   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 416    lr: 0.0     reward: 11.54\n",
      "epis: 2967   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 464    lr: 0.0     reward: 11.51\n",
      "epis: 2968   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 648    lr: 0.0     reward: 11.54\n",
      "epis: 2969   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 464    lr: 0.0     reward: 11.46\n",
      "epis: 2970   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 416    lr: 0.0     reward: 11.39\n",
      "epis: 2971   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 400    lr: 0.0     reward: 11.37\n",
      "epis: 2972   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 402    lr: 0.0     reward: 11.33\n",
      "epis: 2973   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 400    lr: 0.0     reward: 11.28\n",
      "epis: 2974   score: 17.0   mem len: 1000000   epsilon: 0.01    steps: 689    lr: 0.0     reward: 11.32\n",
      "epis: 2975   score: 20.0   mem len: 1000000   epsilon: 0.01    steps: 600    lr: 0.0     reward: 11.41\n",
      "epis: 2976   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 596    lr: 0.0     reward: 11.38\n",
      "epis: 2977   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 485    lr: 0.0     reward: 11.34\n",
      "epis: 2978   score: 15.0   mem len: 1000000   epsilon: 0.01    steps: 712    lr: 0.0     reward: 11.37\n",
      "epis: 2979   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 457    lr: 0.0     reward: 11.38\n",
      "epis: 2980   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 457    lr: 0.0     reward: 11.27\n",
      "epis: 2981   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 457    lr: 0.0     reward: 11.26\n",
      "epis: 2982   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 540    lr: 0.0     reward: 11.16\n",
      "epis: 2983   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 524    lr: 0.0     reward: 11.14\n",
      "epis: 2984   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 477    lr: 0.0     reward: 11.13\n",
      "epis: 2985   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 416    lr: 0.0     reward: 11.09\n",
      "epis: 2986   score: 20.0   mem len: 1000000   epsilon: 0.01    steps: 754    lr: 0.0     reward: 11.17\n",
      "epis: 2987   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 400    lr: 0.0     reward: 11.13\n",
      "epis: 2988   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 490    lr: 0.0     reward: 11.17\n",
      "epis: 2989   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 656    lr: 0.0     reward: 11.23\n",
      "epis: 2990   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 490    lr: 0.0     reward: 11.27\n",
      "epis: 2991   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 438    lr: 0.0     reward: 11.28\n",
      "epis: 2992   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 438    lr: 0.0     reward: 11.27\n",
      "epis: 2993   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 538    lr: 0.0     reward: 11.24\n",
      "epis: 2994   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 591    lr: 0.0     reward: 11.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis: 2995   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 639    lr: 0.0     reward: 11.23\n",
      "epis: 2996   score: 21.0   mem len: 1000000   epsilon: 0.01    steps: 666    lr: 0.0     reward: 11.36\n",
      "epis: 2997   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 637    lr: 0.0     reward: 11.37\n",
      "epis: 2998   score: 9.0   mem len: 1000000   epsilon: 0.01    steps: 457    lr: 0.0     reward: 11.36\n",
      "epis: 2999   score: 8.0   mem len: 1000000   epsilon: 0.01    steps: 436    lr: 0.0     reward: 11.35\n",
      "epis: 3000   score: 12.0   mem len: 1000000   epsilon: 0.01    steps: 595    lr: 0.0     reward: 11.36\n",
      "epis: 3001   score: 13.0   mem len: 1000000   epsilon: 0.01    steps: 628    lr: 0.0     reward: 11.36\n",
      "epis: 3002   score: 10.0   mem len: 1000000   epsilon: 0.01    steps: 479    lr: 0.0     reward: 11.35\n",
      "epis: 3003   score: 11.0   mem len: 1000000   epsilon: 0.01    steps: 515    lr: 0.0     reward: 11.38\n",
      "epis: 3004   score: 16.0   mem len: 1000000   epsilon: 0.01    steps: 640    lr: 0.0     reward: 11.39\n",
      "epis: 3005   score: 14.0   mem len: 1000000   epsilon: 0.01    steps: 535    lr: 0.0     reward: 11.41\n"
     ]
    }
   ],
   "source": [
    "rewards, episodes = [], []\n",
    "best_eval_reward = 0\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "    step = 0\n",
    "    state = env.reset()\n",
    "    next_state = state\n",
    "    life = number_lives\n",
    "\n",
    "    get_init_state(history, state, HISTORY_SIZE)\n",
    "\n",
    "    while not done:\n",
    "        step += 1\n",
    "        frame += 1\n",
    "\n",
    "        # Perform a fire action if ball is no longer on screen to continue onto next life\n",
    "        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "            action = 0\n",
    "        else:\n",
    "            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "        state = next_state\n",
    "        next_state, reward, done, _, info = env.step(action + 1)\n",
    "        \n",
    "        frame_next_state = get_frame(next_state)\n",
    "        history[4, :, :] = frame_next_state\n",
    "        terminal_state = check_live(life, info['lives'])\n",
    "\n",
    "        life = info['lives']\n",
    "        r = reward\n",
    "\n",
    "        # Store the transition in memory \n",
    "        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "        # Start training after random sample generation\n",
    "        if(frame >= train_frame):\n",
    "            agent.train_policy_net(frame)\n",
    "            # Update the target network only for Double DQN only\n",
    "            if (frame % update_target_network_frequency)== 0:\n",
    "                agent.update_target_net()\n",
    "        score += reward\n",
    "        history[:4, :, :] = history[1:, :, :]\n",
    "            \n",
    "        if done:\n",
    "            evaluation_reward.append(score)\n",
    "            rewards.append(np.mean(evaluation_reward))\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, rewards, 'b')\n",
    "            pylab.xlabel('Episodes')\n",
    "            pylab.ylabel('Rewards') \n",
    "            pylab.title('Episodes vs Reward')\n",
    "            pylab.savefig(\"./save_graph/breakout_dqn.png\") # save graph for training visualization\n",
    "            \n",
    "            # every episode, plot the play time\n",
    "            print(\"epis:\", e, \"  score:\", score, \"  mem len:\",\n",
    "                  len(agent.memory), \"  epsilon:\", round(agent.epsilon, 4), \"   steps:\", step,\n",
    "                  \"   lr:\", round(agent.optimizer.param_groups[0]['lr'], 7), \"    reward:\", round(np.mean(evaluation_reward), 2))\n",
    "\n",
    "            # if the mean of scores of last 100 episode is bigger than 5 save model\n",
    "            ### Change this save condition to whatever you prefer ###\n",
    "            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n",
    "                torch.save(agent.policy_net, \"./save_model/breakout_dqn.pth\")\n",
    "                best_eval_reward = np.mean(evaluation_reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Agent Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BE AWARE THIS CODE BELOW MAY CRASH THE KERNEL IF YOU RUN THE SAME CELL TWICE.\n",
    "\n",
    "Please save your model before running this portion of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.policy_net, \"./save_model/breakout_dqn_latest.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import RecordVideo # If importing monitor raises issues, try using `from gym.wrappers import RecordVideo`\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "# Displaying the game live\n",
    "def show_state(env, step=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    ipythondisplay.display(plt.gcf())\n",
    "    \n",
    "# Recording the game and replaying the game afterwards\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else: \n",
    "        print(\"Could not find video\")\n",
    "    \n",
    "\n",
    "def wrap_env(env):\n",
    "    env = RecordVideo(env, './video')\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = Display(visible=0, size=(300, 200))\n",
    "display.start()\n",
    "\n",
    "# Load agent\n",
    "# agent.load_policy_net(\"./save_model/breakout_dqn.pth\")\n",
    "agent.epsilon = 0.0 # Set agent to only exploit the best action\n",
    "\n",
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "env = wrap_env(env)\n",
    "\n",
    "done = False\n",
    "score = 0\n",
    "step = 0\n",
    "state = env.reset()\n",
    "next_state = state\n",
    "life = number_lives\n",
    "history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "get_init_state(history, state)\n",
    "\n",
    "while not done:\n",
    "    \n",
    "    # Render breakout\n",
    "    env.render()\n",
    "#     show_state(env,step) # uncommenting this provides another way to visualize the game\n",
    "\n",
    "    step += 1\n",
    "    frame += 1\n",
    "\n",
    "    # Perform a fire action if ball is no longer on screen\n",
    "    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "        action = 0\n",
    "    else:\n",
    "        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "    state = next_state\n",
    "    \n",
    "    next_state, reward, done, _, info = env.step(action + 1)\n",
    "        \n",
    "    frame_next_state = get_frame(next_state)\n",
    "    history[4, :, :] = frame_next_state\n",
    "    terminal_state = check_live(life, info['ale.lives'])\n",
    "        \n",
    "    life = info['ale.lives']\n",
    "    r = np.clip(reward, -1, 1) \n",
    "    r = reward\n",
    "\n",
    "    # Store the transition in memory \n",
    "    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "    # Start training after random sample generation\n",
    "    score += reward\n",
    "    \n",
    "    history[:4, :, :] = history[1:, :, :]\n",
    "env.close()\n",
    "show_video()\n",
    "display.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
